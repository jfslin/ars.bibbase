% Encoding: windows-1252


@InProceedings{Abbeel2005,
  Title                    = {Discriminative Training of Kalman Filters},
  Author                   = {Abbeel, P. and Coates, A. and Montemerlo, M. and Ng, A. Y. and Thrun, S.},
  Booktitle                = {Proceedings of Robotics: Science and Systems},
  Year                     = {2005},

  Abstract                 = {Kalman filters are a workhorse of robotics and are routinely used in state-estimation problems. However, their performance critically depends on a large number of modeling parameters which can be very difficult to obtain, and are often set via significant manual tweaking and at a great cost of engineering time. In this paper, we propose a method for automatically learning the noise parameters of a Kalman filter. We also demonstrate on a commercial wheeled rover that our Kalman filter’s learned noise covariance parameters—obtained quickly and fully automatically - significantly outperform an earlier, carefully and laboriously hand-designed one.},
  Timestamp                = {2011.11.15}
}

@Article{Admiraal2004,
  Title                    = {Modeling kinematics and dynamics of human arm movements},
  Author                   = {Admiraal, M. A. and Kusters, M. J. M. A. M. and Gielen, S. C. A. M.},
  Journal                  = {Motor Control},
  Year                     = {2004},
  Pages                    = {312--338},
  Volume                   = {8},

  Publisher                = {HUMAN KINETICS},
  Timestamp                = {2015.07.06}
}

@InProceedings{Afonso2007,
  Title                    = {Design and Implementation of a Real-Time Wireless Sensor Network},
  Author                   = {Afonso, J. A. and Silva, H. R. and Oliveira, P. M. and Correia, J. H. and Rocha, L. A.},
  Booktitle                = {Proceedings of the International Conference on Sensor Technologies and Applications},
  Year                     = {2007},
  Pages                    = {496--501},

  Abstract                 = {This paper describes the development of wireless sensor network prototype that gathers biometrical data and posture information from several wearable sensor networks and sends it in real-time to a personal computer where the information is monitored and stored. The wireless sensor network is based on a low power real-time MAC protocol that was designed and implemented in the MICAz platform. This paper also presents some analytical results and several experimental results regarding the behavior of the developed system.},
  Doi                      = {10.1109/SENSORCOMM.2007.4394969},
  Keywords                 = {MAC protocol;MICAz platform;biometrical data;posture information;real-time wireless sensor network;wearable sensor networks;access protocols;biometrics (access control);computerised monitoring;personal area networks;wireless sensor networks;},
  Timestamp                = {2011.12.30}
}

@InProceedings{Aggarwal1997,
  Title                    = {Human Motion Analysis: A Review},
  Author                   = {Aggarwal, J. K. and Cai, Q.},
  Booktitle                = {Proceedings of the IEEE Nonrigid and Articulated Motion Workshop},
  Year                     = {1997},
  Pages                    = {90--102},

  Abstract                 = {Human motion analysis is receiving increasing attention from computer vision researchers. This interest is motivated by a wide spectrum of applications, such as athletic performance analysis, surveillance, man-machine interfaces, content-based image storage and retrieval, and video conferencing. The paper gives an overview of the various tasks involved in motion analysis of the human body. The authors focus on three major areas related to interpreting human motion: 1) motion analysis involving human body parts, 2) tracking of human motion using single or multiple cameras, and 3) recognizing human activities from image sequences. Motion analysis of human body parts involves the low-level segmentation of the human body into segments connected by joints, and recovers the 3D structure of the human body using its 2D projections over a sequence of images. Tracking human motion using a single or multiple camera focuses on higher-level processing, in which moving humans are tracked without identifying specific parts of the body structure. After successfully matching the moving human image from one frame to another in image sequences, understanding the human movements or activities comes naturally, which leads to a discussion of recognizing human activities. The review is illustrated by examples},
  Doi                      = {10.1109/NAMW.1997.609859},
  Keywords                 = {2D projections;3D structure recovery;athletic performance analysis;cameras;computer vision;content-based image retrieval;content-based image storage;higher-level processing;human activity recognition;human body parts;human motion analysis;human motion tracking;image sequences;joints;low-level segmentation;man-machine interfaces;moving human image matching;surveillance;video conferencing;biomechanics;computer vision;image segmentation;image sequences;motion estimation;reviews;surveillance;tracking;user interfaces;},
  Timestamp                = {2011.06.11}
}

@InProceedings{Aghasadeghi2014,
  Title                    = {Inverse optimal control for differentially flat systems with application to locomotion modeling},
  Author                   = {N. Aghasadeghi and T. Bretl},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2014},
  Pages                    = {6018--6025},

  Abstract                 = {Inverse optimal control is the problem of computing a cost function with respect to which observed trajectories of a given dynamic system are optimal. In this paper, we present a new formulation of this problem for the case where the dynamic system is differentially flat. We show that a solution is easy to obtain in this case, in fact reducing to finite-dimensional linear least-squares minimization. We also show how to make this solution robust to model perturbation, sampled data, and measurement noise, as well as provide a recursive implementation for online learning. Finally, we apply our new formulation of inverse optimal control to model human locomotion during stair ascent. Given sparse observations of human walkers, our model predicts joint angle trajectories for novel stair heights that compare well to motion capture data (R2 = 0.97, RMSE = 1.95 degrees). These exemplar trajectories are the basis for an automated method of tuning controller parameters for lower-limb prosthetic devices that extends to locomotion modes other than level ground walking.},
  Doi                      = {10.1109/ICRA.2014.6907746},
  ISSN                     = {1050-4729},
  Keywords                 = {control system synthesis;least squares approximations;legged locomotion;minimisation;motion control;nonlinear control systems;optimal control;prosthetics;trajectory control;controller parameter tuning;cost function;differentially flat systems;exemplar trajectory;finite-dimensional linear least-squares minimization;human locomotion modeling;inverse optimal control;joint angle trajectories;lower-limb prosthetic devices;stair ascent;stair height;Cost function;Equations;Noise measurement;Optimal control;Prosthetics;Trajectory},
  Timestamp                = {2016.07.27}
}

@Article{Agostini2014,
  Title                    = {Segmentation and Classification of Gait Cycles},
  Author                   = {V. Agostini and G. Balestra and M. Knaflitz},
  Journal                  = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  Year                     = {2014},
  Number                   = {5},
  Pages                    = {946--952},
  Volume                   = {22},

  Abstract                 = {Gait abnormalities can be studied by means of instrumented gait analysis. Foot-switches are useful to study the foot-floor contact and for timing the gait phases in many gait disorders, provided that a reliable foot-switch signal may be collected. Considering long walks allows reducing the intra-subject variability, but requires automatic and user-independent methods to analyze a large number of gait cycles. The aim of this work is to describe and validate an algorithm for the segmentation of the foot-switch signal and the classification of the gait cycles. The performance of the algorithm was assessed comparing its results against the manual segmentation and classification performed by a gait analysis expert on the same signal. The performance was found to be equal to 100% for healthy subjects and over 98% for pathological subjects. The algorithm allows determining the atypical cycles (cycles that do not match the standard sequence of gait phases) for many different kinds of pathological gait, since it is not based on pathology-specific templates.},
  Doi                      = {10.1109/TNSRE.2013.2291907},
  ISSN                     = {1534-4320},
  Keywords                 = {diseases;gait analysis;medical disorders;medical signal processing;signal classification;automatic methods;foot-floor contact;foot-switch signal segmentation;gait abnormality;gait cycles;gait disorders;gait phases;intrasubject variability;manual segmentation;pathological gait analysis;pathology-specific templates;performance algorithm;reliable foot-switch signal;signal classification;user-independent methods;Algorithm design and analysis;Classification algorithms;Foot;Manuals;Parkinson's disease;Pathology;Pediatrics;Atypical gait cycles;classification;foot–floor contact;foot-switches;gait analysis;gait event detection;gait phases;signal segmentation;stride-to-stride variability},
  Timestamp                = {2016.03.01}
}

@InProceedings{Ahad2008,
  Title                    = {Human Activity Recognition: Various Paradigms},
  Author                   = {Ahad, M. A. R. and Tan, J. K. and Kim, H. S. and Ishikawa, S.},
  Booktitle                = {Proceedings of the International Conference on Control, Automation and Systems},
  Year                     = {2008},
  Pages                    = {1896--1901},

  Abstract                 = {Action and activity representation and recognition are very demanding research area in computer vision and man-machine interaction. Though plenty of researches have been done in this arena, the field is still immature. Over the last decades, extensive research methodologies have been developed on human activity analysis and recognition for various applications. This paper overviews various recent methods for human activity recognition with analysis. We attempt to sum up the various methods related to human motion representation and recognition. We make an effort to categorize the recent methods from the best in the business, and finally figure out the short-comings and challenges to dig out in future to develop robust action recognition approaches. This work exclusively endeavors to encompass the researches related only to human action recognition mainly from 2001 till-to-date with critical assessment of the methods. We also present our work along with to solve some of the shortcomings. It will widely benefit the researchers to understand and compare the related advancements in this area.},
  Doi                      = {10.1109/ICCAS.2008.4694407},
  Keywords                 = {image motion analysis;image recognition;image representation;action representation;activity representation;computer vision;human activity analysis;human activity recognition;human motion representation;man-machine interaction;Automatic control;Automation;Computer vision;Control engineering;Control systems;Hidden Markov models;Humans;Motion analysis;Skeleton;Training data;DMHI;HMM;Human action/motion recognition;motion representation},
  Timestamp                = {2014.12.18}
}

@InProceedings{Ahsan2011,
  Title                    = {Electromygraphy ({EMG}) signal based hand gesture recognition using artificial neural network ({ANN})},
  Author                   = {Ahsan, M. and Ibrahimy, M. and Khalifa, O.},
  Booktitle                = {ICOM},
  Year                     = {2011},
  Pages                    = {1--6},

  Abstract                 = {Electromyography (EMG) signal is a measure of muscles' electrical activity and usually represented as a function of time, defined in terms of amplitude, frequency and phase. This biosignal can be employed in various applications including diagnoses of neuromuscular diseases, controlling assistive devices like prosthetic/orthotic devices, controlling machines, robots, computer etc. EMG signal based reliable and efficient hand gesture identification can help to develop good human computer interface which in turn will increase the quality of life of the disabled or aged people. The purpose of this paper is to describe the process of detecting different predefined hand gestures (left, right, up and down) using artificial neural network (ANN). ANNs are particularly useful for complex pattern recognition and classification tasks. The capability of learning from examples, the ability to reproduce arbitrary non-linear functions of input, and the highly parallel and regular structure of ANNs make them especially suitable for pattern recognition tasks. The EMG pattern signatures are extracted from the signals for each movement and then ANN utilized to classify the EMG signals based on features. A back-propagation (BP) network with Levenberg-Marquardt training algorithm has been used for the detection of gesture. The conventional and most effective time and time-frequency based features (namely MAV, RMS, VAR, SD, ZC, SSC and WL) have been chosen to train the neural network.},
  Doi                      = {10.1109/ICOM.2011.5937135},
  Keywords                 = {backpropagation;brain-computer interfaces;electromyography;feature extraction;gesture recognition;handicapped aids;medical signal processing;neural nets;EMG pattern signature;Levenberg-Marquardt training algorithm;artificial neural network;backpropagation network;complex pattern recognition;disabled people;electromygraphy signal;hand gesture recognition;human computer interface;muscle electrical activity;time frequency based feature;Artificial neural networks;Electromyography;Feature extraction;Neurons;Noise;Support vector machine classification;Training;Artificial Neural Network;Discrete Wavelet Transform;Electromyography;Levenberg-Marquardt algorithm},
  Owner                    = {jf2lin},
  Review                   = {- 3 subjects, 1 channel. 4 primitives. 
- 6th order Butterworth bandpass at 20-500 Hz + 50 Hz power noise removed with notich filter at 49-51 Hz. Also denoised using wavelet method
- segmentation appears to be manually done
- used discrete wavelet transform

- features: mean abs value, RMS, varaince, std dev, zero crossing, slope sign change, waveform length (has the equations in this paper)

- used ANN to classify},
  Timestamp                = {2015.04.03}
}

@InProceedings{Aksoy2016,
  Title                    = {Enriched Manipulation Action Semantics for Robot Execution of Time Constrained Tasks},
  Author                   = {E. E. Aksoy and Y. Zhou and Mi. W\"{a}chter and T. Asfour},
  Booktitle                = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  Year                     = {2016},
  Note                     = {In press},

  Timestamp                = {2017.01.05}
}

@InProceedings{Albrecht2011,
  Title                    = {Imitating human reaching motions using physically inspired optimization principles},
  Author                   = {S. Albrecht and K. Ram\'{i}rez-Amaro and F. Ruiz-Ugalde and D. Weikersdorfer and M. Leibold and M. Ulbrich and M. Beetz},
  Booktitle                = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  Year                     = {2011},
  Pages                    = {602--607},

  Abstract                 = {We present an end-to-end framework which equips robots with the capability to perform reaching motions in a natural human-like fashion. A markerless, high-accuracy, model- based human motion tracker is used to observe how humans perform everyday activities in real-world scenarios. The obtained trajectories are clustered to represent different types of manipulation and reaching motions occurring in a kitchen environment. Using bilevel optimization methods a combination of physically inspired optimization principles is determined that describes the human motions best. For humanoid robots like the iCub these principles are used to compute reaching motion trajectories which are similar to human behavior and respect the individual requirements of the robotic hardware.},
  Doi                      = {10.1109/Humanoids.2011.6100856},
  ISSN                     = {2164-0572},
  Keywords                 = {humanoid robots;mobile robots;motion control;optimisation;trajectory control;bilevel optimization methods;human like fashion;human motion tracker;human motions;humanoid robots;optimization principles;trajectories clustering;Cost function;Dynamics;Humans;Robot kinematics;Trajectory},
  Timestamp                = {2016.07.26}
}

@Article{Aleotti2006,
  Title                    = {Robust trajectory Learning and Approximation for Robot Programming by Demonstration},
  Author                   = {Aleotti, J. and Caselli, S.},
  Journal                  = {Robotics and Autonomous Systems},
  Year                     = {2006},
  Number                   = {5},
  Pages                    = {409--413},
  Volume                   = {54},

  Publisher                = {Elsevier},
  Timestamp                = {2013.09.23}
}

@Article{Alexander1984,
  Title                    = {The Gaits of Bipedal and Quadrupedal Animals},
  Author                   = {Alexander, R. M.},
  Journal                  = {The International Journal of Robotics Research},
  Year                     = {1984},
  Number                   = {2},
  Pages                    = {49--59},
  Volume                   = {3},

  Abstract                 = {
 The gaits of reptiles, birds, and mammals are reviewed. It is shown that mammals of different sizes tend to move in dy namically similar fashion whenever their Froude numbers u2/gh are equal: here u is speed, g is the acceleration of free fall, and h is the height of the hip joint from the ground. The gaits of turtles and people are examined in detail. The gaits of turtles appear to reduce unwanted displacements (pitch, roll, etc.) to the minimum possible for animals with such slow muscles. The patterns of force exerted in human walking and running minimize the work required of the muscles at each speed. Much of the energy that would otherwise be neededfor running, by people and other large mammals, is saved by tendon elasticity.
 },
  Doi                      = {10.1177/027836498400300205},
  Timestamp                = {2016.07.25}
}

@InProceedings{Ali2008,
  Title                    = {Semi-supervised segmentation for activity recognition with Multiple Eigenspaces},
  Author                   = {Ali, A. and King, R.C. and Guang-Zhong Yang},
  Booktitle                = {Medical Devices and Biosensors, 2008. ISSS-MDBS 2008. 5th International Summer School and Symposium on},
  Year                     = {2008},
  Month                    = {June},
  Pages                    = {314-317},

  Abstract                 = {Body Sensor Networks (BSNs) are increasingly being used in pervasive sensing environments including healthcare, sports, wellbeing, and gaming. Activity segmentation using BSN is challenging and the use of manual annotation is subjective and error prone. In this paper, we investigate a semi-supervised activity segmentation method using a Multiple Eigenspace (MES) technique based on Principal Components Analysis (PCA). Results show that the method can reliably perform activity segmentation and the classification results based on HMMs demonstrate the practical value of the proposed technique.},
  Doi                      = {10.1109/ISSMDBS.2008.4575082},
  Keywords                 = {biomedical equipment;body area networks;health care;medical signal processing;patient monitoring;principal component analysis;sport;activity recognition;body sensor networks;gaming;health care;multiple eigenspace technique;pervasive sensing environments;principal components analysis;semi-supervised activity segmentation;sports;wellbeing;Bayesian methods;Biomedical monitoring;Biosensors;Body sensor networks;Hidden Markov models;Machine learning;Medical services;Microelectromechanical systems;Principal component analysis;Wearable sensors;Body Sensor Networks;HMM;MES;activity recognition;activity segmentation},
  Timestamp                = {2014.12.22}
}

@Article{Allen2006,
  Title                    = {Classification of a Known Sequence of Motions and Postures from Accelerometry Data using Adapted Gaussian Mixture Models},
  Author                   = {Allen, F. and Ambikairajah, E. and Lovell, N. H. and Celler, B. G.},
  Journal                  = {Physiological Measurement},
  Year                     = {2006},
  Number                   = {10},
  Pages                    = {935--951},
  Volume                   = {27},

  Publisher                = {IOP Publishing},
  Timestamp                = {2013.10.06}
}

@Article{Amari1999,
  Title                    = {Improving Support Vector Machine Classifiers by Modifying Kernel Functions},
  Author                   = {Amari, S.-I. and Wu, S.},
  Journal                  = {Neural Networks},
  Year                     = {1999},
  Number                   = {6},
  Pages                    = {783--789},
  Volume                   = {12},

  Abstract                 = {We propose a method of modifying a kernel function to improve the performance of a support vector machine classifier. This is based on
the structure of the Riemannian geometry induced by the kernel function. The idea is to enlarge the spatial resolution around the separating
boundary surface, by a conformal mapping, such that the separability between classes is increased. Examples are given specifically for
modifying Gaussian Radial Basis Function kernels. Simulation results for both artificial and real data show remarkable improvement of
generalization errors, supporting our idea.},
  Publisher                = {Elsevier},
  Review                   = {The practical training process consists of two steps:

In the first step a primary kernel is used to obtain support vectors.
The kernel is then modified conformally in a data dependent
way by using the information of the support vectors. In the
second step the modified kernel is used to obtain the final
classifier.

So uses something called conformal mapping to figure out the surface created by the data, then create a modified SVN kernel from it. doesn't seem like it'll be online though.},
  Timestamp                = {2014.10.24}
}

@InProceedings{Amft2005,
  Title                    = {Detection of Eating and Drinking Arm Gestures using Inertial Body-worn Sensors},
  Author                   = {Amft, O. and Junker, H. and Tr\"{o}ster, G.},
  Booktitle                = {Proceedings of the IEEE International Symposium on Wearable Computers},
  Year                     = {2005},
  Pages                    = {160--163},

  Abstract                 = {We propose a two-stage recognition system for detecting arm gestures related to human meal intake. Information retrieved from such a system can be used for automatic dietary monitoring in the domain of behavioural medicine. We demonstrate that arm gestures can be clustered and detected using inertial sensors. To validate our method, experimental results including 384 gestures from two subjects are presented. Using isolated discrimination based on HMMs an accuracy of 94% can be achieved. When spotting the gestures in continuous movement data, an accuracy of up to 87% is reached.},
  Doi                      = {10.1109/ISWC.2005.17},
  Keywords                 = {arm gestures; automatic dietary monitoring; behavioural medicine; body-worn sensors; hidden Markov model; inertial sensor; information retrieval; biology computing; gesture recognition; hidden Markov models; sensors; motion segmentation},
  Review                   = {Amft \etal \cite{Amft2005} use Keogh's piece-wise regression segmentation method \cite{Keogh2004} for a 4 DOF arm motion identification. Although multiple DOFs were available, they applied the segmentation to a single DOF to reduce the system complexity. If the Euclidean distance between a given segment and a predefined template is sufficiently small, HMM is used for motion identification. This is employed to reject trivial motions. It seems that $Ver_{temporal}$ was employed, but no $t_{error}$ was reported. An $Acc_{precision}$ of 72\% and an $Acc_{recall}$ of 73\% was reported, while examining 384 instances of common eating gestures with 4 motion primitives.},
  Timestamp                = {2011.06.08}
}

@InProceedings{Amstutz2009,
  author    = {Amstutz, R. and Amft, O. and French, B. and Smailagic, A. and Siewiorek, D. and Tr\"{o}ster, G.},
  title     = {Performance Analysis of an {HMM}-Based Gesture Recognition Using a Wristwatch Device},
  booktitle = {Proceedings of the IEEE International Conference on Computational Science},
  year      = {2009},
  volume    = {2},
  pages     = {303--309},
  abstract  = {Interaction with mobile devices that are intended for everyday use is challenging since such systems are continuously optimized towards small outlines. Watches are a particularly critical as display size, processing capabilities, and weight are tightly constraint. This work presents a watch device with an integrated gesture recognition interface. We report the resource-optimized implementation of our algorithmic solution on the watch and demonstrate that the recognition approach is feasible for such constraint devoices. The system is wearable during everyday activities and was evaluated with eight users to complete questionnaires through intuitive one-hand movements. We developed a procedure to spot and classify input gestures from continuous acceleration data acquired by the watch. The recognition procedure is based on hidden Markov models (HMM) and was fully implemented on a watch. The algorithm achieved an average recall of 79% at 93% precision in recognizing the relevant gestures. The watch implementation of continuous gesture spotting showed a delay below 3 ms for feature computation, Viterbi path processing, and final classification at less than 4 KB memory usage.},
  doi       = {10.1109/CSE.2009.58},
  groups    = {IROS2014},
  keywords  = {Viterbi path processing;gesture recognition;gesture spotting;hidden Markov model;mobile device;wristwatch device;gesture recognition;hidden Markov models;mobile handsets;watches;},
  timestamp = {2011.06.15},
}

@Book{Anderson1958,
  Title                    = {An Introduction to Multivariate Statistical Analysis},
  Author                   = {Anderson, T. W.},
  Publisher                = {Wiley New York},
  Year                     = {1958},
  Volume                   = {2},

  Timestamp                = {2013.11.13}
}

@Article{Antfolk2010,
  Title                    = {Using {EMG} for real-time prediction of joint angles to control a prosthetic hand equipped with a sensory feedback system},
  Author                   = {Antfolk, C. and Cipriani, C. and Controzzi, M. and Carrozza, M. and Lundborg, G. and Ros{\'e}n, B. and Sebelius, F.},
  Journal                  = {J Med Biol Eng},
  Year                     = {2010},
  Pages                    = {399--406},
  Volume                   = {30},

  Owner                    = {jf2lin},
  Publisher                = {Institute of Biomedical Engineering, National Cheng Kung University},
  Timestamp                = {2015.05.05}
}

@InProceedings{Aoki2013,
  Title                    = {Segmentation of Human Body Movement Using Inertial Measurement Unit},
  Author                   = {Aoki, T. and Venture, G. and Kuli\'{c}, D.},
  Booktitle                = {Proceedings of the IEEE International Conference on Systems, Man, and Cybernetics},
  Year                     = {2013},
  Pages                    = {1181--1186},

  __markedentry            = {},
  Abstract                 = {This paper proposes an approach for the temporal segmentation of human body movements using IMU (Inertial Measurement Unit). The approach is based on online HMM-based segmentation of continuous time series data. In previous studies, the real-time segmentation of human body movement using joint angles acquired by optical motion capture has been realized, using stochastic motion modeling. The approach is now adapted for angular velocity data. The segmented motions are recognized via HMM models. The segmentation and recognition results of the proposed algorithm are demonstrated with experiments. Auto segmentation of each motion and recognition of motion patterns are verified using angular velocity data obtained by IMU sensors and the Wii remote. The success rate of auto segmentation using the data obtained by Wii remote was more than 80% on average.},
  Doi                      = {10.1109/SMC.2013.205},
  Keywords                 = {angular velocity;hidden Markov models;motion measurement;pattern recognition;sensors;stochastic processes;time series;IMU sensors;Wii remote;angular velocity data;automatic motion segmentation;continuous time series data;inertial measurement unit;joint angles;motion pattern recognition;online HMM-based segmentation;optical motion capture;real-time human body movement segmentation;stochastic motion modeling;temporal segmentation;Angular velocity;Data models;Hidden Markov models;Joints;Motion segmentation;Pattern recognition;Sensors;Arm motion;HMM;Inertial Measurement Unit;Recognition;Segmentation;Wii Remote},
  Review                   = {This is basically an application of Kohlmorgen/Lemm and Dana's TRO paper, but applied to gyro data instead of joint angles},
  Timestamp                = {2015.06.29}
}

@Article{Argall2009,
  author    = {Argall, B. D. and Chernova, S. and Veloso, M. and Browning, B.},
  title     = {A Survey of Robot Learning from Demonstration},
  journal   = {Robotics and Autonomous Systems},
  year      = {2009},
  volume    = {57},
  pages     = {469--483},
  issn      = {0921-8890},
  abstract  = {We present a comprehensive survey of robot Learning from Demonstration (LfD), a technique that develops policies from example state to action mappings. We introduce the LfD design choices in terms of demonstrator, problem space, policy derivation and performance, and contribute the foundations for a structure in which to categorize LfD research. Specifically, we analyze and categorize the multiple ways in which examples are gathered, ranging from teleoperation to imitation, as well as the various techniques for policy derivation, including matching functions, dynamics models and plans. To conclude we discuss LfD limitations and related promising areas for future research.},
  doi       = {10.1016/j.robot.2008.10.024},
  groups    = {IROS2014},
  keywords  = {Learning from demonstration},
  timestamp = {2013.09.19},
}

@InProceedings{Aristidou2008,
  Title                    = {Real-time Estimation of Missing Markers in Human Motion Capture},
  Author                   = {Aristidou, A. and Cameron, J. and Lasenby, J.},
  Booktitle                = {Proceedings of the International Conference on Bioinformatics and Biomedical Engineering},
  Year                     = {2008},
  Pages                    = {1343--1346},

  Timestamp                = {2014.10.29}
}

@InProceedings{Asfour2003,
  Title                    = {Human-like Motion of a Humanoid Robot Arm Based on a Closed-form Solution of the Inverse Kinematics Problem},
  Author                   = {Asfour, T. and Dillmann, R.},
  Booktitle                = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2003},
  Pages                    = {1407--1412},

  Abstract                 = {Humanoid robotics is a new challenging field. To cooperate with human beings, humanoid robots not only have to feature human-like form and structure but, more importantly, they must possess human-like characteristics regarding motion, communication and intelligence. In this paper, we propose an algorithm for solving the inverse kinematics problem associated with the redundant robot arm of the humanoid robot ARMAR. The formulation of the problem is based on the decomposition of the workspace of the arm and on the analytical description of the redundancy of the arm. The solution obtained is characterized by its accuracy and low cost of computation. The algorithm is enhanced in order to generate human-like manipulation motions from object trajectories.},
  Doi                      = {10.1109/IROS.2003.1248841},
  ISSN                     = { },
  Keywords                 = {human-like manipulation motions; humanoid robot ARMAR; humanoid robot arm; inverse kinematics problem; object trajectories; redundant robot arm; motion control; position control; redundant manipulators; ECE780},
  Review                   = {Analytical approach. Difficult, only applied to a single arm

Robot arms should be similar human arm, kinematically, including redundency. The redundency can be used to avoid joint limits, obstacles and singular conifgurations. One can divide redundancy algorithms into global (requires data on entire Cartesian space to generate globally optimal joint angles trajectories) or local (uses instantaneous position of end effect for local optimization in real time) methods. Various hypothetical cost functions has been suggested for human arm, which has been applied to robotics. 

They're using a 7 DOF humanoid, described by DH. Some details about the motion limitation/joint workspace of the joints are described.

- Shoulder workspace is described as an ellipsoid
- The elbow workspace is described as a sphere
- This intersection point is difficult to describe. Lots of math
 - (p3) Describes the elbow vector as a unit vector. 
 - Constrant: position of wrist cannot be further than the physical length of the arm segments

So they're breaking down the complicated IK problem into two segments: Shoulder to elbow, and elbow to end-effector
They take specific elements from the DH matrix (homogenous transformation blah blah) and reverse (ie calculate the arctan) to find specific angles. So even though we can get a closed analytical solution, there is still an infinite solution. Eqn26 describes a set of parameters that imitates human-like arm motion, based on the desired human arm elevation and yaw angle, given wrist position. From this, the robot joint angles can be determined. It's not perfect, but it's pretty good.

Currently, the system ignores dynamics, which is needed to generate realistic velocity.},
  Timestamp                = {2011.01.07}
}

@InProceedings{Ataya2013,
  author    = {Ataya, A. and Jallon, P. and Bianchi, P. and Doron, M.},
  title     = {Improving Activity Recognition using Temporal Coherence},
  booktitle = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  year      = {2013},
  pages     = {4215--4218},
  abstract  = {Assessment of daily physical activity using data from wearable sensors has recently become a prominent research area in the biomedical engineering field and a substantial application for pattern recognition. In this paper, we present an accelerometer-based activity recognition scheme on the basis of a hierarchical structured classifier. A first step consists of distinguishing static activities from dynamic ones in order to extract relevant features for each activity type. Next, a separate classifier is applied to detect more specific activities of the same type. On top of our activity recognition system, we introduce a novel approach to take into account the temporal coherence of activities. Inter-activity transition information is modeled by an oriented graph Markov chain. Confidence measures in activity classes are then evaluated from conventional classifier's outputs and coupled with the graph to reinforce activity estimation. Accurate results and significant improvement of activity detection are obtained when applying our system for the recognition of 9 activities for 48 subjects.},
  groups    = {STAT841},
  keywords  = {Biomedical signal classification, Coherence in biomedical signal processing, Markov models in signal pattern classification, EMBC2013},
  review    = {Previous work found that, in general, discriminative approaches work better than generative approaches in classification tasks. However, discriminative classifiers typically assume the data is time-independent, which is not valid for the type of actions we are considering. Hybrid approaches seems promising. 

A graphical method is used, on 1 hip mounted accelerometer
- Various passive filters used. Median filter to remove noise spikes. LPF and HPF used. HPF to remove accel incline info. LPF to remove movement data. The LPF and the HPF data are used separately. 
- Uses a binary tree to determine if the person is static (posture) or dynamic (activity). This way, the system can be selective at which features they use for different circumstances. But later on it says they uses the Signal Magnitude Area on the HPF, which seems to be the sum of all the magnitudes over all 3 axes, divided by t. If it's above some threshold, there is movement. Otherwise, static. 
 - LPF for static postures. Looks at 14 different features: average mean values, temporal energy, average of L-1 norm of acceleration vector,
sensor’s tilt angle from ground, area under the curve and
mean distances between axis
 - HPF for dynamic activities: 18 different features: median frequencies
of the 3 axis, entropy, mean-cross rate, peak-to-peak
distances, mutual correlation between axis, and spectral
energy
- Uses a 2 second sliding window that advances 1 second at a time

Emphasizes that people do not suddenly shift from one exercise to another, This graph method is suppose to connect one logical activity to another, to reduce spurious classifications (sounds kind of like the HMM transmission mtx). Ah they use a Markov chain. So they figure out the initial and transmission probability by prior training. They then use Viterbi to figure out what the most likely next motion is.


Collected 48 healthy subjects, mean age 36 yo. Motions labelled by medical experts. Performed common everyday activities. Among these activities, 3 are postures or static activities (lying down, slouching/sitting, and standing) and the other 6 activities correspond to motion or dynamic activities (stamping, cycling, running, slow walking, fast walking, and using stairs).

So the different discrim classifers are tested, and its output are used to train the overall HMM or graph method. Does better with graph.


Ataya \etal \cite{Ataya2013} assert that, in general. discriminative approaches work better than generative approaches in classification tasks. However, discriminative classifiers typically assume the data is time-independent, which is not valid for all types of data, in particular that of human movement. A hybrid approach is proposed. The paper employs 1 hip-mounted accelerometer. A decision tree is used to determine if the person is static (holding a given posture) or dynamic (performing an activity). This allows the system to select specific features to analyze the movement. For static postures, the data is low-pass filtered (LPF) to remove noise, then 14 different features to calculated in order to determine the type of motion being performed. These features include average mean, temporal energy, as well as the norm of the acceleration vector. For dynamic movement, the data is high-pass filtered (HPF) to remove sensor DC bias, then 18 different features are calculated. These features include median frequencies, entropy, and mean-crossing rate. It can be noted that people generally do not suddenly shift from one exercise to another, so a pre-generated Markov chain can be used to check that the exercise being suggested by the features are logical. This system was assessed against 48 healthy subjects performing common everyday activities, with 88\% recall accuracy. \todo{come back to this. they use Viterbi to segment}

Ataya \etal \cite{Ataya2013} employed 1 hip-mounted accelerometer and examined numerous features and assessed the classification strengths with several common classifiers, where random forest was shown to perform the best. 9 different postures and activities, such as lying down, slouching, standing, cycling and running, were examined. Data was collected from 48 different subjects, with 55 minutes of accelerometer data each. The outputs of these classifiers are compared against a pre-trained Markov chain and the Viterbi algorithm is used to verify the activity labels proposed by the classifiers. $Ver_{AllPoints}$ verification scheme is used, and $Acc_{Class}$ is 89\%},
  timestamp = {2013.07.29},
}

@InProceedings{Avci2010,
  Title                    = {Activity Recognition Using Inertial Sensing for Healthcare, Wellbeing and Sports Applications: A Survey},
  Author                   = {Avci, Akin and Bosch, Stephan and Marin-Perianu, Mihai and Marin-Perianu, Raluca and Havinga, Paul},
  Booktitle                = {Proceedings of the International Conference on Architecture of Computing Systems},
  Year                     = {2010},
  Month                    = {Feb},
  Pages                    = {1-10},

  Abstract                 = {This paper surveys the current research directions of activity recognition using inertial sensors, with potential application in healthcare, wellbeing and sports. The analysis of related work is organized according to the five main steps involved in the activity recognition process: preprocessing, segmentation, feature extraction, dimensionality reduction and classification. For each step, we present the main techniques utilized, their advantages and drawbacks, performance metrics and usage examples. We also discuss the research challenges, such as user behavior and technical limitations, as well as the remaining open research questions.},
  Keywords                 = {Acceleration;Biomedical monitoring;Feature extraction;Medical services;Monitoring;Sensor systems},
  Timestamp                = {2015.02.06}
}

@Article{Axisa2005,
  Title                    = {Flexible Technologies and Smart Clothing for Citizen Medicine, Home Healthcare, and Disease Prevention},
  Author                   = {Axisa, F. AND Schmitt, P. M. AND Gehin, C. AND Delhomme, G. AND McAdams, E. AND Dittmar, A.},
  Journal                  = {IEEE Transactions on Information Technology in Biomedicine},
  Year                     = {2005},
  Pages                    = {325--337},
  Volume                   = {9},

  Abstract                 = {Improvement of the quality and efficiency of healthcare in medicine, both at home and in hospital, is becoming more and more important for patients and society at large. As many technologies (micro technologies, telecommunication, low-power design, new textiles, and flexible sensors) are now available, new user-friendly devices can be developed to enhance the comfort and security of the patient. As clothes and textiles are in direct contact with about 90% of the skin surface, smart sensors and smart clothes with noninvasive sensors are an attractive solution for home-based and ambulatory health monitoring. Moreover, wearable devices or smart homes with exosensors are also potential solutions. All these systems can provide a safe and comfortable environment for home healthcare, illness prevention, and citizen medicine.},
  Review                   = {Looked at wearable sensors. 
- MARSIAN wearable glove},
  Timestamp                = {2010.06.08}
}

@Conference{Ayoade2011,
  Title                    = {Investigating the Feasibility of a Wireless Motion Capture System to Aid in the Rehabilitation of Total Knee Replacement Patients},
  Author                   = {Ayoade, M. and Morton, L. and Baillie, L.},
  Booktitle                = {Proceedings of the International Conference on Pervasive Computing Technologies for Healthcare},
  Year                     = {2011},
  Pages                    = {404--407},

  Timestamp                = {2012.01.01}
}

@InProceedings{Ayusawa2009,
  Title                    = {Optimal estimation of human body segments dynamics using realtime visual feedback},
  Author                   = {K. Ayusawa and Y. Nakamura and G. Venture},
  Booktitle                = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2009},
  Month                    = {Oct},
  Pages                    = {1627-1632},

  __markedentry            = {},
  Doi                      = {10.1109/IROS.2009.5354711},
  ISSN                     = {2153-0858},
  Keywords                 = {biology computing;biomechanics;data visualisation;graphical user interfaces;real-time systems;graphic interface;human body segments dynamics estimation;identification;motion dynamics;real-time software;realtime visual feedback;visualization;Biological system modeling;Biomechanics;Condition monitoring;Feedback;Humans;Interpolation;Motion estimation;Orthopedic surgery;Robustness;Visualization},
  Timestamp                = {2017.04.24}
}

@InProceedings{Ayusawa2011,
  Title                    = {Real-time Implementation of Physically Consistent Identification of Human Body Segments},
  Author                   = {Ayusawa, K. and Venture, G. and Nakamura, Y.},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2011},
  Pages                    = {6282--6287},

  __markedentry            = {},
  Abstract                 = {The mass parameters of the human body segments are important when studying motion dynamics and the in vivo method to obtain accurate parameters is required in biomechanics studies and for some medical applications. In our previous works, we proposed the method to identify inertial parameters of human body segments in real-time during measurement of motion. However, some obtained parameters are not physically consistent; some masses are negative and inertia tensor matrices are not positive definite. These parameters generate problems in the analysis and the simulation requiring physical consistency. In this paper, we propose the real-time identification method considering physical consistency.},
  Doi                      = {10.1109/ICRA.2011.5979903},
  ISSN                     = {1050-4729},
  Keywords                 = {biomechanics;matrix algebra;motion measurement;biomechanics;human body segment;in vivo method;inertia tensor matrix;inertial parameter identification;mass parameter;medical application;motion dynamics;motion measurement;physically consistent identification;real-time identification method;Joints;Least squares approximation;Mathematical model;Motion segmentation;Optimization;Real time systems},
  Timestamp                = {2015.08.12}
}

@InProceedings{Ayusawa2008,
  Title                    = {Identification of Humanoid Robots Dynamics using Floating-base Motion Dynamics},
  Author                   = {Ayusawa, K. and Venture, G. and Nakamura, Y.},
  Booktitle                = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2008},
  Pages                    = {2854--2859},

  Abstract                 = {When simulating and controlling robot dynamics it is necessary to know the inertial parameters and the joint dynamics accurately. As these parameters are usually not provided by manufacturers, identification is then an essential step in robotics. In addition with the up coming wide-spreading of humanoid robots in the society the identification of humanoid dynamics has became mandatory to insure safety. This paper proposes a method to estimate humanoid robots inertial parameters using a minimal set of sensors. Only joint angles and external forces information are required. Simulations have provided exciting trajectories that are reproduced on a small-size humanoid robot. Experimental results are given.},
  Doi                      = {10.1109/IROS.2008.4650614},
  Keywords                 = {floating-base motion dynamics;humanoid robot dynamics identification;inertial parameter estimation;joint dynamics;humanoid robots;mobile robots;parameter estimation;robot dynamics; ECE780},
  Review                   = {Novality: 
1) Recognizes that the dynamics equations can be separated into a section that depends on torque and one set that doesn't
2) We can take the side that doesn't need torque, since the parameter matrix's rank is the same with or without that component
3) Derive parameters from just joint angles and contact forces

Summary:
"The accuracy of robotic parameters, such as mass, inertia, and moment, is critical to the accuracy of dynamic calculations. Available methods to determine these parameters, such as CAD data, sometimes do not properly account the impact of actuator, sensor and wiring on these parameters. This leads to inaccurate dynamics calculations. By taking the general dynamics equation, one can separate out the equations that are functions of joint torques, and formulate equations of dynamics as functions of joint angles and contact forces. This paper implements these equations and calculate the parameters of a small humanoid robot."

We want inertial parameters and joint dynamics. We usually need torque info to get the full dynamics equations, but humanoids don't typically have torque sensors
 - Can use contact forces and joint angles

They then implements this on a small robot, the magnum, using DH modeling},
  Timestamp                = {2011.01.23}
}

@InCollection{Baby2009,
  author      = {Baby, S. and Kr\"{u}ger, V.},
  title       = {Primitive Based Action Representation and Recognition},
  booktitle   = {Image Analysis},
  publisher   = {Springer Berlin/Heidelberg},
  year        = {2009},
  volume      = {5575},
  series      = {Lecture Notes in Computer Science},
  pages       = {31--40},
  abstract    = {There has been a recent interest in segmenting action sequences into meaningful parts (action primitives) and to model actions on a higher level based on these action primitives. Unlike previous works where action primitives are defined a-priori and search is made for them later, we present a sequential and statistical learning algorithm for automatic detection of the action primitives and the action grammar based on these primitives. We model a set of actions using a single HMM whose structure is learned incrementally as we observe new types. Actions are modeled with sufficient number of Gaussians which would become the states of an HMM for an action. For different actions we find the states that are common in the actions which are then treated as an action primitive.},
  affiliation = {Copenhagen Institute of Technology Computer Vision and Machine Intelligence Lab 2750 Ballerup Denmark},
  groups      = {STAT841, IROS2014},
  keywords    = {Motion Segmentation, Motion Primitive},
  review      = {- Break down actions to smaller primitives
- Want to use HMM to learn primitives
- online!!!

- define two types of actions
 - unique to a single type of action
 - generalizable to all multiple types of actions

Procedure
- defines an array of gaussians to describe data
- defines HMM model to describe this data
 - when new data is available, we calculate the probability that our existing HMM will predict this new data
 - if it's too low, we'll generate another HMM model (ie it is too different to be considered the same motion)
- once all data is in, we apply Viterbi
- The Viterbi paths can be broken down by looking for longest common substrings between each path, and removing common paths until there are no commonality between any paths. The remaining components are termed primitives. 

Primitive Grammer
- generate a graph G that describes the possibility of a given state ci will trasition to state cj
- generate a "stochastic context free grammar" from this graph
- HMM is typically good enough for this, if there's only one type of input observation
 - but this algorithm is designed to handle several types of input


Baby and Kr\"{u}ger \cite{Baby2009} proposed a learning and segmenting technique. To generate a primitive template, a HMM is generated from the observations. When new observation data becomes available, the probability of generating this new observation data, given existing HMMs, is calculated. If this value is low, implying that the newly observed motion is not similar to existing models, a new HMM is generated. The Viterbi algorithm is used to trace through the motions, and common paths are removed from the Viterbi paths via Longest Common Substrings until no common paths exist between any components. Each of these components becomes the primitive library, and denotes segments. This approach was later applied to observe human interactions with objects from the object's point of view \cite{Baby2010}. However, neither articles report segmentation accuracy.

Baby and Kr\"{u}ger \cite{Baby2009} proposed a learning and segmenting technique. Given an existing HMM template $\lambda_m$ and new incoming observation data $x_c$, $P(x_c|\lambda_m)$ is calculated. If this value is low, it indicates that $\lambda_M$ does not adequately model the data described in $x_c$, and thus a second HMM $\lambda_c$ can be trained from the observation. The two models are then merged together. The KL distance between each state for the two models are calculated, and states that are close together are merged. States in $\lambda_c$ that are not close to any of the $\lambda_m$ are added as a new state to $\lambda_m$. Once all the observation data are merged into the HMM, the Viterbi algorithm is used to trace through the model to determine the primitives. This approach was later applied to observe human interactions with objects from the object's point of view \cite{Baby2010}. However, neither articles report segmentation accuracy.},
  timestamp   = {2011.01.19},
}

@InProceedings{Baby2010,
  author    = {Baby, S. and Kr\"{u}ger, V. and Kragic, D.},
  title     = {Unsupervised Learning of Action Primitives},
  booktitle = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  year      = {2010},
  pages     = {554--559},
  abstract  = {Action representation is a key issue in imitation learning for humanoids. With the recent finding of mirror neurons there has been a growing interest in expressing actions as a combination meaningful subparts called primitives. Primitives could be thought of as an alphabet for the human actions. In this paper we observe that human actions and objects can be seen as being intertwined: we can interpret actions from the way the body parts are moving, but as well from how their effect on the involved object. While human movements can look vastly different even under minor changes in location, orientation and scale, the use of the object can provide a strong invariant for the detection of motion primitives. In this paper we propose an unsupervised learning approach for action primitives that makes use of the human movements as well as the object state changes. We group actions according to the changes they make to the object state space. Movements that produce the same state change in the object state space are classified to be instances of the same action primitive. This allows us to define action primitives as sets of movements where the movements of each primitive are connected through the object state change they induce.},
  doi       = {10.1109/ICHR.2010.5686309},
  groups    = {Lit Review 2013-09},
  keywords  = {humanoid robots;learning (artificial intelligence);mobile robots;action primitives;action representation;humanoid robot;imitation learning;object state space;unsupervised learning approach;Buildings;Data models;Hidden Markov models;Humans;Joints;Robots;Trajectory},
  review    = {Want to learn about human actions based on interactions with objects. Want to be able to extract and learn the primitive as a person interact with an object in order to generlize it, instead of only learning the trajectory. purpose is to recognize the motion so that some other tool can perform it 

So they look at the object state space (the POV from the object moving) instead of the user's movement space. The effect of the user's actions on the object is the focus. Segment is based on the movement of the object. Remove all the sections that doesn't involve the object moving.
formulate movement exemplars as a sequence of Gaussians. size of Gaussians is set to a fixed value theta. and they use this to train HMM. merge HMM states based on KL distance if it's small. if two states are very far apart, create new states in the middle. This allows the system to dynamically determine the number of states needed to represent the system. So we create a master HMM with many states, and a primitive is based on a path that is tracable through it. The size of these Gaussians are (hopefully) such that in any repetition of the same motion, each motion would have some points from each of the corresponding Gaussians. Each exemplar is subtracted by its first frame so 

primitive segmentation - once the unified HMM is found, the observations are fed back through the HMM via Viterbi, and each exemplar can be mapped to a sequence of state transitions.

though, it looks like segmentation was mainly performed by isolating the the touch component by looking at the velocity of the object, and the observations has its primitive path determined in the same way as the exemplars, and KL distance is used to identify the motion. no segmentation timing was given.},
  timestamp = {2014.10.04},
}

@Article{Baby2011,
  Title                    = {Primitive-Based Action Representation and Recognition},
  Author                   = {Baby, S. and Kr\"{u}ger, V. and Kragic, D. and Kjellstr\"{o}m, H.},
  Journal                  = {Advanced Robotics},
  Year                     = {2011},
  Pages                    = {871--891},
  Volume                   = {25},

  Abstract                 = {In robotics, there has been a growing interest in expressing actions as a combination of meaningful subparts commonly called motion primitives. Primitives are analogous to words in a language. Similar to words put together according to the rules of language in a sentence, primitives arranged with certain rules make an action. In this paper we investigate modeling and recognition of arm manipulation actions at different levels of complexity using primitives. Primitives are detected automatically in a sequential manner. Here, we assume no prior knowledge on primitives, but look for correlating segments across various sequences. All actions are then modeled within a single hidden Markov models whose structure is learned incrementally as new data is observed. We also generate an action grammar based on these primitives and thus link signals to symbols.},
  Doi                      = {10.1163/016918611X563346},
  Eprint                   = {http://www.tandfonline.com/doi/pdf/10.1163/016918611X563346},
  Review                   = {(looks like the same stuff as Baby2009)},
  Timestamp                = {2013.10.01}
}

@Misc{Bache2013,
  Title                    = {{UCI} Machine Learning Repository},

  Author                   = {K. Bache and M. Lichman},
  Year                     = {2013},

  Institution              = {University of California, Irvine, School of Information and Computer Sciences},
  Timestamp                = {2015.01.26},
  Url                      = {archive.ics.uci.edu/ml}
}

@InProceedings{Balasundaram2013,
  Title                    = {Automated Signal Pattern Detection in {ECG} During Human Ventricular Arrhythmias},
  Author                   = {Balasundaram, K. and Masse, S. and Nair, K. and Umapathy, K.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {Ventricular arrhythmias seriously affects cardiac function. Of these arrhythmias, Ventricular fibrillation is considered as a lethal cardiac condition. Recent studies have reported that ventricular arrhythmias are not completely random and may exhibit regional spatio-temporal organizations. These organizations could be indicative of reoccurring signal patterns and might be embedded within the surface electrocardiograms (ECGs) during ventricular arrhythmias. In this work, we aim to identify such reoccurring ECG signal patterns during ventricular arrhythmias. The detection of such signal patterns and their distribution could be of help in sub-classifying the affected population for better targeted diagnosis and treatment. Our analysis on 14 ECG segments (on average 3.24 minutes per segment) obtained from the MIT-BIH ventricular arrhythmia database identified three reoccurring signal patterns. A wavelet based technique was developed for automating the pattern identification process using ECGs. The proposed method achieved automated detection accuracies of 73.3%, 75.0% and 86.6% for the proposed signal patterns.},
  Keywords                 = {EMBC2013},
  Timestamp                = {2013.07.29}
}

@InCollection{Bao2004,
  Title                    = {Activity Recognition from User-Annotated Acceleration Data},
  Author                   = {Bao, Ling and Intille, StephenS.},
  Booktitle                = {Pervasive Computing},
  Publisher                = {Springer Berlin Heidelberg},
  Year                     = {2004},
  Editor                   = {Ferscha, Alois and Mattern, Friedemann},
  Pages                    = {1-17},
  Series                   = {Lecture Notes in Computer Science},
  Volume                   = {3001},

  Doi                      = {10.1007/978-3-540-24646-6_1},
  ISBN                     = {978-3-540-21835-7},
  Language                 = {English},
  Timestamp                = {2014.12.21},
  Url                      = {http://dx.doi.org/10.1007/978-3-540-24646-6_1}
}

@InProceedings{Barbic2004,
  author    = {Barbi\v{c}, J. and Safonova, A. and Pan, J.-Y. and Faloutsos, C. and Hodgins, J. K. and Pollard, N. S.},
  title     = {Segmenting Motion Capture Data into Distinct Behaviors},
  booktitle = {Proceedings of Graphics Interface},
  year      = {2004},
  pages     = {185--194},
  abstract  = {Much of the motion capture data used in animations, commercials, and video games is carefully segmented into distinct motions either at the time of capture or by hand after the capture session. As we move toward collecting more and longer motion sequences, however, automatic segmentation techniques will become important for processing the results in a reasonable time frame.We have found that straightforward, easy to implement segmentation techniques can be very effective for segmenting motion sequences into distinct behaviors. In this paper, we present three approaches for automatic segmentation. The first two approaches are online, meaning that the algorithm traverses the motion from beginning to end, creating the segmentation as it proceeds. The first assigns a cut when the intrinsic dimensionality of a local model of the motion suddenly increases. The second places a cut when the distribution of poses is observed to change. The third approach is a batch process and segments the sequence where consecutive frames belong to different elements of a Gaussian mixture model. We assess these three methods on fourteen motion sequences and compare the performance of the automatic methods to that of transitions selected manually.},
  acmid     = {1006081},
  groups    = {Lit Review 2013-09},
  isbn      = {1-56881-227-2},
  keywords  = {PCA, human motion, motion capture, motion segmentation},
  location  = {London, Ontario, Canada},
  numpages  = {10},
  review    = {Needs to perform a lot of hand segmentation. Hand segmentation not time efficient. Proposees 3 unsupervised learning algorithms. First two online. Third offline. 

Alg 1 - segment when intrinsic dimensionalty of a window increases. uses PCA
Alg 2 - segment when distrubiton of poses is observed to change. uses probablistic PCA
Alg 3 - segment when GMMs change

Alg 1 looks at the joint angles of the body, and puts a windowed data into SVD/PCA. They look at the error (denote e_i) between x_i (data frame) and x_i' (data frame recon from PCA, to the r^th dim), where r is selected by a ratio (denote E_r) between the 1:r^th singular value (diagonal term in the Sigma term in SVD) and all the terms, when this ratio is above some threshold. First, the system is simplified by taking the top singular values (E_r > 0.9, denoted tau) over 2 seconds of data, and discarding the rest of the dim. Then they calculate the SVD and e_i of each frame. If the motion is not changing, the error will increase steadily, but not significantly. If a new motion occurs, the recon is not able to capture it sufficently, and the error will jump greatly. This jump is detected by thresholding the derivative of the e_i term...if it exceeds 3 stddev from the avg(diff(e_i)), then segment is declared. the 2 seconds is reset there -> though, ti seems like their method would be very sensitive to the thresholds... the 2 seconds, the e_i deriv threshold, etc.

Alg 2 uses the probablistic PCA, which is normal PCA, but also the discarded PCA dims are modeled as noise. The mean and the stddev of the discarded singular values can be calculated and its Gaussian distribution calculated. The first K frames are modeled as PPCA, then calculate the Mahalanobis distance for datapoints beyond K (ie K+1 to K+T, to some T), and incriment K until a segment is found. The Mah distance curve will form valleys and peaks. At the top of the peak, it can be assumed that the area covered in the first K entires are all the same, and thus the subsequent motions to be observed are different. A segment can be declared here. -> however, how well this works depends on how big these windows are set, and the Gaussian. If two subsequent motions have smiliar Gaussians (ie the subj is doing the same motion twice), this may not work out well.

Alg 3 uses GMM. The entire obs is modeled as a GMM, and separate the sequence by looking at which sequence belongs to different Gaussian cluster in the GMM. This assumes that the Gaussians are separable. You would also need to know how many clusters are needed for the GMM. 

Tested this on 14 sequences, with 8000 frames each, consisting of 10 simple motions (walking, running, standing, exercising, sweeping, etc). PPCA preformed the best, at 92% precision and 95% recall. GMM performed the worst. They were not able to determine a single frame of transition since the transition was smooth, so a transiton window was allowed instead of a single frame. Tuning was done on a subset of the database, then applied to the whole thing.




Barbi\v{c} \etal \cite{Barbic2004} calculate the principal component analysis (PCA) transformation matrix from a given frame of data, and only the top \emph{r} dimensions are retained. The subsequent frames are transformed using the original PCA transformation matrix, and the reconstruction error between the original data and the PCA data is calculated. If the underlying motion changed, the PCA-projected data will differ greatly when compared to the original data, and a segment is declared. However, this method is very sensitive to the \emph{r} and error threshold used. This algorithm was tested on 14 different motion sequences, consisting of 10 simple motions such as walking, running, sweeping and standing. Video playback was used to generate ground truth data, but a range of data frames were declared to be a manual segment, instead of a single point, which effectively means that $Ver_{temporalInv}$ was employed, but with a variable $t_{error}$. $Acc_{precision}$ of 79\% and $Acc_{recall}$ of 88\% was reported. \todo{would this more be a distance metric or a variance one? }

Barbi\v{c} \etal \cite{Barbic2004} propose the probabilistic PCA (pPCA), and is used to observe the changes in the pose distribution. The pPCA is PCA, but with the discarded dimensions modeled as Gaussian noise. A \emph{K} amount of data frames are modeled using pPCA, than the Mahalanobis distance between the pPCA frames and frames beyond \emph{K} is calculated. When the Mahalanobis distance forms a local maximum, implying that the discarded terms between the pPCA frames and the subsequent frames have peaked, a segment is declared. This method may not work well if the subsequent motions are all similar in nature. When tested on 14 sequences of 10 different motions performed sequentially, pPCA reported $Acc_{precision}$ of 92\% and $Acc_{recall}$ of 95\% was reported, using $Ver_{temporalInv}$. Ground truth was hand labelled, but the specific mechanism of labelling was unspecified.},
  timestamp = {2011.06.11},
}

@Article{Barshan2011,
  author    = {Barshan, E. and Ghodsi, A. and Azimifar, Z. and Jahromi, M. Z.},
  title     = {Supervised Principal Component Analysis: Visualization, Classification and Regression on Subspaces and Submanifolds},
  journal   = {Pattern Recognition},
  year      = {2011},
  volume    = {44},
  number    = {7},
  pages     = {1357--1371},
  issn      = {0031-3203},
  abstract  = {We propose supervised principal component analysis (supervised PCA), a generalization of \{PCA\} that is uniquely effective for regression and classification problems with high-dimensional input data. It works by estimating a sequence of principal components that have maximal dependence on the response variable. The proposed supervised \{PCA\} is solvable in closed-form, and has a dual formulation that significantly reduces the computational complexity of problems in which the number of predictors greatly exceeds the number of observations (such as \{DNA\} microarray experiments). Furthermore, we show how the algorithm can be kernelized, which makes it applicable to non-linear dimensionality reduction tasks. Experimental results on various visualization, classification and regression problems show significant improvement over other supervised approaches both in accuracy and computational efficiency.},
  doi       = {10.1016/j.patcog.2010.12.015},
  groups    = {STAT841},
  keywords  = {Dimensionality reduction},
  timestamp = {2013.10.29},
}

@Book{Bartel2006,
  Title                    = {Orthopaedic Biomechanics: Mechanics and Design in Musculoskeletal Systems},
  Author                   = {Bartel, D. L. and Davy, D. T. and Keaveny, T. M.},
  Publisher                = {Pearson Prentice Hall},
  Year                     = {2006},

  Timestamp                = {2012.01.10}
}

@InProceedings{Bartneck2009,
  Title                    = {My Robotic Doppelganger - A Critical Look at the Uncanny Valley},
  Author                   = {Bartneck, C. and Kanda, T. and Ishiguro, H. and Hagita, N.},
  Booktitle                = {Proceedings of the IEEE International Symposium on Robot and Human interactive Communication},
  Year                     = {2009},
  Pages                    = {269--276},

  Abstract                 = {The Uncanny Valley hypothesis has been widely used in the areas of computer graphics and Human-Robot Interaction to motivate research and to explain the negative impressions that participants report after exposure to highly realistic characters or robots. Despite its frequent use, empirical proof for the hypothesis remains scarce. This study empirically tested two predictions of the hypothesis: a) highly realistic robots are liked less than real humans and b) the highly realistic robot’s movement decreases its likeability. The results do not support these hypotheses and hence expose a considerable weakness in the Uncanny Valley hypothesis. Anthropomorphism and likeability may be multi-dimensional constructs that cannot be projected into a two-dimensional space. We speculate that the hypothesis ’ popularity may stem from the explanatory escape route it offers to the developers of characters and robots. In any case, the Uncanny Valley hypothesis should no longer be used to hold back the development of highly realistic androids. I.},
  Doi                      = {10.1109/ROMAN.2009.5326351},
  Keywords                 = {Human-robot interaction},
  Review                   = {- Used Ishiguro's android and made it slightly less lifelike so it should sit at the bottom of the Uncanny Valley
- Testing the effects of a moving robot and gauged how well people liked it with a Likert scale
 - Had people talk to Ishiguro and his robot

- Didn't necessarily like the robot less
- Could tell the difference between the human and the robot easily
- More than a single sample is probably needed
- Different cultural uprising may have impact},
  Timestamp                = {2011.02.10}
}

@InProceedings{Bartneck2007,
  Title                    = {Is The Uncanny Valley An Uncanny Cliff?},
  Author                   = {Bartneck, C. and Kanda, T. and Ishiguro, H. and Hagita, N.},
  Booktitle                = {Proceedings of the IEEE International Symposium on Robot and Human interactive Communication},
  Year                     = {2007},
  Pages                    = {368--373},

  Abstract                 = {The uncanny valley theory proposed by Mori in 1970 has been a hot topic in human robot interaction research, in particular since the development of increasingly human-like androids and computer graphics. In this paper we describe an empirical study that attempts to plot Mori's hypothesized curve. In addition, the influence of framing on the users' perception of the stimuli was investigated. Framing had no significant influence on the measurements. The pictures of robots and humans were rated independently of whether the participants knew a particular picture showed a robot or human. Anthropomorphism had a significant influence on the measurements, but not even pictures of real humans were rated as likeable as the pictures of humanoids or toy robots. As a result we suggest the existence of an uncanny cliff model as an alternative to the uncanny valley model. However, this study focused on the perception of pictures of robots and the results, including the suggested model, may be different for the perception of movies of moving robots or the perception of standing right in front of a moving robot.},
  Doi                      = {10.1109/ROMAN.2007.4415111},
  Keywords                 = {anthropomorphism;computer graphics;human robot interaction research;human-like android;toy robots;uncanny valley theory;humanoid robots;man-machine systems;human-robot interaction},
  Review                   = {- Uncanny valley may exist because we look at robots and expect machine-like characteristics, but is weirded out by human-like characteristics -> seems unnatural
- Perhaps uncanny valley only lasts for a short while, when a person first encounters such things, and disappears after a while
- The word used in the original graph better translates to "affection level", not "familiarity", as it is commonly translated into

- Assessed existing tests with Cronbach's alpha (a stats test)
- Showed users a bunch of pictures of humans, robots, CG
 - presented only female pictures because only female androids existed at time of study
 - asked to rank likibility and such 
- the robot was framed as a robot, human or not specified
- sample size: 58, all Japanese university affeliates

- did ANOVA
 - framing had no impact
 - anthropometrism (how humanlike) did
- people like robots toys and humanoids more than people -_-
 - uncanny "cliff" -> might not really want super humanlike robots, since slightly machine like is liked
 - might not like humanlike things really all that much after all

Confounding variables
- Japanese ppl like robots more
- Maybe distracted by beauty bias -> robots made to look pretty
- All pictures were static...},
  Timestamp                = {2011.02.09}
}

@InProceedings{Bashir2004,
  Title                    = {A Hybrid System for Affine-invariant Trajectory Retrieval},
  Author                   = {Bashir, F. and Khokhar, A. and Schonfeld, D.},
  Booktitle                = {Proceedings of the ACM SIGMM International Workshop on Multimedia Information Retrieval},
  Year                     = {2004},
  Pages                    = {235--242},

  Abstract                 = {This paper studies efficient feature spaces for content based indexing and retrieval of object motion trajectories. Taking object trajectory data as input, we first investigate highly compact affine invariant feature spaces based on Fourier Descriptors (FD) and Principal Component Analysis (PCA) techniques. Based on these feature spaces, we then develop a hybrid content based indexing and retrieval system that employs a two-stage matching scheme. The first stage uses affine-invariant Fourier Descriptor (FD) for indexing and retrieval. Top few results from this stage along with the original query are then posed to the second stage of the matching system that employs Principal Component Analysis (PCA) for fast retrieval. We compare our system's performance with two other approaches borrowed from 2-D shape representation in image analysis. For quantitative analysis of the system performance, we report query results in terms of precision-recall metrics},
  Acmid                    = {1026750},
  Doi                      = {10.1145/1026711.1026750},
  ISBN                     = {1-58113-940-3},
  Keywords                 = {affine-invariant trajectory descriptors, curvature scale space, fourier descriptor, motion based indexing and retrieval, principal component analysis},
  Location                 = {New York, NY, USA},
  Numpages                 = {8},
  Timestamp                = {2014.12.11},
  Url                      = {http://doi.acm.org/10.1145/1026711.1026750}
}

@InProceedings{Bashir2005,
  Title                    = {{HMM}-based motion recognition system using segmented {PCA}},
  Author                   = {Bashir, F. and Qu, W. and Khokhar, A. and Schonfeld, D.},
  Booktitle                = {Proceedings of the IEEE International Conference on Image Processings},
  Year                     = {2005},
  Pages                    = {1288--1291},

  __markedentry            = {},
  Abstract                 = {In this paper, we propose a novel technique for model-based recognition of complex object motion trajectories using hidden Markov models (HMM). We build our models on principal component analysis (PCA)-based representation of trajectories after segmenting them into small units of perceptually similar pieces of motions. These subtrajectories are then grouped using spectral clustering to decide on the number of states for each HMM representing a class of object motion. The hidden states of the HMMs are represented by Gaussian mixtures (GM's). This way the HMM topology as well as the parameters are automatically derived from the training data in a fully unsupervised sense. Experiments are performed on two data sets; the ASL data set (from UCI's KDD archives) consists of 207 trajectories depicting signs for three words, from Australian Sign Language (ASL); the HJSL data set contains 108 trajectories from sports videos. Our experiments yield an accuracy of 90+% performing much better than existing approaches.},
  Keywords                 = {Gaussian mixtures; HMM-based motion recognition system; PCA-based representation; hidden Markov models; principal component analysis; segmented PCA; spectral clustering; Gaussian processes; hidden Markov models; image motion analysis; image recognition; image representation; image segmentation; principal component analysis;},
  Review                   = {Bashir \etal \cite{Bashir2005} crops observation data based on zero-crossing occurrences in the curvature data. The Cartesian curvature was used as it is a function of the observation data and its first and second derivative, and therefore incorporates high-level features inherently. The cropped data is reduced using principal component analysis (PCA). Motions that have similar PCA coefficients are clustered together via k-means spectral clustering, and are used to train HMMs. Observation segmentation was performed by reducing the observation data to PCA coefficient vectors, and comparing them to the HMMs to calculate likelihood. However, utilizing PCA coefficients instead of the original data can be difficult, as similar motions may have similar PCA profiles, making them difficult to differentiate. Using curvature to segment may also lead to over-segmentation issues such as those found in the ZVC algorithms. The algorithm was tested on a collection of Australian Sign Language hand motions, as well as high jump motion trajectories, and was shown to outperform similar works. The training components of this algorithm consists of computationally heavy components, the segmentation component may be computationally light enough to be performed on-line, though no explicit timing tests were reported.


Bashir \etal \cite{Bashir2005} crop observation data based on zero-crossing occurrences in the curvature data. The Cartesian curvature was used as it is a function of the observation data and its first and second derivative, and therefore incorporates high-level features inherently. The segmented data is reduced using principal component analysis (PCA). Motions that have similar PCA coefficients are clustered together via k-means spectral clustering, and are used to train HMMs. Observation segmentation was performed by reducing the observation data to PCA coefficient vectors, and comparing them to the HMMs to calculate likelihood. The algorithm was tested on a collection of Australian Sign Language hand motions, as well as high jump motion trajectories. $Ver_{temporal}$ is used, but no $t_{error}$ is provided. Accuracy is given in the form of $1-\frac{FP}{TP+FN}$, and is 90\%.

--- okay...lets try again ---

TRAINING: 
1. LPF and normalized
2. Used GLR on curvature data to crop up the data into subtrajectories
3. These subtraj windows are stacked into a single vector and concatenated to other subjtracj to make a matrix
4. PCA is ran on this matrix and the first m dim are kept
5. Spectral clustering via k-means is used on the PCA coeff, which includes an optimal k estimation technique based on eigenvectors.
6. These clusters form individual classes that are used to train individual HMMs via Baum-Welch. 

CLASS:
1. Classify by HMM.},
  Timestamp                = {2011.04.18}
}

@Article{Baskett1999,
  Title                    = {Shared Responsibility for Ongoing Rehabilitation: A New Approach to Home-based Therapy After Stroke},
  Author                   = {Baskett, J. J. AND Broad, J. B. AND Reekie, G. AND Hocking, C. AND Green, G.},
  Journal                  = {Clinical Rehabilitation},
  Year                     = {1999},
  Pages                    = {23--33},
  Volume                   = {13},

  Abstract                 = {OBJECTIVE: To assess the efficacy of a programme of continuing self-directed exercises for people discharged home after a stroke, supervised once a week by therapists. 
DESIGN: A randomized controlled trial of 100 patients discharged from hospital after a stroke, requiring ongoing therapy. The control group received outpatient or day hospital therapy; the experimental group were visited once a week by an occupational and/or physiotherapist who prescribed a programme of exercises and activities for the following week. Subjects were studied for the first three months after discharge from hospital. 
SETTING: A district general hospital, or the homes of subjects randomized to the experimental group, in New Zealand. 
MAIN OUTCOME MEASURES: (1) Characteristics of the groups, (2) gait speed, limb function, activities of daily living, (3) time with therapists, (4) mood of both subjects and caregivers, (5) anticipation of outcome at entry, compared with perceived outcome at exit. 
RESULTS: No statistical differences between the control and experimental groups in characteristics, or in any outcomes measured, except that the contact time period, but not the number of visits, was longer in the experimental group (p = 0.003). 
CONCLUSIONS: A supervised home-based programme is as effective as outpatient or day hospital therapy.},
  Keywords                 = {Rehabilitation},
  Review                   = {- looked at stroke patients
- people might not feel that they can take ownership of their own rehab, feeling that rehab only happens during their therapy sessions
- this study looks at how useful home-based therapy may be, and if it helps to reduce stress
- Assigned people to a a dedicated rehab clinic, or attended a info session then given home rehab + weekly PT check up -> discussion states that both seems fairly equal in efficientcy
- though, the degree of injuries/disabilities that people get from stroke varies widely
- home rehab is pretty important, since it keeps the person fit(ish) after the PT sessions are over},
  Timestamp                = {2010.09.27}
}

@InProceedings{Batista2011,
  Title                    = {A Complexity-Invariant Distance Measure for Time Series.},
  Author                   = {Batista, G. E. A. P. A. and Wang, X. and Keogh, E. J.},
  Booktitle                = {Proceedings of the SIAM International Conference on Data Mining},
  Year                     = {2011},
  Pages                    = {32--43},
  Volume                   = {31},

  Abstract                 = {The ubiquity of time series data across almost all 
human endeavors has produced a great interest in time 
series data mining in the last decade. While there is a 
plethora of classification algorithms that can be applied 
to time series, all of the current empirical evidence 
suggests that simple nearest neighbor classification is 
exceptionally difficult to beat. The choice of distance 
measure used by the nearest neighbor algorithm 
depends on the invariances required by the domain. 
For example, motion capture data typically requires 
invariance to warping. 
In this work we make a surprising claim. There is an 
invariance that the community has missed, complexity 
invariance. Intuitively, the problem is that in many 
domains the different classes may have different 
complexities, and pairs of complex objects, even those 
which subjectively may seem very similar to the 
human eye, tend to be further apart under current 
distance measures than pairs of simple objects. This 
fact introduces errors in nearest neighbor classification, 
where complex objects are incorrectly assigned to a 
simpler class. 
We introduce the first complexity-invariant distance 
measure for time series, and show that it generally 
produces significant improvements in classification 
accuracy. We further show that this improvement does 
not compromise efficiency, since we can lower bound 
the measure and use a modification of triangular 
inequality, thus making use of most existing indexing 
and data mining algorithms. We evaluate our ideas 
with the largest and most comprehensive set of time 
series classification experiments ever attempted, and 
show that complexity-invariant distance measures can 
produce improvements in accuracy in the vast majority 
of cases},
  Timestamp                = {2013.09.29}
}

@Article{Baziw1972,
  Title                    = {In-Flight Alignment and Calibration of Inertial Measurement Units - Part I: General Formulation},
  Author                   = {Baziw, J. and Leondes, C. T.},
  Journal                  = {IEEE Transactions on Aerospace and Electronic Systems},
  Year                     = {1972},
  Number                   = {4},
  Pages                    = {439--449},
  Volume                   = {AES-8},

  Abstract                 = {This is the first part of a two-part paper which summarizes work pursued by the author in 1966 [1]. The paper describes the application of minimum-variance estimation techniques for in-flight alignment and calibration of an inertial measurement unit (IMU) relative to another IMU and/or some other reference. The first part formulates the problem, and the second part [2] reports numerical results and analyses. The approach taken is to cast the problem into the framework of Kalman-Bucy estimation theory, where velocity and position differences between the two IMU's are used as observations and the IMU parameters of interest become part of the state vector. Instrument quantization and computer roundoff errors are considered as measurement noise, and environmental induced random accelerations are considered as state noise. Typical applications of the technique presented might include the alignment and calibration of IMU's on aircraft carriers, the initialization of rockets or rocket airplanes which are launched from the wing of a mother ship, the alignment and calibration of IMU's which are only used in the latter phases of rocket flight, and for the initialization/updating of SST guidance systems.},
  Doi                      = {10.1109/TAES.1972.309541},
  ISSN                     = {0018-9251},
  Review                   = {- Uses Kalman-Bucy (Continious version of Kalman)
- Talks about drift correction, not sensitivity correction},
  Timestamp                = {2011.07.19}
}

@TechReport{Bellet2014,
  Title                    = {A Survey on Metric Learning for Feature Vectors and Structured Data},
  Author                   = {Bellet, A. and Habrard, A. and Sebban, M.},
  Institution              = {Universit\'{e} de Sait-Etienne},
  Year                     = {2013},

  Abstract                 = {The need for appropriate ways to measure the distance or similarity between data is ubiquitous in machine learning, pattern recognition and data mining, but handcrafting such good metrics for specific problems is generally difficult. This has led to the emergence of metric learning, which aims at automatically learning a metric from data and has attracted a lot of interest in machine learning and related fields for the past ten years. This survey paper proposes a systematic review of the metric learning literature, highlighting the pros and cons of each approach. We pay particular attention to Mahalanobis distance metric learning, a well-studied and successful framework, but additionally present a wide range of methods that have recently emerged as powerful alternatives, including nonlinear metric learning, similarity learning and local metric learning. Recent trends and extensions, such as semi-supervised metric learning, metric learning for histogram data and the derivation of generalization guarantees, are also covered. Finally, this survey addresses metric learning for structured data, in particular edit distance learning, and attempts to give an overview of the remaining challenges in metric learning for the years to come.},
  Bibsource                = {dblp computer science bibliography, http://dblp.org},
  Biburl                   = {http://dblp.uni-trier.de/rec/bib/journals/corr/BelletHS13},
  Timestamp                = {2015.05.13},
  Url                      = {http://arxiv.org/abs/1306.6709}
}

@Article{Bentivegna2004,
  Title                    = {LEARNING TO ACT FROM OBSERVATION AND PRACTICE},
  Author                   = {Bentivegna, DARRIN C. and ATKESON, CHRISTOPHER G. and UDE, ALEŠ and CHENG, GORDON},
  Journal                  = {International Journal of Humanoid Robotics},
  Year                     = {2004},
  Number                   = {04},
  Pages                    = {585-611},
  Volume                   = {01},

  Doi                      = {10.1142/S0219843604000307},
  Eprint                   = {http://www.worldscientific.com/doi/pdf/10.1142/S0219843604000307},
  Timestamp                = {2014.12.22},
  Url                      = {http://www.worldscientific.com/doi/abs/10.1142/S0219843604000307}
}

@Article{Bergmann2011,
  Title                    = {Body-Worn Sensor Design: What Do Patients and Clinicians Want?},
  Author                   = {Bergmann, J. and McGregor, A.},
  Journal                  = {Annals of Biomedical Engineering},
  Year                     = {2011},
  Pages                    = {2299--2312},
  Volume                   = {39},
  Abstract                 = {User preferences need to be taken into account in order to be able to design devices that will gain acceptance both in a clinical and home setting. Sensor systems become redundant if patients or clinicians do not want to work with them. The aim of this systematic review was to determine both patients’ and clinicians’ preferences for non-invasive body-worn sensor systems. A search for relevant articles and conference proceedings was performed using MEDLINE, EMBASE, Current Contents Connect, and EEEI explore. In total 843 papers were identified of which only 11 studies were deemed suitable for inclusion. A range of different clinically relevant user groups were included. The key user preferences were that a body-worn sensor system should be compact, embedded and simple to operate and maintain. It also should not affect daily behavior nor seek to directly replace a health care professional. It became apparent that despite the importance of user preferences, they are rarely considered and as such there is a lack of high-quality studies in this area. We therefore would like to encourage researchers to focus on the implications of user preferences when designing wearable sensor systems.},
  Affiliation              = {Medical Engineering Solutions in Osteoarthritis Centre of Excellence, Charing Cross Hospital, Imperial College London, Room 7L13, London, W6 8RF UK},
  Doi                      = {10.1007/s10439-011-0339-9},
  ISSN                     = {0090-6964},
  Issue                    = {9},
  Keyword                  = {Biomedical and Life Sciences},
  Publisher                = {Springer Netherlands},
  Timestamp                = {2011.08.08}
}

@Article{Bergmann2009,
  author    = {Bergmann, J. H. M. and Mayagoitia, R. E. and Smith, I. C. H.},
  title     = {A Portable System for Collecting Anatomical Joint Angles During Stair Ascent: A Comparison with an Optical Tracking Device},
  journal   = {Dynamic Medicine},
  year      = {2009},
  volume    = {8},
  pages     = {1--7},
  issn      = {1476-5918},
  abstract  = {Assessments of stair climbing in real-life situations using an optical tracking system are lacking, as it is difficult to adapt the system for use in and around full flights of stairs. Alternatively, a portable system that consists of inertial measurement units (IMUs) can be used to collect anatomical joint angles during stair ascent. The purpose of this study was to compare the anatomical joint angles obtained by IMUs to those calculated from position data of an optical tracking. Anatomical joint angles of the thigh, knee and ankle, obtained using IMUs and an optical tracking device, were compared for fourteen healthy subjects. Joint kinematics obtained with the two measurement devices were evaluated by calculating the root mean square error (RMSE) and by calculating a two-tailed Pearson product-moment correlation coefficient (r) between the two signals. Strong mean correlations (range 0.93 to 0.99) were found for the angles between the two measurement devices, as well as an average root mean square error (RMSE) of 4 degrees over all the joint angles, showing that the IMUs are a satisfactory system for measuring anatomical joint angles. These highly portable body-worn inertial sensors can be used by clinicians and researchers alike, to accurately collect data during stair climbing in complex real-life situations.},
  doi       = {10.1186/1476-5918-8-3},
  groups    = {EMBC2013},
  keywords  = {Postural detection, IMU},
  pubmedid  = {19389238},
  review    = {Looked at stair climbing and joint angles with IMUs and compared it to camera-based systems. Placed sensors on pretermined anatomical locations. Use anthropometric values and derived inverse kinematics equations for the lower body. Not too much details on signal processing, however.

They looked at only the knee flex-ext plane, and thus ignored hip rotation. For joint length, they estimated using anthropometrics. Broke it down to Euler angles, implied using gravity (so accel as inclinometers).

Bergmann2009
Cited by: 8
Motion type: Stair climbing
Recovery methodology: IMU (100 Hz), Euler angle, IK. Unclear, but seems to rely on accelerometer only to determine angle. Uses a rotation matrix generated by each IMU (using accel as inclinometer) and Euler angle matrices to get angle to ground. Using knowledge of lower body kinematics, they subtract the reported knee IMU angle from the hip IMU angle to get the knee angle. These data are combined with link length (from anthropometrics) to get EF position, which is used to get RMS to the mocap data
Verification technique: Motion capture, Codamotion
Subject demographics: 14 healthy adults
Error reported: RMS deg, 4 for ankle, 4 for knee, 5 for thigh
Conclusions: Reports that accel IMU is a good alternative to getting position},
  tag       = {Really related works},
  timestamp = {2009.05.01},
}

@InCollection{Berkhin2006,
  Title                    = {A Survey of Clustering Data Mining Techniques},
  Author                   = {Berkhin, P.},
  Booktitle                = {Grouping Multidimensional Data},
  Publisher                = {Springer Berlin / Heidelberg},
  Year                     = {2006},
  Editor                   = {Kogan, Jacob and Nicholas, Charles and Teboulle, Marc},
  Pages                    = {25--71},

  Abstract                 = {Clustering is the division of data into groups of similar objects. In clustering, some details are disregarded in exchange for data simplification. Clustering can be viewed as a data modeling technique that provides for concise summaries of the data. Clustering is therefore related to many disciplines and plays an important role in a broad range of applications. The applications of clustering usually deal with large datasets and data with many attributes. Exploration of such data is a subject of data mining. This survey concentrates on clustering algorithms from a data mining perspective.},
  Affiliation              = {Yahoo! 701 First Avenue Sunnyvale CA 94089 USA},
  Doi                      = {10.1007/3-540-28349-8_2},
  ISBN                     = {978-3-540-28349-2},
  Keyword                  = {Computer Science},
  Keywords                 = {Clustering, survey},
  Review                   = {Clustering survey paper. Looks like a good paper, but not quite what I was looking for...},
  Timestamp                = {2011.04.24}
}

@InProceedings{Berlin2012,
  author    = {Berlin, E. and Van Laerhoven, K.},
  title     = {Detecting Leisure Activities with Dense Motif Discovery},
  booktitle = {Proceedings of the ACM Conference on Ubiquitous Computing},
  year      = {2012},
  pages     = {250--259},
  abstract  = {This paper proposes an activity inference system that has
been designed for deployment in mood disorder research,
which aims at accurately and efficiently recognizing selected
leisure activities in week-long continuous data. The approach
to achieve this relies on an unobtrusive and wrist-worn data
logger, in combination with a custom data mining tool that
performs early data abstraction and dense motif discovery to
collect evidence for activities. After presenting the system
design, a feasibility study on weeks of continuous inertial
data from 6 participants investigates both accuracy and execution speed of each of the abstraction and detection steps.
Results show that our method is able to detect target activities in a large data set with a comparable precision and recall
to more conventional approaches, in approximately the time
it takes to download and visualize the logs from the sensor.},
  acmid     = {2370257},
  doi       = {10.1145/2370216.2370257},
  file      = {Berlin2012 - Detecting leisure activities with dense motif discovery.pdf:Research\\2013-09 SegLitReview\\2013-09\\1 - InJabRef\\Berlin2012 - Detecting leisure activities with dense motif discovery.pdf:PDF},
  groups    = {Lit Review 2013-09, IROS2014},
  isbn      = {978-1-4503-1224-0},
  keywords  = {activity detection, motif discovery, psychiatric monitoring},
  location  = {Pittsburgh, Pennsylvania},
  numpages  = {10},
  review    = {Want to monitor psychiatric patients by examining their movements and mood and using their diaries and activity labels.Actions are recognitized at motifs, and placed into a suffic tree. Motifs are discovred at training time by extracting features found in raw accel peaks and placing them into a suffix tree. Classification done with bag-of-words.

The key factors to consider are: supervised learning (entries from diaries), lon term monitoring (week long, 24/7), small activity set. Want to be able to upload this data once a week so psyciatrists can examine the movement profile of the patient, and can be used to suppliment existing psych scales and questionaires.

They build a watch that logs accel, light and temperature at 100 Hz. Linear segments are created from observation data (piecewise linear approximation - Keogh2001), using online alg that minimizes residual error between linear segment and obs data.They look at the slope and length of each linear segment and assign a symbol to it. The slope of the linear segment was converted to an angle, and binned. Low motion (slope close to 0) were assumed to be stationary data and not considered. The labels were assigned by taking these bins and assign labels based on each two subsequent motions and their angle bin.This creates a long sequence of symbols, which can be searched for a motiff by suffix tree. Bag of words used to find occurances of events once the suffix are labeled.

Berlin and Van Laerhoven \cite{Berlin2012} monitor psychiatric patients using accelerometers on a wrist watch, and applied Keogh's performed piecewise linear approximation \cite{Keogh2004}. The slope of the linear segments are converted to angles and binned, thus discretizing the data. Symbols are assigned to sequential pairs of bins (see Figure \ref{fig:Berlin2012_binAngles}). Motifs are located from these symbols by a suffix tree, and labelled using a bag-of-words classifier. 6 subjects were assessed, over the span of a day. In general, the proposed approach outperforms SVM trained with mean, variance and FFT features.},
  timestamp = {2013.09.29},
}

@Article{Bernardin2005,
  Title                    = {A sensor fusion approach for recognizing continuous human grasping sequences using hidden Markov models},
  Author                   = {Bernardin, K. and Ogawara, K. and Ikeuchi, K. and Dillmann, R.},
  Journal                  = {IEEE Transactions on Robotics},
  Year                     = {2005},
  Pages                    = {47--57},
  Volume                   = {21},

  Abstract                 = {The Programming by Demonstration (PbD) technique aims at teaching a robot to accomplish a task by learning from a human demonstration. In a manipulation context, recognizing the demonstrator's hand gestures, specifically when and how objects are grasped, plays a significant role. Here, a system is presented that uses both hand shape and contact-point information obtained from a data glove and tactile sensors to recognize continuous human-grasp sequences. The sensor fusion, grasp classification, and task segmentation are made by a hidden Markov model recognizer. Twelve different grasp types from a general, task-independent taxonomy are recognized. An accuracy of up to 95% could be achieved for a multiple-user system.},
  Doi                      = {10.1109/TRO.2004.833816},
  ISSN                     = {1552-3098},
  Keywords                 = {control engineering computing;data gloves;hidden Markov models;manipulators;sensor fusion;sequences;tactile sensors;continuous human grasping sequences recognition;data glove;grasp classification;hidden Markov models;programming by demonstration technique;robot system;sensor fusion;tactile sensor;task segmentation;Data gloves;Education;Educational robots;Grasping;Hidden Markov models;Humans;Robot programming;Robot sensing systems;Sensor fusion;Shape},
  Review                   = {- use data glove finger angles and contact information to segment. HMM based.
- want to recgonize everyday life activities, by looking at 14 types of grips.
- want tactile info to prevent false alarm on resting hand (and confusion against grasping motion) based on joint angles or visual sensors
-> hence sensor fusion between the two is used
- each grasp type is trained by a flat HMM
- Viterbi},
  Timestamp                = {2014.12.21}
}

@Article{Berret2011,
  Title                    = {Evidence for Composite Cost Functions in Arm Movement Planning: An Inverse Optimal Control Approach},
  Author                   = {Berret, B. and Chiovetto, E. and Nori, F. and Pozzo, T.},
  Journal                  = {PLoS Computational Biology},
  Year                     = {2011},

  Abstract                 = {An important issue in motor control is understanding the basic principles underlying the accomplishment of natural movements. According to optimal control theory, the problem can be stated in these terms: what cost function do we optimize to coordinate the many more degrees of freedom than necessary to fulfill a specific motor goal? This question has not received a final answer yet, since what is optimized partly depends on the requirements of the task. Many cost functions were proposed in the past, and most of them were found to be in agreement with experimental data. Therefore, the actual principles on which the brain relies to achieve a certain motor behavior are still unclear. Existing results might suggest that movements are not the results of the minimization of single but rather of composite cost functions. In order to better clarify this last point, we consider an innovative experimental paradigm characterized by arm reaching with target redundancy. Within this framework, we make use of an inverse optimal control technique to automatically infer the (combination of) optimality criteria that best fit the experimental data. Results show that the subjects exhibited a consistent behavior during each experimental condition, even though the target point was not prescribed in advance. Inverse and direct optimal control together reveal that the average arm trajectories were best replicated when optimizing the combination of two cost functions, nominally a mix between the absolute work of torques and the integrated squared joint acceleration. Our results thus support the cost combination hypothesis and demonstrate that the recorded movements were closely linked to the combination of two complementary functions related to mechanical energy expenditure and joint-level smoothness.},
  Owner                    = {jf2lin},
  Review                   = {Reaching for a horizontal bar},
  Timestamp                = {2015.07.27}
}

@Misc{BertecForcePlate,
  Title                    = {Bertec Force Plates},

  Author                   = {{Bertec Corporation}},
  HowPublished             = {www.bertec.com},
  Year                     = {1987},

  Owner                    = {jf2lin},
  Timestamp                = {2016.12.06}
}

@Article{Betts1998,
  author    = {J. T. Betts},
  title     = {Survey of Numerical Methods for Trajectory Optimization},
  journal   = {Journal of Guidance, Control, and Dynamics},
  year      = {1998},
  volume    = {21},
  number    = {2},
  pages     = {193--207},
  owner     = {jf2lin},
  timestamp = {2017.03.01},
  url       = {http://appliedmathematicalanalysis.com/downloads/surveyppr.pdf},
}

@InCollection{Billard2008,
  Title                    = {Robot Programming by Demonstration},
  Author                   = {Billard, A and Calinon, S. and Dillmann, R. and Schaal, S.},
  Booktitle                = {Springer Handbook of Robotics},
  Publisher                = {Springer Berlin / Heidelberg},
  Year                     = {2008},
  Pages                    = {1371--1394},

  Doi                      = {10.1007/978-3-540-30301-5_60},
  ISBN                     = {978-3-540-23957-4},
  Timestamp                = {2013.09.19}
}

@Article{Billard2006,
  Title                    = {Discriminative and Adaptive Imitation in Uni-manual and Bi-manual Tasks},
  Author                   = {Billard, A. AND Calinon, S. AND Guenter, F.},
  Journal                  = {Robotics and Autonomous Systems},
  Year                     = {2006},
  Number                   = {5},
  Pages                    = {370--384},
  Volume                   = {54},

  Abstract                 = {The Social Mechanisms of Robot Programming from Demonstration

This paper addresses the problems of what to imitate and how to imitate in simple uni and bi-manual manipulatory tasks. To solve the what to imitate issue, we use a probabilistic method, based on Hidden Markov Models (HMM), to extract the relative importance of reproducing either the gesture or the specific hand path in a given task. This allows us to determine a metric of imitation performance. To solve the how to imitate issue, we compute the trajectory that optimizes the metric given the constraints of the robot's body. We validate the methods using a series of experiments where a human demonstrator uses kinesthetics in order to teach a robot how to manipulate simple objects.},
  Doi                      = {DOI: 10.1016/j.robot.2006.01.007},
  ISSN                     = {0921-8890},
  Keywords                 = {Discriminative imitation, Learning, Humanoid robots, Kinesthetic teaching, HMM, Lagrange optimization, motion primitive, ECE780},
  Timestamp                = {2011.02.16}
}

@InCollection{Billard2012,
  Title                    = {Imitation Learning in Robots},
  Author                   = {Billard, A. and Grollman, D. H.},
  Booktitle                = {Encyclopedia of the Sciences of Learning},
  Publisher                = {Springer},
  Year                     = {2012},
  Pages                    = {1494--1496},

  Timestamp                = {2013.09.19}
}

@Book{Bishop2010_PatternRec,
  Title                    = {Pattern Recognition and Machine Learning, 2nd Ed},
  Author                   = {Bishop, C. M.},
  Publisher                = {Springer},
  Year                     = {2010},

  Timestamp                = {2014.11.11}
}

@Article{Blake2007,
  Title                    = {Perception of Human Motion},
  Author                   = {Blake, R. AND Shiffrar, M.},
  Journal                  = {Annual Review of Psychology},
  Year                     = {2007},
  Pages                    = {47--73},
  Volume                   = {58},

  Abstract                 = {Humans, being highly social creatures, rely heavily on the ability to perceive what others are doing and to infer from gestures and expressions what others may be intending to do. These perceptual skills are easily mastered by most, but not all, people, in large part because human action readily communicates intentions and feelings. In recent years, remarkable advances have been made in our understanding of the visual, motoric, and affective influences on perception of human action, as well as in the elucidation of the neural concomitants of perception of human action. This article reviews those advances and, where possible, draws links among those findings.},
  Doi                      = {10.1146/annurev.psych.57.102904.190152},
  Review                   = {Can we figure out who someone is just by looking at their kinematic patterns? Yes, you can. Using motion capture (or 'point light' techniques), where we strip away all information except the kinematics, observers usually have no problem figuring out what the actor is trying to do. For example, putting reflective markers on joints instead of on non-moving parts of the body are more effective for drivers to recognize. Detection coordinates are egocentric (wrt to the user)...they have a much harder time detecting an upside down set of joints than a right-side up one. Not just humans though; they can tell the type of animal, if all they had was animal kinematic data.},
  Timestamp                = {2010.05.07}
}

@InProceedings{Blanke2010,
  Title                    = {Remember and transfer what you have learned - recognizing composite activities based on activity spotting},
  Author                   = {Blanke, U. and Schiele, B.},
  Booktitle                = {Wearable Computers (ISWC), 2010 International Symposium on},
  Year                     = {2010},
  Month                    = {Oct},
  Pages                    = {1-8},

  Abstract                 = {Activity recognition approaches have shown to enable good performance for a wide variety of applications. Most approaches rely on machine learning techniques requiring significant amounts of training data for each application. Consequently they have to be retrained for each new application limiting the real-world applicability of today's activity recognition methods. This paper explores the possibility to transfer learned knowledge from one application to others thereby significantly reducing the required training data for new applications. To achieve this transferability the paper proposes a new layered activity recognition approach that lends itself to transfer knowledge across applications. Besides allowing to transfer knowledge across applications this layered approach also shows improved recognition performance both of composite activities as well as of activity events.},
  Doi                      = {10.1109/ISWC.2010.5665869},
  ISSN                     = {1550-4816},
  Keywords                 = {image motion analysis;image recognition;learning (artificial intelligence);activity recognition approach;activity spotting;machine learning technique;training data;Data models;Hidden Markov models;Joints;Knowledge transfer;Mirrors;Training;Training data},
  Timestamp                = {2014.12.22}
}

@InProceedings{Bonato2009,
  author    = {Bonato, P.},
  title     = {Clinical Applications of Wearable Technology},
  booktitle = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  year      = {2009},
  pages     = {6580--6583},
  abstract  = {An important factor contributing to the process involved in choosing a rehabilitation intervention is the assessment of its impact on the real life of patients. Therapists and physicians have to infer the effectiveness of rehabilitation approaches from observations performed in the clinical setting and from patients' feedback. Recent advances in wearable technology have provided means to supplement the information gathered using tools based on patient's direct observation as well as interviews and questionnaires. A new generation of wearable sensors and systems has recently become available thus providing clinical personnel with a ldquowindow of observationrdquo in the home and community settings. These tools allow one to capture patients' activity level and exercise compliance, facilitate titration of medications in chronic patients, and provide means to assess the ability of patients to perform specific motor activities. In this paper, we review recent advances in the field of wearable technology and provide examples of application of this technology in rehabilitation.},
  doi       = {10.1109/IEMBS.2009.5333997},
  file      = {Bonato2009 - WearableTechApplications.PDF:Research\\Motion Detection and Wearables\\Bonato2009 - WearableTechApplications.PDF:PDF},
  issn      = {1557-170X},
  keywords  = {clinical personnel;exercise compliance;patient activity level;patient feedback;rehabilitation intervention;wearable sensors;wearable technology;biomedical equipment;body area networks;health care;patient rehabilitation;telemedicine;wearable computers;wireless sensor networks;},
  review    = {- Sensors embedded into shirts didn't seem that practical.
- A bit preamble of how wireless sensors are good, since can do home rehab with them
- looked at COPD, Parkinsons and Stroke
- noted low battery life},
  timestamp = {2010.09.28},
}

@Article{Bonato2005,
  Title                    = {Advances in Wearable Technology and Applications in Physical Medicine and Rehabilitation},
  Author                   = {Bonato, P.},
  Journal                  = {Journal of Neuroengineering and Rehabilitation},
  Year                     = {2005},
  Pages                    = {2},
  Volume                   = {2},

  Abstract                 = {The development of miniature sensors that can be unobtrusively attached to the body or can be part of clothing items, such as sensing elements embedded in the fabric of garments, have opened countless possibilities of monitoring patients in the field over extended periods of time. This is of particular relevance to the practice of physical medicine and rehabilitation. Wearable technology addresses a major question in the management of patients undergoing rehabilitation, i.e. have clinical interventions a significant impact on the real life of patients? Wearable technology allows clinicians to gather data where it matters the most to answer this question, i.e. the home and community settings. Direct observations concerning the impact of clinical interventions on mobility, level of independence, and quality of life can be performed by means of wearable systems. Researchers have focused on three main areas of work to develop tools of clinical interest: 1)the design and implementation of sensors that are minimally obtrusive and reliably record movement or physiological signals, 2)the development of systems that unobtrusively gather data from multiple wearable sensors and deliver this information to clinicians in the way that is most appropriate for each application, and 3)the design and implementation of algorithms to extract clinically relevant information from data recorded using wearable technology. Journal of NeuroEngineering and Rehabilitation has devoted a series of articles to this topic with the objective of offering a description of the state of the art in this research field and pointing to emerging applications that are relevant to the clinical practice in physical medicine and rehabilitation.},
  Keywords                 = {wireless sensors},
  Review                   = {Good summory paper on sensor technology...there's a followup apparently, in 2009.},
  Timestamp                = {2010.09.28}
}

@InProceedings{Bonnet2016,
  Title                    = {A constrained Extended Kalman Filter for dynamically consistent inverse kinematics and inertial parameters identification},
  Author                   = {V. Bonnet and G. Daune and V. Joukov and R. Dumas and P. Fraisse and D. Kuli/'{c} and A. Seilles and S. Andary and G. Venture},
  Booktitle                = {Proceedings of IEEE RAS/EMBS International Conference on Biomedical Robotics and Biomechatronics},
  Year                     = {2016},
  Pages                    = {944--949},

  Doi                      = {10.1109/BIOROB.2016.7523749},
  Keywords                 = {Kalman filters;biomechanics;kinematics;constrained Extended Kalman Filter;dynamically consistent inverse kinematics;dynamometric data;human joint accelerations;human joint angles;human joint torques;human joint velocities;inertial parameters identification;optimal tuning procedure;skin markers;stereophotogrammetric data;Acceleration;Kalman filters;Kinematics;Mathematical model;Real-time systems;Robots;Trajectory},
  Timestamp                = {2016.09.02}
}

@Article{Bonnet2013,
  Title                    = {Use of weighted Fourier linear combiner filters to estimate lower trunk 3D orientation from gyroscope sensors data},
  Author                   = {Bonnet, V.
and Mazz{\`a}, C.
and McCamley, J.
and Cappozzo, A.},
  Journal                  = {Journal of NeuroEngineering and Rehabilitation},
  Year                     = {2013},
  Number                   = {1},
  Pages                    = {29:1--7},
  Volume                   = {10},

  __markedentry            = {},
  Abstract                 = {The present study aimed at devising a data processing procedure that provides an optimal estimation of the 3-D instantaneous orientation of an inertial measurement unit (IMU). This result is usually obtained by fusing the data measured with accelerometers, gyroscopes, and magnetometers. Nevertheless, issues related to compensation of integration errors and high sensitivity of these devices to magnetic disturbances call for different solutions. In this study, a method based on the use of gyroscope data only is presented, which uses a Weighted Fourier Linear Combiner adaptive filter to perform a drift-free estimate of the 3D orientation of an IMU located on the lower trunk during walking.},
  Doi                      = {10.1186/1743-0003-10-29},
  ISSN                     = {1743-0003},
  Owner                    = {jf2lin},
  Timestamp                = {2017.04.24},
  Url                      = {http://dx.doi.org/10.1186/1743-0003-10-29}
}

@Article{Bonnet2012,
  Title                    = {A least-squares identification algorithm for estimating squat exercise mechanics using a single inertial measurement unit},
  Author                   = {Bonnet, V. and Mazza, C. and Fraisse, P. and Cappozzo, A.},
  Journal                  = {Journal of Biomechanics},
  Year                     = {2012},
  Number                   = {8},
  Pages                    = {1472--1477},
  Volume                   = {45},

  Doi                      = {10.1016/j.jbiomech.2012.02.014},
  Publisher                = {Elsevier},
  Timestamp                = {2016.09.08}
}

@Article{Bonnet2015,
  Title                    = {Fast Determination of the Planar Body Segment Inertial Parameters Using Affordable Sensors},
  Author                   = {Bonnet, V. and Venture, G.},
  Journal                  = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  Year                     = {2015},
  Pages                    = {628--635},
  Volume                   = {23},

  Abstract                 = {This study aimed at developing and evaluating a new method for the fast and reliable identification of body segment inertial parameters with a planar model using affordable sensors. A Kinect sensor, with a new marker-based tracking system, and a Wii balance board were used as an affordable and portable motion capture system. A set of optimal exciting motions was used in a biofeedback interface to identify the body segment parameters. The method was validated with 12 subjects performing various standardized motions. The same dynamometric quantities estimated both with the proposed system and, as a reference, with a laboratory grade force-plate were compared. The results showed that the proposed method could successfully estimate the resultant moment and the vertical ground reaction force (rms errors less than 8 Nm and 12 N, respectively). Finally, when local segment values were artificially varied, the proposed method was able to detect and estimate the additional masses accurately and with an error of less than 0.5 Kg, contrary to values generated with commonly used anthropometric tables.},
  Doi                      = {10.1109/TNSRE.2015.2405087},
  ISSN                     = {1534-4320},
  Keywords                 = {Joints;Kinetic theory;Mathematical model;Robots;Sensors;Tracking;Visualization;Body segment inertial parameters;identification;inverse dynamics},
  Review                   = {3 step system:
- set up the forward model (standard robotics equn -> regressor matrix)
- set up optimal exciting motion by setting a given joint to excite, and they generate the movements of the other joints via Fourier series (so there's a way to generate the joints)
- optimize, to minimize the error between the forward model and the measured force and coupling matrix (eqn 12)},
  Timestamp                = {2015.07.09}
}

@Article{Boonstra2006,
  author    = {Boonstra, M. C. and van der Slikke, R. M. A. and Keijsers, N. L. W. and van Lummel, R. C. and de Waal Malefijt, M. C. and Verdonschot, N.},
  title     = {The Accuracy of Measuring the Kinematics of Rising from a Chair with Accelerometers and Gyroscopes},
  journal   = {Journal of Biomechanics},
  year      = {2006},
  volume    = {39},
  pages     = {354--358},
  abstract  = {The purpose of this study was to assess the accuracy of measuring angle and angular velocity of the upper body and upper leg during rising from a chair with accelerometers, using low-pass filtering of the accelerometer signal. Also, the improvement in accuracy of the measurement with additional use of high-pass filtered gyroscopes was assessed.

Two uni-axial accelerometers and one gyroscope (DynaPort) per segment were used to measure angles and angular velocities of upper body and upper leg. Calculated angles and angular velocities were compared to a high-quality optical motion analysis system (Optotrak), using root mean squared error (RMS) and correlation coefficient () as parameters.

The results for the sensors showed that two uni-axial accelerometers give a reasonable accurate measurement of the kinematics of rising from a chair (RMS=2.9, 3.5, and 2.6° for angle and RMS=9.4, 18.4, and 11.5°/s for angular velocity for thorax, pelvis, and upper leg, respectively). Additional use of gyroscopes improved the accuracy significantly (RMS=0.8, 1.1, and 1.7° for angle and RMS=2.6, 4.0 and 4.9°/s for angular velocity for thorax, pelvis and upper leg, respectively).

The low-pass Butterworth filter had optimal cut-off frequencies of 1.05, 1.3, and 1.05 for thorax, pelvis, and upper leg, respectively. For the combined signal, the optimal cut-off frequencies were 0.18, 0.2, and 0,38 for thorax, pelvis and upper leg, respectively. The filters showed no subject specificity.

This study provides an accurate, inexpensive and simple method to measure the kinematics of movements similar to rising from a chair.},
  groups    = {EMBC2013},
  keywords  = {Accelerometers, Gyroscopes, Kinematics, Rising from a chair, Postural detection, IMU},
  review    = {Used accelerometers and gyroscopes to detect standing angle. High accuracy claimed.

Intergrated gyro. High passed it. Low passed accelerometer.

Boonsta2006
Cited by: 58
Motion type: Sit to stand
Recovery methodology: 2-axis accel, 1 gyro (32 Hz). Joint angle was calculated from both sensor types, and combined (did not specify how they 'combined' it). Trig for accel. Integration for gyro. Calculated angle to ground of hip, knee and ankle. 
Verification technique: Optotrak
Subject demographics: 5 healthy adults
Error reported: RMS deg, 0.8 for chest, 1.1 for hip, 1.7 for upper leg},
  tag       = {Really related works},
  timestamp = {2009.09.11},
}

@Article{Boots2011,
  Title                    = {Closing the Learning-planning Loop with Predictive State Representations},
  Author                   = {Boots, B. and Siddiqi, S. M. and Gordon, G. J.},
  Journal                  = {International Journal of Robotics Research},
  Year                     = {2011},
  Pages                    = {954--966},
  Volume                   = {30},

  Abstract                 = {A central problem in artificial intelligence is to choose actions to maximize reward in a partially observable, uncertain environment. To do so, we must learn an accurate environment model, and then plan to maximize reward. Unfortunately, learning algorithms often recover a model that is too inaccurate to support planning or too large and complex for planning to succeed; or they require excessive prior domain knowledge or fail to provide guarantees such as statistical consistency. To address this gap, we propose a novel algorithm which provably learns a compact, accurate model directly from sequences of action-observation pairs. We then evaluate the learner by closing the loop from observations to actions. In more detail, we present a spectral algorithm for learning a predictive state representation (PSR), and evaluate it in a simulated, vision-based mobile robot planning task, showing that the learned PSR captures the essential features of the environment and enables successful and efficient planning. Our algorithm has several benefits which have not appeared together in any previous PSR learner: it is computationally efficient and statistically consistent; it handles highdimensional observations and long time horizons; and, our close-the-loop experiments provide an end-to-end practical test.},
  Doi                      = {10.1177/0278364911404092},
  Eprint                   = {http://ijr.sagepub.com/content/early/2011/04/13/0278364911404092.full.pdf+html},
  Timestamp                = {2011.06.24},
  Url                      = {http://ijr.sagepub.com/content/early/2011/04/13/0278364911404092.abstract}
}

@InProceedings{Boreczky1998,
  Title                    = {A Hidden {Markov} Model Framework for Video Segmentation using Audio and Image Features},
  Author                   = {Boreczky, J. S. and Wilcox, L. D.},
  Booktitle                = {Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing},
  Year                     = {1998},
  Pages                    = {3741--3744},
  Volume                   = {6},

  Abstract                 = {This paper describes a technique for segmenting video using hidden Markov models (HMM). Video is segmented into regions defined by shots, shot boundaries, and camera movement within shots. Features for segmentation include an image-based distance between adjacent video frames, an audio distance based on the acoustic difference in intervals just before and after the frames, and an estimate of motion between the two frames. Typical video segmentation algorithms classify shot boundaries by computing an image-based distance between adjacent frames and comparing this distance to fixed, manually determined thresholds. Motion and audio information is used separately. In contrast, our segmentation technique allows features to be combined within the HMM framework. Further, thresholds are not required since automatically trained HMMs take their place. This algorithm has been tested on a video data base, and has been shown to improve the accuracy of video segmentation over standard threshold-based systems},
  Doi                      = {10.1109/ICASSP.1998.679697},
  ISSN                     = {1520-6149},
  Keywords                 = {feature extraction;hidden Markov models;image segmentation;image sequences;motion estimation;video signal processing;acoustic difference;adjacent video frames;audio distance;audio features;automatically trained HMM;camera movement;hidden Markov model;image features;image-based distance;motion estimation;shot boundaries classification;shots;threshold-based systems;video data base;video segmentation algorithms;Cameras;Hidden Markov models;Histograms;Image segmentation;Indexing;Laboratories;Motion detection;Motion estimation;System testing;TV},
  Review                   = {Want to segment video clips. Typically use histogram thresholding, or edge changes, etc. Audio and motion features can be incorporated to improve segmentation quality. Can use silence, speech (or change in speech person), music or noise detection to verify shot boundaries hypothesized by image-based features. 

This work proposes an algorithm that segment based on image, audio and motion differences, within an HMM.},
  Timestamp                = {2013.08.09}
}

@Misc{Borman2009,
  Title                    = {The Expectation Maximization Algorithm - A Short Tutorial},

  Author                   = {Borman, S.},
  HowPublished             = {seanborman.com/publications/EM\_algorithm.pdf},
  Year                     = {2009},

  Timestamp                = {2014.03.14}
}

@InProceedings{Borras2015,
  Title                    = {A Whole-Body Pose Taxonomy for Loco-Manipulation Tasks},
  Author                   = {J. Borr\'{a}s and T. Asfour},
  Booktitle                = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2015},
  Pages                    = {1578--1585},

  Timestamp                = {2017.01.05}
}

@InProceedings{Boyd2009,
  author    = {Boyd, J. and Sundaram, H.},
  title     = {A Framework to Detect and Classify Activity Transitions in Low-power Applications},
  booktitle = {Proceedings of the IEEE International Conference on Multimedia and Expo},
  year      = {2009},
  pages     = {1712--1715},
  abstract  = {Minimizing the number of computations a low-power device makes is important to achieve long battery life. In this paper we present a framework for a low-power device to minimize the number of calculations needed to detect and classify simple activities of daily living such as sitting, standing, walking, reaching, and eating. This technique uses wavelet analysis as part of the feature set extracted from accelerometer data. A log-likelihood ratio test and Hidden Markov Models (HMM) are used to detect transitions and classify different activities. A trade-off is made between power and accuracy.},
  acmid     = {1699355},
  groups    = {Lit Review 2013-09, STAT841},
  isbn      = {978-1-4244-4290-4},
  keywords  = {HMM, gesture recognition, inertial sensors, low power, wavelet analysis, motion segmentation},
  location  = {New York, NY, USA},
  numpages  = {4},
  review    = {- use some wierd gaussian/probability test to figure out segment transistion points
- uses HMM to classify motion

Has two overall states: sleep and active. Looked at sitting, standing, walking, reaching and eating. They are "different enough that they can be distinguished from each other"

A window is slid over the observation and wavelet analysis is performed over the window. The wavelet coefficients are used as feature vectors for HMM classification. Tihs window is divided in half. The left and right window also has the wavelet analysis completed and LL calculated.


A window to the left and right of the sliding window also has its wavelet analysis completed, and LL calculated. The LL of the full window is ratioed against the sum of the two small windowed LLs.

Tested system on a wrist mounted 9DOF IMU while doing some sitting/standing tasks. Looked at only 3DOF accel. Used a 4 sec window lead. Might be hard to use online. 17/18 classifications correct. Average segmentation error of 0.5s to 1.1s, depending on configuration.



A window is created around a given sample, and is divided into two smaller windows, and had its likelihood calculated \cite{Gish1994}, using wavelet features instead of distance. If the LL of $LL_whole/(LL_left+LL_right)$ is at a local maxima, a segment is declared. HMM is used to classify the motion after segmentation. The system was tested on a wrist mounted accelerometer and was shown to have a segmentation error of 0.5 seconds, with 94\% labeling accuracy.},
  timestamp = {2011.01.27},
}

@Book{Boyd2004,
  Title                    = {Convex Optimization},
  Author                   = {Boyd, S. and Vandenberghe, L.},
  Publisher                = {Cambridge University Press},
  Year                     = {2004},

  Owner                    = {jf2lin},
  Timestamp                = {2016.09.07}
}

@Article{Bradski2002,
  Title                    = {Motion segmentation and pose recognition with motion history gradients},
  Author                   = {Bradski, Gary R. and Davis, James W.},
  Journal                  = {Machine Vision and Applications},
  Year                     = {2002},
  Number                   = {3},
  Pages                    = {174-184},
  Volume                   = {13},

  Doi                      = {10.1007/s001380100064},
  ISSN                     = {0932-8092},
  Keywords                 = {Key words: Motion segmentation – Normal optical flow},
  Language                 = {English},
  Publisher                = {Springer-Verlag},
  Timestamp                = {2014.12.22},
  Url                      = {http://dx.doi.org/10.1007/s001380100064}
}

@Article{Brailovsky1992,
  author    = {Brailovsky, V. L. and Kempner, Y.},
  title     = {Application of Piece-wise Regression to Detecting Internal Structure of Signal},
  journal   = {Pattern Recognition},
  year      = {1992},
  volume    = {25},
  pages     = {1361--1370},
  groups    = {Lit Review 2013-09},
  publisher = {Elsevier},
  review    = {Observation is divided up into k regions. Each region is represented by a simple form (constant, linear, quadratic). Want to find k, the length of each region, and the appropriate singal. Given a fixed value for 'k', they use Bellman and Roth's piece-wise regression to calculate the best fit. But the problem is how to select this value k? We can usually guess a upperbound for k (and thus calculate k regressions, and thus getting k error values between the function and the obs), but selecting based on least error will automatically mean the highest possible k value is chosen, so this is not the best movie.

They use 'predictive probabilistic estimate' to select the best subset of regressors.

Set of value response function (SVRF), which is basically the observation plus some normally distrubited noise, and the regression calculated. -> can't really follow this section, but it seems to have nothing to do with the 'k' selection

There is no way this method can be used online...it seems like the solution is to calculate the regression for an array of k, calculate the error, and pick a reasonable one. -> yeah, doesn't look like online k calculations are done


Brailovsky and Kempner \cite{Brailovsky1992} employs piecewise regression, allowing the regression to fit both linear and quadratic equations. The main issue they examine is how to divide up the observation data, noting that simply using a distance error metric is insufficient as it will simply choose the highest number of segments to result in the smallest error, leading to over-fitting. Instead, a normally distributed perturbation is applied to observation data, and the sample estimate of fit (SEF) is calculated. This is performed several times, generating an array of SEFs, and the predictive probabilistic estimate, $PPE = Pr(\Delta_{perturb} \geq \Delta_{non-pertrubed}$ is calculated. The number of regions that results in the largest PPE is considered the best fit.},
  timestamp = {2013.10.06},
}

@Article{Brand2000,
  Title                    = {Discovery and Segmentation of Activities in Video},
  Author                   = {Brand, M. and Kettnaker, V.},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {2000},
  Number                   = {8},
  Pages                    = {844--851},
  Volume                   = {22},
  Abstract                 = {Hidden Markov models (HMMs) have become the workhorses of the monitoring and event recognition literature because they bring to time-series analysis the utility of density estimation and the convenience of dynamic time warping. Once trained, the internals of these models are considered opaque; there is no effort to interpret the hidden states. We show that by minimizing the entropy of the joint distribution, an HMM's internal state machine can be made to organize observed activity into meaningful states. This has uses in video monitoring and annotation, low bit-rate coding of scene activity, and detection of anomalous behavior. We demonstrate with models of office activity and outdoor traffic, showing how the framework learns principal modes of activity and patterns of activity change. We then show how this framework can be adapted to infer hidden state from extremely ambiguous images, in particular, inferring 3D body orientation and pose from sequences of low-resolution silhouettes},
  Doi                      = {10.1109/34.868685},
  ISSN                     = {0162-8828},
  Keywords                 = {computer vision;hidden Markov models;image segmentation;learning systems;minimum entropy methods;object recognition;parameter estimation;Hidden Markov models;hidden state;image segmentation;internal state machine;minimum entropy;parameter estimation;pattern recognition;video activity monitoring;Entropy;Hidden Markov models;Inference algorithms;Layout;Monitoring;Parameter estimation;Sampling methods;Statistics;Time series analysis;Traffic control},
  Timestamp                = {2013.10.07}
}

@Article{Breazeal2006,
  Title                    = {Using Perspective Taking to Learn from Ambiguous Demonstrations},
  Author                   = {Breazeal, C. and Berlin, M. and Brooks, A. and Gray, J. and Thomaz, A. L.},
  Journal                  = {Robotics and Autonomous Systems},
  Year                     = {2006},
  Number                   = {5},
  Pages                    = {385--393},
  Volume                   = {54},

  Publisher                = {Elsevier},
  Timestamp                = {2013.09.23}
}

@InProceedings{Breazeal2005,
  author    = {Breazeal, C. and Kidd, C. D. and Thomaz, A. L. and Hoffman, G. and Berlin, M.},
  title     = {Effects of Nonverbal Communication on Efficiency and Robustness in Human-robot Teamwork},
  booktitle = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year      = {2005},
  pages     = {708--713},
  abstract  = { Nonverbal communication plays an important role in coordinating teammates' actions for collaborative activities. In this paper, we explore the impact of non-verbal social cues and behavior on task performance by a human-robot team. We report our results from an experiment where naive human subjects guide a robot to perform a physical task using speech and gesture. Both self-report via questionnaire and behavioral analysis of video offer evidence to support our hypothesis that implicit non-verbal communication positively impacts human-robot task performance with respect to understandability of the robot, efficiency of task performance, and robustness to errors that arise from miscommunication.},
  doi       = {10.1109/IROS.2005.1545011},
  groups    = {IROS2014},
  keywords  = { human-robot interaction; human-robot teamwork; humanoid robots; nonverbal communication; gesture recognition; human computer interaction; humanoid robots; man-machine systems; speech recognition;},
  timestamp = {2011.06.15},
}

@Article{Breiman2001,
  Title                    = {Random Forests},
  Author                   = {Breiman, L.},
  Journal                  = {Machine Learning},
  Year                     = {2001},
  Number                   = {1},
  Pages                    = {5--32},
  Volume                   = {45},

  Doi                      = {10.1023/A:1010933404324},
  ISSN                     = {0885-6125},
  Keywords                 = {classification; regression; ensemble},
  Language                 = {English},
  Publisher                = {Kluwer Academic Publishers},
  Timestamp                = {2014.10.29}
}

@Article{Breiman1996,
  Title                    = {Bagging Predictors},
  Author                   = {Breiman, L.},
  Journal                  = {Machine Learning},
  Year                     = {1996},
  Number                   = {2},
  Pages                    = {123--140},
  Volume                   = {24},

  Publisher                = {Springer},
  Timestamp                = {2014.01.22}
}

@Book{Bridger2008,
  Title                    = {Introduction to Ergonomics, Third Edition},
  Author                   = {Bridger, R. S.},
  Publisher                = {CRC Press},
  Year                     = {2008},

  Timestamp                = {2012.01.10},
  Url                      = {http://www.crcpress.com/product/isbn/9780849373060}
}

@Article{Brodie2008,
  Title                    = {The Static Accuracy and Calibration of Inertial Measurement Units for {3D} Orientation},
  Author                   = {Brodie, M. A. and Walmsley, A. and Page, W.},
  Journal                  = {Computer Methods in Biomechanics and Biomedical Engineering},
  Year                     = {2008},
  Number                   = {6},
  Pages                    = {641--648},
  Volume                   = {11},

  Abstract                 = {Inertial measurement units (IMUs) are integrated electronic devices that contain accelerometers, magnetometers and gyroscopes. Wearable motion capture systems based on IMUs have been advertised as alternatives to optical motion capture. In this paper, the accuracy of five different IMUs of the same type in measuring 3D orientation in static situations, as well as the calibration of the accelerometers and magnetometers within the IMUs, has been investigated. The maximum absolute static orientation error was 5.2°, higher than the 1° claimed by the vendor. If the IMUs are re-calibrated at the time of measurement with the re-calibration procedure described in this paper, it is possible to obtain an error of less than 1°, in agreement with the vendor's specifications (XSens Technologies B.V. 2005. Motion tracker technical documentation Mtx-B. Version 1.03. Available from: www.xsens.com). The new calibration appears to be valid for at least 22 days providing the sensor is not exposed to high impacts. However, if several sensors are 'daisy chained' together changes to the magnetometer bias can cause heading errors of up to 15°. The results demonstrate the non-linear relationship between the vendor's orthogonality claim of < 0.1° and the accuracy of 3D orientation obtained from factory calibrated IMUs in static situations. The authors hypothesise that the high magnetic dip (64°) in our laboratory may have exacerbated the errors reported. For biomechanical research, small relative movements of a body segment from a calibrated position are likely to be more accurate than large scale global motion that may have an error of up to 9.8°.},
  Doi                      = {doi:10.1080/10255840802326736},
  Keywords                 = {Inertial movement units},
  Review                   = {Calibrated accel and mag meter using defined rotations},
  Timestamp                = {2011.11.01},
  Url                      = {http://www.ingentaconnect.com/content/tandf/gcmb/2008/00000011/00000006/art00006}
}

@InProceedings{Brossier2004,
  Title                    = {Real-time Temporal Segmentation of Note Objects in Music Signals},
  Author                   = {Brossier, P. and Bello, J. P. and Plumbley, M. D.},
  Booktitle                = {Proceedings of the International Computer Music Association},
  Year                     = {2004},

  Review                   = {Brossier \etal \cite{Brossier2004} want to segment musical notes via onset detection. In order to do so, the onset and offset of an isolated music note can be approximated by locating the Attack Decay Sustain Release characteristic waveforms. However, when notes are not played in isolation, this process is much more difficult. Several different methods to perform onset detection can be constructed. It can be facilitated by calculating the distance of the observed data's Short Time Fourier Transform (STFT) and that of a known note. Alternatively, the phase deviation or the spectral magnitude differences between two STFTs can be examined. In order to obtain a sequence of onset times, a peak-picking technique is used, where local maximas above a certain threshold is selected. Filtering and dynamic thresholding is used to improve the segmentation quality.},
  Timestamp                = {2013.08.29}
}

@InProceedings{Bruckner2013,
  Title                    = {Modification and Fixed-Point Analysis of a {Kalman} Filter for Orientation Estimation Based on 9D Inertial Measurement Unit Data},
  Author                   = {Bruckner, H. P. and Spindeldreier, C. and Blume, H.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},
  Pages                    = {3953--3956},

  Abstract                 = {A common approach for high accuracy sensor fusion based on 9D inertial measurement unit data is Kalman filtering. State of the art floating-point filter algorithms differ in their computational complexity nevertheless, real-time operation on a low-power microcontroller at high sampling rates is not possible. This work presents algorithmic modifications to reduce the computational demands of a two-step minimum order Kalman filter. Furthermore, the required bit-width of a fixed-point filter version is explored. For evaluation real-world data captured using an Xsens MTx inertial sensor is used. Changes in computational latency and orientation estimation accuracy due to the proposed algorithmic modifications and fixed-point number representation are evaluated in detail on a variety of processing platforms enabling on-board processing on wearable sensor platforms.},
  Keywords                 = {EMBC2013},
  Review                   = {Lighten the computation costs of the KF so that it can run on on-board processor, so that less data needs to be transmitted, and thus can increase tx rate.

- Uses predefined fixed values for the error covar mtx
- Uses a "fixed-point" decimal instead of "floating-point" decimal, to reduce the memory needed
- Showed negligable degradiation},
  Timestamp                = {2013.08.03}
}

@InProceedings{Buerger2004,
  Title                    = {Rehabilitation Robotics: Adapting Robot Behavior to Suit Patient Needs and Abilities},
  Author                   = {Buerger, S. P. and Palazzolo, J. J. and Krebs, H. I. and Hogan, N.},
  Booktitle                = {Proceedings of the American Control Conference},
  Year                     = {2004},
  Pages                    = {3239--3244},
  Volume                   = {4},

  Abstract                 = {Robotics offers one solution to the rising problem of rehabilitating victims of neurological injury and disease. Rehabilitation robots have proven successful in speeding recovery for recent stroke victims, and in reducing impairment and pain for chronic victims who were thought to have little opportunity for improvement. Such robots require high force capability with a closely controlled "feel", requiring low endpoint impedance. For complex robot configurations, a combination of backdrivable hardware design and impedance-reducing controller design may offer the best solution. A novel therapy algorithm that exploits similarities between motor recovery and motor learning adapts robot impedance to patients as they recover. Results of therapy using this algorithm are a substantial improvement over the original robot therapy.},
  ISSN                     = {0743-1619},
  Keywords                 = {adapting robot behaviour;backdrivable hardware design;impedance reducing controller design;neurological diseases;neurological injury;patient recovery;patient rehabilitation;rehabilitation robotics;robot endpoint impedance;robot therapy;therapy algorithm;adaptive systems;control system synthesis;medical robotics;patient rehabilitation;},
  Timestamp                = {2012.11.13}
}

@Article{Buhmann2000,
  Title                    = {Radial Basis Functions},
  Author                   = {Buhmann, M. D.},
  Journal                  = {Acta Numerica},
  Year                     = {2000},
  Pages                    = {1--38},
  Volume                   = {9},

  Publisher                = {Cambridge Univ Press},
  Timestamp                = {2014.10.30}
}

@Article{Bullock2014,
  Title                    = {The {Yale} human grasping dataset: Grasp, object, and task data in household and machine shop environments},
  Author                   = {Bullock, I. M. and Feix, T. and Dollar, A. M.},
  Journal                  = {International Journal of Robotics Research},
  Year                     = {2014},

  Abstract                 = {This paper presents a dataset of human grasping behavior in unstructured environments. Wide-angle head-mounted camera video was recorded from two housekeepers and two machinists during their regular work activities, and the grasp types, objects, and tasks were analyzed and coded by study staff. The full dataset contains 27.7 hours of tagged video and represents a wide range of manipulative behaviors spanning much of the typical human hand usage. We provide the original videos, a spreadsheet including the tagged grasp type, object, and task parameters, time information for each successive grasp, and video screenshots for each instance. Example code is provided for MATLAB and R, demonstrating how to load in the dataset and produce simple plots.},
  Doi                      = {10.1177/0278364914555720},
  Eprint                   = {http://ijr.sagepub.com/content/early/2014/12/17/0278364914555720.full.pdf+html},
  Timestamp                = {2015.01.26}
}

@Article{Burges1998,
  author    = {Burges, C. J. C.},
  title     = {A Tutorial on Support Vector Machines for Pattern Recognition},
  journal   = {Data Mining and Knowledge Discovery},
  year      = {1998},
  volume    = {2},
  pages     = {121--167},
  abstract  = {The tutorial starts with an overview of the concepts of VC dimension and structural risk minimization. We then describe linear Support Vector Machines (SVMs) for separable and non-separable data, working through a non-trivial example in detail. We describe a mechanical analogy, and discuss when SVM solutions are unique and when they are global. We describe how support vector training can be practically implemented, and discuss in detail the kernel mapping technique which is used to construct SVM solutions which are nonlinear in the data. We show how Support Vector machines can have very large (even infinite) VC dimension by computing the VC dimension for homogeneous polynomial and Gaussian radial basis function kernels. While very high VC dimension would normally bode ill for generalization performance, and while at present there exists no theory which shows that good generalization performance is guaranteed for SVMs, there are several arguments which support the observed high accuracy of SVMs, which we review. Results of some experiments which were inspired by these arguments are also presented. We give numerous examples and proofs of most of the key theorems. There is new material, and I hope that the reader will find that even old material is cast in a fresh light.},
  groups    = {STAT841, IROS2014},
  publisher = {Springer},
  timestamp = {2013.09.18},
}

@InProceedings{Burns2010b,
  Title                    = {{SHIMMER}: An Extensible Platform for Physiological Signal Capture},
  Author                   = {Burns, A. and Doheny, E. P. and Greene, B. R. and Foran, T. and Leahy, D. and O'Donovan, K. and McGrath, M. J.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2010},
  Pages                    = {3759--3762},

  Abstract                 = {Wireless sensor networks have become increasingly common in everyday applications due to decreasing technology costs and improved product performance, robustness and extensibility. Wearable physiological monitoring systems have been utilized in a variety of studies, particularly those investigating ECG or EMG during human movement or sleep monitoring. These systems require extensive validation to ensure accurate and repeatable functionality. Here we validate the physiological signals (EMG, ECG and GSR) of the SHIMMER (Sensing Health with Intelligence, Modularity, Mobility and Experimental Reusability) against known commercial systems. Signals recorded by the SHIMMER EMG, ECG and GSR daughter-boards were found to compare well to those obtained by commercial systems.},
  Doi                      = {10.1109/IEMBS.2010.5627535},
  ISSN                     = {1557-170X},
  Keywords                 = {SHIMMER;SHIMMER ECG;SHIMMER EMG;experimental reusability;galvanic skin response;human movement;physiological signal capture;sensing health with intelligence;sleep monitoring;wearable physiological monitoring systems;wireless sensor networks;electrocardiography;electromyography;medical signal processing;patient monitoring;skin;wireless sensor networks;},
  Timestamp                = {2011.03.03}
}

@Article{Burns2010a,
  Title                    = {{SHIMMER}: A Wireless Sensor Platform for Noninvasive Biomedical Research},
  Author                   = {Burns, A. and Greene, B. R. and McGrath, M. J. and O'Shea, T. J. and Kuris, B. and Ayer, S. M. and Stroiescu, F. and Cionca, V.},
  Journal                  = {IEEE Sensors Journal},
  Year                     = {2010},
  Pages                    = {1527--1534},
  Volume                   = {10},

  Abstract                 = {Applying new sensing technology to healthcare maybe part of a solution to the financial and demographic crisis facing global healthcare systems. Researchers applying new approaches to noninvasive patient monitoring and diagnostics are assisted by the features of Sensing Health with Intelligence, Modularity, Mobility and Experimental Reusability (SHIMMER), a flexible sensing platform. Integrated peripherals, open software, modular expansion, specific power management hardware, and a library of applications supported with platform validation provide SHIMMER with advantages over many other medical research platforms.},
  Doi                      = {10.1109/JSEN.2010.2045498},
  ISSN                     = {1530-437X},
  Keywords                 = {SHIMMER;Sensing Health with Intelligence, Modularity, Mobility and Experimental Reusability;healthcare;noninvasive biomedical research;patient diagnostics;patient monitoring;wireless sensor platform;health care;patient monitoring;wireless sensor networks; postural detection},
  Review                   = {Paper describes the hardware specs of SHIMMER

- Existing systems tend to be very locked/propritary, does not ineteroperate

- Talks about the hardware specs
 - 8 ADCs. 3 for accel. the rest are add-on boards
 - Chipcon CC2420 trasnsceiver and 2.4 GHz Rufa antenna (802.15.4)
 - Roving Networks RN-41 Class 2 BT
 - MicroSD flash
- There's a SHIMMER2 upgrade
 - Tilt/vibration based power management

- Sensing capabilities
 - Kinematic: accel, gyro, mag
 - Physiological: ECG, EMG, EDR
 - Ambient: temperature, giht, vibration

- Standard exp
 - General purpose expansion: external breakout + 3->5V conv
 - GLIMMER: LED extension

- Collected ECG data. Looks good, compared against a Medilog holter monitor

- Software
 - Runs on TinyOS
 - Streams 500 Hz on wireless (single module?)
 - "byte stuffing" is used
 - low-power streaming should use 802.15.4

- good battery life for what we need},
  Timestamp                = {2011.03.03}
}

@InProceedings{Buschmann2007,
  Title                    = {A collocation method for real-time walking pattern generation},
  Author                   = {T. Buschmann and S. Lohmeier and M. Bachmayer and H. Ulbrich and F. Pfeiffer},
  Booktitle                = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  Year                     = {2007},
  Pages                    = {1--6},

  Keywords                 = {closed loop systems;humanoid robots;legged locomotion;path planning;quadratic programming;robot dynamics;splines (mathematics);JOHNNIE robot dynamics simulation;biped locomotion;closed loop system;humanoid robot;motion equation;offline optimisation;quadratic programming;real-time planning;real-time walking controller pattern generation;spline collocation method;torque pattern;trajectory planning;Automatic generation control;Closed loop systems;Equations;Legged locomotion;Motion planning;Optimal control;Quadratic programming;Real time systems;Spline;Torque},
  Timestamp                = {2017.03.04}
}

@InProceedings{Buss2003,
  Title                    = {Towards an Autonomous, Humanoid, and Dynamically Walking Robot: Modeling, Optimal Trajectory Planning, Hardware Architecture, and Experiments},
  Author                   = {M. Buss and M. Hardt and J. Kiener and M. Sobotka and M. Stelzer and von Stryk, O. and D. Wollherr},
  Booktitle                = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  Year                     = {2003},
  Pages                    = {2491--2496},

  Timestamp                = {2017.03.04}
}

@Article{Busso2008,
  Title                    = {{IEMOCAP}: interactive emotional dyadic motion capture database},
  Author                   = {Busso, C. and Bulut, M. and Lee, C.-C. and Kazemzadeh, A. and Mower, E. and Kim, S. and Chang, J. N. and Lee, S. and Narayanan, S. S.},
  Journal                  = {Language Resources and Evaluation},
  Year                     = {2008},
  Number                   = {4},
  Pages                    = {335},
  Volume                   = {42},

  Abstract                 = {Since emotions are expressed through a combination of verbal and non-verbal channels, a joint analysis of speech and gestures is required to understand expressive human communication. To facilitate such investigations, this paper describes a new corpus named the ``interactive emotional dyadic motion capture database'' (IEMOCAP), collected by the Speech Analysis and Interpretation Laboratory (SAIL) at the University of Southern California (USC). This database was recorded from ten actors in dyadic sessions with markers on the face, head, and hands, which provide detailed information about their facial expressions and hand movements during scripted and spontaneous spoken communication scenarios. The actors performed selected emotional scripts and also improvised hypothetical scenarios designed to elicit specific types of emotions (happiness, anger, sadness, frustration and neutral state). The corpus contains approximately 12 h of data. The detailed motion capture information, the interactive setting to elicit authentic emotions, and the size of the database make this corpus a valuable addition to the existing databases in the community for the study and modeling of multimodal and expressive human communication.},
  Doi                      = {10.1007/s10579-008-9076-6},
  ISSN                     = {1574-0218},
  Timestamp                = {2017.01.16},
  Url                      = {http://dx.doi.org/10.1007/s10579-008-9076-6}
}

@Article{Byrd2000,
  Title                    = {A trust region method based on interior point techniques for nonlinear programming},
  Author                   = {Byrd, R. H. and Gilbert, J. C. and Nocedal, J.},
  Journal                  = {Mathematical Programming},
  Year                     = {2000},
  Number                   = {1},
  Pages                    = {149-185},
  Volume                   = {89},

  Doi                      = {10.1007/PL00011391},
  ISSN                     = {0025-5610},
  Keywords                 = {Key words: constrained optimization – interior point method – large-scale optimization – nonlinear programming – primal method – primal-dual method – SQP iteration – barrier method – trust region method Mathematics Subject Classification (1991): 20E28, 20G40, 20C20},
  Language                 = {English},
  Publisher                = {Springer-Verlag},
  Timestamp                = {2015.09.09},
  Url                      = {http://dx.doi.org/10.1007/PL00011391}
}

@InCollection{Byun2002,
  Title                    = {Applications of Support Vector Machines for Pattern Recognition: A Survey},
  Author                   = {Byun, H. and Lee, S.-W.},
  Booktitle                = {Pattern Recognition with Support Vector Machines},
  Publisher                = {Springer},
  Year                     = {2002},
  Pages                    = {213--236},

  Review                   = {svm survey paper},
  Timestamp                = {2014.10.24}
}

@InProceedings{Calinon2007,
  Title                    = {Incremental Learning of Gestures by Imitation in a Humanoid Robot},
  Author                   = {Calinon, S. and Billard, A.},
  Booktitle                = {Proceedings of the ACM/IEEE international Conference on Human-robot Interaction},
  Year                     = {2007},
  Pages                    = {255--262},

  Acmid                    = {1228751},
  Doi                      = {10.1145/1228716.1228751},
  ISBN                     = {978-1-59593-617-2},
  Keywords                 = {gaussian mixture model, imitation learning, incremental learning, programming by demonstration},
  Location                 = {Arlington, Virginia, USA},
  Numpages                 = {8},
  Timestamp                = {2013.09.19}
}

@InProceedings{Calinon2004,
  author    = {Calinon, S. and Billard, A.},
  title     = {Stochastic Gesture Production and Recognition Model for a Humanoid Robot},
  booktitle = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year      = {2004},
  volume    = {3},
  pages     = {2769--2774},
  abstract  = {Robot programming by demonstration (PbD) aims at developing adaptive and robust controllers to enable the robot to learn new skills by observing and imitating a human demonstration. While the vast majority of PbD works has focused on systems that learn a specific subset of tasks, our work explores the problem of recognizing, generalizing, and reproducing tasks in a unified mathematical framework. The approach makes abstraction of the task and dataset at hand to tackle the general issue of learning which of the features are the relevant ones to imitate. In this paper, we present an implementation of this framework to the determination of the optimal strategy to reproduce arbitrary gestures. The model is tested and validated on a humanoid robot, using recordings of the kinematics of the demonstrator's arm motion. The hand path and joint angle trajectories are encoded in hidden Markov models. The system uses the optimal prediction of the models to generate the reproduction of the motion.},
  doi       = {10.1109/IROS.2004.1389828},
  groups    = {Lit Review 2013-09},
  keywords  = {adaptive control;gesture recognition;hidden Markov models;humanoid robots;learning by example;robust control;adaptive controller;hand path trajectory;hidden Markov models;humanoid robot;joint angle trajectory;recognition model;robot programming;robust controller;stochastic gesture production;unified mathematical framework;Adaptive control;Hidden Markov models;Humanoid robots;Humans;Production;Programmable control;Robot programming;Robust control;Stochastic processes;Testing},
  review    = {Imitation learning for robotics.

Recognize air-writing, similar to Palm Graffiti. Using joint angle velocity crossings to determine inflection points in the movements.



Calinon and Billard \cite{Calinon2004} used velocity crossings to segment Palm Graffiti alphabet writing into key points. Segments separated by these key points are used as states in left-right HMM models and is used to train a robot to reproduce the movement. The classification rate is 100\% when using joint angle trajectory and 92\% when using end-effector trajectory. % not actually a segmentation paper. it's more of a classification paper where segmentation is used for something.

Calinon and Billard \cite{Calinon2004} segment Palm Graffiti alphabet writing into smaller writing primitives. Segment points in the writing are denoted by velocity crossings, and to train states in left-right HMM models, and is used to train a robot to reproduce the movement.},
  timestamp = {2013.10.07},
}

@Article{Calinon2010,
  author    = {Calinon, S. and D'halluin, F. and Sauser, E. L. and Caldwell, D. G. and Billard, A. G.},
  title     = {Learning and Reproduction of Gestures by Imitation},
  journal   = {IEEE Robotics and Automation Magazine},
  year      = {2010},
  volume    = {17},
  pages     = {44--54},
  issn      = {1070-9932},
  abstract  = {We presented and evaluated an approach based on HMM, GMR, and dynamical systems to allow robots to acquire new skills by imitation. Using HMM allowed us to get rid of the explicit time dependency that was considered in our previous work [12], by encapsulating precedence information within the statistical representation. In the context of separated learning and reproduction processes, this novel formulation was systematically evaluated with respect to our previous approach, LWR [20], LWPR [21], and DMPs [13]. We finally presented applications on different kinds of robots to highlight the flexibility of the proposed approach in three different learning by imitation scenarios.},
  doi       = {10.1109/MRA.2010.936947},
  groups    = {IROS2014},
  keywords  = {Gaussian mixture regression;dynamical system;gesture reproduction;hidden Markov model;imitation learning;information encapsulation;robot learning;statistical representation;Gaussian processes;control engineering education;gesture recognition;hidden Markov models;humanoid robots;learning (artificial intelligence);robot programming;},
  timestamp = {2010.07.12},
}

@Misc{CJRR2005,
  Title                    = {Total Hip and Total Knee Replacements in Canada},

  Author                   = {{Canadian Joint Replacement Registry}},
  Year                     = {2005},

  Institution              = {Canadian Institute for Health Information},
  Keywords                 = {physiotherapy},
  Timestamp                = {2011.12.29}
}

@Misc{CMUGraphics,
  Title                    = {{CMU} Graphics Lab Motion Capture Database},

  Author                   = {{Carnegie Mellon University}},
  HowPublished             = {mocap.cs.cmu.edu},
  Year                     = {2010},

  Timestamp                = {2015.01.13}
}

@InProceedings{Carrino2012,
  Title                    = {Gesture Segmentation and Recognition with an {EMG}-Based Intimate Approach - An Accuracy and Usability Study},
  Author                   = {Carrino, F. and Ridi, A. and Mugellini, E. and Khaled, O. and Ingold, R.},
  Booktitle                = {Proceedings of the International Conference on Complex, Intelligent and Software Intensive Systems},
  Year                     = {2012},
  Pages                    = {544--551},

  Abstract                 = {In this paper we propose an approach to address the gesture segmentation issue, an important concern strongly related to the gesture recognition field. Gesture segmentation has two main goals: first, detecting when a gesture begins and ends, second, understanding whether a gesture is meant to be meaningful for the machine or is a non-command gesture (such as gesticulation). This work proposes a novel hands-free, always-available approach for the gesture segmentation and recognition in which the user can communicate directly to the system through a wearable and "intimate" interface based on electromyography signals (EMG). The system addresses the well-known "gorilla-arm" problem recognizing subtle gestures and segmenting them through motionless gestures. We report experimental results indicating that the system is able to reliably detect and recognize subtle gestures, with minimal training across users with different muscle volumes, representing a consistent gesture segmentation approach. Finally, the usability tests showed that the system is easy to use and the subjects felt quickly confident with its utilization.},
  Doi                      = {10.1109/CISIS.2012.173},
  Keywords                 = {electromyography;gesture recognition;image segmentation;medical image processing;EMG-based intimate approach;electromyographic signals;gesticulation;gesture segmentation approach;gorilla-arm problem;intimate interface;motionless gestures;muscle volumes;non-command gesture;usability study;wearable interface;Electromyography;Gesture recognition;Muscles;Sensors;Training;Usability;Wrist;Muscle-Computer Interface;electromyography;gesture segmentation;intimate interface;subtle interaction},
  Owner                    = {jf2lin},
  Review                   = {want to segment hand gestures and classify them. uses LDA to perform segmentation on proxy signal (ticep activation) to guide classification, also with LDA. So segmentation with classifier is done, but},
  Timestamp                = {2015.04.24}
}

@InProceedings{Castellani2004,
  author    = {Castellani, A. and Botturi, D. and Bicego, M. and Fiorini, P.},
  title     = {Hybrid {HMM/SVM} Model for the Analysis and Segmentation of Teleoperation Tasks},
  booktitle = {Proceedings of the IEEE International Conference on Robotics and Automation},
  year      = {2004},
  volume    = {3},
  pages     = {2918--2923},
  abstract  = {The automatic execution of a complex task requires the identification of an underlying mental model to derive a possible task control sequence. The model aims at analysing and segmenting the task in simpler sub-tasks. As an example of a complex task, in this paper we consider teleoperation where a person commands a remote robot. This paper presents a new modeling approach using hidden Markov models (HMM) and support vector machines (SVM) to analyse the force/torque signals of a teleoperation task. The task is divided into simpler sub-tasks and the model is used to segment the signals in each sub-task. The segmentation gives informations on the system behavior identifying the changes of the model states. Peg in hole force/torque data are used for testing the model. The results are consistent with the literature with respect to off-line analysis, whereas a significant increase of performance is achieved for on-line analysis.},
  doi       = {10.1109/ROBOT.2004.1307504},
  groups    = {Lit Review 2013-09},
  issn      = {1050-4729},
  keywords  = {hidden Markov models;support vector machines;telerobotics;SVM model;automatic execution;hidden Markov models;hybrid HMM model;mental model;peg-in-hole force data;remote robot;support vector machines;task control sequence;teleoperation tasks;Automatic control;Cognitive science;Computer science;Hidden Markov models;Neural networks;Performance analysis;Probability distribution;Robotics and automation;Support vector machine classification;Support vector machines},
  review    = {SVM/HMM hybrid system used. 

An SVM is used to train each subtask signal (HMM state) and a SVM surface is formed. This surface is reformulated into a sigmoid to form an emission probability, and is used in HMM state emissions.


Viterbi is used to segment. However, Viterbi assumes the full data sequence is available. We're interested in real-time tihngs. There is a Viterbi Sampled version of Viterbi which only calculates the state probabilities forward (no backtracking, unlike vanilla Viterbi). The two versions of Viterbi do generally produce the same results. Tested results with the "peg in the hole" task. The offline (Viterbi standard) got 100% segmentation accuracy, the online (Viterbi Sampled) got 84%.

Castellani \etal \cite{Castellani2004} uses one-vs-all SVMs to train sub-task signals for robotic teleoperation tasks. The SVM decision plane is translated into a sigmoid function and used as HMM state emission probability. An online Viterbi algorithm is used to segment the whole data sequence. A 'peg in hole' telerobotic task was used as to verify the segmentation accuracy, which consists of several smaller sub-tasks. The state transitions, denoting the change from one sub-task to another, are defined as the segment points. $Ver_{AllPoints}$ is used. The algorithm reports perfect $Acc_{Class}$ with the standard Viterbi, and $Acc_{Class}$ of 84\% with the online Viterbi. Ekvall \etal \cite{Ekvall2006} applies a similar method to other telerobotic tasks with success, but no segmentation results were given.},
  timestamp = {2013.10.07},
}

@Article{Cattell1977,
  Title                    = {A Comprehensive Trial of the Scree and KG Criteria for Determining the Number of Factors},
  Author                   = {Cattell, R. B. and Vogelmann, S.},
  Journal                  = {Multivariate Behavioral Research},
  Year                     = {1977},
  Number                   = {3},
  Pages                    = {289--325},
  Volume                   = {12},

  Publisher                = {Taylor \& Francis},
  Timestamp                = {2014.09.17}
}

@InProceedings{Cavallo2009,
  Title                    = {A First Step Toward a Pervasive and Smart {ZigBee} Sensor System for Assistance and Rehabilitation},
  Author                   = {Cavallo, F. and Aquilano, M. and Odetti, L. and Arvati, M. and Carrozza, M.C.},
  Booktitle                = {Proceedings of the IEEE International Conference on Rehabilitation Robotics},
  Year                     = {2009},
  Pages                    = {632--637},

  Abstract                 = {This paper shows the general concept and the primary implementation of a pervasive intelligent system for rehabilitation. The scope of this work is to highlight the possibility to join two important research fields, i.e. rehabilitation and ambient assisted living, to enhance the capabilities and independence of disable and aged people. The described system was composed of a ZigBee network, with coordinator, sensor and actuator nodes, able to identify and control patient's activities and send warning to caregiver if requests in warning functionality, and of a software interface to manage the whole network and to monitor patient in outdoor environment.},
  Doi                      = {10.1109/ICORR.2009.5209471},
  ISSN                     = {1945-7898},
  Keywords                 = {GSM network;ZigBee network;actuator node;aged people;ambient assisted living;assistive robot;disabled people;outdoor environment;patient activity control;patient caregiver;patient monitoring;pervasive intelligent rehabilitation system;smart ZigBee sensor system;software interface;therapeutic robot;warning functionality;cellular radio;geriatrics;handicapped aids;intelligent actuators;intelligent sensors;medical robotics;mobile computing;patient care;patient monitoring;patient rehabilitation;service robots;telemedicine;wireless sensor networks;},
  Timestamp                = {2011.12.30}
}

@InProceedings{Cervantes2013,
  Title                    = {Learning from non-stationary data using a growing network of prototypes},
  Author                   = {Cervantes, A. and Isasi, P. and Gagne, C. and Parizeau, M.},
  Booktitle                = {Evolutionary Computation (CEC), 2013 IEEE Congress on},
  Year                     = {2013},
  Month                    = {June},
  Pages                    = {2634-2641},

  Abstract                 = {Learning from non-stationary data requires methods that are able to deal with a continuous stream of data instances, possibly of infinite size, where the class distributions are potentially drifting over time. For handling such datasets, we are proposing a new method that incrementally creates and adapts a network of prototypes for classifying complex data received in an online fashion. The algorithm includes both an accuracy-based and time-based forgetting mechanisms that ensure that the model size does not grow indefinitely with large datasets. We have performed tests on seven benchmarking datasets for comparing our proposal with several approaches found in the literature, including ensemble algorithms associated to two different base classifiers. Performances obtained show that our algorithm is comparable to the best of the ensemble classifiers in terms of accuracy/time trade-off. Moreover, our approach appears to have significant advantages for dealing with data that has a complex, non-linearly separable topology.},
  Doi                      = {10.1109/CEC.2013.6557887},
  Keywords                 = {data handling;learning (artificial intelligence);pattern classification;accuracy-based forgetting mechanism;class distribution;data classification;data instance;dataset handling;ensemble classifier;nonstationary data learning;prototype network;time-based forgetting mechanism;Accuracy;Algorithm design and analysis;Boosting;Heuristic algorithms;Prototypes;Testing;Training},
  Review                   = {Uses GPNC - an incremental learning algorithm that generates a network fo linked prototypes, and is used to classify unlabeled data using nearest neighbour rule
- uses some heuristics to decide if a new data point should be made its own prototype, or merged into an existing one. looks at...
 - existance of clusters with the same label
 - distance to clusters of the same label vs other labels
 - use "links" to shift the overall class distribution
 - forgets old data, or clusters that has not observed data that falls into its cluster in a while},
  Timestamp                = {2015.05.12}
}

@Misc{Cham_phdcomics,
  Title                    = {Piled Higher and Deeper ({PHD})},

  Author                   = {Cham, J.},
  HowPublished             = {www.phdcomics.com},
  Year                     = {1997},

  Timestamp                = {2012.12.19}
}

@Article{Chamroukhi2013,
  author    = {Chamroukhi, F. and Mohammed, S. and Trabelsi, D. and Oukhellou, L. and Amirat, Y.},
  title     = {Joint Segmentation of Multivariate Time Series with Hidden Process Regression for Human Activity Recognition},
  journal   = {Neurocomputing},
  year      = {2013},
  volume    = {120},
  pages     = {633--644},
  issn      = {0925-2312},
  abstract  = {The problem of human activity recognition is central for understanding and predicting the human behavior, in particular in a prospective of assistive services to humans, such as health monitoring, well being, security, etc. There is therefore a growing need to build accurate models which can take into account the variability of the human activities over time (dynamic models) rather than static ones which can have some limitations in such a dynamic context. In this paper, the problem of activity recognition is analyzed through the segmentation of the multidimensional time series of the acceleration data measured in the 3-d space using body-worn accelerometers. The proposed model for automatic temporal segmentation is a specific statistical latent process model which assumes that the observed acceleration sequence is governed by sequence of hidden (unobserved) activities. More specifically, the proposed approach is based on a specific multiple regression model incorporating a hidden discrete logistic process which governs the switching from one activity to another over time. The model is learned in an unsupervised context by maximizing the observed-data log-likelihood via a dedicated expectation-maximization (EM) algorithm. We applied it on a real-world automatic human activity recognition problem and its performance was assessed by performing comparisons with alternative approaches, including well-known supervised static classifiers and the standard hidden Markov model (HMM). The obtained results are very encouraging and show that the proposed approach is quite competitive even it works in an entirely unsupervised way and does not requires a feature extraction preprocessing step.},
  doi       = {10.1016/j.neucom.2013.04.003},
  groups    = {IROS2014},
  keywords  = {<!-- Tag Not Handled --><keyword id=#key0010#>Human activity recognition},
  review    = {Chamroukhi \etal \cite{Chamroukhi2013} detects human activities by examining and segmenting acceleration data. They extend the regression model with a hidden logistic process, which allows it to handle multivariate time-series data. The observation data $y$ is represented by a regression model, $y_i = \beta_{z_i} t_i + \epsilon_i$, where the regression coefficient $\beta_{z_i}$ is a function of the logistic hidden state $z_i$. $z_i$ controls the switching from one activity to another, for $k$ different activities. That is, the regression model describes a different motion according to the state of $z_i$. When the state of $z_i$ changes, a segment point is declared. The parameters of the regression models and $z$ is trained by the EM algorithm. To verify the algorithm, accelerometer data for 12 different primitive types, from 6 healthy participant, were collected. $Ver_{AllPoints}$ was used, and $Acc_{class}$ was 90\%.},
  timestamp = {2013.06.13},
}

@InProceedings{Chan2013,
  Title                    = {Ambulatory Respiratory Rate Detection Using {ECG} and a Triaxial Accelerometer},
  Author                   = {Chan, A. M. and Ferdosi, N. and Narasimhan, R.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {Continuous monitoring of respiratory rate in ambulatory conditions has widespread applications for screening of respiratory diseases and remote patient monitoring. Unfortunately, minimally obtrusive techniques often suffer from low accuracy. In this paper, we describe an algorithm with low computational complexity for combining multiple respiratory measurements to estimate breathing rate from an unobtrusive chest patch sensor. Respiratory rates derived from the respiratory sinus arrhythmia (RSA) and modulation of the QRS amplitude of electrocardiography (ECG) are combined with a respiratory rate derived from tri-axial accelerometer data. The three respiration rates are combined by a weighted average using weights based on quality metrics for each signal. The algorithm was evaluated on 15 elderly subjects who performed spontaneous and metronome breathing as well as a variety of activities of daily living (ADLs). When compared to a reference device, the mean absolute error was 1.02 breaths per minute (BrPM) during metronome breathing, 1.67 BrPM during spontaneous breathing, and 2.03 BrPM during ADLs.},
  Keywords                 = {EMBC2013},
  Review                   = {Want to use less intrusive technology to measure respiration and such.},
  Timestamp                = {2013.07.31}
}

@Article{Chang2011_libsvm,
  Title                    = {{LIBSVM}: A Library for Support Vector Machines},
  Author                   = {Chang, C.-C. and Lin, C.-J.},
  Journal                  = {ACM Transactions on Intelligent Systems and Technology},
  Year                     = {2011},
  Note                     = {Software available at \url{http://www.csie.ntu.edu.tw/~cjlin/libsvm}},
  Pages                    = {27:1--27:27},
  Volume                   = {2},

  Issue                    = {3},
  Timestamp                = {2014.01.23}
}

@Article{Chao1980,
  Title                    = {Justification of Triaxial Goniometer for the Measurement of Joint Rotation},
  Author                   = {Chao, E. Y. S.},
  Journal                  = {Journal of Biomechanics},
  Year                     = {1980},
  Pages                    = {989--1006},
  Volume                   = {13},

  Abstract                 = {The modified triaxial goniometer was designed based on the gyroscopic concept. This device is capable of measuring the joint three-dimensional angular motion corresponding to a specific set of Eulerian angles. Since the angular measurement by this device is not sequence dependent, it is convenient to provide unique motion patterns of the joint from one position to another. The joint rotational axes are oriented based on identifiable bony landmarks which provide a convenient visualization of the anatomical motion involved. The error caused by the exoskeletal attachment of the instrument can be theoretically corrected. Considering all factors in joint functional evaluation, the triaxial goniometer is a useful and effective method to provide simple real time three-dimensional angular motion measurements.},
  ISSN                     = {0021-9290},
  Timestamp                = {2012.09.29}
}

@InProceedings{Chapelle2006,
  Title                    = {A Continuation Method for Semi-supervised SVMs},
  Author                   = {Chapelle, O. and Chi, M. and Zien, A.},
  Booktitle                = {Proceedings of the International Conference on Machine Learning},
  Year                     = {2006},
  Pages                    = {185--192},

  Abstract                 = {Semi-Supervised Support Vector Machines
(S
3
VMs) are an appealing method for using unlabeled data in classification: their objective function favors decision boundaries
which do not cut clusters. However their
main problem is that the optimization problem is non-convex and has many local minima, which often results in suboptimal performances. In this paper we propose to use a
global optimization technique known as continuation to alleviate this problem. Compared to other algorithms minimizing the
same objective function, our continuation
method often leads to lower test errors.},
  Timestamp                = {2014.10.24}
}

@InProceedings{Chapelle2007,
  Title                    = {Branch and Bound for Semi-supervised Support Vector Machines},
  Author                   = {Chapelle, O. and Sindhwani, V. and Keerthi, S.},
  Booktitle                = {Proceedings of Neural Information Processing Systems},
  Year                     = {2007},

  Abstract                 = {Semi-supervised SVMs (S
3
VM) attempt to learn low-density separators by
maximizing the margin over labeled and unlabeled examples. The associated optimization problem is non-convex. To examine the full potential
of S
3
VMs modulo local minima problems in current implementations, we
apply branch and bound techniques for obtaining exact, globally optimal
solutions. Empirical evidence suggests that the globally optimal solution
can return excellent generalization performance in situations where other
implementations fail completely. While our current implementation is only
applicable to small datasets, we discuss variants that can potentially lead
to practically useful algorithms.},
  Timestamp                = {2014.10.24}
}

@Article{Chapelle2008,
  Title                    = {Optimization techniques for semi-supervised support vector machines},
  Author                   = {Chapelle, O. and Sindhwani, V. and Keerthi, S. S.},
  Journal                  = {The Journal of Machine Learning Research},
  Year                     = {2008},
  Pages                    = {203--233},
  Volume                   = {9},

  Abstract                 = {Due to its wide applicability , the problem of semi-supervised classification is attracting increasing attention in machine learning. Semi-Supervised Support V ector Machines (S
3
VMs) are based
on applying the margin maximization principle to both labeled and unlabeled examples. Unlike
SVMs, their formulation leads to a non-convex optimization problem. A suite of algorithms have
recently been proposed for solving S
3
VMs. This paper reviews key ideas in this literature. The
performance and behavior of various S
3
VM algorithms is studied together , under a common experimental setting.},
  Review                   = {Semi-supervised learning. Uses the cluster assumption (points in a data cluster have similar labels).},
  Timestamp                = {2014.10.24}
}

@Article{Chaquet2013,
  Title                    = {A Survey of Video Datasets for Human Action and Activity Recognition},
  Author                   = {Chaquet, J. M. and Carmona, E. J. and Fern\'{a}ndez-Caballero, A.},
  Journal                  = {Computer Vision and Image Understanding },
  Year                     = {2013},
  Pages                    = {633--659},
  Volume                   = {117},

  Abstract                 = {Abstract Vision-based human action and activity recognition has an increasing importance among the computer vision community with applications to visual surveillance, video retrieval and humanâ€“computer interaction. In recent years, more and more datasets dedicated to human action and activity recognition have been created. The use of these datasets allows us to compare different recognition systems with the same input data. The survey introduced in this paper tries to cover the lack of a complete description of the most important public datasets for video-based human activity and action recognition and to guide researchers in the election of the most suitable dataset for benchmarking their algorithms.},
  Doi                      = {http://dx.doi.org/10.1016/j.cviu.2013.01.013},
  ISSN                     = {1077-3142},
  Keywords                 = {Human action recognition},
  Timestamp                = {2014.12.18}
}

@Article{Chen2007,
  Title                    = {Learning a {3D} Human Pose Distance Metric from Geometric Pose Descriptor},
  Author                   = {Chen, C. AND Zhuang, Y. AND Nie, F. AND Yang, Y. AND Wu, F. AND Xiao, J.},
  Journal                  = {IEEE Transactions on Visualization and Computer Graphics},
  Year                     = {2007},
  Pages                    = {1--5},
  Volume                   = {99},

  Address                  = {Los Alamitos, CA, USA},
  Doi                      = {10.1109/TVCG.2010.272},
  ISSN                     = {1077-2626},
  Keywords                 = {ECE780},
  Publisher                = {IEEE Computer Society},
  Timestamp                = {2011.03.05}
}

@Article{Chen2012_survey,
  Title                    = {Sensor-Based Activity Recognition},
  Author                   = {Chen, L. and Hoey, J. and Nugent, C. D. and Cook, D. J. and Yu, Z.},
  Journal                  = {IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews},
  Year                     = {2012},
  Pages                    = {790--808},
  Volume                   = {42},

  Abstract                 = {Research on sensor-based activity recognition has, recently, made significant progress and is attracting growing attention in a number of disciplines and application domains. However, there is a lack of high-level overview on this topic that can inform related communities of the research state of the art. In this paper, we present a comprehensive survey to examine the development and current status of various aspects of sensor-based activity recognition. We first discuss the general rationale and distinctions of vision-based and sensor-based activity recognition. Then, we review the major approaches and methods associated with sensor-based activity monitoring, modeling, and recognition from which strengths and weaknesses of those approaches are highlighted. We make a primary distinction in this paper between data-driven and knowledge-driven approaches, and use this distinction to structure our survey. We also discuss some promising directions for future research.},
  Doi                      = {10.1109/TSMCC.2012.2198883},
  ISSN                     = {1094-6977},
  Keywords                 = {knowledge engineering;ubiquitous computing;data-driven approach;knowledge-driven approach;pervasive computing;primary distinction;sensor-based activity recognition;vision-based activity recognition;Biomedical monitoring;Data models;Hidden Markov models;Human factors;Monitoring;Wearable sensors;Activity modeling;activity monitoring;activity recognition;dense sensing;pervasive computing},
  Timestamp                = {2015.04.04}
}

@Article{Chen2013_emg,
  Title                    = {Pattern recognition of number gestures based on a wireless surface {EMG} system},
  Author                   = {Chen, X. Wang, Z.},
  Journal                  = {Biomedical Signal Processing and Control},
  Year                     = {2013},
  Pages                    = {184--92},
  Volume                   = {8},

  Abstract                 = {Using surface electromyography (sEMG) signal for efficient recognition of hand gestures has attracted increasing attention during the last decade, with most previous work being focused on recognition of upper arm and gross hand movements and some work on the classification of individual finger movements such as finger typing tasks. However, relatively few investigations can be found in the literature for automatic classification of multiple finger movements such as finger number gestures. This paper focuses on the recognition of number gestures based on a 4-channel wireless sEMG system. We investigate the effects of three popular feature types (i.e. Hudgins’ time–domain features (TD), autocorrelation and cross-correlation coefficients (ACCC) and spectral power magnitudes (SPM)) and four popular classification algorithms (i.e. k-nearest neighbor (k-NN), linear discriminant analysis (LDA), quadratic discriminant analysis (QDA) and support vector machine (SVM)) in offline recognition. Motivated by the good performance of SVM, we further propose combining the three features and employing a new classification method, multiple kernel learning \{SVM\} (MKL-SVM). Real sEMG results from six subjects show that all combinations, except k-NN or \{LDA\} using \{ACCC\} features, can achieve above 91% average recognition accuracy, and the highest accuracy is 97.93% achieved by the proposed MKL-SVM method using the three feature combination (3F). Referring to the offline recognition results, we also implement a real-time recognition system. Our results show that all six subjects can achieve a real-time recognition accuracy higher than 90%. The number gestures are therefore promising for practical applications such as human–computer interaction (HCI).},
  Doi                      = {http://dx.doi.org/10.1016/j.bspc.2012.08.005},
  ISSN                     = {1746-8094},
  Keywords                 = {Multiple kernel learning},
  Owner                    = {jf2lin},
  Review                   = {- 10 motions, hand gesturing performing numbers (ie hand signing 0 to 9), 4 channel surface emg on forearm. 
- uses some sort of multiple kernel system
- 6 subjects.
- uses transient energy: average value of a window, squared, and divided by width. when this value is above some threshold, then an "active segment" is declared
- once that is determined, they look at a bunch of different features
 - hudgin's time domain features
 - auto correlation, cross coeelation coeff
 - spectral power magnidutes
- didn't use, but these features are popular
 - short time Fourier transform
 - wavelet transform
 - high order statistics
- applied kNN, LDA, QDA and SVM, as comparison against multi kernel learning (MKL), which is a way to optimalize for a kernel given the data to make up for unknown kernels in the svm. seems like multiple svms combined together},
  Timestamp                = {2015.04.03}
}

@InProceedings{Cheng2008,
  Title                    = {Semi-supervised learning with data calibration for long-term time series forecasting},
  Author                   = {Cheng, H. and Tan, P.-N.},
  Booktitle                = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  Year                     = {2008},
  Pages                    = {133--141},

  Abstract                 = {Many time series prediction methods have focused on single
step or short term prediction problems due to the inher-
ent di±culty in controlling the propagation of errors from
one prediction step to the next step. Yet, there is a broad
range of applications such as climate impact assessments
and urban growth planning that require long term forecast-
ing capabilities for strategic decision making. Training an
accurate model that produces reliable long term predictions
would require an extensive amount of historical data, which
are either unavailable or expensive to acquire. For some of
these domains, there are alternative ways to generate po-
tential scenarios for the future using computer-driven sim-
ulation models, such as global climate and tra±c demand
models. However, the data generated by these models are
currently utilized in a supervised learning setting, where a
predictive model trained on past observations is used to es-
timate the future values. In this paper, we present a semi-
supervised learning framework for long-term time series fore-
casting based on Hidden Markov Model Regression. A co-
variance alignment method is also developed to deal with the
issue of inconsistencies between historical and model simu-
lation data. We evaluated our approach on data sets from
a variety of domains, including climate modeling. Our ex-
perimental results demonstrate the e±cacy of the approach
compared to other supervised learning methods for long-
term time series forecasting.},
  Review                   = {Use HMM for SSL. Shows that SSL HMM is better than normal HMM in Canadian weather prediction. Uses BW algorithm. New (unlabelled) points are assessed (by looking at distance between points) to make sure that they would keep the function smooth and assign weights to the data, by comparing the unlabelled points to HMM prediction of new points. Want to use a weighted version between the predicted and actual obs point. The model is retrained.},
  Timestamp                = {2015.05.13}
}

@InProceedings{Chiappa2010,
  author    = {Chiappa, S. AND Peters, J.},
  title     = {Movement Extraction by Detecting Dynamics Switches and Repetitions},
  booktitle = {Proceedings of the Advances in Neural Information Processing Systems},
  year      = {2010},
  pages     = {388--396},
  abstract  = {Many time-series such as human movement data consist of a sequence of basic actions, e.g., forehands and backhands in tennis. Automatically extracting and characterizing such actions is an important problem for a variety of different applications. In this paper, we present a probabilistic segmentation approach in which an observed time-series is modeled as a concatenation of segments corresponding to different basic actions. Each segment is generated through a noisy transformation of one of a few hidden trajectories representing different types of movement, with possible time re-scaling. We analyze three different approximation methods for dealing with model intractability, and demonstrate how the proposed approach can successfully segment table tennis movements recorded using a robot arm as haptic input device.},
  groups    = {IROS2014},
  keywords  = {Segmentation},
  review    = {Chiappa2010

INTRODUCTION
- Motion capture systems widespread
- Want to obtain movement templates
 - need to detect action boundaries
 - need to recognize the motion as well
- most modern approaches needs some degree of supervision
- this paper presents unsupervised system, using probability
 - "hidden trajectories" -> (probably HMM)
 - non-linear time scaling -> (dynamic time scaling?)
 - imposed min/max bounds on length of primitives to guide segmentation

SEGMENTATION MODEL
- Assume there is some hidden trajectory, contaminated by noise and time-scaled from expected template
- variables (ways to classify the signal)
 - v: observation data points
 - h: hidden trajectory
 - sigma: used to decide which movement template is being observed, segmentation bounds and time constraints
 - actually, it's a tuple of 3 varibles of "explicit regime-duration distribution" (refers to another paper)
 - s: indicates the movement template that is being observed
 - d: duration of how long the motion is. set between dmin and dmax (hard bounds on the length of a primitive)
 - c: time till next action
 - z: indicate which elements in the hidden trajectory generated the observation
 - combine the four into a joint probability distribution

INFERENCE AND LEARNING
- Compares three methods
 1. (Variation) Approximates the probability that the the observed signal is the hidden trajectory with another variable 'q' and optimizes 'q' by using an expectation-maximization (EM) method
 - (a lot of math that I don't currently get)
 2. (MAP) Estimate the most likely set of trajectories with EM
 - (similar to method 1)
 3. Gibbs sampling and EM
 - (uh. right)


An interesting approach towards temporal segmentation is to assume that the observed data evolves according to an underlying deterministic model, but has been contaminated with time warping and additive noise. Probabilistic methods can be used to approximate both the parameters of the underlying model and find the segmentation locations. Chiappa and Peters \cite{Chiappa2010} derived the underlying signal using the Bayesian likelihood that a sequence of observation data is from some underlying action model, as well as the warping needed to transform the observation sequence to the action. This is estimated by an expectation-maximization routine. They showed that a routine that provided maximum a posteriori estimates for the template provided the best segmentation match. This algorithm was tested on table tennis motions, and was found to be in strong agreement with manual visual segmentation. However, this approach requires that the entire sequence is available for action fitting, making it unsuitable for online applications.},
  timestamp = {2011.01.17},
}

@TechReport{Cho2004,
  Title                    = {Calibration of a Redundant {IMU}},
  Author                   = {Cho, S. Y. and Park, C. G.},
  Institution              = {American Institute of Aeronautics and Astronautics},
  Year                     = {2004},

  Abstract                 = {A calibration technique for a redundant IMU is proposed. The conventional orthogonal IMU with three gyros and three accelerometers may cause the enormous navigation error even if one sensor fault occurs. In order to overcome this problem, the redundant IMU is constructed by configuring redundant sensors. The redundant IMU has a merit that it can detect and isolate the faults. So far, the sensor configurations and FDI techniques have been investigated. However, the research on the calibration of the redundant IMU has not been carried out. In this paper, three coordinate frames in the redundant IMU are defined and the IMU error is modeled based on the frames to establish a calibration procedure for the redundant IMU. A technique for estimating the error coefficients of accelerometers and gyros is proposed. And a test procedure of the 2-axis turntable for the cone configuration IMU is presented. Finally, a redundant IMU with cone configuration is implemented and the performance of the proposed technique is verified by some experiments.},
  Review                   = {uses turntables and regression
contraint: accel sum of squares = 1
yeah, uses turntable},
  Timestamp                = {2011.07.19}
}

@Unpublished{Choudhury2010,
  Title                    = {Accurate Determination of Joint Angles from Inertial Measurement Unit Data},
  Author                   = {Choudhury, S.},
  Note                     = {ECE687 Final Report (Dana Kulic)},

  Month                    = jul,
  Year                     = {2010},

  Abstract                 = {This paper describes an approach to accurately determine joint angles from the sensor fusion of gyroscopic and acceleration data by implementing an Extended Kalman Filter (EKF). In similar research it has been determined that the sensor fusion of inertial measurement unit (IMU) data gives rise to drift errors due to integration. The magnitude of this error increases further as you traverse down the kinematic chain. The Extended Kalman Filter adjusts for this non-linear drift error by using a state prediction model. Through simulations based on measured data, it was shown to be an effective in reducing drift errors in calculating the shoulder joint angle. Furthermore, it was also shown that the impact of drift errors further down the kinematic chain (i.e. the elbow) were also reduced by training the EKF with a dynamic model prior to running simulation.},
  Review                   = {- Measured arm (2 links)
- Used Carnegie Mellon's Kitchen Capture as base data 
- Used Euler angles to describe model
- Applied Extended Kalman (ReBEL toolkit)
- Good results},
  Timestamp                = {2010.09.29}
}

@InProceedings{Choujaa2008,
  Title                    = {TRAcME: Temporal Activity Recognition Using Mobile Phone Data},
  Author                   = {Choujaa, D. and Dulay, N.},
  Booktitle                = {Proceedings of the IEEE/IFIP International Conference on Embedded and Ubiquitous Computing},
  Year                     = {2008},
  Month                    = {Dec},
  Pages                    = {119-126},
  Volume                   = {1},

  Abstract                 = {The aim of human activity recognition is to identify what a user or a group of users are doing at a given point in time, for example travelling or working. Activity recognition plays an important role in mobile and ubiquitous computing both as a goal in itself and as an intermediate task in the design of advanced applications. Virtually all existing activity recognition systems for mobile phones base their predictions on location cues. This approach forces the user to disclose personal information such as her home or work area. In this paper, we present a novel activity recognition system called TRAcME (temporal recognition of activities for mobile environments) which recognises generic human activities from large windows of context, Allenpsilas temporal relations and anonymous landmarks. Unlike existing systems, TRAcME handles simultaneous activities and outputs activities which are consistent with each other at the scale of a userpsilas day.},
  Doi                      = {10.1109/EUC.2008.33},
  Keywords                 = {learning (artificial intelligence);mobile computing;mobile computing;mobile phone data;temporal activity recognition;ubiquitous computing;Educational institutions;Embedded computing;Fluctuations;Global Positioning System;Humans;Machine learning;Mobile computing;Mobile handsets;Pervasive computing;Ubiquitous computing;Activity recognition;Allen's temporal logic;Context awareness;Machine learning;Mobile phone},
  Timestamp                = {2014.12.21}
}

@Article{Chowdhury2003,
  Title                    = {Natural Language Processing},
  Author                   = {Chowdhury, G. G.},
  Journal                  = {Annual Review of Information Science and Technology},
  Year                     = {2003},
  Number                   = {1},
  Pages                    = {51--89},
  Volume                   = {37},

  Publisher                = {Wiley Online Library},
  Timestamp                = {2013.08.08}
}

@Misc{CIRGaitrite,
  Title                    = {GAITRite},

  Author                   = {{CIR Systems Inc.}},
  HowPublished             = {www.gaitrite.com},
  Year                     = {2017},

  Owner                    = {jf2lin},
  Timestamp                = {2016.12.21}
}

@Article{Clamann1969,
  Title                    = {Statistical Analysis of Motor Unit Firing Patterns in a Human Skeletal Muscle},
  Author                   = {Clamann, H. P.},
  Journal                  = {Biophysical Journal},
  Year                     = {1969},
  Pages                    = {1233--1251},
  Volume                   = {9},

  Owner                    = {jf2lin},
  Timestamp                = {2015.07.14}
}

@Article{Clancy2002,
  Title                    = {Sampling, noise-reduction and amplitude estimation issues in surface electromyography},
  Author                   = {Clancy, E. AND Morin, E. AND Merletti, R},
  Journal                  = {Journal of Electromyography and Kinesiology},
  Year                     = {2002},
  Pages                    = {1--16},
  Volume                   = {12},

  Abstract                 = {This paper reviews data acquisition and signal processing issues relative to producing an amplitude estimate of surface EMG. The paper covers two principle areas. First, methods for reducing noise, artefact and interference in recorded EMG are described. Wherever possible noise should be reduced at the source via appropriate skin preparation, and the use of well designed active electrodes and signal recording instrumentation. Despite these efforts, some noise will always accompany the desired signal, thus signal processing techniques for noise reduction (e.g. band-pass filtering, adaptive noise cancellation filters and filters based on the wavelet transform) are discussed. Second, methods for estimating the amplitude of the EMG are reviewed. Most advanced, high-fidelity methods consist of six sequential stages: noise rejection/filtering, whitening, multiple-channel combination, amplitude demodulation, smoothing and relinearization. Theoretical and experimental research related to each of the above topics is reviewed and the current recommended practices are described.},
  Keywords                 = {Artefact rejection, Electromyography, EMG, EMG amplitude, Measurement noise, Noise, Surface EMG},
  Owner                    = {jf2lin},
  Review                   = {Reduce noise with proper skin preparation. Use good eletrode and recording instrumentation. BPF and noise cancellation is good. A method to estimate EMG aplitude is offered. 

Electrodes: Use the same metal to prevent half-cell potentials. Ag-AgCl is your best bet. Minimize electrode-skin impedance and use a amplifier with an input impedance that is at least 100x higher than the electrode's. Conductive paste can be used to reduce conductivity. In terms of movement, mechanical movement of electrode detection area (so if electrode moves or the muscle under it moves) and skin deformation under skin. The conductive gel and minimizing skin impedence helps, respectively. 

Cable motion artefact can be reduced by reducing electrode-skin impedance.The friction and deformation of the cable causes capacitance though. Using an opamp at the electrode helps, as would preamping the signal.

60Hz noise: This could be several times larger than the EMG signal. Move away from interference sources, if possible. Differential amp helps, but is far from perfect. Use EM knowledge, form closed loops to reduce induction from AC signals. Also, use of a notch filter may be needed, but this is only good if we want a rough EMG estimate, since we're removing signal as well, when we notch at 60Hz. Could consider adaptive filters, which has a LMS algorithm at its core. Sometimes, higher harmonics holds more power than the fundemental 60Hz. 

Other noises: High freq noise can be knocked out with LPFs. If noise frequency overlaps with EMG, examine the nature of the signal and its frequency content. Equipment has noise too, which is more evident at lower amplitude of contraction. Take lots of resting trials to keep an eye on the background noise. 

Aliasing: Typical EMG signals is [10, 500] Hz, so keep Nyquist in mind. Use LPF to knock out high freq noise. Know your conversion range too, to reduce quantization. 

Biosignals: ECG and whatnot. HPF at 20-30 Hz seems helpful. 

EMG amplitude is then estimated with...

Whitening: Remove a constant power (something like white noise) from the EMG, so all we're looking at is the signal itself, and not some offset bias. 

Multiple-channel combination: Multiple channels tend to collect better signal. Yay. But...the number of failed recording channels also increases. So more processing is needed to figure out what is usable and what is not. 

Demodulation: Use a full-wave rectifier. Something or another. Easier to model. EMG is pretty random, so they modelled it as...you guess it, noise. Or 'random process'. 

Smoothing: For constant-force, constant-angle, non-fatiguing msucles, RMS correlates with the bandwidth fo signal. 

Relinearization:(hmm. no details on this section?)},
  Timestamp                = {2009.12.07}
}

@Article{Clever2014_PAMM,
  Title                    = {Studying Dynamical Principles of Human Locomotion using Inverse Optimal Control},
  Author                   = {Clever, D. and Hatz, K. and Mombaur, K.},
  Journal                  = {Proceedings in Applied Mathematics and Mechanics},
  Year                     = {2014},
  Number                   = {1},
  Pages                    = {801--802},
  Volume                   = {14},

  Publisher                = {Wiley Online Library},
  Timestamp                = {2016.07.27}
}

@InProceedings{Clever2014,
  Title                    = {A new template model for optimization studies of human walking on different terrains},
  Author                   = {D. Clever and K. Mombaur},
  Booktitle                = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  Year                     = {2014},
  Pages                    = {500--505},

  Abstract                 = {Human movement, as for example human gait, can be considered as an optimal realization of some given task. If the optimization criteria for different types of gait were known, this knowledge could help to improve robot motion generation and control, also for complex walking motions on slopes or stairs. Unfortunately, in general the criteria for which the naturally performed human motion is optimal, are not known. Therefore, in this article we study the relevance of different measurable quantities in human locomotion based on human motion capture data and a new template model that is able to capture the main dynamical characteristics we are interested in. To this end we introduce a three dimensional actuated walking model, with an upper body, two actuated legs and two point-masses as feet. Taking into account single and double support phases and the impact at touch down, the model is suitable to reproduce realistic three dimensional center of mass and swing foot trajectories even in constrained environments. In this article, we focus on walking up and down stairs and compare the observed quantities.},
  Doi                      = {10.1109/HUMANOIDS.2014.7041408},
  ISSN                     = {2164-0572},
  Keywords                 = {humanoid robots;legged locomotion;motion control;optimisation;robot dynamics;trajectory control;3D actuated walking model;3D center of mass;actuated legs;complex walking motion;constrained environment;double support phase;dynamical characteristics;human gait;human locomotion;human motion capture data;human movement;human walking;optimization criteria;point mass;robot motion control;robot motion generation;single support phase;slopes;stairs;swing foot trajectory;template model;terrain;touch down;upper body;Computational modeling;Foot;Legged locomotion;Optimal control;Optimization;Solid modeling;Trajectory},
  Timestamp                = {2015.11.17}
}

@Conference{Clever2016,
  Title                    = {Inverse optimal control based identification of optimality criteria in whole-body human walking on level ground},
  Author                   = {D. Clever and R. M. Schemschat and M. L. Felis and K. Mombaur},
  Booktitle                = {Proceedings of IEEE RAS/EMBS International Conference on Biomedical Robotics and Biomechatronics},
  Year                     = {2016},
  Pages                    = {1192--1199},

  Owner                    = {jf2lin},
  Timestamp                = {2016.07.27}
}

@Article{Clifton2012,
  Title                    = {Gaussian Processes for Personalised e-Health Monitoring with Wearable Sensors},
  Author                   = {Clifton, L. and Clifton, D. and Pimentel, M. and Watkinson, P. and Tarassenko, L.},
  Journal                  = {IEEE Transactions on Biomedical Engineering},
  Year                     = {2013},

  Month                    = { },
  Number                   = {1},
  Pages                    = {193--197},
  Volume                   = {60},

  Abstract                 = {Advances in wearable sensing and communications infrastructure have allowed the widespread development of prototype medical devices for patient monitoring. However, such devices have not penetrated into clinical practice, primarily due to a lack of research into intelligent analysis methods that are sufficiently robust to support large-scale deployment. Existing systems are typically plagued by large false-alarm rates, and an inability to cope with sensor artefact in a principled manner. This paper has two aims: (i) proposal of a novel, patientpersonalised system for analysis and inference in the presence of data uncertainty, typically caused by sensor artefact and data incompleteness; (ii) demonstration of the method using a large-scale clinical study in which 200 patients have been monitored using the proposed system. This latter provides muchneeded evidence that personalised e-health monitoring is feasible within an actual clinical environment, at scale, and that the method is capable of improving patient outcomes via personalised healthcare.},
  Doi                      = {10.1109/TBME.2012.2208459},
  ISSN                     = {0018-9294},
  Timestamp                = {2012.07.18}
}

@InProceedings{Cohen2013,
  Title                    = {Automated Detection of Sleep Apnea in Infants Using Minimally Invasive Sensors},
  Author                   = {Cohen, G. and de Chazal, P.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {To address the difficult and necessity of early detection of sleep apnea hypopnea syndrome in infants, we present a study into the effectiveness of pulse oximetry as a minimally invasive means of automated diagnosis of sleep apnea in infants. Overnight polysomnogram data from 328 infants were used to extract time-domain based oximetry features and scored arousal data for each subject. These records were then used to determine apnea events and to train a classifier model based on linear discriminants. Performance of the classifier was evaluated using a leave-one-out cross-validation scheme and an accuracy of 68% was achieved, with a specificity of 68.6% and a sensitivity of 55.9%.},
  Keywords                 = {EMBC2013},
  Review                   = {Looked at an existing database and extracted correlations between patterns and outcomes. For features, they looked at mean, medium, min, threshold, inter-measurement intervals. Not actually what we're looking for.

Cohen and de Chazal \cite{Cohen2013} wanted to detect sleep apnea in infants. They examined the National Collaborative Home Infant Monitoring Evaluation (CHIME) and extracted several physiological features, such as pulse oximetry (SpO2), as well as infant sleep state data and arousal events. The sleep state data was used to discard data right before and after sleep state change to remove transient data. Arousal events were assumed to be caused by sleep apnea, and was labeled accordingly. A linear discriminant classifier was used to determine the correlation between SpO2 levels and sleep apnea occurrences, by examining the observation data at 30 second intervals. An accuracy of 68\% was reported.},
  Timestamp                = {2013.07.31}
}

@Article{Coleman1996,
  Title                    = {An Interior, Trust Region Approach for Nonlinear Minimization Subject to Bounds},
  Author                   = {Coleman, T. F. and Li, Y.},
  Journal                  = {SIAM Journal on Optimization},
  Year                     = {1996},
  Pages                    = {418--445},
  Volume                   = {6},

  Owner                    = {jf2lin},
  Timestamp                = {2017.04.09}
}

@TechReport{Colton2007,
  Title                    = {The Balance Filter},
  Author                   = {Colton, S.},
  Institution              = {Chief Delphi},
  Year                     = {2007},

  Review                   = {Combines accelerometer and gyroscopes to attempt to address drift issues. Composite filter},
  Timestamp                = {2010.04.01}
}

@Article{Cooper2009,
  Title                    = {Inertial Sensor-based Knee Flexion/extension Angle Estimation},
  Author                   = {Cooper, G. and Sheret, I. and McMillian, L. and Siliverdis, K. and Sha, N. and Hodgins, D. and Kenney, L. and Howard, D.},
  Journal                  = {Journal of Biomechanics },
  Year                     = {2009},
  Number                   = {16},
  Pages                    = {2678--2685},
  Volume                   = {42},

  Abstract                 = {A new method for estimating knee joint flexion/extension angles from segment acceleration and angular velocity data is described. The approach uses a combination of Kalman filters and biomechanical constraints based on anatomical knowledge. In contrast to many recently published methods, the proposed approach does not make use of the earth's magnetic field and hence is insensitive to the complex field distortions commonly found in modern buildings. The method was validated experimentally by calculating knee angle from measurements taken from two \{IMUs\} placed on adjacent body segments. In contrast to many previous studies which have validated their approach during relatively slow activities or over short durations, the performance of the algorithm was evaluated during both walking and running over 5&#xa0;minute periods. Seven healthy subjects were tested at various speeds from 1 to 5&#xa0;mile/h. Errors were estimated by comparing the results against data obtained simultaneously from a 10 camera motion tracking system (Qualysis). The average measurement error ranged from 0.7 degrees for slow walking (1&#xa0;mph) to 3.4 degrees for running (5&#xa0;mph). The joint constraint used in the \{IMU\} analysis was derived from the Qualysis data. Limitations of the method, its clinical application and its possible extension are discussed. },
  Doi                      = {10.1016/j.jbiomech.2009.08.004},
  ISSN                     = {0021-9290},
  Keywords                 = {Kalman filters},
  Timestamp                = {2013.05.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S002192900900459X}
}

@Article{Corke1996,
  Title                    = {A Robotics Toolbox for {MATLAB}},
  Author                   = {Corke, P. I.},
  Journal                  = {IEEE Robotics and Automation Magazine},
  Year                     = {1996},
  Pages                    = {24--32},
  Volume                   = {3},

  Timestamp                = {2010.01.20}
}

@InProceedings{Corrales2008,
  Title                    = {Hybrid Tracking of Human Operators Using {IMU/UWB} Data Fusion by a Kalman Filter},
  Author                   = {Corrales, J. A. and Candelas, F. A. and Torres, F.},
  Booktitle                = {Proceedings of the ACM/IEEE International Conference on Human Robot Interaction},
  Year                     = {2008},
  Pages                    = {193--200},

  Abstract                 = {The precise localization of human operators in robotic workplaces is an important requirement to be satisfied in order to develop human-robot interaction tasks. Human tracking provides not only safety for human operators, but also context information for intelligent human-robot collaboration. This paper evaluates an inertial motion capture system which registers full-body movements of an user in a robotic manipulator workplace. However, the presence of errors in the global translational measurements returned by this system has led to the need of using another localization system, based on Ultra-WideBand (UWB) technology. A Kalman filter fusion algorithm which combines the measurements of these systems is developed. This algorithm unifies the advantages of both technologies: high data rates from the motion capture system and global translational precision from the UWB localization system. The developed hybrid system not only tracks the movements of all limbs of the user as previous motion capture systems, but is also able to position precisely the user in the environment.},
  Acmid                    = {1349848},
  Doi                      = {http://doi.acm.org/10.1145/1349822.1349848},
  ISBN                     = {978-1-60558-017-3},
  Keywords                 = {data fusion, human tracking and monitoring, indoor location, inertial sensors, kalman filter, motion capture, uwb, postural detection},
  Location                 = {Amsterdam, The Netherlands},
  Numpages                 = {8},
  Review                   = {- Uses IMU and a radio-based positioning system and combined them with Kalman},
  Timestamp                = {2011.03.01},
  Url                      = {http://doi.acm.org/10.1145/1349822.1349848}
}

@InProceedings{Costanza2005,
  Title                    = {Toward Subtle Intimate Interfaces for Mobile Devices Using an {EMG} Controller},
  Author                   = {Costanza, E. and Inverso, S. and Allen, R.},
  Booktitle                = {SIGCHI},
  Year                     = {2005},
  Pages                    = {481--9},

  Acmid                    = {1055039},
  Doi                      = {10.1145/1054972.1055039},
  ISBN                     = {1-58113-998-5},
  Keywords                 = {electromyogram, intimate interface, mobile computing, social acceptance, subtle interaction, wearable computing},
  Location                 = {Portland, Oregon, USA},
  Numpages                 = {9},
  Owner                    = {jf2lin},
  Review                   = {- bicep emg. recognizes trigger signals (ie detected a contraction). one to two gestures, based on emg std.dev peaks.},
  Timestamp                = {2015.04.03}
}

@Article{Cott2007,
  Title                    = {Barriers to Rehabilitation in Primary Health Care in Ontario: Funding and Wait Times for Physical Therapy Services},
  Author                   = {Cott, C. A. and Devitt, R. M. A. and Falter, L. and Soever, L. J. and Passalent, L. A.},
  Journal                  = {Physiotherapy Canada},
  Year                     = {2007},
  Pages                    = {173--183},
  Volume                   = {3},

  Abstract                 = {Purpose: The purpose of this study was to examine barriers to accessing physical therapy (PT) services in Ontario primary health care with respect to funding sources and wait times.

Methods: A stratified random sample of 1100 registered Ontario PTs and 3000 Ontario family physicians were surveyed by mail in 2004. Relationships were examined between PT wait times, funding source, geographical region and caseload composition.

Results: Physicians identified the cost of private rehabilitation and long wait times as the most common barriers to referring patients to rehabilitation. Wait times for PT were longer in publicly funded settings than in privately funded practice settings (p, 0.001) and in the North (p, 0.001) and East (p 5 0.010) regions of Ontario compared with the most urban region of Ontario. Patients with chronic musculoskeletal conditions, cardiopulmonary conditions and general debility were at least three times more likely to receive PT services at publicly funded than privately funded practice settings. Furthermore, patients with acute musculoskeletal conditions were less likely to receive PT services in publicly funded practice settings (odds ratio 5 0.11, 95% confidence interval 5 0.05-0.23).

Conclusions: Current Ontario health-care structures may affect access to PT services for vulnerable populations such as those with chronic conditions, those lacking private health insurance and those living in less urban regions of Ontario.},
  Doi                      = {10.3138/ptc.59.3.173},
  Keywords                 = {Physiotherapy},
  Timestamp                = {2011.12.23}
}

@Misc{CrossbowTechnology2012,
  Title                    = {MICAz Mesh Network Radio Module Datasheet},

  Author                   = {{Crossbow Technology}},
  Year                     = {2012},

  Timestamp                = {2012.11.16},
  Url                      = {http://bullseye.xbow.com:81/Products/Product_pdf_files/Wireless_pdf/MICAz_OEM_Edition_Datasheet.pdf}
}

@InProceedings{Curey2004,
  Title                    = {Proposed IEEE inertial systems terminology standard and other inertial sensor standards},
  Author                   = {Curey, R. K. and Ash, M. E. and Thielman, L. O. and Barker, C. H.},
  Booktitle                = {Proceedings of the Position Location and Navigation Symposium},
  Year                     = {2004},
  Pages                    = {83--90},

  Abstract                 = {A new inertial systems terminology standard is being developed by the IEEE/AESS Gyro and Accelerometer Panel for consideration by the IEEE Standards Board as IEEE Std 1559. It is intended to be a companion to IEEE Std 528-2001, IEEE Standard for Inertial Sensor Terminology. These two documents as well as IEEE standards that have been published for single- and two-degree-of-freedom spinning wheel gyros, laser gyros, interferometric fiber optic gyros, Coriolis vibratory gyros (including MEMS gyros), angular accelerometers, linear accelerometers, accelerometer centrifuge testing, and an inertial sensor test equipment and analysis document are discussed in this paper.},
  Doi                      = {10.1109/PLANS.2004.1308978},
  ISSN                     = { },
  Keywords                 = {Coriolis vibratory gyros; IEEE inertial systems terminology standard; MEMS gyros; accelerometer centrifuge testing; angular accelerometers; inertial sensor standards; inertial sensor test equipment; interferometric fiber optic gyros; laser gyros; linear accelerometers; spinning wheel gyros; Global Positioning System; IEEE standards; accelerometers; gyroscopes; inertial navigation; inertial systems; micromechanical devices; microsensors;},
  Review                   = {Lists standardized naming conventions for IMU things.},
  Timestamp                = {2011.07.19}
}

@Article{Cybenko1989,
  Title                    = {Approximation by Superpositions of a Sigmoidal function},
  Author                   = {Cybenko, G. V.},
  Journal                  = {Mathematics of Control, Signals and Systems},
  Year                     = {1989},
  Number                   = {4},
  Pages                    = {303--314},
  Volume                   = {2},

  Keywords                 = {Lab reading (Cecille)},
  Review                   = {- Don't want too much neural network (NN) layers -> overfits data},
  Timestamp                = {2011.01.18}
}

@InProceedings{D'Souza2001,
  Title                    = {Learning Inverse Kinematics},
  Author                   = {D'Souza, A. and Vijayakumar, S. and Schaal, S.},
  Booktitle                = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2001},
  Pages                    = {298 -303},
  Volume                   = {1},

  Abstract                 = {Real-time control of the end-effector of a humanoid robot in external coordinates requires computationally efficient solutions of the inverse kinematics problem. In this context, this paper investigates inverse kinematics learning for resolved motion rate control (RMRC) employing an optimization criterion to resolve kinematic redundancies. Our learning approach is based on the key observations that learning an inverse of a nonuniquely invertible function can be accomplished by augmenting the input representation to the inverse model and by using a spatially localized learning approach. We apply this strategy to inverse kinematics learning and demonstrate how a recently developed statistical learning algorithm, locally weighted projection regression, allows efficient learning of inverse kinematic mappings in an incremental fashion even when input spaces become rather high dimensional. Our results are illustrated with a 30-DOF humanoid robot},
  Doi                      = {10.1109/IROS.2001.973374},
  Keywords                 = {30-DOF humanoid robot;RMRC;computationally efficient solutions;humanoid robot end-effector;incremental learning;inverse kinematics learning;kinematic redundancies;locally weighted projection regression;nonuniquely invertible function inverse;optimization criterion;real-time control;resolved motion rate control;statistical learning algorithm;computational complexity;learning (artificial intelligence);real-time systems;redundant manipulators;robot kinematics;statistical analysis; ECE780},
  Review                   = {Inverse Kinematics with Machine Learning

Introduction
Need to teach things in task space, but need to convert that to actuator space for the joints. We'll look at redundant manipulators. In these, we have many non-unique solutions, so we'll need specific ways to handle this. Redundant DOFs are not a bad thing; we can use them to impose optimization criterions. We can impose functions with global minimums, but that's computationally expensive. So what we could do is look for a optimum change (delta theta) for a small given motion (delta x), then integrate the delta theta to get the joint space path motion (known as RMRC - Resolved Motion Rate Control). 

To generate a solution, however, we'll need to invert the Jacobian. For a non-square Jacobian, we need to add additional constrants to obtain a unique solution. So lets somehow combine RMRC with the psuedo-inverse.



Learning Inverse Kinematics
IK i shandy when...
- FK model is not available
- End-effector Cartesian info is not in robot frame
- Analytical solutions are too expensive

Learning methods are self-calibrating, so won't suffer from issues like sensor noise cumulation or inaccurate FK model. Also, we won't have any kinematic singularity issues if we're learning a solution. However, IK on a redundant system has infinite solutions. Learning methods needs to make sure that calculated angles form a convex set (belongs totally within) with the training angle ranges, or else the calculated angles are invalid. Unfortunally, this happens all the time with IK (IK are non-convex, due to, I'm guessing, the fact that there are infinite number of solutions). However, if we fix a few angles ("within the vicinity of a particular theta")


Locally Weighted Projection Regression (LWPR)
LWPR is a supervised learning algorithm. It approximates non-linear functions with piecewise linear models. The validity of these piecewise functions ("receptive fields")...ie how closely they match the actual non-linear function, is calculated with a Gaussian function. To decrease the computation expensiveness, a 1dim regression is used instead of 2dim linear regression. Which they use Partial Least Squares (PLS), slightly modified to including a forgetting factor to indicate how fast old data are forgotten. When the receptive field is determined to be insufficient (that 1dim regression is kept tracked of, and we're looking at the MSE), a new one is generated. 

Ultimately, we want to map (dx, theta) -> dtheta. (generate joint trajectory)
Input to the system is (dx, theta). 
Output to the system (to the robot) is (dtheta). 


Inverse Kinematics Learning with LWPR
Need a cost function, which decided to be as close as possible to some default posture theta_opt. So they have a function that minimizes the current angles from theta_opt. As an exploratory initial step for training, we give it a target task, but bias the motion such that it moves towards theta_opt. As time goes on, this bias weighting decreases, so it performs all it's motion commanded by its learned data. Apparently it picks it up pretty quickly. 


Experimentation - tracking a figure eight
- "Motor babbling" (random sinusoidal motion around each DOF) to train the IK algorithm -> results isn't that great, since the babbling didn't train the robot in the regions needed for the figure eight.

- After a minute of self-learning from attempting the figure eight, the robot tracked better
- What if we didn't babble at all, and just told the robot to attempt the motion? It converges after 3 minutes. 



Sidenotes: Partial Least Squares
It generates the linear regression model by projecting the independent and dependent (dependent and observable) varable into a new space. It is used to find relations between two matricies


Critism
- Ignores dynamics, so thus ignoring potentially dangerous accelerations
- What about impossible postures? 
- Old data?
- Joints in humanoids are typically round, therefore are characterized by sine functions, which are relatively non-linear. 
- If we have a bad linear estimate somewhere, there's no procedure to making that estimate better, only replacing nearby areas with another linear function},
  Timestamp                = {2011.01.07}
}

@InBook{Dasgupta2006_DynamicProgramming,
  Title                    = {Algorithms},
  Author                   = {Dasgupta, S. and Papadimitriou, C. H. and Vazirani, U.},
  Chapter                  = {Dynamic Programming},
  Pages                    = {169--199},
  Publisher                = {McGraw-Hill, Inc.},
  Year                     = {2006},

  Timestamp                = {2014.03.14}
}

@Article{Davidson2002,
  Title                    = {A Comparison of Five Low Back Disability Questionnaires: Reliability and Responsiveness},
  Author                   = {Davidson, M. and Keating, J. L.},
  Journal                  = {Physical Therapy},
  Year                     = {2002},
  Number                   = {1},
  Pages                    = {8--24},
  Volume                   = {82},

  Abstract                 = {Background and Purpose. The aim of this study was to examine 5 commonly used questionnaires for assessing disability in people with low back pain. The modified Oswestry Disability Questionnaire, the Quebec Back Pain Disability Scale, the Roland-Morris Disability Questionnaire, the Waddell Disability Index, and the physical health scales of the Medical Outcomes Study 36-Item Short-Form Health Survey (SF-36) were compared in patients undergoing physical therapy for low back pain. Subjects and Methods. Patients with low back pain completed the questionnaires during initial consultation with a physical therapist and again 6 weeks later (n=106). Test-retest reliability was examined for a group of 47 subjects who were classified as “unchanged” and a subgroup of 16 subjects who were self-rated as “about the same.” Responsiveness was compared using standardized response means, receiver operating characteristic curves, and the proportions of subjects who changed by at least as much as the minimum detectable change (MDC) (90% confidence interval [CI] of the standard error for repeated measures). Scale width was judged as adequate if no more than 15% of the subjects had initial scores at the upper or lower end of the scale that were insufficient to allow change to be reliably detected. Results. Intraclass correlation coefficients (2,1) calculated to measure reliability for the subjects who were classified as “unchanged” and those who were self-rated as “about the same” were greater than .80 for the Oswestry and Quebec questionnaires and the SF-36 Physical Functioning scale and less than .80 for the Waddell and Roland-Morris questionnaires and the SF-36 Role Limitations–Physical and Bodily Pain scales. None of the scales were more responsive than any other. Discussion and Conclusion. Measurements obtained with the modified Oswestry Disability Questionnaire, the SF-36 Physical Functioning scale, and the Quebec Back Pain Disability Scale were the most reliable and had sufficient width scale to reliably detect improvement or worsening in most subjects. The reliability of measurements obtained with the Waddell Disability Index was moderate, but the scale appeared to be insufficient to recommend it for clinical application. The Roland-Morris Disability Questionnaire and the Role Limitations–Physical and Bodily Pain scales of the SF-36 appeared to lack sufficient reliability and scale width for clinical application.},
  Eprint                   = {http://ptjournal.apta.org/content/82/1/8.full.pdf+html},
  Timestamp                = {2013.12.10},
  Url                      = {http://ptjournal.apta.org/content/82/1/8.abstract}
}

@Article{Davis1991,
  Title                    = {A Gait Analysis Data Collection and Reduction Technique},
  Author                   = {Davis, R. B. and \~{O}unpuu, S. and Tybursky, D. and Gage, J. R.},
  Journal                  = {Human Movement Science},
  Year                     = {1991},
  Number                   = {5},
  Pages                    = {575--587},
  Volume                   = {10},

  Abstract                 = {The clinical objective of the gait analysis laboratory, developed by United Technologies Corporation (Hartford, CT, USA) in 1980, at the Newington Children's Hospital is to provide quantified assessments of human locomotion which assist in the orthopaedic management of various pediatric gait pathologies. The motion measurement system utilizes a video-based data collection strategy similar to commercially available systems for motion data collection. Anatomically aligned, passive, retroreflective markers placed on the subject are illuminated, detected, and stored in dedicated camera hardware while data are acquired from force platforms and EMG transducers. Three-dimensional marker position information is used to determine: (i) the orientation of segmentally-embedded coordinate systems, (ii) instantaneous joint center locations, and (iii) joint angles. Joint kinetics, i.e., moments and powers, may also be computed if valid force plate data are collected.},
  Doi                      = {DOI: 10.1016/0167-9457(91)90046-Z},
  ISSN                     = {0167-9457},
  Keywords                 = {Helen Hayes marker set},
  Timestamp                = {2011.07.18},
  Url                      = {http://www.sciencedirect.com/science/article/pii/016794579190046Z}
}

@Article{Davy1987,
  Title                    = {A dynamic optimization technique for predicting muscle forces in the swing phase of gait},
  Author                   = {D. T. Davy and M. L. Audu},
  Journal                  = {Journal of Biomechanics},
  Year                     = {1987},
  Number                   = {2},
  Pages                    = {187--201},
  Volume                   = {20},

  Abstract                 = {The muscle force sharing problem was solved for the swing phase of gait using a dynamic optimization algorithm. For comparison purposes the problem was also solved using a typical static optimization algorithm. The objective function for the dynamic optimization algorithm was a combination of the tracking error and the metabolic energy consumption. The latter quantity was taken to be the sum of the total work done by the muscles and the enthalpy change during the contraction. The objective function for the static optimization problem was the sum of the cubes of the muscle stresses. To solve the problem using the static approach, the inverse dynamics problem was first solved in order to determine the resultant joint torques required to generate the given hip, knee and ankle trajectories. To this effect the angular velocities and accelerations were obtained by numerical differentiation using a low-pass digital filter. The dynamic optimization problem was solved using the Fletcher-Reeves conjugate gradient algorithm, and the static optimization problem was solved using the Gradient-restoration algorithm. The results show influence of internal muscle dynamics on muscle control histories vis a vis muscle forces. They also illustrate the strong sensitivity of the results to the differentiation procedure used in the static optimization approach.},
  Doi                      = {http://dx.doi.org/10.1016/0021-9290(87)90310-1},
  ISSN                     = {0021-9290},
  Timestamp                = {2017.04.17},
  Url                      = {http://www.sciencedirect.com/science/article/pii/0021929087903101}
}

@InProceedings{Davy2002,
  Title                    = {Detection of Abrupt Spectral Changes Using Support Vector Machines: An Application to Audio Signal Segmentation},
  Author                   = {Davy, M. and Godsill, S.},
  Booktitle                = {Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  Year                     = {2002},
  Pages                    = {II--1313},
  Volume                   = {2},

  Abstract                 = {In this paper, we introduce an hybrid time-frequency/support vector machine algorithm for the detection of abrupt spectral changes. A stationarity index is derived from support vector novelty detection theory by using sub-images extracted from the time-frequency plane as feature vectors. Simulations show the efficiency of this new algorithm for audio signal segmentation, compared to another nonparametric detector.},
  Review                   = {- Employs Cohen's Time-Freq Representation to account for both time and frequency changes in audio signals (some sort of parsing function). Describes signal energy content
- Paper uses SVM to classify the TFR signals. 
- Given some TFR training data, create SVMs, then use "support vector novelty detection" (or "soft margin novelty detection") to determine if a given window of the obs data is "normal" or "novel" compared to SVM -> segment if marked novel
- It would seem that they used a single SVM...


Davy and Godsill \cite{Davy2002} proposes a hybrid time-frequency and SVM algorithm to detect spectral changes to perform audio signal segmentation. Cohen's class time frequency representation describes a given signal's energy content, where abrupt changes are characterized by abrupt beginning/ending of several spectral components at a time. This is combined with SVM novelty detection to determine if a given observation window is atypical or not. If atypical, the SVM suggests a segment. The algorithm was applied to some music clips of guitars playing, but no segmentation accuracy was given.

Davy and Godsill \cite{Davy2002} apply SVM to detect spectral changes to perform audio signal segmentation. Cohen's class time frequency representation describes a given signal's energy content, where abrupt changes are characterized by abrupt beginning/ending of several spectral components at a time. This is used to train an one-verses-all SVM classifier, where the abrupt changes are considered not within the class of interest. Over a sliding window, when SVM detects these changes, a segment is detected. The algorithm was applied to some music clips of guitars playing, but no segmentation accuracy was given.},
  Timestamp                = {2013.08.29}
}

@TechReport{DelaTorre2009,
  Title                    = {Guide to the Carnegie Mellon University Multimodal Activity ({CMU-MMAC}) Database},
  Author                   = {De la Torre, F. and Hodgins, J. and Bargteil, A. and Martin, X. and Macey, J. and Collado, A. and Beltran, P.},
  Institution              = {Carnegie Mellon University Robotics Institute},
  Year                     = {2009},

  Keywords                 = {Motion Capture, postural detection},
  Timestamp                = {2011.03.22},
  Url                      = {http://kitchen.cs.cmu.edu/index.php}
}

@Article{Dejnabadi2006,
  Title                    = {Estimation and Visualization of Sagittal Kinematics of Lower Limbs Orientation Using Body-fixed Sensors},
  Author                   = {Dejnabadi, H. and Jolles, B. M. and Casanova, E. and Fua, P. and Aminian, K.},
  Journal                  = {IEEE Transactions on Biomedical Engineering},
  Year                     = {2006},
  Number                   = {7},
  Pages                    = {1385--1393},
  Volume                   = {53},

  Abstract                 = {A new method of estimating lower limbs orientations using a combination of accelerometers and gyroscopes is presented. The model is based on estimating the accelerations of ankle and knee joints by placing virtual sensors at the centers of rotation. The proposed technique considers human locomotion and biomechanical constraints, and provides a solution to fusing the data of gyroscopes and accelerometers that yields stable and drift-free estimates of segment orientation. The method was validated by measuring lower limb motions of eight subjects, walking at three different speeds, and comparing the results with a reference motion measurement system. The results are very close to those of the reference system presenting very small errors (Shank: rms=1.0, Thigh: rms=1.6 deg;) and excellent correlation coefficients (Shank: r=0.999, Thigh: r=0.998). Technically, the proposed ambulatory system is portable, easily mountable, and can be used for long term monitoring without hindrance to natural activities. Finally, a gait analysis tool was designed to visualize the motion data as synthetic skeletons performing the same actions as the subjects.},
  Doi                      = {10.1109/TBME.2006.873678},
  ISSN                     = {0018-9294},
  Keywords                 = {accelerometers;ankle;biomechanical constraints;body-fixed sensors;gait analysis;gyroscopes;human locomotion;knee joints;lower limbs orientation;sagittal kinematics estimation;sagittal kinematics visualization;segment orientation;virtual sensors;walking;accelerometers;biomedical equipment;gait analysis;gyroscopes;kinematics;sensors;Acceleration;Adult;Aged;Algorithms;Biomechanics;Computer Graphics;Diagnosis, Computer-Assisted;Equipment Design;Equipment Failure Analysis;Female;Gait;Humans;Joints;Lower Extremity;Male;Middle Aged;Monitoring, Ambulatory;Orientation;Range of Motion, Articular;Software;Transducers;User-Computer Interface;},
  Review                   = {Dejnabadi2006 (cited by 48)
Cited by: 48
Motion type: Gait on treadmill. Kept slow in order to be able to use accel as inclionometer
Recovery methodology: 2-axis accel, gyro. Trig for accel. Integration for gyro. Using accel during stationary and double-support phase since low leg movement during those times.
Verification method: Optical camera with marker
Subject demographics: 8 subjects, mean age 58.7
Error reported: RMS deg. 0.74 at shank. 1.42 at thigh.},
  Timestamp                = {2012.02.03}
}

@Article{Vecchio2003,
  Title                    = {Decomposition of human motion into dynamics-based primitives with application to drawing tasks },
  Author                   = {Del Vecchio, D. and Murray, R. M. and Perona, P.},
  Journal                  = {Automatica },
  Year                     = {2003},
  Number                   = {12},
  Pages                    = {2085--2098},
  Volume                   = {39},

  Abstract                 = {Using tools from dynamical systems and systems identification, we develop a framework for the study of primitives for human motion, which we refer to as movemes. The objective is understanding human motion by decomposing it into a sequence of elementary building blocks that belong to a known alphabet of dynamical systems. We develop a segmentation and classification algorithm in order to reduce a complex activity into the sequence of movemes that have generated it. We test our ideas on data sampled from five human subjects who were drawing figures using a computer mouse. Our experiments show that we are able to distinguish between movemes and recognize them even when they take place in activities containing an unspecified number of movemes. },
  Doi                      = {http://dx.doi.org/10.1016/S0005-1098(03)00250-4},
  ISSN                     = {0005-1098},
  Keywords                 = {Classification},
  Timestamp                = {2014.12.22}
}

@InProceedings{DelVecchio2002,
  author    = {Del Vecchio, D. and Murray, R. M. and Perona, P.},
  title     = {Primitives for Human Motion: A Dynamical Approach},
  booktitle = {International Federation of Automatic Control World Congress},
  year      = {2002},
  abstract  = {Using tools from dynamical systems theory and systems identi¯cation theory we develop
the study of primitives for human motion which we refer to asmovemes. We introduce basic
de¯nitions of dynamical independenceof LTI systems andsegmentabilityof signals and we
develop classi¯cation and segmentation algorithms for two dimensional motions. We test
our ideas on data sampled from four human subjects who were engaged in a simple reallife activity including two movemes. Our experiments show that we are able to distinguish
between the two movemes and recognize them even when they take place in an activity
containing more than one moveme.},
  groups    = {Lit Review 2013-09},
  timestamp = {2013.10.08},
}

@Article{Delacourt2000,
  Title                    = {{DISTBIC}: A Speaker-based Segmentation for Audio Data Indexing},
  Author                   = {Delacourt, P. and Wellekens, C. J.},
  Journal                  = {Speech Communication },
  Year                     = {2000},
  Note                     = {Accessing Information in Spoken Audio},
  Pages                    = {111--126},
  Volume                   = {32},

  Abstract                 = {In this paper, we address the problem of speaker-based segmentation, which is the first necessary step for several indexing tasks. It aims to extract homogeneous segments containing the longest possible utterances produced by a single speaker. In our context, no assumption is made about prior knowledge of the speaker or speech signal characteristics (neither speaker model, nor speech model). However, we assume that people do not speak simultaneously and that we have no real-time constraints. We review existing techniques and propose a new segmentation method, which combines two different segmentation techniques. This method, called DISTBIC, is organized into two passes: first the most likely speaker turns are detected, and then they are validated or discarded. The advantage of our algorithm is its efficiency in detecting speaker turns even close to one another (i.e., separated by a few seconds).},
  Doi                      = {http://dx.doi.org/10.1016/S0167-6393(00)00027-3},
  ISSN                     = {0167-6393},
  Keywords                 = {Speaker turn detection},
  Review                   = {- want to be able to sort through audio records. hard to do compared to written records
- not online, no a priori data
- proposed an algorithm that determined who is speaking and when

(actually, can't tell if this is part of existing algorithm or they're proposing this one) Algorithm applied to the MFC, looking at 200ms segments at a time. The segments are separated into 3 classes by looking at the MAD values, which determines if the signal is noise, is some speech, or unreliable. GMMs are trained from the speech segments to improve label recognition. A maximum likelihood approach i sused to separate speaker type ("pilots" or "air traffic controller").


MCP: mel-frequency cepstrum (MFC) is a representation of the short-term power spectrum of a sound, based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency.
MAD: median absolute deviation

Cuz they go on to talk about other segmentation methods. 
- Silence detection - can look at energy and thresholidng, but assumes that there's always a good chunk of silence between speakers
- Speaker turn detection - segment based assumption that two different speakers would result in some difference. So they take two adjacent windows and take the KL between them. They also used BIC as a variance change detector.

Hm. This paper uses KL. (come back in a bit, this alg is totally not online but might be useful to ponder)


Delacourt and Wellekens \cite{Delacourt2000} aims to generate segments containing the longest possible utterances produced by a single speaker. The algorithm assumes no \emph{a priori} knowledge of the speaker, but also assume that no two speakers are speaking simultaneously and that no real-time constraints exist. This paper uses two sliding windows (denote as window $X$ and window $Y$) that are sequentially connected, and examines several different criteria to determine if a segment should be declared between the two sliding windows. These criteria are: (1) the generalized likelihood ratio ($R$ = $L_{X+Y}$/($L_X$ $L_Y$)), where $L_X$ and $L_Y$ represents the likelihood of the two windows and $L_{X+Y}$ represents the likelihood of the two windows combined. This was first proposed by Gish and Schmidt \cite{Gish1994}. (2) the Kullback-Leibler distance is calculated and considered. (3) several similarity measures that compare the covariance matrix of $X$ and $Y$ are examined. If the two windows contain data from the same speaker, the two covariance matrices should be similar. (4) if the two windows contains the voice data from two different sources, it would be best modeled by two different Gaussian distributions instead of just one. The Bayesian information criterion (BIC) can be assessed with one or two Gaussians, and its BIC scores can be compared. If the BIC score is lower for two Gaussians, then it is likely a segmentation point.

Delacourt and Wellekens \cite{Delacourt2000} apply both Gish \etal's GRL \cite{Gish1991} and Tritschler and Gopinath's BIC test \cite{Tritschler1999} in a two-tier system. A two temporally adjacent windows, denoted as $x_1$ and $x_2$, are passed along the observation data, and declared segments when a given distance metric is at a turning point. In the first pass, they tested several different distance metrics. Of the examined algorithms used to compare the two windows, Gish's approach \cite{Gish1991} and KL distances outperform two other distance metrics, the similarity measure and the speaker turn detector. The similarity measure looks at the covariances of the two windowed data (See Figure \ref{fig:Delacourt2000_segmentModel}), $\Sigma_1$ and $\Sigma_2$ and calculate the similarity matrix $\Gamma = \Sigma_1 \Sigma_2^{-1}$. The closer $\Gamma$ is to the identity matrix, the more similar $x_1$ is to $x_2$. Segments can also be declared on speaker turns, where the range of a positive peak to the negative peak to the left and right of it both exceeds some threshold (See Figure \ref{fig:Delacourt2000_speakerTurn}). In the second tier, Tritschler's BIC test \cite{Tritschler1999} is used to refine the segments. This algorithm was tested against several sets of conversational datasets. Using the same verification scheme as Tritschler and Gopinath \cite{Tritschler1999}, the proposed algorithm report an average $Err_{FAR}$ of 34\%, and a $Err_{MAR}$ false negative rate of 17\% if only the distance metric is used, and $Err_{FAR}$ of 22\%, and a $Err_{MAR}$ false negative rate of 20\% if the BIC component is added as well.

Delacourt and Wellekens \cite{Delacourt2000} apply both the GRL \cite{Gish1991} and the BIC test \cite{Tritschler1999} in a two-tier system. A two temporally adjacent windows, denoted as $x_1$ and $x_2$, are passed along the observation data, and declared segments when a given distance metric is at a turning point. In the first pass, they tested several different distance metrics. Of the examined algorithms used to compare the two windows, Gish's approach \cite{Gish1991} and KL distances outperform two other distance metrics, the similarity measure and the speaker turn detector. The similarity measure looks at the covariances of the two windowed data (See Figure \ref{fig:Delacourt2000_segmentModel}), $\Sigma_1$ and $\Sigma_2$ and calculate the similarity matrix $\Gamma = \Sigma_1 \Sigma_2^{-1}$. The closer $\Gamma$ is to the identity matrix, the more similar $x_1$ is to $x_2$. Segments can also be declared on speaker turns, where the range of a positive peak to the negative peak to the left and right of it both exceeds some threshold (See Figure \ref{fig:Delacourt2000_speakerTurn}). In the second tier, Tritschler's BIC test \cite{Tritschler1999} is used to refine the segments.},
  Timestamp                = {2013.08.09}
}

@Book{DeLisa2005,
  Title                    = {Physical Medicine and Rehabilitation: Principles and Practice, 4th edition},
  Author                   = {DeLisa, J. A. and Gans, B. M. and Walsh, N. E. and Bockenek, W. L.},
  Publisher                = {Lippincott Williams and Wilkins},
  Year                     = {2005},

  Timestamp                = {2014.02.22}
}

@InProceedings{DeMenthon2003,
  Title                    = {Video Retrieval using Spatio-temporal Descriptors},
  Author                   = {DeMenthon, D. and Doermann, D.},
  Booktitle                = {Proceedings of the ACM International Conference on Multimedia},
  Year                     = {2003},
  Pages                    = {508--517},

  Abstract                 = {This paper describes a novel methodology for implementing video search functions such as retrieval of near-duplicate videos and recognition of actions in surveillance video. Videos are divided into half-second clips whose stacked frames produce 3D space-time volumes of pixels. Pixel regions with consistent color and motion properties are extracted from these 3D volumes by a threshold-free hierarchical space-time segmentation technique. Each region is then described by a high-dimensional point whose components represent the position, motion and, when possible, color of the region. In the indexing phase for a video database, these points are assigned labels that specify their video clip of origin. All the labeled points for all the clips are stored into a single binary tree for efficient $k$-nearest neighbor retrieval. The retrieval phase uses video segments as queries. Half-second clips of these queries are again segmented to produce sets of points, and for each point the labels of its nearest neighbors are retrieved. The labels that receive the largest numbers of votes correspond to the database clips that are the most similar to the query video segment. We illustrate this approach for video indexing and retrieval and for action recognition. First, we describe retrieval experiments for dynamic logos, and for video queries that differ from the indexed broadcasts by the addition of large overlays. Then we describe experiments in which office actions (such as pulling and closing drawers, taking and storing items, picking up and putting down a phone) are recognized. Color information is ignored to insure independence to people's appearance. One of the distinct advantages of using this approach for action recognition is that there is no need for detection or recognition of body parts.},
  Review                   = {- movement (video) seg},
  Timestamp                = {2013.08.29}
}

@InProceedings{Diehl2003_svm,
  Title                    = {{SVM} Incremental Learning, Adaptation and Optimization},
  Author                   = {Diehl, C. P. and Cauwenberghs, G.},
  Booktitle                = {Proceedings of the International Joint Conference on Neural Networks},
  Year                     = {2003},
  Pages                    = {2685--2690},
  Volume                   = {4},
  Abstract                 = {The objective of machine learning is to identify a model that yields good generalization performance. This involves repeatedly selecting a hypothesis class, searching the hypothesis class by minimizing a given objective function over the model's parameter space, and evaluating the generalization performance of the resulting model. This search can be computationally intensive as training data continuously arrives, or as one needs to tune hyperparameters in the hypothesis class and the objective function. In this paper, we present a framework for exact incremental learning and adaptation of support vector machine (SVM) classifiers. The approach is general and allows one to learn and unlearn individual or multiple examples, adapt the current SVM to changes in regularization and kernel parameters, and evaluate generalization performance through exact leave-one-out error estimation.},
  Doi                      = {10.1109/IJCNN.2003.1223991},
  ISSN                     = {1098-7576},
  Keywords                 = {generalisation (artificial intelligence);learning (artificial intelligence);optimisation;support vector machines;adaptation;exact leave-one-out error estimation;generalization;hyperparameters;hypothesis class;incremental learning;kernel parameters;optimization;regularization;support vector machine classifiers;Error analysis;Kernel;Laboratories;Machine learning;Physics;Risk management;Statistical learning;Support vector machine classification;Support vector machines;Training data},
  Review                   = {SVs can be separated into 3 types:
- margin support: on the margin
- error support: violating the margin
- reserve support: exceed the margin -> during incremental learning, things that exceed the margin are automatically added to this category, while the other two will not be categorized yet},
  Timestamp                = {2013.10.14}
}

@Article{Dillmann2010,
  Title                    = {Advances in Robot Programming by Demonstration},
  Author                   = {Dillmann, R. and Asfour, T. and Do, M. and Jakel, R. and Kasper, A. and Azad, P. and Ude, A. and Schmidt-Rohr, S. R. and Losch, M.},
  Journal                  = {Kustliche Intelligenz},
  Year                     = {2010},
  Number                   = {4},
  Pages                    = {295--303},
  Volume                   = {24},

  Doi                      = {10.1007/s13218-010-0060-0},
  ISSN                     = {0933-1875},
  Language                 = {English},
  Publisher                = {Springer-Verlag},
  Timestamp                = {2013.09.29},
  Url                      = {http://dx.doi.org/10.1007/s13218-010-0060-0}
}

@Article{Dillmann2008,
  Title                    = {Imitation Learning of Dual-arm Manipulation Tasks in Humanoid Robots},
  Author                   = {Dillmann, R. and Azad, P. and Gyarfas, F. and Asfour, T.},
  Journal                  = {International Journal of Humanoid Robotics},
  Year                     = {2008},
  Number                   = {2},
  Pages                    = {183--202},
  Volume                   = {5},

  Doi                      = {10.1142/S0219843608001431},
  Eprint                   = {http://www.worldscientific.com/doi/pdf/10.1142/S0219843608001431},
  Timestamp                = {2013.09.25},
  Url                      = {http://www.worldscientific.com/doi/abs/10.1142/S0219843608001431}
}

@Article{Dillmann2000,
  author    = {Dillmann, R. AND Rogalla, O. AND Ehrenmann, M. AND Zollner, R. AND Bordegoni, M.},
  title     = {Learning Robot Behaviour and Skills Based on Human Demonstration and Advice: The Machine Learning Paradigm},
  journal   = {Proceedings of the International Symposium on Robotics Research},
  year      = {2000},
  volume    = {9},
  pages     = {229--238},
  abstract  = {Service robots require easy programming methods allowing the unexperienced human user to easily integrate motion and perception skills or complex problem solving strategies. To achieve this goal, robots should learn from operators how and what to do considering hard- and software constraints. Various approaches modelling the man-machine skill transfer have been proposed. Systems following the Programming by Demonstration (PbD) paradigm that were developed within the last decade are getting closer to this goal. 

However, most of these systems lack the possibility for the user to supervise and influence the process of program generation after the initial demonstration was performed. In this paper a principle learning methodology is discussed, which allows to transfer human skills and to supervise the learning process including subsymbolic and symbolic task knowledge. Here, several existing approaches will be discussed and compared to each other. Moreover, a system approach is presented, integrating the overall process of sill transfer from a human to a robotic manipulation system. One major goal is to modify information gained by the demonstration in that way that different target systems are supported. The resulting PbD-system yields towards a hybrid learning approach in robotics to support natural programming based on human demonstration and user advice.},
  groups    = {IROS2014},
  keywords  = {motion primitive},
  review    = {Want to create an interface for unexperienced users so they can instruct a robot to do something. This Programming by Demonstration (PbD) is pretty popular. Lots of applications in reconstructing/replicating user demonstrated motions. Some look at breaking down a given task into subparts. This paper focuses on robotics application, but learning from users has applications in GUI design or workflow management. We'll look at 3 different ways to catigorize things. 

ABSTRACTION LEVEL - Complexity of task
- lower level or elementary skills
 - ie human reflex, or unconscious motion
 - train robots for grasping or peg-in-hole problems
 - training data for one robot is hard to retarget for another robot
 - but not too hard to train
- higher level or complex task knowledge
 - need a lot more input from the user

EXAMPLE DISTINCTION - How to give example to the system?
- Active
 - User performs action himself. System uses sensors to track 
 - Need power sensors
- Passive 
 - Robot controlled by external master
 - ie GUIs. a mouse
 - So there's some mapping between user action and actions to be carried out
- Implicit
 - User specify system goals by selecting it from a list of commands
 - User is restricted to giving only a specific set of instructions

INTERNAL REPRESENTATION 
- Look at it from the following aspects:
- Effects in environment
 - Observing user trajectory is often not enough for real world applications. What if the environment changes? Need to be able to track objects
- Trajectories
 - If all we want is to translate user demonstration to pre-defined action, this is 'operation based representation'
 - Easy to implement
 - Only good for structured environments, small number of actions
 - Authors feels that hybrid respresentation is best
 - ie the user provides information on several different representation levels
- Operations and object positions
 - Need to map user demo to target system
 - Robot movement planning is straightforward if user demo and objectives were object avoidance and the object positions are given
 - Or direct mapping methods can be used, but demo environment and robot environment must be similar},
  timestamp = {2011.01.06},
}

@InProceedings{Dines2006,
  Title                    = {The Segmentation of Multi-channel Meeting Recordings for Automatic Speech Recognition},
  Author                   = {Dines, J. and Vepa, J. and Hain, T.},
  Booktitle                = {Interspeech},
  Year                     = {2006},

  Review                   = {- automated speech recog (ASR) and transcribing
- asusme only one speaker at a time
- uses multilayer preceptron (MLP) - a type of NN
- achieves 1.3% of...something
- feeds ASR features into NN

Dines \etal \cite{Dines2006} is interested in performing automated speech recognition using multi-layer preceptron (MLP). This work assumes that only one speaker is speaking at a time. 12 mel-frequency features, their derivatives and energy features were used features inside the MLP and is used to determine speech/non-speech classes. Viterbi is used to used to determine likely segmentation boundaries.

Dines \etal \cite{Dines2006} perform automated speech recognition using the multi-layer preceptron (MLP). This work assumes that only one speaker is speaking at a time. 12 mel-frequency features, their derivatives and energy features were used features inside the MLP and are used to determine speech/non-speech classes. The MLP classifier class posterior estimates and class prior probabilities are used in the Viterbi search, and is used to used to determine likely segmentation boundaries. Testing the algorithm on a set of labelled audio data from the NIST, they report a $Acc_{Class}$ of 96\%.},
  Timestamp                = {2013.08.29}
}

@Article{Do2008,
  Title                    = {What is the Expectation Maximization Algorithm?},
  Author                   = {Do, C. B. and Batzoglou, S.},
  Journal                  = {Nature Biotechnology},
  Year                     = {2008},
  Number                   = {8},
  Pages                    = {897--899},
  Volume                   = {26},

  Comment                  = {10.1038/nbt1406},
  ISSN                     = {1087-0156},
  Publisher                = {Nature Publishing Group},
  Timestamp                = {2014.07.16},
  Url                      = {http://dx.doi.org/10.1038/nbt1406}
}

@InProceedings{Domeniconi2001,
  Title                    = {Incremental Support Vector Machine Construction},
  Author                   = {Domeniconi, C. and Gunopulos, D.},
  Booktitle                = {Proceedings of the IEEE International Conference on Data Mining},
  Year                     = {2001},
  Pages                    = {589--592},

  Abstract                 = {SVMs (support vector machines) suffer from the problem of large memory requirement and CPU time when trained in batch mode on large data sets. We overcome these limitations, and at the same time make SVMs suitable for learning with data streams, by constructing incremental learning algorithms. We first introduce and compare different incremental learning techniques, and show that they are capable of producing performance results similar to the batch algorithm, and in some cases superior condensation properties. We then consider the problem of training SVMs using stream data. Our objective is to maintain an updated representation of recent batches of data. We apply incremental schemes to the problem and show that their accuracy is comparable to the batch algorithm},
  Doi                      = {10.1109/ICDM.2001.989572},
  Keywords                 = {batch processing (computers);data analysis;learning (artificial intelligence);learning automata;very large databases;CPU time;SVMs;batch algorithm;batch mode;condensation properties;data streams;incremental learning algorithms;incremental schemes;incremental support vector machine construction;large data sets;large memory requirement;stream data;updated representation;Computer science;Marketing and sales;Partitioning algorithms;Solids;Support vector machine classification;Support vector machines;Telephony;Training data},
  Timestamp                = {2014.11.14}
}

@Conference{Dong2007,
  Title                    = {Measuring Uniaxial Joint Angles with a Minimal Accelerometer Configuration},
  Author                   = {Dong, W. and Chen, I. M. and Lim, K. Y. and Goh, Y. K.},
  Booktitle                = {Proceedings of the International Convention on Rehabilitation Engineering and Assistive Technology},
  Year                     = {2007},
  Pages                    = {88--91},
  Abstract                 = {This paper describes an approach to accurate measurement of human joint flexion-extension angles with four biaxial accelerometers. In this method, the absolute joint angle is calculated by comparing the readings of a pair of virtual accelerometers at the joint center of rotation. The simulation results show that the measurement has high accuracy compared to the reference system (correlation coefficient factor = 0.982). Given its portability, relative low cost and high accuracy proven by simulation results, the system can be applied to motion tracking for home-based rehabilitation.},
  Doi                      = {10.1145/1328491.1328515},
  ISBN                     = {978-1-59593-852-7},
  Keywords                 = {Postural detection},
  Location                 = {Singapore},
  Review                   = {Uses only accelerometers, but only promises accuracy in sag plane.

If need to, the original name is: i-CREATe '07: Proceedings of the 1st international convention on Rehabilitation engineering and assistive technology



Dong2007
Motion type: Gait
Recovery methodology: Low-pass accel. Sagittal plane measurement only. Uses length information to project numerious accelerometers to joint centers. They then use trig to get the angle, and subtract one set of angles from another to get local angles. 2 accel on each segment
Verification technqiue: Optical camera
Subject demographics: Unspecified
Error reported: 0.4 degrees for knee},
  Timestamp                = {2010.04.01},
  Url                      = {http://dl.acm.org/citation.cfm?doid=1328491.1328515}
}

@MastersThesis{Doshida2015,
  author    = {N. Doshida},
  title     = {Classification of Grasping Motions for Smooth Communication between Human and Robots},
  school    = {Tokyo University of Agriculture and Technology},
  year      = {2015},
  owner     = {jf2lin},
  timestamp = {2017.04.24},
}

@TechReport{Drillis1966,
  Title                    = {Body Segment Parameters},
  Author                   = {Drillis, R. and Contini, R.},
  Institution              = {Office of Vacational Rehabilitation, Department of Health, Education, and Welfare},
  Year                     = {1966},
  Number                   = {1166--03},

  Pages                    = {88--118},
  Timestamp                = {2012.01.10},
  Url                      = {http://scholar.google.com/scholar?q=intitle:model+for+body+segment+paramenters#1}
}

@Article{Dukelow2009,
  Title                    = {Quantitative Assessment of Limb Position Sense Following Stroke},
  Author                   = {Dukelow, S. AND Merter, T. AND Moore, K. AND Demers, M. J. AND Glasgow, J. AND Bagg, S. AND Norman, K. AND Scott, S.},
  Journal                  = {Neurorehabilitaiton and Neural Repair},
  Year                     = {2009},
  Pages                    = {1--10},
  Volume                   = {20},

  Abstract                 = {Background. Impairment of position sense of the upper extremity (UE) may impede activities of daily living and limit motor gains after stroke. Most clinical assessments of position sense rely on categorical or ordinal ratings by clinicians that lack sensitivity to change or the ability to discriminate subtle deficits. 

Objective. Use robotic technology to develop a reliable, quantitative technique with a continuous scale to assess UE position sense following stroke. 

Methods. Forty-five patients recruited from an inpatient stroke rehabilitation service and 65 age-matched healthy controls performed an arm position matching task. Each UE was fitted in the exoskeleton of a KINARM device. One UE was passively placed in one of 9 positions, and the subject was told to match his or her position with the other UE. Patients were compared with statistical distributions of control data to identify those with deficits in UE position sense. Test–retest sessions using 2 raters established interrater reliability. 

Results. Two thirds of left hemiparetic and one third of right hemiparetic patients had deficits in limb position sense. Left-affected stroke subjects demonstrated significantly more trial-to-trial variability than right-affected or control subjects. The robotic assessment technique demonstrated good interrater reliability but limited agreement with the clinical thumb localizing test. 

Conclusions. Robotic technology can provide a reliable quantitative means to assess deficits in limb position sense following stroke.},
  Keywords                 = {Postural detection},
  Review                   = {1/3 to 1/2 of all stroke patients suffers from a loss from proprioception. Current techniques to assess this has poor interrater reliability, sensitivity and poor normal value critera. 

The robot moves one arm of the patient to a certain position, then ask the patient to match that position with his/her other arm. They used Cartesian coordinates (the KINARM robot has encoders, of course) so they can do straight-forward position difference. 

-> skipped to Discussion ->

1) the KINARM robot is expensive, but if it can save on physician and therapist costs...(though, I didn't note them mentioning anything about using the robot itself to help with rehab)
2) robot is more accurate than human inspection

3) they found that left-affected patients had more accuracy variance than right-affected (ie right side of brain is more important for spatial awareness)
4) they're trying to replace a standard test (thumb localizing test) by saying that robot matching is objective, the position measured are continous (not discrete, which is what phyician assessements would be), and stats can be more easily applied to the robot position data. There is no need for a human operator, and faster assessment time is noted with the robot.},
  Timestamp                = {2010.01.17}
}

@Article{Dumas2007,
  Title                    = {Adjustments to {McConville} et al. and {Young} et al. body segment inertial parameters},
  Author                   = {R. Dumas and L. Ch\'{e}ze and J.-P. Verriest},
  Journal                  = {Journal of Biomechanics },
  Year                     = {2007},
  Pages                    = {543--553},
  Volume                   = {40},

  Abstract                 = {Body segment inertial parameters (BSIPs) are important data in biomechanics. They are usually estimated from predictive equations reported in the literature. However, most of the predictive equations are ambiguously applicable in the conventional 3D segment coordinate systems (SCSs). Also, the predictive equations reported in the literature all include two assumptions: the centre of mass and the proximal and distal endpoints are assumed to be aligned, and the inertia tensor is assumed to be principal in the segment axes. These predictive equations, restraining both position of the centre of mass and orientation of the principal axes of inertia, become restrictive when computing 3D inverse dynamics, when analyzing the influence of \{BSIP\} estimations on joint forces and moments and when evaluating personalized 3D \{BSIPs\} obtained from medical imaging. In the current study, the extensive data from McConville et al. (1980. Anthropometric relationships of body and body segment moments of inertia. AFAMRL-TR-80-119, Aerospace Medical Research Laboratory, Wright–Patterson Air Force Base, Dayton, Ohio) and from Young et al. (1983. Anthropometric and mass distribution characteristics of the adults female. Technical Report AFAMRL-TR-80-119, \{FAA\} Civil Aeromedical Institute, Oklaoma City, Oklaoma) are adjusted in order to correspond to joint centres and to conventional segment axes. In this way, scaling equations are obtained for both males and females that provide \{BSIPs\} which are directly applicable in the conventional \{SCSs\} and do not restrain the position of the centre of mass and the orientation of the principal axes. These adjusted scaling equations may be useful for researchers who wish to use appropriate 3D \{BSIPs\} for posture and movement analysis. },
  Doi                      = {http://dx.doi.org/10.1016/j.jbiomech.2006.02.013},
  ISSN                     = {0021-9290},
  Keywords                 = {Body segment inertial parameters},
  Timestamp                = {2016.03.13}
}

@Article{Dunbabin2012,
  Title                    = {Robotics for Environmental Monitoring},
  Author                   = {M. Dunbabin and L. Marques},
  Journal                  = {IEEE Robotics Automation Magazine},
  Year                     = {2012},

  Month                    = {March},
  Number                   = {1},
  Pages                    = {20-23},
  Volume                   = {19},

  Abstract                 = {Presents the guest editorial for this issue of the publication.},
  Doi                      = {10.1109/MRA.2012.2186482},
  ISSN                     = {1070-9932},
  Keywords                 = {Environmental factors;Environmental management;Geoscience;Mobile robots;Modeling;Special issues and sections},
  Timestamp                = {2017.04.24}
}

@Article{Dyer2014,
  Title                    = {COMPOSE: A Semisupervised Learning Framework for Initially Labeled Nonstationary Streaming Data},
  Author                   = {Dyer, K. B. and Capo, R. and Polikar, R.},
  Journal                  = {IEEE Transactions on Neural Networks and Learning Systems},
  Year                     = {2014},

  Month                    = {Jan},
  Number                   = {1},
  Pages                    = {12-26},
  Volume                   = {25},

  Abstract                 = {An increasing number of real-world applications are associated with streaming data drawn from drifting and nonstationary distributions that change over time. These applications demand new algorithms that can learn and adapt to such changes, also known as concept drift. Proper characterization of such data with existing approaches typically requires substantial amount of labeled instances, which may be difficult, expensive, or even impractical to obtain. In this paper, we introduce compacted object sample extraction (COMPOSE), a computational geometry-based framework to learn from nonstationary streaming data, where labels are unavailable (or presented very sporadically) after initialization. We introduce the algorithm in detail, and discuss its results and performances on several synthetic and real-world data sets, which demonstrate the ability of the algorithm to learn under several different scenarios of initially labeled streaming environments. On carefully designed synthetic data sets, we compare the performance of COMPOSE against the optimal Bayes classifier, as well as the arbitrary subpopulation tracker algorithm, which addresses a similar environment referred to as extreme verification latency. Furthermore, using the real-world National Oceanic and Atmospheric Administration weather data set, we demonstrate that COMPOSE is competitive even with a well-established and fully supervised nonstationary learning algorithm that receives labeled data in every batch.},
  Doi                      = {10.1109/TNNLS.2013.2277712},
  ISSN                     = {2162-237X},
  Keywords                 = {Bayes methods;computational geometry;data handling;geophysics computing;learning (artificial intelligence);meteorology;pattern classification;COMPOSE;compacted object sample extraction;computational geometry-based framework;concept drift;drifting distributions;extreme verification latency;initially labeled nonstationary streaming data;labeled instances;nonstationary distributions;optimal Bayes classifier;real-world national oceanic and atmospheric administration weather data set;semisupervised learning framework;Algorithm design and analysis;Classification algorithms;Data mining;Semisupervised learning;Shape;Signal processing algorithms;Alpha shape;concept drift;nonstationary environment;semisupervised learning (SSL);verification latency},
  Review                   = {A form of clustering approach, where they attempt to track slowly moving distributions:
- by constructing an alpha shape (a n-dimensional convex hull) around the data points of the two classes
- classify unknown data points with this classifier
- remove outlying data points to form a core shape
- the data points in the core shape is used train the next iteration of the classifier

This way, the classifier is pruning out outlier points, and can move the distribution according to the input data, assuming the jumps are not dramatic.},
  Timestamp                = {2015.04.14}
}

@Article{Earley1970,
  Title                    = {An Efficient Context-free Parsing Algorithm},
  Author                   = {Earley, J.},
  Journal                  = {Communications of the ACM},
  Year                     = {1970},
  Number                   = {2},
  Pages                    = {94--102},
  Volume                   = {13},

  Acmid                    = {362035},
  Address                  = {New York, NY, USA},
  Doi                      = {10.1145/362007.362035},
  ISSN                     = {0001-0782},
  Issue_date               = {Feb 1970},
  Keywords                 = {compilers, computational complexity, context-free grammar, parsing, syntax analysis},
  Numpages                 = {9},
  Publisher                = {ACM},
  Timestamp                = {2014.07.21},
  Url                      = {http://doi.acm.org.proxy.lib.uwaterloo.ca/10.1145/362007.362035}
}

@Article{Edwards2004,
  Title                    = {Measuring Flexion in Knee Arthroplasty Patients},
  Author                   = {Edwards, J. Z. and Greene, K. A. and Davis, R. S. and Kovacik, M. W. and Noe, D. A. and Askew, M. J.},
  Journal                  = {Journal of Arthroplasty},
  Year                     = {2004},
  Pages                    = {369--372},
  Volume                   = {19},

  Abstract                 = {Flexion following total knee arthroplasty can be visually estimated, measured with a goniometer placed against the patient’s leg, or measured from a lateral radiograph of the flexed knee. Three examiners, in a blinded fashion, estimated the degree of maximal knee flexion and measured the flexion with a goniometer for 27 knees in 16 patients. A lateral knee radiograph then was taken and the flexion angle was measured from the radiograph by 2 different methods. Although interobserver and intraobserver correlation coefficients were high (0.79 and 0.92), 45% of the visual estimates and 22% of the goniometer measurements differed by 5° or greater from the radiographic measurements. These differences increased as the flexion angle increased. Body mass index did not affect the accuracy of the estimates or goniometer measurements.},
  ISSN                     = {0883-5403},
  Keywords                 = {knee arthroplasty},
  Timestamp                = {2012.09.29}
}

@Article{Ekvall2006,
  author    = {Ekvall, S. and Aarno, D. and Kragic, D.},
  title     = {Online Task Recognition and Real-time Adaptive Assistance for Computer-aided Machine Control},
  journal   = {IEEE Transactions on Robotics},
  year      = {2006},
  volume    = {22},
  pages     = {1029--1033},
  issn      = {1552-3098},
  abstract  = {Segmentation and recognition of operator-generated motions are commonly facilitated to provide appropriate assistance during task execution in teleoperative and human-machine collaborative settings. The assistance is usually provided in a virtual fixture framework where the level of compliance can be altered online, thus improving the performance in terms of execution time and overall precision. However, the fixtures are typically inflexible, resulting in a degraded performance in cases of unexpected obstacles or incorrect fixture models. In this paper, we present a method for online task tracking and propose the use of adaptive virtual fixtures that can cope with the above problems. Here, rather than executing a predefined plan, the operator has the ability to avoid unforeseen obstacles and deviate from the model. To allow this, the probability of following a certain trajectory (subtask) is estimated and used to automatically adjusts the compliance, thus providing the online decision of how to fixture the movement},
  doi       = {10.1109/TRO.2006.878976},
  groups    = {Lit Review 2013-09},
  keywords  = {compliance control;control engineering computing;hidden Markov models;man-machine systems;manipulators;support vector machines;telerobotics;adaptive virtual fixtures;computer-aided machine control;hidden Markov models;human-machine collaborative settings;online task recognition;operator-generated motion recognition;real-time adaptive assistance;Adaptive control;Collaboration;Degradation;Fixtures;Hidden Markov models;Machine control;Programmable control;Robotics and automation;State estimation;Support vector machines;Hidden Markov models (HMMs);human&#8211;machine collaborative systems (HMCSs);support vector machines (SVMs);virtual fixtures},
  review    = {Want to recognize the user's intent in a human-machine interactive setting. Need to figure out what the human is thinking in order to guide the user via virtual fixture (sensory overlay - visual or haptic, typically)

Uses SVM. And HMM. Together. 

Position data is encoded and normalized and represented as a sequence of lines motions (represents direction of the exemplars). The number of lines are a determined automatically, by k-means, where the cluster centres denote the directions. Cluster count is increased as long as some validation score continues to improve. Only 1/3 of the exemplar data is used in this k-means method. The other 2/3 is used to verify. Each of these clustered (as far as I can tell) is referred to as states afterwards. 

Each state is used to train SVMs (one-vs-all), which is reformulated into a conditional probability using a sigmoid function. This function is used to calculate an HMM observation probability, so the SVM serves as the probability estimator for both HMM training and state estimation. The HMM is fully-connected, with a uniform prior matrix. Baum-Welch is used to train the A and pi matrix for HMM, since B is provided by the SVM. The HMM continously report which state (line motion) the user is in, and provide the appropriate fixture.},
  timestamp = {2013.09.29},
}

@Article{Falou2005,
  Title                    = {A segmentation approach to long duration surface {EMG} recordings},
  Author                   = {El Falou, W. and Duch\^{e}ne, J. and Hewson, D. and Khalil, M. and Grabisch, M. and Lino, F.},
  Journal                  = {Journal of Electromyography and Kinesiology},
  Year                     = {2005},
  Pages                    = {111--9},
  Volume                   = {15},

  Abstract                 = {The purpose of this study was to develop an automatic segmentation method in order to identify postural surface \{EMG\} segments in long-duration recordings. Surface \{EMG\} signals were collected from the cervical erector spinae (CES), erector spinae (ES), external oblique (EO), and tibialis anterior (TA) muscles of 11 subjects using a bipolar electrode configuration. Subjects remained seated in a car seat over the 150-min data-collection period. The modified dynamic cumulative sum (MDCS) algorithm was used to automatically segment the surface \{EMG\} signals. Signals were rejected by comparison with an exponential mathematical model of the spectrum of a surface \{EMG\} signal. The average power ratio computed between two successive retained segments was used to classify segments as postural or surface EMG. The presence of a negative slope of a regression line fitted to the median frequency values of postural surface \{EMG\} segments was taken as an indication of fatigue. Alpha level was set at 0.05. The overall classification error rate was 8%, and could be performed in 25 min for a 150-min signal using a custom-built software program written in C (Borland Software Corporation, CA, USA). This error rate could be enhanced by concentrating on the rejection method, which caused most of the misclassification (6%). Furthermore, the elimination of non-postural surface \{EMG\} segments by the use of a segmentation approach enabled muscular fatigue to be identified in signals that contained no evidence of fatigue when analysed using traditional methods.},
  Doi                      = {http://dx.doi.org/10.1016/j.jelekin.2004.07.004},
  ISSN                     = {1050-6411},
  Keywords                 = {Electromyography},
  Owner                    = {jf2lin},
  Review                   = {Won't include, not arm EMG},
  Timestamp                = {2015.04.24}
}

@InProceedings{Elgammal2003,
  Title                    = {Learning dynamics for exemplar-based gesture recognition},
  Author                   = {Elgammal, A. and Shet, V. and Yacoob, Y. and Davis, L.S.},
  Booktitle                = {Computer Vision and Pattern Recognition, 2003. Proceedings. 2003 IEEE Computer Society Conference on},
  Year                     = {2003},
  Month                    = {June},
  Pages                    = {I-571-I-578 vol.1},
  Volume                   = {1},

  Abstract                 = {This paper addresses the problem of capturing the dynamics for exemplar-based recognition systems. Traditional HMM provides a probabilistic tool to capture system dynamics and in exemplar paradigm, HMM states are typically coupled with the exemplars. Alternatively, we propose a non-parametric HMM approach that uses a discrete HMM with arbitrary states (decoupled from exemplars) to capture the dynamics over a large exemplar space where a nonparametric estimation approach is used to model the exemplar distribution. This reduces the need for lengthy and non-optimal training of the HMM observation model. We used the proposed approach for view-based recognition of gestures. The approach is based on representing each gesture as a sequence of learned body poses (exemplars). The gestures are recognized through a probabilistic framework for matching these body poses and for imposing temporal constraints between different poses using the proposed non-parametric HMM.},
  Doi                      = {10.1109/CVPR.2003.1211405},
  ISSN                     = {1063-6919},
  Keywords                 = {computer vision;edge detection;feature extraction;gesture recognition;hidden Markov models;image matching;learning by example;nonparametric statistics;arbitrary state;body pose matching;body pose sequence;computer vision;discrete HMM;exemplar distribution model;exemplar space;exemplar-based gesture recognition;hidden Markov model;human gesture;human motion;learning dynamics;nonparametric HMM;nonparametric estimation;probabilistic framework;probabilistic tool;system dynamics;temporal constraint;view-based recognition;Biological system modeling;Computer science;Computer vision;Educational institutions;Graphical models;Hidden Markov models;Humans;Laboratories;Motion analysis;Training data},
  Timestamp                = {2014.12.22}
}

@Article{El-Gohary2012,
  Title                    = {Shoulder and Elbow Joint Angle Tracking With Inertial Sensors},
  Author                   = {El-Gohary, M. and McNames, J.},
  Journal                  = {IEEE Transactions on Biomedical Engineering},
  Year                     = {2012},
  Number                   = {9},
  Pages                    = {2635--2641},
  Volume                   = {59},

  Abstract                 = {Wearable inertial systems have recently been used to track human movement in and outside of the laboratory. Continuous monitoring of human movement can provide valuable information relevant to individuals’ level of physical activity and functional ability. Traditionally, orientation has been calculated by integrating the angular velocity from gyroscopes. However, a small drift in the measured velocity leads to increasing integration error over time. To compensate that drift, complementary data from accelerometers are normally fused into tracking systems using the Kalman or extended Kalman filter. In this study, we combine kinematic models designed for control of robotic arms with state-space methods to continuously estimate the angles of human shoulder and elbow using two wearable inertial measurement units. We use the unscented Kalman filter to implement the nonlinear state-space inertial tracker. Shoulder and elbow joint angles obtained from 8 subjects using our inertial tracker were compared to the angles obtained from an optical-tracking reference system. On average, there was an RMS angle error of less than 8 $^circ$ for all shoulder and elbow angles. The average correlation coefficient for all movement tasks among all subjects was $rge hbox{0.95}$ . This agreement between our inertial tracker and the optical reference system was obtained for both regular and fast-speed movement of the arm. The same method can be used to track movement of other joints.},
  Doi                      = {10.1109/TBME.2012.2208750},
  ISSN                     = {0018-9294},
  Keywords                 = {Adaptive optics;Elbow;Gyroscopes;Joints;Mathematical model;Shoulder;Tracking;Elbow;inertial sensors;joint angle tracking;kinematics;shoulder;wearable devices;Algorithms;Biomechanics;Clothing;Elbow;Elbow Joint;Fiducial Markers;Humans;Models, Biological;Monitoring, Ambulatory;Shoulder;Shoulder Joint},
  Timestamp                = {2014.10.29}
}

@Article{Engelbrecht2001,
  Title                    = {Minimum Principles in Motor Control },
  Author                   = {Engelbrecht, S. E.},
  Journal                  = {Journal of Mathematical Psychology },
  Year                     = {2001},
  Pages                    = {497--542},
  Volume                   = {45},

  Abstract                 = {Minimum (or minimal) principles are mathematical laws that were first used in physics: Hamilton's principle and Fermat's principle of least time are two famous example. In the past decade, a number of motor control theories have been proposed that are formally of the same kind as the minimum principles of physics, and some of these have been quite successful at predicting motor performance in a variety of tasks. The present paper provides a comprehensive review of this work. Particular attention is given to the relation between minimum theories in motor control and those used in other disciplines. Other issues around which the review is organized include: (1) the relation between minimum principles and structural models of motor planning and motor control, (2) the empirically-driven development of minimum principles and the danger of circular theorizing, and (3) the design of critical tests for minimum theories. Some perspectives for future research are discussed in the concluding section of the paper. },
  Doi                      = {http://dx.doi.org/10.1006/jmps.2000.1295},
  ISSN                     = {0022-2496},
  Timestamp                = {2015.07.06}
}

@InProceedings{Englert2015,
  Title                    = {{Inverse {KKT} -- Learning Cost Functions of Manipulation Tasks from Demonstrations}},
  Author                   = {Englert, P. and Toussaint, M.},
  Booktitle                = {Proceedings of the International Symposium of Robotics Research},
  Year                     = {2015},

  Abstract                 = {Inverse Optimal Control (IOC) assumes that demonstrations are the solution to an optimal control problem with unknown underlying costs, and extracts parameters of these underlying costs. We propose the framework of Inverse KKT, which assumes that the demonstrations fulfill the Karush-Kuhn-Tucker conditions of an unknown underlying constrained optimization problem, and extracts parameters of this underlying problem. Using this we can exploit the latter to extract the relevant task spaces and cost parameters from demonstrations of skills that involve contacts. For a typical linear parameterization of cost functions this reduces to a quadratic program, ensuring guaranteed and very efficient convergence, but we can deal also with arbitrary non-linear parameterizations of cost functions. The aim of our approach is to push learning from demonstration to more complex manipulation scenarios that include the interaction with objects and therefore the realization of contacts/constraints within the motion. We demonstrate the approach on tasks such as sliding a box and opening a door.},
  Annote                   = {paper/2015_Englert_ISRR.pdf},
  Annote2                  = {videos/2015_Englert_ISRR.mp4},
  Timestamp                = {2015.10.15}
}

@InProceedings{Eriksson2005,
  Title                    = {Hands-off Assistive Robotics for Post-stroke Arm Rehabilitation},
  Author                   = {Eriksson, J. and Matari\'{c}, M. J. and Winstein, C. J.},
  Booktitle                = {Proceedings of the IEEE International Conference of Rehabilitation Robotics},
  Year                     = {2005},
  Pages                    = {21--24},

  Abstract                 = {This paper describes an autonomous assistive mobile robot that aids stroke patient rehabilitation by providing monitoring, encouragement, and reminders. The robot navigates autonomously, monitors the patient's arm activity, and helps the patient remember to follow a rehabilitation program. Our experiments show that patients post-stroke are positive about this approach and that increasingly active and animated robot behavior is positively received by stroke survivors.},
  Doi                      = {10.1109/ICORR.2005.1501042},
  Keywords                 = { autonomous assistive mobile robot; hands-off assistive robotics; post-stroke arm rehabilitation; stroke patient rehabilitation; handicapped aids; medical robotics; mobile robots; patient rehabilitation;},
  Timestamp                = {2011.06.15}
}

@Article{Erman2007,
  Title                    = {Offline/realtime traffic classification using semi-supervised learning},
  Author                   = {Erman, J. and Mahanti, A. and Arlitt, M. and Cohen, I. and Williamson, C.},
  Journal                  = {Performance Evaluation},
  Year                     = {2007},
  Pages                    = {1194--1213},
  Volume                   = {64},

  Abstract                 = {Identifying and categorizing network tra
ffic by application type is challenging
because of the continued evolution of a
pplications, especially of those with 
a
desire to be undetectable. The diminished effectiveness of port-
b
ased
identification and the overheads of deep 
packet inspection approaches motivate
us to classify traffic by exploiting distin
ctive flow characteristics of applications 
when they communicate on a network. In
 this paper, we explore this latte
r
approach and propose a 
semi-supervised
 classification method that can 
accommodate both known and unknown app
lications. To the best of ou
r
knowledge, this is the first work to use semi-supervised learning techniques fo
r
the traffic classification problem. Our approach allows classifiers to be designed 
from training data that consists of only 
a few labeled and many unlabeled flows. 
We consider pragmatic classification issues such as longevity of classifiers and 
the need for retraining of classifiers. Our performance evaluation using 
empirical Internet traffic traces that span a 6-month period shows that: 1) hig
h
flow and byte classification accuracy (i.e., greater than 90%) can be achieved 
using training data that consists of a 
small number of labele
d and a large numbe
r
of unlabeled flows; 2) presence of “mice” and “elephant” flows in the Interne
t
complicates the design of classifiers, especially of those with high byte 
accuracy, and necessities use of weighted 
sampling techniques to obtain training
flows; and 3) retraining of classifiers is necessary only when there are non-
transient changes in the netw
ork usage characteristics. As a proof of concept, we 
implement prototype 
offline
 and 
realtime
classification systems to demonstrate 
the feasibility of our approach.},
  Publisher                = {Elsevier},
  Review                   = {Looking at network data transmission. Want to classify network flow by application using flow statistics. Want to relate flow to application (ie web, P2P, email, FTP, etc).
- labels are hard to come by. lots of examples of labelled network traffic data
- use clustering methods, which allows expansion to unknown labels (uses kmeans)
 - maps obs to it based on Euclidean distance to kmeans centroid
 - uses a probablistic approach to map the known labels to the clusters},
  Timestamp                = {2015.05.13}
}

@Article{Erol2007,
  Title                    = {Vision-based hand pose estimation: A review},
  Author                   = {Erol, A. and Bebis, G. and Nicolescu, M. and Boyle, R. and Twombly, X.},
  Journal                  = {Comput Vis Image Und},
  Year                     = {2007},
  Pages                    = {52--73},
  Volume                   = {108},

  Abstract                 = {Direct use of the hand as an input device is an attractive method for providing natural human–computer interaction (HCI). Currently, the only technology that satisfies the advanced requirements of hand-based input for \{HCI\} is glove-based sensing. This technology, however, has several drawbacks including that it hinders the ease and naturalness with which the user can interact with the computer-controlled environment, and it requires long calibration and setup procedures. Computer vision (CV) has the potential to provide more natural, non-contact solutions. As a result, there have been considerable research efforts to use the hand as an input device for HCI. In particular, two types of research directions have emerged. One is based on gesture classification and aims to extract high-level abstract information corresponding to motion patterns or postures of the hand. The second is based on pose estimation systems and aims to capture the real 3D motion of the hand. This paper presents a literature review on the latter research direction, which is a very challenging problem in the context of HCI. },
  Doi                      = {http://dx.doi.org/10.1016/j.cviu.2006.10.012},
  ISSN                     = {1077-3142},
  Keywords                 = {Hand pose estimation},
  Owner                    = {jf2lin},
  Timestamp                = {2015.04.27}
}

@Article{Erren2007,
  Title                    = {Ten Simple Rules for Doing Your Best Research, According to Hamming},
  Author                   = {Erren, T. C AND Cullen, P. AND Erren, M. AND Bourne, P. E.},
  Journal                  = {PLoS Computational Biology},
  Year                     = {2007},
  Number                   = {10},
  Pages                    = {e213},
  Volume                   = {3},

  Comment                  = {http://dx.plos.org/10.1371%2Fjournal.pcbi.0030213},
  Doi                      = {10.1371/journal.pcbi.0030213},
  Publisher                = {Public Library of Science},
  Timestamp                = {2010.10.19},
  Url                      = {http://www.ploscompbiol.org/article/info:doi/10.1371/journal.pcbi.0030213}
}

@InProceedings{Everett2008,
  Title                    = {Electronic Voting Machines Versus Traditional Methods: Improved Preference, Similar Performance},
  Author                   = {Everett, S. P. and Greene, K. K. and Byrne, M. D. and Wallach, D. S. and Derr, K. and Sandler, D. and Torous, T.},
  Booktitle                = {Proceeding of the Annual SIGCHI Conference on Human Factors in Computing Systems},
  Year                     = {2008},

  Address                  = {New York, NY, USA},
  Pages                    = {883--892},
  Publisher                = {ACM},
  Series                   = {CHI '08},

  Abstract                 = {In the 2006 U.S. election, it was estimated that over 66 million people would be voting on direct recording electronic (DRE) systems in 34% of the nation's counties [8]. Although these computer-based voting systems have been widely adopted, they have not been empirically proven to be more usable than their predecessors. The series of studies reported here compares usability data from a DRE with those from more traditional voting technologies (paper ballots, punch cards, and lever machines). Results indicate that there were little differences between the DRE and these older methods in efficiency or effectiveness. However, in terms of user satisfaction, the DRE was significantly better than the older methods. Paper ballots also perform well, but participants were much more satisfied with their experiences voting on the DRE. The disconnect between subjective and objective usability has potential policy ramifications.},
  Acmid                    = {1357195},
  Doi                      = {http://doi.acm.org/10.1145/1357054.1357195},
  ISBN                     = {978-1-60558-011-1},
  Keywords                 = {dre, electronic voting, preference, usability, voting},
  Location                 = {Florence, Italy},
  Numpages                 = {10},
  Timestamp                = {2010.12.13},
  Url                      = {http://doi.acm.org/10.1145/1357054.1357195}
}

@Article{Farris2011,
  Title                    = {Preliminary Evaluation of a Powered Lower Limb Orthosis to Aid Walking in Paraplegic Individuals},
  Author                   = {Farris, R. J. and Quintero, H. A. and Goldfarb, M.},
  Journal                  = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  Year                     = {2011},
  Number                   = {6},
  Pages                    = {652--659},
  Volume                   = {19},

  Publisher                = {IEEE},
  Timestamp                = {2012.11.12}
}

@Article{Favre2009,
  Title                    = {Functional Calibration Procedure for 3D Knee Joint Angle Description using Inertial Sensors},
  Author                   = {Favre, J. and Aissaoui, R. and Jolles, B. M. and de Guise, J. A. and Aminian, K.},
  Journal                  = {Journal of Biomechanics},
  Year                     = {2009},
  Pages                    = {2330--2335},
  Volume                   = {42},

  Abstract                 = {Measurement of three-dimensional (3D) knee joint angle outside a laboratory is of benefit in clinical examination and therapeutic treatment comparison. Although several motion capture devices exist, there is a need for an ambulatory system that could be used in routine practice. Up-to-date, inertial measurement units (IMUs) have proven to be suitable for unconstrained measurement of knee joint differential orientation. Nevertheless, this differential orientation should be converted into three reliable and clinically interpretable angles. Thus, the aim of this study was to propose a new calibration procedure adapted for the joint coordinate system (JCS), which required only IMUs data. The repeatability of the calibration procedure, as well as the errors in the measurement of 3D knee angle during gait in comparison to a reference system were assessed on eight healthy subjects. The new procedure relying on active and passive movements reported a high repeatability of the mean values (offset<1°) and angular patterns (SD<0.3° and CMC>0.9). In comparison to the reference system, this functional procedure showed high precision (SD<2° and CC>0.75) and moderate accuracy (between 4.0° and 8.1°) for the three knee angle. The combination of the inertial-based system with the functional calibration procedure proposed here resulted in a promising tool for the measurement of 3D knee joint angle. Moreover, this method could be adapted to measure other complex joint, such as ankle or elbow.},
  Doi                      = {10.1016/j.jbiomech.2009.06.025},
  ISSN                     = {0021-9290},
  Keywords                 = {Knee; 3D Kinematics; Inertial sensors; Functional calibration; Ambulatory measurement; Gyroscopes; Accelerometers},
  Timestamp                = {2011.11.01},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021929009003649}
}

@Article{Favre2008,
  Title                    = {Ambulatory Measurement of 3D Knee Joint Angle},
  Author                   = {Favre, J. and Jolles, B. M. and Aissaoui, R. and Aminian, K.},
  Journal                  = {Journal of Biomechanics},
  Year                     = {2008},
  Pages                    = {1029--1035},
  Volume                   = {41},

  Abstract                 = {Three-dimensional measurement of joint motion is a promising tool for clinical evaluation and therapeutic treatment comparisons. Although many devices exist for joints kinematics assessment, there is a need for a system that could be used in routine practice. Such a system should be accurate, ambulatory, and easy to use. The combination of gyroscopes and accelerometers (i.e., inertial measurement unit) has proven to be suitable for unrestrained measurement of orientation during a short period of time (i.e., few minutes). However, due to their inability to detect horizontal reference, inertial-based systems generally fail to measure differential orientation, a prerequisite for computing the three-dimentional knee joint angle recommended by the Internal Society of Biomechanics (ISB). A simple method based on a leg movement is proposed here to align two inertial measurement units fixed on the thigh and shank segments. Based on the combination of the former alignment and a fusion algorithm, the three-dimensional knee joint angle is measured and compared with a magnetic motion capture system during walking. The proposed system is suitable to measure the absolute knee flexion/extension and abduction/adduction angles with mean (SD) offset errors of -1° (1°) and 0° (0.6°) and mean (SD) root mean square (RMS) errors of 1.5° (0.4°) and 1.7° (0.5°). The system is also suitable for the relative measurement of knee internal/external rotation (mean (SD) offset error of 3.4° (2.7°)) with a mean (SD) RMS error of 1.6° (0.5°). The method described in this paper can be easily adapted in order to measure other joint angular displacements such as elbow or ankle.},
  Doi                      = {10.1016/j.jbiomech.2007.12.003},
  ISSN                     = {0021-9290},
  Keywords                 = {Knee},
  Review                   = {Motion type: Assorted. Overlaps on knee flexion
Recovery methodology: 2 6DOF IMU (240 Hz)
Verification technique: Liberty magnetic tracking device
Subject demographics: 10 healthy adults
Error reported: RMS deg. 1.5° (SD = 0.4°)},
  Timestamp                = {2012.02.06},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021929007005350}
}

@Article{Favre2006,
  Title                    = {Quaternion-based Fusion of Gyroscopes and Accelerometers to Improve 3D Angle Measurement},
  Author                   = {Favre, J. and Jolles, B. M. and Siegrist, O. and Aminian, K.},
  Journal                  = {Electronics Letters},
  Year                     = {2006},
  Pages                    = {612--614},
  Volume                   = {42},

  Abstract                 = {Two methods to fuse a 3D gyroscope with a 3D accelerometer in order to measure rotations are presented. They are compared with a method requiring only a 3D gyroscope and assessed with a reference system. The good reported accuracies make this system suitable for clinical evaluation.

Integration in quarterion. Fixes drift by using accel periodically, when subject is stationary.},
  Doi                      = {10.1049/iel:20060124},
  ISSN                     = {0013-5194},
  Keywords                 = { 3D accelerometer; 3D angle measurement; 3D gyroscope; clinical evaluation; quaternion-based fusion; rotation measurement; accelerometers; angular velocity measurement; biomechanics; biomedical equipment; biomedical measurement; gyroscopes;},
  Timestamp                = {2012.02.06}
}

@Article{Fayyad1992,
  Title                    = {On the Handling of Continuous-valued Attributes in Decision Tree Generation},
  Author                   = {Fayyad, U. M. and Irani, K. B.},
  Journal                  = {Machine learning},
  Year                     = {1992},
  Number                   = {1},
  Pages                    = {87--102},
  Volume                   = {8},

  Publisher                = {Springer},
  Timestamp                = {2014.11.11}
}

@Article{Featherstone1999,
  Title                    = {A Divide-and-Conquer Articulated-Body Algorithm for Parallel O(log(n)) Calculation of Rigid-Body Dynamics. Part 1: Basic Algorithm},
  Author                   = {Featherstone, R.},
  Journal                  = {The International Journal of Robotics Research},
  Year                     = {1999},
  Number                   = {9},
  Pages                    = {867-875},
  Volume                   = {18},

  Abstract                 = {This paper presents a recursive, divide-and-conquer algorithm for calculating the forward dynamics of a robot mechanism, or general rigid-body system, on a parallel computer. It features O(log(n)) time complexity on O(n) processors and is the fastest available algorithm for a computer with a large number of processors and low communications costs. It is an exact, noniterative algorithm and is applicable to mechanisms with any joint type and any topology, including branches and kinematic loops. The algorithm works by recursive application of a formula that constructs the articulatedbody equations of motion of an assembly from those of its constituent parts. The inputs to this formula are the equations of motion of two independent subassemblies, plus a description of how they are to be connected, and the output is the equation of motion of the assembly. Starting with a collection of unconnected rigid bodies, the equations of motion of any rigid-body system can be constructed by repeated application of this formula. This paper, being the first in a two-part series, presents an overview of the new algorithm and a detailed description of the simplest case: unbranched kinematic chains. Details of the general case are presented in Part 2.},
  Doi                      = {10.1177/02783649922066619},
  Eprint                   = {http://ijr.sagepub.com/content/18/9/867.full.pdf+html},
  Keywords                 = {ECE780, Dynamics},
  Review                   = {Divide and conquer algorithm (DCA) - "recursively apply a formula that constructs the equations of motion of an assembly from its parts"
- input the equation of motion of two subassemblies and a description of how its connected
- output is the equations of motion of assembly
- recurse through the joints
- can use parallel computing, since these assemblies are split up

Several other similar algorithms exist, such as Constraint Force Algorithm (CFA)
- though, to determine which algorithm is 'best' is fairly difficult, since they're all different in nature

Rigid system. Assumes body position and velocity are known, and all non-accel-based forces. We're missing accel and kinematic-constraining forces. want to solve for accel. Not too bad. A fairly standard forward dynamics type situation, with well-known methods that exist. But what if we added some unknown forces to some of the links? Can no longer figure out the specific acceleration...but we can write things as a function of the unknown accels.

The system makes four passes through the system to obtain the equations as needed: 1st and 3rd start at leaves, the other two start at the root. First two passes calulcates x, dx from q and dq. 3rd pass gets the assembled dynamics and the 4th pass is the back-subsitution, which propagates the known forces to get the ddq.},
  Timestamp                = {2011.01.12},
  Url                      = {http://ijr.sagepub.com/content/18/9/867.abstract}
}

@InProceedings{Fergus2009,
  Title                    = {Remote Physiotherapy Treatments using Wireless Body Sensor Networks},
  Author                   = {Fergus, P. and Kafiyat, K. and Merabti, M. and Taleb-bendiab, A. and El Rhalibi, A.},
  Booktitle                = {Proceedings of the International Conference on Wireless Communications and Mobile Computing: Connecting the World Wirelessly},
  Year                     = {2009},
  Pages                    = {1191--1197},

  Acmid                    = {1582640},
  Keywords                 = {home medical networks, measurement and movement, medical plug and play devices, physiotherapy, wireless body area sensor networks, wireless medical sensors},
  Timestamp                = {2011.12.30}
}

@Article{Ferraris1995,
  Title                    = {Procedure for Effortless In-field Calibration of Three-axial Rate Gyro and Accelerometers},
  Author                   = {Ferraris, F. and Grimaldi, U. and Parvis, M.},
  Journal                  = {Sensors and Materials},
  Year                     = {1995},
  Pages                    = {311--330},
  Volume                   = {7},

  Review                   = {Shimmer calibration},
  Timestamp                = {2012.07.10},
  Url                      = {http://porto.polito.it/1404539/}
}

@InProceedings{Finkelstein2013,
  Title                    = {Remotely Controlled Cycling Exercise System for Home-Based Telerehabilitation},
  Author                   = {Finkelstein, J. and Jeong, I. C.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {Limited research has been conducted in utilizing telemedicine to promote upper and lower limb rehabilitation using remotely controlled home-based ergometers. The goal of this study was to develop and assess a telerehabilitation system supporting internet-controlled home-based cycling exercise. We designed an interface to control cycling speed of an ergometer from a remote server via Internet. The evaluation of the interface included consecutive transmission of 7 different cycling speed levels, each level of 2-minute duration. Overall, the mean difference between remotely setup and actual cycling speed was 0.002±0.03 miles/hour. Our evaluation demonstrated high fidelity of the proposed system and reliability of controlling individualized exercise prescription for home-based cycling equipment via Internet.},
  Keywords                 = {EMBC2013},
  Review                   = {Describes a home rehab package for stationary cycling.},
  Timestamp                = {2013.08.03}
}

@Article{Flanagan1995,
  Title                    = {Trajectory Adaptation to a Nonlinear Visuomotor Transformation: Evidence of Motion Planning in Visually Perceived Space},
  Author                   = {Flanagan, J. R. and Rao, A. K.},
  Journal                  = {Journal of Neurophysiology},
  Year                     = {1995},
  Number                   = {5},
  Pages                    = {2174--2178},
  Volume                   = {74},

  Abstract                 = {1. Although reaching movements are characterized by hand paths that tend to follow roughly straight lines in Cartesian space, a fundamental issue is whether this reflects constraints associated with perception or movement production. 2. To address this issue, we examined two-joint planar reaching movements in which we manipulated the mapping between actual and visually perceived motion. In particular, we used a nonlinear transformation such that straight line hand paths in Cartesian space would result in curved paths in perceived space and vice versa. 3. Under these conditions, subjects learned to make straight line paths in perceived space even though the paths of the hand in Cartesian space were markedly curved. In contrast, when the motion was perceived in Cartesian space (i.e., in the absence of a nonlinear distortion), straight line hand paths were observed. 4. These findings suggest that visually guided reaching movements are planned in a perceptual frame of reference. Reaching movements in the horizontal plane are adapted so as to produce straight lines in visually perceived space.},
  Eprint                   = {http://jn.physiology.org/content/74/5/2174.full.pdf+html},
  Timestamp                = {2012.11.17},
  Url                      = {http://jn.physiology.org/content/74/5/2174.abstract}
}

@Article{Flash1985,
  Title                    = {The coordination of arm movements: an experimentally confirmed mathematical model},
  Author                   = {Flash, T. and Hogan, N.},
  Journal                  = {Journal of Neuroscience},
  Year                     = {1985},
  Number                   = {7},
  Pages                    = {1688--1703},
  Volume                   = {5},

  Abstract                 = {This paper presents studies of the coordination of voluntary human arm movements. A mathematical model is formulated which is shown to predict both the qualitative features and the quantitative details observed experimentally in planar, multijoint arm movements. Coordination is modeled mathematically by defining an objective function, a measure of performance for any possible movement. The unique trajectory which yields the best performance is determined using dynamic optimization theory. In the work presented here, the objective function is the square of the magnitude of jerk (rate of change of acceleration) of the hand integrated over the entire movement. This is equivalent to assuming that a major goal of motor coordination is the production of the smoothest possible movement of the hand. Experimental observations of human subjects performing voluntary unconstrained movements in a horizontal plane are presented. They confirm the following predictions of the mathematical model: unconstrained point-to-point motions are approximately straight with bell-shaped tangential velocity profiles; curved motions (through an intermediate point or around an obstacle) have portions of low curvature joined by portions of high curvature; at points of high curvature, the tangential velocity is reduced; the durations of the low-curvature portions are approximately equal. The theoretical analysis is based solely on the kinematics of movement independent of the dynamics of the musculoskeletal system and is successful only when formulated in terms of the motion of the hand in extracorporal space. The implications with respect to movement organization are discussed.},
  Owner                    = {jf2lin},
  Timestamp                = {2016.07.25}
}

@Article{Fod2002,
  author    = {Fod, A. and Matari\'{c}, M. J. and Jenkins, O. C.},
  title     = {Automated Derivation of Primitives for Movement Classification},
  journal   = {Autonomous Robots},
  year      = {2002},
  volume    = {12},
  pages     = {39--54},
  abstract  = {We describe a new method for representing human movement compactly, in terms of a linear super-imposition of simpler movements termed primitives. This method is a part of a larger research project aimed at modeling motor control and imitation using the notion of perceptuo-motor primitives, a basis set of coupled perceptual and motor routines. In our model, the perceptual system is biased by the set of motor behaviors the agent can execute. Thus, an agent can automatically classify observed movements into its executable repertoire. In this paper, we describe a method for automatically deriving a set of primitives directly from human movement data.

We used movement data gathered from a psychophysical experiment on human imitation to derive the primitives. The data were first filtered, then segmented, and principal component analysis was applied to the segments. The eigenvectors corresponding to a few of the highest eigenvalues provide us with a basis set of primitives. These are used, through superposition and sequencing, to reconstruct the training movements as well as novel ones. The validation of the method was performed on a humanoid simulation with physical dynamics. The effectiveness of the motion reconstruction was measured through an error metric. We also explored and evaluated a technique of clustering in the space of primitives for generating controllers for executing frequently used movements.},
  groups    = {STAT841, IROS2014},
  keywords  = {imitation, learning, robotics, movement control, basis behaviors, motion segmentation},
  review    = {Data input: FastTrak motion tracking

They refer to ‘motor primitives’ and ‘mirror neurons’ in previous works, and looked at spinal fields (?) and central pattern generators. They break down complicated motions into building blocks called ‘primitives’.


Their model: Perception (Tracking, Attention), Encoding (Learning, Classification), Action (Actuation). 
Tracking – feature extraction from perceptual inputs. If it can’t be perceived, it can’t be used properly. 
Attention – selecting relevant information from perceived motion in order to simply the Classification and Learning section. Achieved by fitting input into some form of structure (ie significant features or into some kinematic structure). This is fairly flexible. 
Classification – sequence of segments representing a motion. Tells the system which segments are active at a given time. 
Learning – set of constraints for creating motor controllers for each primitive in the primitive set. 
Actuation – reduplicates actions provided by Classification. 

The rest of the paper focuses on 3 of these components (Attention, Learning, Classification)

Methods – They used a motion capture system and recorded a few people doing stuff (arms only), at 34 ms/reading (~30 Hz), accuracy within 2mm. Applied inverse kinematics (transforms Cartesian coordinates to joint angles, in Euler angle form). Filtered out noise to remove noisy zero-velocity points (10th order Butterworth, cutoff at 0.25)

Segmentation is rather difficult. They wanted to have...consistency (same type of motions would be analyzed correctly) and completeness (no segment overlap and the chain of segments is sufficient to rebuild the original movement). Segments can be defined as when a certain feature, or contact configuration changes. Used in the past are things like RMS velocity of joints. But here, they assumed that ZVC (zero-velo crossing) signified a chance in direction (they looked primarily at joint angles). Need to be cautious about noise and oscillations causing turning points, so can look at the segment and derive thresholds to prevent segments being formed out of a chunk that has almost no motion. 

In order to reduce noise/oscillation effects, they noted that between segments, ZVC occurs for multiple DOF at a time, so they included an additional criteria of needing multiple ZVCs in a 300 ms frame (emperically derived) before declaring a segment as separate. This is denoted as the SEG-1 routine. They applied this principle to both the start of a segment and the end of one. This lead to segments that didn’t fit this, and was thus dropped, making it impossible to re-construct motion (Completeness) from it. In a given segment, it is most likely that the segment velocity is constant, thus the change in directions and whatnot symbolizes a different primitive.


SEG-1 however, has many flaws with it. Euler angles represent the system as 4 angles, and there are times when a set of angles would ZVC while other angles would not. Sometimes, ZVC wouldn’t characterize change in primitives (such as movement in smooth curve patterns, like tracing out a circle repeatedly). So SEG-1 is only good for well-defined primitives. We’re not always going to get well-defined segments...so...

SEG-2 looks at sum of squares of the angular velocity (denote this as z). Noted that z is high within a segment and low at segment edges. When z is low for an extended amount of time, the person is stationary.


(I think I understood this correctly...) For each segment, they divided each into 100 vectors (so 400 vectors for all 4 DOF), and calculated the mean/covariance. (This is where I got lost) they derive eigenvalues from this array and represent the other vectors with respects to it (they use a clustering technique for this). It is mentioned that the more eigenvalues that are used, the more accurate the system becomes. This can be reversed to reconstruct the segments. Time data needs to be stored separately since this technique normalizes the time. 

The rest of the article talks about reconstruction (duplication on a humanoid) and stats at how well it worked.



They expanded on the basic ZVC approach, considering both Pomplun's velocity thresholds \cite{Pomplun2000}, as well as declaring a segment point when multiple DOFs exhibit ZVCs within a short timespan. To reduce over-segmentation, only motions that begin and end with this given characteristic is marked as a segment. This method works only with certain types of movements, since not all motions would be characterized by multiple ZVCs. For example, a circular motion would not cause ZVCs in joint-based DOFs. Slow movement at the start or end of segments would also prevent a ZVC declaration at the correct location, even though the movement has effectively ceased. Also, this algorithm provides no method to reject over-segmentation caused by high-frequency movements, such as tremors. This algorithm was developed to segment motion for robot motion control, and thus segmentation accuracy was not a focus.},
  timestamp = {2009.09.11},
}

@TechReport{Fodor2002,
  Title                    = {A Survey of Dimension Reduction Techniques},
  Author                   = {Fodor, I. K.},
  Institution              = {Lawrence Livermore National Laboratory},
  Year                     = {2002},

  Abstract                 = {Advances in data collection and storage capabilities during the past decades have led to an information overload in most sciences. Researchers working in domains as diverse as engineering, astronomy, biology, remote sensing, economics, and consumer transactions, face larger and larger observations and simulations on a daily basis. Such datasets, in contrast with smaller, more traditional datasets that have been studied extensively in the past, present new challenges in data analysis. Traditional statistical methods break down partly because of the increase in the number of observations, but mostly because of the increase in the number of variables associated with each observation. The dimension of the data, is the number of variables that are measured on each observation. High-dimensional datasets present many mathematical challenges as well as some opportunities, and are bound to give rise to new theoretical developments. One of the problems with high-dimensional datasets is that, in many cases, not all the measured variables are ''important'' for understanding the underlying phenomena of interest. While certain computationally expensive novel methods can construct predictive models with high accuracy from high-dimensional data, it is still of interest in many applications to reduce the dimension of the original data prior to any modeling of the data. In this paper, we described several dimension reduction methods.},
  Keywords                 = {GENERAL AND MISCELLANEOUS//MATHEMATICS, COMPUTING, AND INFORMATION SCIENCE; ACCURACY; ASTRONOMY; BIOLOGY; DATA ANALYSIS; DIMENSIONS; ECONOMICS; REMOTE SENSING; SIMULATION; STORAGE, survey},
  Location                 = {http://www.scientificcommons.org/43425035},
  Review                   = {PCA - Find principle components, drop insig ones
FA - Find underlying factors and correlations
PFA - 
MLFA - 

...},
  Timestamp                = {2011.04.25}
}

@Article{Foerster1999,
  Title                    = {Detection of Posture and Motion by Accelerometry: A Validation Study in Ambulatory Monitoring},
  Author                   = {Foerster, F. and Smeja, M. and Fahrenberg, J.},
  Journal                  = {Computers in Human Behavior},
  Year                     = {1999},
  Number                   = {5},
  Pages                    = {571--583},
  Volume                   = {15},

  Publisher                = {Elsevier},
  Review                   = {Classification by looking at distance metric. Euclidean.

- sensor: accel, head movement, speech activity -> used L1 distance (threshold)},
  Timestamp                = {2013.10.04}
}

@Article{Fong2008,
  Title                    = {Methods for In-field User Calibration of an Inertial Measurement Unit Without External Equipment},
  Author                   = {Fong, W. T. and Ong, S. K. and Nee, A. Y. C.},
  Journal                  = {Measurement Science and Technology},
  Year                     = {2008},
  Number                   = {8},
  Pages                    = {085202:1-11},
  Volume                   = {19},

  Abstract                 = {This paper presents methods to calibrate and compensate for non-zero biases, non-unit scale factors, axis misalignments and cross-axis sensitivities of both the tri-axial accelerometer and gyroscopic setups in a micro-electro-mechanical systems (MEMS) based inertial measurement unit (IMU). These methods depend on the Earth's gravity as a stable physical calibration standard. Specifically, the calibration of gyroscopes is significantly improved by comparing the outputs of the accelerometer and the IMU orientation integration algorithm, after arbitrary motions. The derived property and proposed cost function allow the gyroscopes to be calibrated without external equipment, such as a turntable, or requiring precise maneuvers. Both factors allow the IMU to be easily calibrated by the user in the field so that it can function as an accurate orientation sensor. A custom-made prototype IMU is used to demonstrate the effectiveness of the proposed methods, with data that are carefully obtained using prescribed motions, as well as those less rigorously collected from the IMU when it is mounted on the head of a user or held in hands with brief random movements. With calibration, the observed average static angular error is less than a quarter of a degree and the dynamic angular error is reduced by a factor of 2 to 5.},
  Keywords                 = {IMU calibration},
  Review                   = {- pervious methods requires a lot of equipment. this paper claims no extra equipment
- mentions that recal needs ot occur often
- relies on: 1) static accel mag = 1, and 2) gravity vector measured in static must equal the one from IMU integration

- uses a series of cost min functions
- multistage calibration
 - 18 sets of static measurements: 6 flat surfaces, 12 edges, at least 1 second each
 - 18 sets of dynamic measurements: static (1s)-dyn (20s)-static (1s), mount on hinge to allow ease of rotation. rotation precision not critical, but should be secure
 - 24 sets of in-field collection

- i think this also expects constant ang velo},
  Timestamp                = {2011.07.19},
  Url                      = {http://stacks.iop.org/0957-0233/19/i=8/a=085202}
}

@Conference{Fontaine2003,
  Title                    = {Sourceless Human Body Motion Capture},
  Author                   = {Fontaine, D. AND David, D. AND Caritu, Y.},
  Booktitle                = {Proceedings of the Smart Objects Conference},
  Year                     = {2003},

  Abstract                 = {We introduce a new human machine interface based on the human body posture tracking. The using of multiple low cost and miniaturized sensors distributed on the body is able to provide the movement without any external sources. This information can then be used for real time character animation, interaction with virtual worlds and medical applications. Thanks to ease of use and low cost required components, such system will be compatible with consumer applications.},
  Keywords                 = {Postural detection},
  Review                   = {3D VR interfaces are very expensive. They want a cheaper option for the public. And do this without using sources (ie IR) or integration. They're doing this with accelerometers (sense direction of gravitational field) and magnetometer (direction of magnetic field), allowing for orientation to be obtained. The usual issues of dynamic objects interfering with accelerometer readings and ferromagnetic materials disturbing the magnetic field are noted. So they change the weightings of significance of depending on the situation. If the object is moving, then downgrade the accel importance. They calculate the norm (= g, if stationary) to determine this. 

As expected, this would give good results when static and poor results when dynamic. But they want real-time stuff. So they address a few issues...

1) Magnetic field calibration error - reading of Earth's field can change from location to location, so would need to recalibrate. Would need to be able to detect bad calibration due to ferric material in the environment. 

2) Tracking module sliding on skin - place the sensor near boney area (less muscle/fat, which slides)

3) Human motion are complicated - they applied the accel/mag data to a simplified model, which does not account for certain curvatures such as clavical motion and spinal lordosis. 

And this is just a proof of concept, I guess. They talk about how it's possible, but doesn't comment too much more.},
  Timestamp                = {2010.01.17}
}

@InProceedings{Fook2008,
  Title                    = {Innovative Platform for Tele-physiotherapy},
  Author                   = {Fook, V. F. S. and Hao, S. Z. and Wai, A. A. P. and Jayachandran, M. and Biswas, J. and Yee, L. S. and Yap, P.},
  Booktitle                = {Proceedings of the International Conference on e-health Networking, Applications and Services},
  Year                     = {2008},

  Abstract                 = {This paper introduces a novel tele-physiotherapy platform for supporting physiotherapy over the internet beyond the current manual, dedicated and hospital-based physiotherapy sessions. In particular, we explore the design and development of an integrated platform that supports synchronous and asynchronous physiotherapy collaborations between different users, automated rating of physiotherapy exercises, electronic recording for physiotherapy compliance by patients, and provides a three-dimensional (3D) visual output to feedback and motivate the patients to perform the physiotherapy exercises. It is hoped that that the platform will evolve by getting more feedbacks and reviews from all stakeholders such as the patients, physiotherapists, caregivers and medical professionals to improve patientspsila health state so that they can get back to their active lifestyle as soon as possible and to improve their quality of life.},
  Doi                      = {10.1109/HEALTH.2008.4600111},
  Keywords                 = {Internet;active lifestyle;asynchronous physiotherapy;caregivers;electronic recording;hospital-based physiotherapy sessions;medical professionals;patient health state improvement;physiotherapists;physiotherapy compliance;physiotherapy exercise automated rating;physiotherapy exercise performance;quality-of-life improvement;synchronous physiotherapy;tele-physiotherapy platform;three-dimensional visual output;Internet;biomechanics;patient rehabilitation;patient treatment;telemedicine;},
  Timestamp                = {2011.12.31}
}

@Article{Foster1982,
  Title                    = {Toward an Intelligent Editor of Digital Audio: Signal Processing Methods},
  Author                   = {Foster, S. and Schloss, W. A. and Rockmore, A. J.},
  Journal                  = {Computer Music Journal},
  Year                     = {1982},
  Number                   = {1},
  Pages                    = {42--51},
  Volume                   = {6},

  Publisher                = {JSTOR},
  Review                   = {- First pass: thresholding on peak amplitude envelope (denote silence areas), but does not solve all problems. For example, music notes can overlap, complicating the the segmentation
- Second pass: autoregressive model. Model the music signal as a n-th order autoregressive model


Foster \etal \cite{Foster1982} is interested in extracting musical contents and segmenting out musical notes. Three methods are proposed. First method involves thresholding on the peak amplitude envelope of the observation, to remove silence. However, music notes do not tend to be isolated, so this method is not perfect. Second method involves modeling the music signal as a \emph{n}-th order auto-regressive model, which can segment out details that is missed by the amplitude method. However, the auto-regressive model is unable to segment signals that change subtly. The third method focus on pitch detection. The loudest part of a given sound is modeled as a summation of amplitudes in order to determine the notes that contributed into creating such sound. Some of these algorithms were details for future works, and thus implementation details were not provided.},
  Timestamp                = {2013.08.29}
}

@InProceedings{Fothergill2012,
  Title                    = {Instructing people for training gestural interactive systems},
  Author                   = {Fothergill, S. and Mentis, H. M. and Kohli, P. and Nowozin, S.},
  Booktitle                = {ACM Conference on Human Factors in Computing Systems},
  Year                     = {2012},
  Pages                    = {1737--1746},

  Timestamp                = {2015.07.01}
}

@Article{Fox2014,
  Title                    = {Joint modeling of multiple time series via the Beta process with application to motion capture segmentation},
  Author                   = {Fox, E. B. and Hughes, M. C. and Sudderth, E. B. and Jordan, M. I.},
  Journal                  = {The Annals of Applied Statistics},
  Year                     = {2014},
  Pages                    = {1281--1313},
  Volume                   = {8},

  Abstract                 = {We propose a Bayesian nonparametric approach to the problem of jointly
modeling multiple related time series. Our model discovers a latent set of
dynamical behaviors shared among the sequences, and segments each time
series into regions defined by a subset of these behaviors. Using a beta process
prior, the size of the behavior set and the sharing pattern are both inferred
from data. We develop Markov chain Monte Carlo (MCMC) methods based
on the Indian buffet process representation of the predictive distribution of the
beta process. Our MCMC inference algorithm efficiently adds and removes
behaviors via novel split-merge moves as well as data-driven birth and death
proposals, avoiding the need to consider a truncated model. We demonstrate
promising results on unsupervised segmentation of human motion capture
data.},
  Publisher                = {Institute of Mathematical Statistics},
  Review                   = {Mocap doing exercises from many individuals. uses CMU datasets. 12 DOF, some exercises complete with manual segmentation

Uses a Markov model (Markov switching processes) with switching vector autoregression - we have a global set of possible behaviours, but each time series only exhibit a subset of these behaviours. a beta process determines which of the behaviours (the HMMs) are enabled at a time. BP is sparce in nature, which forces generalization. Each activity is "feature-constrained" (only a handful of HMMs can be enabled for that behaviour) by Dirichlet probability, the training of this favours the remaining in the same state. 

Fox et al examines multiple sets of time series data simultatnously to extract global movement characteristics over all the movements, to which individual time series only exhibit some subset of these characteristcs, over certain lengths of time. These characteristics are assumed to obey the Markov condition and are modelled as autoregression processes. Segments are declared when the time series shift from one model to another. 

, while the specific charact, while the specific , as a collection of autoregressive processes.

-},
  Timestamp                = {2015.06.30}
}

@Article{Francois2009,
  Title                    = {A Long-term Study of Children with Autism Playing with a Robotic Pet: Taking Inspirations from Non-directive Play Therapy to Encourage Children's Proactivity and Initiative-taking},
  Author                   = {Fran\c{c}ois, D. AND Powell, S. AND Dautenhahn, K.},
  Journal                  = {Interaction Studies},
  Year                     = {2009},
  Pages                    = {324--373},
  Volume                   = {10},

  Abstract                 = {This paper presents a novel methodological approach of how to design, conduct and analyse robot-assisted play. This approach is inspired by non-directive play therapy. The experimenter participates in the experiments, but the child remains the main leader for play. Besides, beyond inspiration from non-directive play therapy, this approach enables the experimenter to regulate the interaction under specific conditions in order to guide the child or ask her questions about reasoning or affect related to the robot. This approach has been tested in a long-term study with six children with autism in a school setting. An autonomous robot with zoomorphic, dog-like appearance was used in the studies. The children's progress was analyzed according to three dimensions, namely, Play, Reasoning and Affect. Results from the case-study evaluations have shown the capability of the method to meet each child's needs and abilities. Children who mainly played solitarily progressively experienced basic imitation games with the experimenter. Children who proactively played socially progressively experienced higher levels of play and constructed more reasoning related to the robot. They also expressed some interest in the robot, including, on occasion, affect.},
  Keywords                 = {human-robot interaction},
  Review                   = {50 pages!

- modelled after non-directed play (no specific instuctions are given to the autistic child, beyond safety-based ones)
- autistic children tend to be more reactive to robotic toys than mechanical toys
- had a bunch of autistic kids play with a Sony AIBO
 - very detailed analysis and discussion of interactions of 6 autistic kids and the AIBO, programmed with some simple action/reaction scripts},
  Timestamp                = {2011.02.09}
}

@InProceedings{Franc2011,
  Title                    = {Support vector machines as probabilistic models},
  Author                   = {Franc, Vojtech and Zien, Alexander and Sch{\"o}lkopf, Bernhard},
  Booktitle                = {Proceedings of the International Conference on Machine Learning},
  Year                     = {2011},
  Pages                    = {665--672},

  Review                   = {Related work:
Sollich2002 - converts the hinge loss (the error of the classifier during training? basically an error function for the training) into a likelihood. However, it's bad: it's minimal at margin (since it's a measure of uncertainity), and increases at higher distance from decision surface.
Grandvalet2005 - SVM objective function (...the Lagrangian?) is mapped to a LL
Platt2000 - Fits a logit function to map SVM output to probablities. Effectively MAP. 

They recast SVM into an ML problem, thus getting a generative SVM. Doesn't actually modify the SVM, but come up with a new algorithm that uses the same principles of SVM. Cannot be kernelized.},
  Timestamp                = {2015.02.05}
}

@PhdThesis{Freeman2014_thesis,
  Title                    = {Feature selection and hierarchical classifier design with applications to human motion recognition.},
  Author                   = {Freeman, C.},
  School                   = {University of Waterloo},
  Year                     = {2014},

  Owner                    = {jf2lin},
  Timestamp                = {2015.04.06}
}

@Article{Freeman2015,
  Title                    = {An evaluation of classifier-specific filter measure performance for feature selection},
  Author                   = {Cecille Freeman and Dana Kuli\'{c} and Otman Basir},
  Journal                  = {Pattern Recognition },
  Year                     = {2015},
  Number                   = {5},
  Pages                    = {1812--1826},
  Volume                   = {48},

  Abstract                 = {Abstract Feature selection is an important part of classifier design. There are many possible methods for searching and evaluating feature subsets, but little consensus on which methods are best. This paper examines a number of filter-based feature subset evaluation measures with the goal of assessing their performance with respect to specific classifiers. This work tests 16 common filter measures for use with K-nearest neighbors and support vector machine classifiers. The measures are tested on 20 real and 20 artificial data sets, which are designed to probe for specific challenges. The strengths and weaknesses of each measure are discussed with respect to the specific challenges and correlation with classifier accuracy. The results highlight several challenging problems with a number of common filter measures. The results indicate that the best filter measure is classifier-specific. K-nearest neighbors classifiers work well with subset-based RELIEF, correlation feature selection or conditional mutual information maximization, whereas Fisher's interclass separability criterion and conditional mutual information maximization work better for support vector machines. Despite the large number and variety of feature selection measures proposed in the literature, no single measure is guaranteed to outperform the others, even within a single classifier, and the overall performance of a feature selection method cannot be characterized independently of the subsequent classifier.},
  Doi                      = {http://dx.doi.org/10.1016/j.patcog.2014.11.010},
  ISSN                     = {0031-3203},
  Keywords                 = {Feature selection},
  Timestamp                = {2015.03.12},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0031320314004804}
}

@Article{Freund1999,
  Title                    = {A Short Introduction to Boosting},
  Author                   = {Freund, Y. AND Schapire, R. E.},
  Journal                  = {Journal of Japanese Society for Artificial Intelligence},
  Year                     = {1999},
  Pages                    = {771--780},
  Volume                   = {14},

  Abstract                 = {Boosting is a general method for improving the accuracy of any given learning algorithm. This short overview paper introduces the boosting algorithm AdaBoost, and explains the underlying theory of boosting, including an explanation of why boosting often does not suffer from overfitting as well as boosting’s relationship to support-vector machines. Some examples of recent applications of boosting are also described.},
  Timestamp                = {2011.04.27}
}

@Article{Freund1997,
  Title                    = {A Decision-Theoretic Generalization of On-line Learning and an Application to Boosting},
  Author                   = {Freund, Y. AND Schapire, R. E.},
  Journal                  = {Journal of Computer and System Sciences},
  Year                     = {1997},
  Number                   = {1},
  Pages                    = {119--139},
  Volume                   = {55},

  Abstract                 = {In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weightupdate rule of Littlestone and Warmuth [15] can be adapted to this model yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games and prediction of points in R n . In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line.},
  Booktitle                = {Journal of Computer and System Sciences},
  Keywords                 = {Lab reading (Ali)},
  Review                   = {- Machine learning algorithm. Fast. 

- Take a bunch of weak classifiers (could just be slightly better than chance)
- Feed in sample data and see how they classify things. If they're correct, weigh them higher
- Classify based on the entire combined weaker classifiers},
  Timestamp                = {2011.02.17}
}

@Conference{Fu2009,
  author    = {Fu, Y. AND Ayyagari, D. AND Colquitt, N.},
  title     = {Pulmonary Disease Management System with Distributed Wearable Sensors},
  booktitle = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  year      = {2009},
  abstract  = {A pulmonary disease management system with on-body and near-body sensors is introduced in this presentation. The system is wearable for continuous ambulatory monitoring. Distributed sensor data is transferred through a wireless body area network (BAN) to a central controller for real time analysis. Physiological and environmental parameters are monitored and analyzed using prevailing clinical guidelines for self-management of environmentally-linked pulmonary ailments. The system provides patients with reminders, warnings, and instructions to reduce emergency room and physician visits, and improve clinical outcomes.},
  groups    = {EMBS2009},
  review    = {- pulmonary disease (ie asthma) requires scheduling and on-going reassessment
- disease management: managing a patient with known diagnosis with intent of providing patient education and monitoring symptoms
- advances in sensors and low-power wireless network allows for low-cost, small/light non-invasive monitoring system},
  timestamp = {2009.11.09},
}

@InProceedings{Fung2002,
  Title                    = {Incremental Support Vector Machine Classification},
  Author                   = {Fung, G. and Mangasarian, O. L.},
  Booktitle                = {Proceedings of the SIAM International Conference on Data Mining},
  Year                     = {2002},
  Pages                    = {247--260},

  Abstract                 = {Using a recently introduced proximal support vector machine classifier [4], a very fast and simple incremental support vector machine (SVM) classifier is proposed which is capable of modifying an existing linear classifier by both retiring old data and adding new data. A very important feature of the proposed single-pass algorithm, which allows it to handle massive datasets, is that huge blocks of data, say of the order of millions of points, can be stored in blocks of size (n + 1)2, where n is the usually small (typically less than 100) dimensional input space in which the data resides. To demonstrate the effectiveness of the algorithm we classify a dataset of 1 billion points in 10-dimensional input space into two classes in less than 2.5 hours on a 400 MHz Pentium II processor.


Read More: http://epubs.siam.org/doi/abs/10.1137/1.9781611972726.15},
  Timestamp                = {2014.10.25}
}

@MastersThesis{Futamure2015,
  Author                   = {Futamure, S.},
  School                   = {Tokyo University of Agriculture and Technology},
  Year                     = {2015},

  Owner                    = {jf2lin},
  Timestamp                = {2016.02.11}
}

@InProceedings{Gallagher2004,
  Title                    = {An Efficient Real-time Human Posture Tracking Algorithm using Low-cost Inertial and Magnetic Sensors},
  Author                   = {Gallagher, A. and Matsuoka, Y. and Ang, W. T.},
  Booktitle                = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2004},
  Pages                    = {2967 - 2972},
  Volume                   = {3},

  Abstract                 = {Real-time accurate human posture tracking in unconstrained environments provides an enabling technology for physicians and other care providers to monitor the movements of their patients in real-life situations. Constructing a posture tracking system with the form factor suitable for human wear requires the development of miniature units that can be attached to the limb segments of interest in an unobtrusive way. Simultaneously, fast algorithms that can produce real-time posture estimates at sufficient rates are needed. In this paper, we focus on the development of efficient and accurate algorithms that compute the human posture information from low-cost miniature inertial and magnetic sensors. We present a new technique that computes posture estimates from the sensor data 23.8 times faster than the most efficient previously proposed technique, and simultaneously increases the accuracy of the estimates.},
  Doi                      = {10.1109/IROS.2004.1389860},
  Keywords                 = {human posture; human wear; inertial sensor; limb segments; magnetic sensor; real-time human posture tracking algorithm; computerised monitoring; magnetic sensors; patient monitoring; postural detection},
  Review                   = {Uses accel, gyro, mag sensors.},
  Timestamp                = {2011.03.01}
}

@Article{Ganapathiraju2004,
  Title                    = {Applications of Support Vector Machines to Speech Recognition},
  Author                   = {Ganapathiraju, A. and Hamaker, J. E. and Picone, J.},
  Journal                  = {IEEE Transactions on Signal Processing},
  Year                     = {2004},
  Pages                    = {2348--2355},
  Volume                   = {52},

  Abstract                 = {Recent work in machine learning has focused on models, such as the support vector machine (SVM), that automatically control generalization and parameterization as part of the overall optimization process. In this paper, we show that SVMs provide a significant improvement in performance on a static pattern classification task based on the Deterding vowel data. We also describe an application of SVMs to large vocabulary speech recognition and demonstrate an improvement in error rate on a continuous alphadigit task (OGI Alphadigits) and a large vocabulary conversational speech task (Switchboard). Issues related to the development and optimization of an SVM/HMM hybrid system are discussed.},
  Publisher                = {IEEE},
  Review                   = {- applied SVM to ASR of std test data sets
- hybrid SVM/HMM alg

Ganapathiraju \etal \cite{Ganapathiraju2004} proposes a hybrid support vector machine (SVM) and HMM system to classify and segment speech data. Probabilistic approaches such as HMMs and artificial neural networks (ANNs) are not ideal due to impreciseness of machine learning algorithms, long training time, and the potential to overfit the data. SVM is able to determine the most optimal classifier boundary via empirical risk minimization. However, SVM provides a classification decision and not the uncertainty associated with the decision. It is unclear the relationship between the distance from the classification boundary and the posterior probability, resulting in overconfident classifications. SVM also does not properly consider temporal details, making it difficult to use for segmentation purposes. [don't quite follow yet, come back later]},
  Timestamp                = {2013.08.29}
}

@Article{Ganea2012,
  Title                    = {Detection and Classification of Postural Transitions in Real-world Conditions},
  Author                   = {Ganea, R. and Paraschiv-Ionescu, A. and Aminian, K.},
  Journal                  = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  Year                     = {2012},
  Number                   = {5},
  Pages                    = {688--696},
  Volume                   = {20},

  Abstract                 = {This study proposes a new robust classifier for sitto- stand (SiSt) and stand-to-sit (StSt) detection in daily activity. The monitoring system consists of a single inertial sensor placed on the trunk. By using dynamic time warping, the trunk acceleration patterns of SiSt and StSi are classified based on their similarity with specific templates. The classification algorithm is validated with actual data obtained in a real-world environment (5 healthy subjects and 5 chronic pain patients); the best accuracy is obtained through using a custom template defined for each subject (> 95% for healthy subjects and 89% for chronic pain). Real-world examinations are found to be preferable because after validating results collected in both real-world and laboratory conditions, the controlled conditions predictions are too optimistic. Finally the potential of the new method in clinical evaluation is studied in both healthy and frail elderly subjects. Frail elderly participants show a significantly lower rate of postural transitions, longer SiSt duration and lower SiSt trunk tilt and acceleration compared to healthy elderly subjects. We conclude that the proposed wearable system provides a simple method to detect and characterize postural transitions in healthy, chronic pain and frail elderly subjects.},
  Doi                      = {10.1109/TNSRE.2012.2202691},
  ISSN                     = {1534-4320},
  Keywords                 = {Posture detection},
  Timestamp                = {2012.07.10}
}

@InProceedings{Ganesh2008,
  Title                    = {Recognition of Human Actions using an Optimal Control Based Motor Model},
  Author                   = {S. Ganesh and R. Bajcsy},
  Booktitle                = {Proceedings of the IEEE Workshop on Applications of Computer Vision},
  Year                     = {2008},
  Pages                    = {1--6},

  Abstract                 = {We present a novel approach to the problem of representation and recognition of human actions, that uses an optimal control based model to connect the high-level goals of a human subject to the low-level movement trajectories captured by a computer vision system. These models quantify the high-level goals as a performance criterion or cost function which the human sensorimotor system optimizes by picking the control strategy that achieves the best possible performance. We show that the human body can be modeled as a hybrid linear system that can operate in one of several possible modes, where each mode corresponds to a particular high-level goal or cost function. The problem of action recognition, then is to infer the current mode of the system from observations of the movement trajectory. We demonstrate our approach on 3D visual data of human arm motion.},
  Doi                      = {10.1109/WACV.2008.4544021},
  ISSN                     = {1550-5790},
  Keywords                 = {computer vision;gait analysis;image motion analysis;image representation;object recognition;optimal control;stereo image processing;3D visual data;computer vision system;cost function;human action recognition;human action representation;human arm motion;human motion analysis;human sensorimotor system;human subject;hybrid linear system;motor model;movement trajectory;optimal control;Biological system modeling;Computer vision;Cost function;Humans;Kinematics;Linear systems;Mathematical model;Motion control;Optimal control;Switches},
  Timestamp                = {2017.02.23}
}

@Conference{Gao2008,
  Title                    = {Wireless Medical Sensor Networks in Emergency Response: Implementation and Pilot Results},
  Author                   = {Gao, T. AND Pesto, C. AND Selavo, L. AND Chen, Y. AND Ko, J.-G. AND Lim, J.-H. AND Terzis, A. AND Watt, A. AND Jeng, J. AND Chen, B.-R. AND Lorincz, K. AND Welch, M.},
  Booktitle                = {Proceedings of the IEEE International Conference on Technologies for Homeland Security},
  Year                     = {2008},

  Abstract                 = {This project demonstrates the feasibility of using cost-effective, flexible, and scalable sensor networks to address critical bottlenecks of the emergency response process. For years, emergency medical service providers conducted patient care by manually measuring vital signs, documenting assessments on paper, and communicating over handheld radios. When disasters occurred, the large numbers of casualties quickly and easily overwhelmed the responders. Collaboration with EMS and hospitals in the Baltimore Washington Metropolitan region prompted us to develop miTag (medical information tag), a cost-effective wireless sensor platform that automatically track patients throughout each step of the disaster response process, from disaster scenes, to ambulances, to hospitals. 

The miTag is a highly extensible platform that supports a variety of sensor add-ons - GPS, pulse oximetry, blood pressure, temperature, ECG - and relays data over a self-organizing wireless mesh network. Scalability is the distinguishing characteristic of miTag: its wireless network scales across a wide range of network densities, from sparse hospital network deployments to very densely populated mass casualty sites. 

The miTag system is out-of-the-box operational and includes the following key technologies: 1) cost-effective sensor hardware, 2) self-organizing wireless network and 3) scalable server software that analyzes sensor data and delivers real-time updates to handheld devices and web portals. The system has evolved through multiple iterations of development and pilot deployments to become an effective patient monitoring solution. A pilot conducted with the Department of Homeland Security indicates miTags can increase the patient care capacity of responders in the field. A pilot at Washington Hospital showed miTags are capable of reliably transmitting data inside radio-interference-rich critical care settings.},
  Review                   = {Triage - The prioritization of patients by seriousness in a disaster situation. Currently done very disorderly, so electronic tags were created to help address this issue. These electronic tags, called miTags, can store the same type of information as paper tags, but also provide sensor data, such as vital signs and location, and transmit all these data over a mesh network to monitoring stations. The sensors on these tags can include: GPS, pulse oximeter (blood saturation), blood pressure cuff, temperature and ECG. This allows supervisors to obtain real-time patient information, and act with an accurate sense of situational awareness. Must be completely reliable, and easy to deploy. 

Current works are typically require a gateway device (ie PDA or smart-phone) to transmit data, which scales poorly, or are standalone, and cannot accept additional equipment/sensor types easily (so not flexible). miTag was designed to be flexible, according to the situation of where it is being used. It transmits more often if the patient is deteriorates. It can support a wide variety of sensor types. 

miTag consists of: duplex wireless communication. Sensor interfaces to support additional sensors. It supports mesh network. So what ideally happens is that the various miTags sends info into a local node on the body (in the case where multiple miTags are placed on a given patient), then transmitted long-range via mesh networking. The mesh network is facilitated by repeater nodes that would need to be dropped as the responders move throughout the crisis area, thus expanding the coverage area. Data in the mesh are pushed to a central server that collects the data and allows third parties to retrieve data. The server relies on MySQL and Java Message Service protocols to provide web portals for data access. 

The incident was simulated. One was a traffic accident (20 patients). A pilot was ran at a Bur Centre. No interference found.},
  Timestamp                = {2010.05.17}
}

@Article{Garcia2007,
  Title                    = {The Evolution of Robotics Research},
  Author                   = {Garcia, E. and Jimenez, M. A. and de Santos, P. G. and Armada, M.},
  Journal                  = {IEEE Robotics Automation Magazine},
  Year                     = {2007},
  Number                   = {1},
  Pages                    = {90--103},
  Volume                   = {14},

  Abstract                 = {This article surveys traditional research topics in industrial robotics and mobile robotics and then expands on new trends in robotics research that focus more on the interaction between human and robot. The new trends in robotics research have been denominated service robotics because of their general goal of getting robots closer to human social needs, and this article surveys research on service robotics such as medical robotics, rehabilitation robotics, underwater robotics, field robotics, construction robotics and humanoid robotics. The aim of this article is to provide an overview of the evolution of research topics in robotics from classical motion control for industrial robots to modern intelligent control techniques and social learning paradigms, among other aspects},
  Doi                      = {10.1109/MRA.2007.339608},
  ISSN                     = {1070-9932},
  Keywords                 = {construction robotics;field robotics;humanoid robotics;industrial robotics;intelligent control;medical robotics;mobile robotics;motion control;rehabilitation robotics;service robotics;underwater robotics;humanoid robots;industrial robots;intelligent control;medical robotics;mobile robots;motion control;service robots;underwater vehicles;},
  Timestamp                = {2011.06.11}
}

@InProceedings{Gehrig2010,
  Title                    = {Towards Semantic Segmentation of Human Motion Sequences},
  Author                   = {Gehrig, D. and Stein, T. and Fischer, A. and Schwameder, H. and Schultz, T.},
  Booktitle                = {Proceedings of the 33rd Annual German Conference on Advances in Artificial Intelligence},
  Year                     = {2010},
  Pages                    = {436--443},
  Publisher                = {Springer-Verlag},
  Series                   = {KI'10},

  Abstract                 = {In robotics research is an increasing need for knowledge about human motions. However humans tend to perceive motion in terms of discrete motion primitives. Most systems use data-driven motion segmentation to retrieve motion primitives. Besides that the actual intention and context of the motion is not taken into account. In our work we propose a procedure for segmenting motions according to their functional goals, which allows a structuring and modeling of functional motion primitives. The manual procedure is the first step towards an automatic functional motion representation. This procedure is useful for applications such as imitation learning and human motion recognition. We applied the proposed procedure on several motion sequences and built a motion recognition system based on manually segmented motion capture data. We got a motion primitive error rate of 0.9% for the marker-based recognition. Consequently the proposed procedure yields motion primitives that are suitable for human motion recognition.},
  Acmid                    = {1882207},
  ISBN                     = {3-642-16110-3, 978-3-642-16110-0},
  Keywords                 = {Motion Segmentation},
  Location                 = {Karlsruhe, Germany},
  Numpages                 = {8},
  Review                   = {- "However, humans tend to perceive motion in terms of discrete motion primitives" (wow, there's papers for this?)

- Uses joint angles from camera data
- HMM model
- Manual segmentation},
  Timestamp                = {2011.01.27},
  Url                      = {http://portal.acm.org/citation.cfm?id=1882150.1882207}
}

@Article{Geib2009,
  author    = {Geib, C. W. and Goldman, R. P.},
  title     = {A Probabilistic Plan Recognition Algorithm Based on Plan Tree Grammars},
  journal   = {Artificial Intelligence},
  year      = {2009},
  volume    = {173},
  number    = {11},
  pages     = {1101--1132},
  issn      = {0004-3702},
  abstract  = {We present the \{PHATT\} algorithm for plan recognition. Unlike previous approaches to plan recognition, \{PHATT\} is based on a model of plan execution. We show that this clarifies several difficult issues in plan recognition including the execution of multiple interleaved root goals, partially ordered plans, and failing to observe actions. We present the \{PHATT\} algorithm's theoretical basis, and an implementation based on tree structures. We also investigate the algorithm's complexity, both analytically and empirically. Finally, we present PHATT's integrated constraint reasoning for parametrized actions and temporal constraints.},
  doi       = {10.1016/j.artint.2009.01.003},
  groups    = {Lit Review 2013-09},
  keywords  = {Plan recognition},
  review    = {Used Poole's Probablistic Horn Abudction (PHA) logic prover to generate a plan and for a sequence of observations. Want to generate Context Free Grammars (CFG)},
  timestamp = {2013.09.29},
  url       = {http://www.sciencedirect.com/science/article/pii/S0004370209000459},
}

@Article{George1991,
  Title                    = {A Low-cost Fiber-optic Strain Gauge System for Biological Applications},
  Author                   = {George, D. T. AND Bogen, D. K.},
  Journal                  = {IEEE Transactions on Biomedical Engineering},
  Year                     = {1991},
  Pages                    = {919--924},
  Volume                   = {38},

  Abstract                 = {A novel low-cost strain measurement system has been developed for the mechanical testing of biological soft tissues. The technique creates four spots of light on a tissue sample surface by piercing the tissue sample with two pairs of small light-conducting optical fibers (one pair for each axis of a biaxial stretch), terminated by high intensity infrared emitters. A large-area photodiode, located below the tissue sample, detects the light emitted from the two pairs of light-spots. Analog and digital circuitry analyze the current signal from the photodiode to determine the position of a light-spot in real time. Each infrared emitter is sequentially cycled 'on' at a rate of 3 kHz and the resulting photodiode current signal, after being converted to a voltage signal, is held by an integrated circuit sample and hold amplifier. Analog differencing of pairs of light-spot voltage signals provides a final output proportional to the separation between coaxial light-spots.},
  Review                   = {Punched holes in the tissue and threaded optical fibers into them, with IR LEDs. Photodiodes detect light emittion and bend pattern. Very ECE471. Use very small (760 um diameter) optical fiber. When the tissues move, the light from the photodiode would shift on the photodiode. Photodiode produces current (photoelectric effect), which is converted to voltage via opamps. A differnetial circuit is used to prevent amplification of common signals (ie current flow to power the systems). 

Would light-fibers inserted into the tissue interfere with deformation? Consider the light-fiber as a cantilever beam. One side is fixed by LED housing, the other side is the stainless steel needle that's pushed into the tissue. When it bends, it acts like a lever...they did some calculations, which they figured is actually rather small compared to the tissue itself. So should be okay...note that it's not just a hole, there is some 'filling-in'. The tissue, after being penetrated by a needle, would 'close in' around the issue since it's not actually a cut. This will create a stress concentration point.


Strain gauge linearity is an important point. 1) If the light strays too far from the central axis of the photodiode, we have problems. 2) Light-to-current conversion of the photodiode is non-linear. 3) Light-spot intensity itself is non-linear. 

Conclusion: low cost (~$1000), high sample rate, and not dependent on tissue sample itself to have uniform color and whatnot. Bad in that there is a fixed field of view, tissue interruption due to light-fiber insertion and non-linearitiy.},
  Timestamp                = {2009.12.07},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=83612}
}

@Article{Gerard2002,
  Title                    = {Application of Conducting Polymers to Biosensors},
  Author                   = {Gerard, M. and Chaubey, A. and Malhotra, B. D.},
  Journal                  = {Biosensors and Bioelectronics},
  Year                     = {2002},
  Number                   = {5},
  Pages                    = {345--359},
  Volume                   = {17},

  Abstract                 = {Recently, conducting polymers have attracted much interest in the development of biosensors. The electrically conducting polymers are known to possess numerous features, which allow them to act as excellent materials for immobilization of biomolecules and rapid electron transfer for the fabrication of efficient biosensors. In the present review an attempt has been made to describe the salient features of conducting polymers and their wide applications in health care, food industries, environmental monitoring etc.},
  Doi                      = {DOI: 10.1016/S0956-5663(01)00312-8},
  ISSN                     = {0956-5663},
  Keywords                 = {Conduction polymer},
  Timestamp                = {2010.11.01},
  Url                      = {http://www.sciencedirect.com/science/article/B6TFC-44NM0GH-8/2/82b6788478f57887b65b1b32baf59797}
}

@Article{Geyer2006,
  Title                    = {Compliant leg behaviour explains basic dynamics of walking and running},
  Author                   = {Geyer, H. and Seyfarth, A. and Blickhan, R.},
  Journal                  = {Proceedings of the Royal Society B: Biological Sciences},
  Year                     = {2006},
  Number                   = {1603},
  Pages                    = {2861-2867},
  Volume                   = {273},

  Abstract                 = {The basic mechanics of human locomotion are associated with vaulting over stiff legs in walking and rebounding on compliant legs in running. However, while rebounding legs well explain the stance dynamics of running, stiff legs cannot reproduce that of walking. With a simple bipedal spring–mass model, we show that not stiff but compliant legs are essential to obtain the basic walking mechanics; incorporating the double support as an essential part of the walking motion, the model reproduces the characteristic stance dynamics that result in the observed small vertical oscillation of the body and the observed out-of-phase changes in forward kinetic and gravitational potential energies. Exploring the parameter space of this model, we further show that it not only combines the basic dynamics of walking and running in one mechanical system, but also reveals these gaits to be just two out of the many solutions to legged locomotion offered by compliant leg behaviour and accessed by energy or speed.},
  Doi                      = {10.1098/rspb.2006.3637},
  Eprint                   = {http://rspb.royalsocietypublishing.org/content/273/1603/2861.full.pdf+html},
  Keywords                 = {ECE780},
  Timestamp                = {2011.03.10},
  Url                      = {http://rspb.royalsocietypublishing.org/content/273/1603/2861.abstract}
}

@Article{Ghahramani2001,
  Title                    = {An introduction to hidden Markov models and Bayesian networks},
  Author                   = {Ghahramani, Zoubin},
  Journal                  = {International Journal of Pattern Recognition and Artificial Intelligence},
  Year                     = {2001},
  Number                   = {01},
  Pages                    = {9--42},
  Volume                   = {15},

  Keywords                 = {HMM tutorial Survey},
  Publisher                = {World Scientific},
  Timestamp                = {2014.02.26}
}

@Article{Giansanti2003,
  Title                    = {Is it feasible to reconstruct body segment 3-D position and orientation using accelerometric data?},
  Author                   = {Giansanti, D. and Macellari, V. and Maccioni, G. and Cappozzo, A.},
  Journal                  = {IEEE Transactions on Biomedical Engineering},
  Year                     = {2003},
  Pages                    = {476--483},
  Volume                   = {50},

  Abstract                 = {The analysis of the mechanics of the musculo-skeletal system during the execution of a motor task requires the determination of the instantaneous position and orientation of the body segments involved in relation to an inertial system of reference. By using adequately assembled uniaxial accelerometric sensors, an easy-to-manage measurement system can be obtained that estimates the three-dimensional position and orientation (P&O) of a body segment through an appropriate analytical model. However, the extent to which experimental errors, in particular accelerometers (ACs) assembly inaccuracies, affect such estimation has never been systematically investigated. 

This paper systematically analyzes the sensitivity of analytical models of body segment P&O reconstruction through a six-AC system and a nine-AC system to different sources of experimental error. We simulated and statistically assessed the performance of these models in the case of body segment motions typical of movements under muscular control. The results obtained indicated that the inaccuracy in the orientation of the individual AC's active axes and the offset error in the AC responses were the major sources of P&O estimation errors. In particular, no accurate estimation of position was possible with the analytical models analyzed. 

Under the motion conditions simulated in this study, no substantial advantages were found in using a nine-AC system rather than a six-AC system. Considering that the magnitudes of the simulated experimental errors were quite low (LTE 0.1 deg: AC's orientation; LTE 10-4 m: uncertainty of the distance between two ACs; LTE 10-2 ms-2: random error; 0.5·10-2 ms-2: offset error), the results indicate that none of the two ACs systems analyzed is suitable for body segment P&O estimation in routine biomechanical applications.

LTE = less than or equal to},
  Doi                      = {10.1109/TBME.2003.809490},
  ISSN                     = {0018-9294},
  Keywords                 = {accelerometers, biocontrol, biomechanics, biomedical measurement, measurement errors, muscle, neurophysiology, physiological modelsaccelerometric data, active axes, analytical model, body segment 3-D position, body segment motions, body segment orientation, body segment reconstruction, easy-to-manage measurement system, estimation errors, experimental errors, inertial system of reference, mechanics, motor task execution, muscular control, musculo-skeletal system, nine-accelerometer system, offset error, random error, routine biomechanical applications, six-accelerometer system, statistical assessment, three-dimensional position, uniaxial accelerometric sensors, Postural detection},
  Review                   = {Want to have source-less sensors. Complained about cross-sensitivity. Maybe 3-axis accel is new technology?

Noise is not major source of inaccuracy. 
Gravity containmation is an issue. 
Complex motions are horrible. 
Provides only relative data.},
  Timestamp                = {2010.01.18}
}

@Article{Gibbons2001,
  Title                    = {Reference Values for a Multiple Repetition 6-Minute Walk Test in Healthy Adults Older Than 20 Years},
  Author                   = {Gibbons, W. J. and Fruchter, N. and Sloan, S. and Levy, R. D.},
  Journal                  = {Journal of Cardiopulmonary Rehabilitation},
  Year                     = {2001},
  Pages                    = {87--93},
  Volume                   = {21},

  Abstract                 = {PURPOSE: To (1) identify greatest 6-minute walk distance (6MWD) from among several repetitions (best 6MWD) in a wide age range of healthy volunteers to develop reference values for the multiple repetition 6MWD, and (2) investigate the influence of demographics, anthropometrics, and habitual exercise activity on best 6MWD.

METHODS: Four 6MWD were performed on the same day in a 20-meter corridor by 41 male and 38 female healthy volunteers ranging in age from 20 to 80 years. The greatest 6MWD by each subject from among four 6MWDs was the primary outcome measure.

RESULTS: Eighty-six percent had their best 6MWD after the first walk; an average increase of 43 meters was observed from first to best 6MWD (P < 0.003). Best 6MWD averaged 698 ± 96 meters and was inversely related to age (P < 0.001), directly to height (P < 0.001), and was greater in men than women (P < 0.0002). A regression model accounted for 41% of between-subject variability in best 6MWD (P < 0.00000001). In a subset of older subjects, predicted 6MWD significantly underestimated measured best 6MWD when reference values were used from another study where test familiarization was not provided, but this difference disappeared when values were used from the present and a third study where test familiarization was provided.

CONCLUSIONS: The present study is the first to provide predicted 6MWD values performed with multiple repetitions and for subjects in the 20-40-year-old age range. Selection of appropriate predicted 6MWD values for interpretation of performance should be guided by subject age and degree of test familiarization provided.},
  Timestamp                = {2014.02.23}
}

@Article{Gibbs2005,
  Title                    = {Wearable Conductive Fiber Sensors for Multi-Axis Human Joint Angle Measurements},
  Author                   = {Gibbs, P. T. and Asada, H. H.},
  Journal                  = {Journal of NeuroEngineering and Rehabilitation},
  Year                     = {2005},
  Pages                    = {1},
  Volume                   = {2},

  Abstract                 = {A novel technique of incorporating conductive fibers into flexible, skin-tight fabrics surrounding a joint is developed. Resistance changes across these conductive fibers are measured, and directly related to specific single or multi-axis joint angles through the use of a non-linear predictor after an initial, one-time calibration. Because these sensors are intended for multiple uses, an automated registration algorithm has been devised using a sensitivity template matched to an array of sensors spanning the joints of interest. In this way, a sensor array can be taken off and put back on an individual for multiple uses, with the sensors automatically calibrating themselves each time.

The wearable sensors designed are comfortable, and acceptable for long-term wear in everyday settings. Results have shown the feasibility of this type of sensor, with accurate measurements of joint motion for both a single-axis knee joint and a double axis hip joint when compared to a standard goniometer used to measure joint angles. Self-registration of the sensors was found to be possible with only a few simple motions by the patient.

After preliminary experiments involving a pants sensing garment for lower body monitoring, it has been seen that this methodology is effective for monitoring joint motion of the hip and knee. This design therefore produces a robust, comfortable, truly wearable joint monitoring device.},
  Keywords                 = {Postural detection, IMU},
  Review                   = {Used a wearable stretch sensor system that performed basic motion detection of patient.},
  Tag                      = {Related works},
  Timestamp                = {2009.05.01},
  Url                      = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=555561}
}

@InBook{Giegerich2012,
  Title                    = {RNA Sequence, Structure and Function: Computational and Bioinformatic Methods},
  Author                   = {Giegerich, Robert},
  Chapter                  = {Introduction to Stochastic Context Free Grammars},
  Editor                   = {Gorodkin, Jan and Weinberg, Sasha},
  Publisher                = {Humana Press},
  Year                     = {2012},

  Abstract                 = {Stochastic context free grammars are a formalism which plays a prominent role in RNA secondary structure analysis. This chapter provides the theoretical
background on stochastic context free grammars. We recall the general definitions
and study the basic properties, virtues and shortcomings of stochastic context free
grammars. We then introduce two ways in which they are used in RNA secondary
structure analysis, secondary structure prediction and RNA family modeling. This
prepares for the discussion of applications of stochastic context free grammars in
the chapters on Rfam, Infernal, and Pfold.},
  Timestamp                = {2013.11.20}
}

@InProceedings{Giese1999,
  Title                    = {Synthesis and recognition of biological motion patterns based on linear superposition of prototypical motion sequences},
  Author                   = {Giese, M. A. and Poggio, T.},
  Booktitle                = {Proceedings of the IEEE Workshop on Multi-View Modeling and Analysis of Visual Scenes},
  Year                     = {1999},
  Pages                    = {73--80},

  Abstract                 = {The linear combination of prototypical views has been shown to provide a powerful method for the recognition and analysis of images of three-dimensional stationary objects. We present preliminary results on an extension of this idea to video sequences. For this extension, the computation of correspondences in space-time turns out to be the central theoretical problem, which we solve with a new correspondence algorithm. Using simulated images of biological motion we demonstrate the usefulness of the superposition of prototypical sequences for the synthesis of new video sequences, and for the analysis and recognition of actions. Our method permits to impose a topology over the space of video sequences of action patterns. This topology is more complicated than a linear space. We present a new method that is based on the structural risk minimization principle of statistical learning theory, which permits to exploit this knowledge about the topology of the pattern space for recognition},
  Doi                      = {10.1109/MVIEW.1999.781085},
  Keywords                 = {3D stationary objects;biological motion pattern recognition;biological motion pattern synthesis;correspondence algorithm;linear superposition;prototypical motion sequences;prototypical views;space time correspondence;statistical learning theory;structural risk minimization;three-dimensional stationary objects;topology;video sequences;computer animation;image motion analysis;image sequences;learning (artificial intelligence);pattern recognition;},
  Review                   = {This paper describes the algorithm used for Ilg2004},
  Timestamp                = {2012.07.28}
}

@Book{Gill1981,
  Title                    = {Practical Optimization},
  Author                   = {Gill, P. E. and Murray, W. and Wright, M. H.},
  Publisher                = {Academic Press, Inc},
  Year                     = {1981},

  Owner                    = {jf2lin},
  Timestamp                = {2016.06.01}
}

@Article{Gish1994,
  Title                    = {Text-independent speaker identification},
  Author                   = {Gish, H. and Schmidt, M.},
  Journal                  = {Signal Processing Magazine, IEEE},
  Year                     = {1994},
  Number                   = {4},
  Pages                    = {18--32},
  Volume                   = {11},

  Abstract                 = {We describe current approaches to text-independent speaker identification based on probabilistic modeling techniques. The probabilistic approaches have largely supplanted methods based on comparisons of long-term feature averages. The probabilistic approaches have an important and basic dichotomy into nonparametric and parametric probability models. Nonparametric models have the advantage of being potentially more accurate models (though possibly more fragile) while parametric models that offer computational efficiencies and the ability to characterize the effects of the environment by the effects on the parameters. A robust speaker-identification system is presented that was able to deal with various forms of anomalies that are localized in time, such as spurious noise events and crosstalk. It is based on a segmental approach in which normalized segment scores formed the basic input for a variety of robust 43% procedures. Experimental results are presented, illustrating 59% the advantages and disadvantages of the different procedures. 64%. We show the role that cross-validation can play in determining how to weight the different sources of information when combining them into a single score. Finally we explore a Bayesian approach to measuring confidence in the decisions made, which enabled us to reject the consideration of certain tests in order to achieve an improved, predicted performance level on the tests that were retained.<>},
  Doi                      = {10.1109/79.317924},
  ISSN                     = {1053-5888},
  Keywords                 = {Bayes methods;crosstalk;speech recognition;Bayesian approach;confidence measurement;crosstalk;experimental results;nonparametric models;parametric models;performance level;probabilistic modeling;robust speaker-identification system;segmental approach;spurious noise events;text-independent speaker identification;Automatic speech recognition;Automatic testing;Communication channels;Humans;Pattern classification;Robustness;Speaker recognition;Speech recognition;Telephony;Text recognition},
  Timestamp                = {2013.09.07}
}

@InProceedings{Gish1991,
  Title                    = {Segregation of Speakers for Speech Recognition and Speaker Identification},
  Author                   = {Gish, H. and Siu, M.-S. and Rohlicek, R.},
  Booktitle                = {Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  Year                     = {1991},
  Pages                    = {873--876},
  Volume                   = {2},

  Abstract                 = {A method for segregating speech from speakers engaged in dialogs is described. The method, assuming no prior knowledge of the speakers, employs a distance measure between speech segments used in conjunction with a clustering algorithm to perform the segregation. Properties of the distance measure are discussed, and an air traffic control application is described},
  Doi                      = {10.1109/ICASSP.1991.150477},
  ISSN                     = {1520-6149},
  Keywords                 = {air-traffic control;speech analysis and processing;speech recognition;air traffic control application;clustering algorithm;dialogs;distance measure;speaker identification;speech recognition;speech segments;Air traffic control;Automatic control;Automatic speech recognition;Clustering algorithms;Maximum likelihood estimation;Performance evaluation;Speech processing;Speech recognition;Testing},
  Review                   = {Gish \etal \cite{Gish1991} apply the generalized likelihood ratio (GLR) to audio labelling. Although they do not use this algorithm for segmentation, it is introduced here, as a subsequent group will apply it for segmentation purposes. They segments on changes in the measured energy, but this is not explored in detail. 

The GLR test is a statistical test used to for hypothesis testing, compare the fit of two model. In this case, the null hypothesis that two different segments, $x_1$ and $x_2$, were generated from the same model, and the alternative hypothesis is that they were generated by two different models. If the two models are denoted as $L(\mu_1, \Sigma_1 | x_1)$ and $L(\mu_2, \Sigma_2 | x_2)$, then the likelihood of two segments being generated by these two different models is $L_1 = L(\mu_1, \Sigma_1 | x_1) L(\mu_2, \Sigma_2 | x_2)$, whereas the likelihood of the them being generated by the same model is $L_0 = L(\mu, \Sigma | x)$ where $x$ is the union of $x_1$ and $x_2$. The likelihood ratio can now be formulated as:
%
\begin{align}
 \lambda = \frac{L_0}{L_1} = \frac{L(\mu, \Sigma | x)}{L(\mu_1, \Sigma_1 | x_1) L(\mu_2, \Sigma_2 | x_2)}
\end{align}
%
\noindent such that if $\lambda$ is above some threshold, then the null hypothesis cannot be rejected. The ratio test can be recasted as a function of the mean and covariance of the two models \cite{Anderson1958}:
%
\begin{align}
 \lambda &= \lambda_{\Sigma} \lambda_{\mu} \\
 \lambda_{\Sigma} &= \frac{|\hat{\Sigma}_1|^\alpha |\hat{\Sigma}_2|^{1-\alpha}}{|W|}^{\frac{N}{2}} \\
 \lambda_{\mu} &= 1 + (\frac{N_1 N_2}{N^2} (\hat{\mu_1} - \hat{\mu_2})^T W^{-1} (\hat{\mu_1} - \hat{\mu_2}))^{-\frac{N}{2}}
\end{align}
%
\noindent where $\alpha = N_1/N$, $N_1$ is the number of data points in $x_1$, and $N$ is the number of data points in $x$. $\hat{\Sigma}_1$ and $\hat{\Sigma}_2$ denotes the sample covariance for $x_1$ and $x_2$, and $W = \frac{N1}{N} S_1 + \frac{N2}{N} S_2$ is their frequency weighted average. $\hat{\mu_1}$ and $\hat{\mu_2}$ denotes the sample mean for $x_1$ and $x_2$. $\lambda_{\Sigma}$ is the likelihood ratio that test the hypothesis that two segments are from the same model with the same covariance matrix, and $\lambda_{\mu}$ is the likelihood ratio that tests the hypothesis that the two segments are from the same model with the same mean. 

Gish \etal \cite{Gish1991} calculate two distance metrics from these two ratios, $d_\Sigma = -\log(\lambda_\Sigma)$ and $d_\mu = -\log(\lambda_\mu)$. $d_\Sigma$ is calculated between two temporally adjacent windows over the observation data. These distance metrics are used to cluster air traffic controller speech data from pilot data, and has a 90\% classification accuracy. No segmentation accuracy was reported.},
  Timestamp                = {2013.10.21}
}

@Article{Glass2003,
  Title                    = {A probabilistic framework for segment-based speech recognition},
  Author                   = {Glass, J. R.},
  Journal                  = {Computer Speech \& Language},
  Year                     = {2003},
  Number                   = {2},
  Pages                    = {137--152},
  Volume                   = {17},

  Abstract                 = {Most current speech recognizers use an observation space based on a temporal sequence of measurements extracted from fixed-length “frames” (e.g., Mel-cepstra). Given a hypothetical word or sub-word sequence, the acoustic likelihood computation always involves all observation frames, though the mapping between individual frames and internal recognizer states will depend on the hypothesized segmentation. There is another type of recognizer whose observation space is better represented as a network, or graph, where each arc in the graph corresponds to a hypothesized variable-length segment that is represented by a fixed-dimensional “feature”. In such feature-based recognizers, each hypothesized segmentation will correspond to a segment sequence, or path, through the overall segment-graph that is associated with a subset of all possible feature vectors in the total observation space. In this work we examine a maximum a posteriori decoding strategy for feature-based recognizers and develop a normalization criterion useful for a segment-based Viterbi or A* search. Experiments are reported for both phonetic and word recognition tasks.},
  Publisher                = {Elsevier},
  Timestamp                = {2013.08.29}
}

@InProceedings{Glorennec1994,
  Title                    = {Fuzzy Q-learning and dynamical fuzzy Q-learning},
  Author                   = {P.Y. Glorennec},
  Booktitle                = {Proceedings of the Third IEEE Conference on Fuzzy Systems, IEEE World Congress on Computational Intelligence},
  Year                     = {1994},
  Month                    = {June},
  Pages                    = {474-479},
  Volume                   = {1},

  Keywords                 = {dynamical, fuzzy, Q-learning, fuzzy control, fuzzy inference},
  Timestamp                = {2011.07.11}
}

@InProceedings{Godase2012,
  Title                    = {Classification of data streams with skewed distribution},
  Author                   = {Godase, A. and Attar, V.},
  Booktitle                = {Evolving and Adaptive Intelligent Systems (EAIS), 2012 IEEE Conference on},
  Year                     = {2012},
  Pages                    = {151--156},

  Abstract                 = {One of fundamental problem in the task of mining streaming data is the concept drift over time. Such data Streams may also exhibit high and varying degrees of class imbalance, which can further complicate the task. In scenarios like these, class imbalance is particularly difficult to overcome and has not been as thoroughly studied. Most of the studies on classification of data streams assume relatively balanced and stable data streams but cannot handle well rather skewed streams which are typical in many data stream applications. Class imbalance in such skewed data streams can be seen in many real world applications. In such scenarios learning from skewed data streams results in classifier biased towards the majority class which results in misclassification of minority class examples, since in these scenarios minority class examples are too less than the majority class. The losses associated with misclassification of minority classes can be higher in some applications. In this paper we present our preliminary work to deal with classification of the data streams with skewed distribution of classes.},
  Doi                      = {10.1109/EAIS.2012.6232821},
  Keywords                 = {data mining;pattern classification;class imbalance;data stream classification;skewed distribution;streaming data mining;Classification algorithms},
  Review                   = {Uses AUROC (area under RO curve) as a metric to determine if a classifier is any good. 
Builds an ensemble classifier
- each classifier is trained by taking a sample of the TN, all the TP, and all the TP from previous training cycles, to have a lot of data available
- use k-means to form clusters, which was used to train classifiers. AUROC used to determine which classifier is the best and thus should be included in the emsemble

ultimately, uses decision tree as the base classifier},
  Timestamp                = {2015.05.12}
}

@Article{Gong2000,
  Title                    = {Nongeometric error identification and compensation for robotic system by inverse calibration},
  Author                   = {Gong, C. and Yuan, J. and Ni, J.},
  Journal                  = {International Journal of Machine Tools and Manufacture},
  Year                     = {2000},
  Number                   = {14},
  Pages                    = {2119--2137},
  Volume                   = {40},

  Abstract                 = {In order to achieve the stringent accuracy requirement of some robotic applications such as robotic measurement systems, it is critical to compensate for nongeometric errors such as compliance errors and thermal errors in addition to geometric errors. This paper investigates the effect of geometric errors, link compliance and temperature variation on robot positioning accuracy. A comprehensive error model is derived for combining geometric errors, positionâ€“dependent compliance errors and timeâ€“variant thermal errors. A general methodology is developed to identify these errors simultaneously. A laser tracker is applied to calibrate these errors by an inverse calibration method. Robot geometric errors and compliance errors are calibrated at room temperature while robot parameter thermal errors are calibrated at different temperatures when the robot warms up and cools down. Empirical thermal error models are established using orthogonal regression methods to correlate robot parameter thermal errors with the corresponding temperature field. These models can be built into the controller and used to compensate for quasi-static thermal errors due to internal and external heat sources. Experimental results show that the robot accuracy is improved by an order of magnitude after calibration.},
  Doi                      = {10.1016/S0890-6955(00)00023-7},
  ISSN                     = {0890-6955},
  Keywords                 = {Robot calibration},
  Timestamp                = {2012.12.16},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0890695500000237}
}

@Article{Goswami1999,
  Title                    = {Postural Stability of Biped Robots and the Foot-Rotation Indicator (FRI) Point},
  Author                   = {Goswami, A.},
  Journal                  = {The International Journal of Robotics Research},
  Year                     = {1999},
  Number                   = {6},
  Pages                    = {523-533},
  Volume                   = {18},

  Abstract                 = {The focus of this paper is the problem of foot rotation in biped robots during the single-support phase. Foot rotation is an indication of postural instability, which should be carefully treated in a dynamically stable walk and avoided altogether in a statically stable walk.We introduce the foot-rotation indicator (FRI) point, which is a point on the foot/ground-contact surface where the net ground-reaction force would have to act to keep the foot stationary. To ensure no foot rotation, the FRI point must remain within the convex hull of the foot-support area.In contrast with the ground projection of the center of mass (GCoM), which is a static criterion, the FRI point incorporates robot dynamics. As opposed to the center of pressure (CoP)—better known as the zero-moment point (ZMP) in the robotics literature—which may not leave the support area, the FRI point may leave the area. In fact, the position of the FRI point outside the footprint indicates the direction of the impending rotation and the magnitude of rotational moment acting on the foot. Owing to these important properties, the FRI point helps not only to monitor the state of postural stability of a biped robot during the entire gait cycle, but indicates the severity of instability of the gait as well. In response to a recent need, the paper also resolves the misconceptions surrounding the CoP/ZMP equivalence.},
  Doi                      = {10.1177/02783649922066376},
  Eprint                   = {http://ijr.sagepub.com/content/18/6/523.full.pdf+html},
  Keywords                 = {ECE780, ZMP},
  Review                   = {NOVELTY
Uses FRI (ie FZMP) as an indicator of stability. 

SUMMARY
Foot rotation is a sign of postural instability. If foot rotation occurs, the biped can fall over. We can use gravitational centre of mass (GCOM) to determine static stability, but it does not provide insight into dynamic stability. Foot-rotation indicator (FRI) can be used instead, since falling over is seen as a rotation at the foot. 

The FRI point is defined as “the point on the foot/ground contact surface at which the resultant moment of the force/torque impressed on the foot is normal to the surface” (that is, the sum of all forces and torque at the foot), and can be within or outside the support polygon. This point is equal to GCOM at in static postures. 

Definitions:
- Center of pressure (COP) – “Point on the ground where resultant of the ground reaction force acts”
 - Cannot leave the support polygon, or else the force would not be acting on a physical object
- Zero-moment point (ZMP) – “The point where the vertical reaction force intersects the ground”
 - Equals the COP, thus it cannot leave the support polygon
- Foot-rotation indicator point (FRI) – “the point on the foot/ground contact surface at which the resultant moment of the force/torque impressed on the foot is normal to the surface”
 - Equals COP if the foot is at rest, or if the foot has zero mass and inertia
- Gravitational centre-of-mass (GCOM) – Centre of mass of the biped
 - Equals COP when stationary},
  Timestamp                = {2011.01.28},
  Url                      = {http://ijr.sagepub.com/content/18/6/523.abstract}
}

@InProceedings{Grollman2011,
  Title                    = {Donut as I do: Learning from failed demonstrations},
  Author                   = {Grollman, D.H. and Billard, A.},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2011},
  Pages                    = {3804-3809},

  Abstract                 = {The canonical Robot Learning from Demonstration scenario has a robot observing human demonstrations of a task or behavior in a few situations, and then developing a generalized controller. Current work further refines the learned system, often to perform the task better than the human could. However, the underlying assumption is that the demonstrations are successful, and are appropriate to reproduce. We, instead, consider the possibility that the human has failed in their attempt, and their demonstration is an example of what not to do. Thus, instead of maximizing the similarity of generated behaviors to those of the demonstrators, we examine two methods that deliberately avoid repeating the human's mistakes.},
  Doi                      = {10.1109/ICRA.2011.5979757},
  ISSN                     = {1050-4729},
  Keywords                 = {human-robot interaction;learning (artificial intelligence);generalized controller;human demonstration;robot learning;Convergence;Equations;Humans;Learning;Mathematical model;Robots;Trajectory},
  Timestamp                = {2013.09.19}
}

@InProceedings{Grollman2010,
  author    = {Grollman, D. H. and Jenkins, O. C.},
  title     = {Incremental Learning of Subtasks from Unsegmented Demonstration},
  booktitle = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year      = {2010},
  pages     = {261--266},
  abstract  = {We propose to incrementally learn the segmentation of a demonstrated task into subtasks and the individual subtask policies themselves simultaneously. Previous robot learning from demonstration techniques have either learned the individual subtasks in isolation, combined known subtasks, or used knowledge of the overall task structure to perform segmentation. Our infinite mixture of experts approach instead automatically infers an appropriate partitioning (number of subtasks and assignment of data points to each one) directly from the data. We illustrate the applicability of our technique by learning a suitable set of subtasks from the demonstration of a finite-state machine robot soccer goal scorer.},
  doi       = {10.1109/IROS.2010.5650500},
  groups    = {Lit Review 2013-09},
  issn      = {2153-0858},
  keywords  = {finite state machines;learning (artificial intelligence);mobile robots;multi-robot systems;sport;finite state machine;goal scorer;incremental learning;robot learning;robot soccer;unsegmented demonstration},
  review    = {Want to perform learning by generating the components of a finite-state-machine (FSM). The FSM states forms the subtasks in in the overall task we want to learn. So want to segment up the overall task to train the states/subtasks individually. This allow individual subtasks to be trained/refined as needed. We can also group together movements that look different, but generate the same result (Perceptual aliasing) as a subtask by looking at the emission. Gaussian Processes Regression can be used to achieve this. Minimnizing the KL dist between each exemplar subtask helps to keep the computational costs down. 

Each exemplar is modeled as a Gaussian in robot perception space, along with a sparse approximation Gaussian process (SOGP) that maps the precieved subtask to the action. When a subtask is inserted into the library, it is inserted by Chinese Restaurant Process (has a chance to be either added to an existing cluster, or a new cluster is created for it), and segmented that way. 

(come back to read about the optimization components)


Grollman and Jenkins \cite{Grollman2010} perform robot learning by generating components from unsegmented demonstration data. They model a given task as a FSM. Each state in the FSM, a subtask, is modeled as a Gaussian process, and is estimated by a Gaussian process regressor. As new data training is inserted into the FSM, it is placed in an existing subtask, or assigned to a new subtask, by the Chinese restaurant process (CRP). The CRP assigns data points by examining the number of points already in a given state. The probability that a data point would be assigned to an existing state $s_b$ is $\frac{b}{n+1}$, where $b$ is the number of existing points in $s_b$ and $n$ is the number of data point in total, or create a new state for this data point with probability $\frac{1}{n+1}$. The Gaussian process is updated with this data. When new data is observed, it is inserted into all of the subtasks, and the likelihood assessed, and is labelled accordingly.},
  timestamp = {2013.09.29},
}

@Article{Gross2011,
  Title                    = {Commentary on an article by Trevor G. Russell, MD, et al.: “Internet-Based Outpatient Telerehabilitation for Patients Following Total Knee Arthroplasty. A Randomized Controlled Trial”},
  Author                   = {Gross, A. E.},
  Journal                  = {Bone},
  Year                     = {2011},
  Pages                    = {E6 1--2},
  Volume                   = {93},

  Timestamp                = {2011.12.29}
}

@InProceedings{Guan2007,
  Title                    = {Activity Recognition Based on Semi-supervised Learning},
  Author                   = {Donghai Guan and Weiwei Yuan and Young-Koo Lee and Gavrilov, A. and Sungyoung Lee},
  Booktitle                = {IEEE International Conference on Embedded and Real-Time Computing Systems and Applications},
  Year                     = {2007},
  Pages                    = {469--475},

  Abstract                 = {Activity recognition is a hot topic in context-aware computing. In activity recognition, machine learning techniques have been widely applied to learn the activity models from labeled activity samples. Since labeling samples requires human's efforts, most existing research in activity recognition focus on refining learning techniques to utilize the costly labeled samples as effectively as possible. However, few of them consider using the costless unlabeled samples to boost learning performance. In this work, we propose a novel semi-supervised learning algorithm named En-Co-training to make use of the unlabeled samples. Our algorithm extends the co- training paradigm by using ensemble method. Experimental results show that En-Co-training is able to utilize the available unlabeled samples to enhance the performance of activity learning with a limited number of labeled samples.},
  Doi                      = {10.1109/RTCSA.2007.17},
  ISSN                     = {1533-2306},
  Keywords                 = {learning (artificial intelligence);training;En-Co-training;activity recognition;context-aware computing;machine learning;semisupervised learning;Aging;Bayesian methods;Computerized monitoring;Context-aware services;Humans;Intelligent sensors;Machine learning;Semisupervised learning;Sensor systems;Smart homes},
  Timestamp                = {2014.12.22}
}

@Article{Guerra-Filho2007,
  author    = {Guerra-Filho, G. and Aloimonos, Y.},
  title     = {A language for human action},
  journal   = {Computer},
  year      = {2007},
  volume    = {40},
  pages     = {42--51},
  abstract  = {Human-centered computing (HCC) involves conforming computer technology to humans while naturally achieving human-machine interaction. In a human-centered system, the interaction focuses on human requirements, capabilities, and limitations. These anthropocentric systems also focus on the consideration of human sensory-motor skills in a wide range of activities. This ensures that the interface between artificial agents and human users accounts for perception and action in a novel interaction paradigm. In turn, this leads to behavior understanding through cognitive models that allow content description and, ultimately, the integration of real and virtual worlds. Our work focuses on building a language that maps to the lower-level sensory and motor languages and to the higher-level natural language. An empirically demonstrated human activity language provides sensory-motor-grounded representations for understanding human actions. A linguistic framework allows the analysis and synthesis of these actions.},
  groups    = {EMBC2014},
  publisher = {IEEE},
  review    = {- Cited Fod et al 2002. 
- Breaks down human movement into small units ("kinetemes", similar to phonemes) and proposes a "Human Activity Language"
- Considered each joint independently. As long as that joint is moving in the in the same direction in velocity or acceleration, it is segmented together. So there is 4 categories of grouping: pos-velo, neg-velo, pos-accel, neg-accel
- motions with similar profiles are labeled the same (actiongrams)
- also considers other factors such as reproducibility (likely the most interesting measure). they seem to be assigning a measure of how well an action over some sample data

Guerra-Filho and Aloimonos \cite{Guerra-Filho2007} breaks down human movement into small units, which they refer to as kinetemes, in a similar as to phonemes, and proposes a Human Activity Language to describe human movement. Each joint is considered independently. Taking guidance from Fod \etal \cite{Fod2002}, as long as that joint is moving in the same direction in both velocity and acceleration, it is considered one segment. Thus, four types of groups are utilized: positive-velocity and positive-acceleration, positive-velocity and negative-acceleration, negative-velocity and positive-acceleration, and negative-velocity and negative-acceleration. When the velocity and acceleration direction change, segments are declared.

Guerra-Filho and Aloimonos \cite{Guerra-Filho2007} break down human movement into small units by declaring a segment when either velocity or acceleration crosses the zero line. Each segment is denoted as a combination of its velocity and acceleration profile. That is, it is assigned four possible states: positive-velocity and positive-acceleration, positive-velocity and negative-acceleration, negative-velocity and positive-acceleration, and negative-velocity and negative-acceleration. SCFG is employed to label and identify sequences of these states into action grammar units.},
  timestamp = {2013.08.29},
}

@Article{Guyon2003,
  Title                    = {An Introduction to Variable and Feature Selection},
  Author                   = {Guyon, I. and Elisseeff, A.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2003},
  Pages                    = {1157--1182},
  Volume                   = {3},

  Review                   = {Variable ranking 
- Given m examples of n input variables and 1 output variable, use a scoring function to rank the input variables
- Considered a pre-processing step, indep from predictor choice

Correlation Criteria
- Use Pearson's correlation "r"},
  Timestamp                = {2014.04.09}
}

@Article{Gyllensten2011,
  Title                    = {Identifying Types of Physical Activity With a Single Accelerometer: Evaluating Laboratory-trained Algorithms in Daily Life.},
  Author                   = {Gyllensten, I. C. and Bonomi, A.},
  Journal                  = {IEEE Transactions on Biomedical Engineering},
  Year                     = {2011},

  Month                    = { },
  Number                   = {99},
  Pages                    = {1},
  Volume                   = {2656--2663},

  Abstract                 = {Accurate identification of physical activity types has been achieved in laboratory conditions using single-site accelerometers and classification algorithms. This methodology is then applied to free-living subjects to determine activity behaviour. This study aimed at analysing the reproducibility of the accuracy of laboratory-trained classification algorithms in free-living subjects during daily life. A support vector machine (SVM), a feed-forward neural network (NN) and a decision tree (DT) were trained with data collected by a waist-mounted accelerometer during a laboratory trial. The reproducibility of the classification performance was tested on data collected in daily life using a multiple-site accelerometer (IDEEA) augmented with an activity diary for 20 healthy subjects (age: 30 ± 9; BMI: 23.0 ± 2.6 kg/m2). Leave-one-subject-out cross-validation of the training data showed accuracies of 95.1 ± 4.3%, 91.4 ± 6.7% and 92.2 ± 6.6% for the SVM, NN and DT, respectively. All algorithms showed a significantly decreased accuracy in daily life as compared to the reference truth represented by the IDEEA and diary classifications (75.6 ± 10.4%, 74.8 ± 9.7%, and 72.2 ± 10.3%; p<0.05). In conclusion, cross-validation of training data overestimates the accuracy of the classification algorithms in daily life.},
  Doi                      = {10.1109/TBME.2011.2160723},
  ISSN                     = {0018-9294},
  Review                   = {Got 20 healthy volunteers. Hip mounted accel. Performed a set of supervised activities. A few other accels placed on the body, on foot and thigh and sternum.
Actually. Seems to be classification only.},
  Timestamp                = {2011.07.26}
}

@InProceedings{Hadjidj2011,
  Title                    = {Toward a high-fidelity wireless sensor network for rehabilitation supervision},
  Author                   = {Hadjidj, A. and Challal, Y. and Bouabdallah, A.},
  Booktitle                = {Proceedings of the 36th IEEE Conference on Local Computer Networks},
  Year                     = {2011},
  Pages                    = {458--465},

  Journal                  = {Local Computer Networks},
  Timestamp                = {2012.01.01}
}

@Article{Hall2000,
  Title                    = {Case study: Inertial measurement unit calibration platform},
  Author                   = {Hall, J. J. and Williams, R. L.},
  Journal                  = {Journal of Robotic Systems},
  Year                     = {2000},
  Number                   = {11},
  Pages                    = {623--632},
  Volume                   = {17},

  Abstract                 = {The Department of Mechanical Engineering and the Avionics Engineering Center at Ohio University are developing an electromechanical system for the calibration of an inertial measurement unit (IMU) using global positioning system (GPS) antennas. The GPS antennas and IMU are mounted to a common platform to be oriented in the angular roll, pitch, and yaw motions. Vertical motion is also included to test the systems in a vibrational manner. A 4-DOF system based on the parallel carpal wrist is under development for this task. High-accuracy positioning is not required from the platform since the GPS technology provides absolute positioning for the IMU calibration process.},
  Doi                      = {10.1002/1097-4563(200011)17:11<623::AID-ROB4>3.0.CO;2-7},
  ISSN                     = {1097-4563},
  Keywords                 = {IMU calibration},
  Review                   = {Uses GPS. Seems to target vehicle calibration},
  Timestamp                = {2011.07.19},
  Url                      = {http://dx.doi.org/10.1002/1097-4563(200011)17:11<623::AID-ROB4>3.0.CO;2-7}
}

@Conference{Hamano2011,
  Title                    = {Motion Data Retrieval Based on Statistic Correlation between Motion Symbol Space and Language},
  Author                   = {Hamano, S. and Takano, W. and Nakamura, Y.},
  Booktitle                = {Proceedings of the IEEE International Conference Intelligent Robots and Systems, Workshop on Robotics for Neurology and Rehabilitation},
  Year                     = {2011},

  Abstract                 = {Captured human motion data are used so that
humanoid robots or computer graphics (CG) characters can be-
have naturally. Because the motion capture system is expensive,
and time-consuming process is needed to acquire motion data,
technology that enables to reuse existing motion data ef?ciently
is required. This paper proposes motion retrieval method
with natural language word based on stochastic correlation
between motion and language. We construct a space which has
maximum correlation with motion pattern features and word
features, and we use this space as search space for motion
retrieval. Proto-symbol space, which represents the relationship
of each symbolized motion patterns, is used as motion feature
space. And as word feature, binary features are used which
represent whether a word label is attached or not. Because
the constructed search space has correlation between motion
patterns and words, associative motion retrieval considering
similarity of motion pattern or closeness of word meaning be-
comes possible. We validate proposed motion retrieval method
by constructing motion database with captured human motion
data.},
  Timestamp                = {2011.09.22}
}

@Article{Han2010,
  Title                    = {Discriminative human action recognition in the learned hierarchical manifold space },
  Author                   = {Lei Han and Xinxiao Wu and Wei Liang and Guangming Hou and Yunde Jia},
  Journal                  = {Image and Vision Computing },
  Year                     = {2010},
  Note                     = {Best of Automatic Face and Gesture Recognition 2008 },
  Number                   = {5},
  Pages                    = {836 - 849},
  Volume                   = {28},

  Abstract                 = {In this paper, we propose a hierarchical discriminative approach for human action recognition. It consists of feature extraction with mutual motion pattern analysis and discriminative action modeling in the hierarchical manifold space. Hierarchical Gaussian Process Latent Variable Model (HGPLVM) is employed to learn the hierarchical manifold space in which motion patterns are extracted. A cascade \{CRF\} is also presented to estimate the motion patterns in the corresponding manifold subspace, and the trained \{SVM\} classifier predicts the action label for the current observation. Using motion capture data, we test our method and evaluate how body parts make effect on human action recognition. The results on our test set of synthetic images are also presented to demonstrate the robustness. },
  Doi                      = {http://dx.doi.org/10.1016/j.imavis.2009.08.003},
  ISSN                     = {0262-8856},
  Keywords                 = {Human action recognition},
  Timestamp                = {2014.12.21},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0262885609001723}
}

@InProceedings{Hanai2009,
  Title                    = {Haar-Like Filtering for Human Activity Recognition Using 3D Accelerometer},
  Author                   = {Hanai, Y. and Nishimura, J. and Kuroda, T.},
  Booktitle                = {Digital Signal Processing Workshop and 5th IEEE Signal Processing Education Workshop, 2009. DSP/SPE 2009. IEEE 13th},
  Year                     = {2009},
  Month                    = {Jan},
  Pages                    = {675-678},

  Abstract                 = {In this paper, novel 2 one-dimensional (1D) Haar-like filtering techniques are proposed as a new and low calculation cost feature extraction method suitable for 3D acceleration signals based human activity recognition. Proposed filtering method is a simple difference filter with variable filter parameters. Our method holds a strong adaptability to various classification problems which no previously studied features (mean, standard deviation, etc.) possessed. In our experiment on human activity recognition, the proposed method achieved both the highest recognition accuracy of 93.91% while reducing calculation cost to 21.22% compared to previous method.},
  Doi                      = {10.1109/DSP.2009.4786008},
  Keywords                 = {Haar transforms;accelerometers;feature extraction;filtering theory;image classification;image recognition;3D acceleration signal;3D accelerometer;feature extraction method;haar-like filtering technique;human activity recognition;image classification problem;Acceleration;Accelerometers;Costs;Equations;Face detection;Feature extraction;Filtering;Filters;Humans;Wearable sensors;1D Haar-like filtering;accelerometer;human activity recognition;sensornet},
  Timestamp                = {2014.12.21}
}

@InProceedings{Hao2013,
  author    = {Hao, Y. and Chen, Y. and Zakaria, J. and Hu, B. and Rakthanmanon, T. and Keogh, E.},
  title     = {Towards Never-ending Learning from Time Series Streams},
  booktitle = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2013},
  pages     = {874--882},
  abstract  = {Time series classification has been an active area of research in the data mining community for over a decade, and significant progress has been made in the tractability and accuracy of learning. However, virtually all work assumes a one-time training session in which labeled examples of all the concepts to be learned are provided. This assumption may be valid in a handful of situations, but it does not hold in most medical and scientific applications where we initially may have only the vaguest understanding of what concepts can be learned. Based on this observation, we propose a never-ending learning framework for time series in which an agent examines an unbounded stream of data and occasionally asks a teacher (which may be a human or an algorithm) for a label. We demonstrate the utility of our ideas with experiments in domains as diverse as medicine, entomology, wildlife monitoring, and human behavior analyses.},
  acmid     = {2487634},
  doi       = {10.1145/2487575.2487634},
  groups    = {Lit Review 2013-09},
  isbn      = {978-1-4503-2174-7},
  keywords  = {classification, data streams, never-ending learning, time series},
  location  = {Chicago, Illinois, USA},
  numpages  = {9},
  review    = {Want to be able to pull out data that we see once in a while, with the occasitional input from a teacher to as what it is. A "continuous/endless" learning system. Found that nearest neightbour works well with time series data. Using Euclidean distance as the distance metric and not DTW since DTW needs warping window length and they don't know how ot use that.

So assume that S is the data stream, and P is some surrogate/observation for S (with the possibility of S = P), and that we have access to some teacher/labeling system (but without making any assumption about the teacher). As such, we can break the system into three parts:

1) subsequent processing (looks at incoming data and compare it to dictionary, and attempt to classify), 
2) frequent pattern maintenance (if not in the dictionary, look in cache for existance of a similar pattern) and 
3) active learning system (if this motion warrents learning, wait for a label from the teacher and learn it).

Dictionary consists of entries of tuples: prototype name, threshold and occurance rate. Can initiate it empty, or can prime the data with some priors to help the system along. 

-1- (actually, it looks like details of segmentation is not clear. it assumes that a window can be made somehow and the data passed into the dictionary)

-2- can cluster motions that are similar together by looking at their distances. if we imagine a dendrogram (tree diagram), motions that occur repeatedly would end up as dense subtrees. So we just need to pull out these subtrees. to save space, when the dendrogram is full, when you're adding a new item, a old one is thrown out.

-3- Can assume either strong teaches (correct and unambiguous class labels) or weak teachers (tentative, probabilistic labels). Strong doesn't have much to discuss, but weak can operate off of frequency. If some signal shows up and the weak labeler says it's one thing more often than another, then we can label it that.

Tested it on a few things. Only note bio/med stuff
- 13 min of physical activity video, 1 actor performing 8 activities. 42% precision, 88% recall on running, but didn't do as well on other activities. 
- 20 hour ECG data, 48 yr old. 99% precision and recall on normal heart beat. abnormal beats had less samples and performed worse.

---

- Uses a Euclidean, nearest neighbour approach -> if close to some template, then it gets the label
- assume data "S" has a proxy stream "P" -> P is low dim
- teacher sparcely labels data
- data normalized, and attempt classification using library
 - if no label but considered valid, the motion is retained until future cases occur again
- group similar movements together -> if lots of a given example, we would end up with dense subtree -> significant movement implied by lots of examples
- uses "domain specific subseq extraction" -> doesn't seem to be very specific on details},
  timestamp = {2013.09.29},
}

@InProceedings{Harbert2013,
  Title                    = {Mobile Motion Capture - MiMiC},
  Author                   = {Harbert, S. D. and Jaiswal, T. and Harley, L. R. and Vaughn, T. W. and Baranak, A. S.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {The low cost, simple, robust, mobile, and easy to use Mobile Motion Capture (MiMiC) system is presented and the constraints which guided the design of MiMiC are discussed. The MiMiC Android application allows motion data to be captured from kinematic modules such as Shimmer 2r sensors over Bluetooth. MiMiC is cost effective and can be used for an entire day in a person’s daily routine without being intrusive. MiMiC can be used to study fall detection in older adult’s homes, to detect fatigue in industry workers, and to analyze individuals’ work patterns in various environments.},
  Keywords                 = {EMBC2013},
  Review                   = {Stream Shimmer data via Bluetooth to an Android app. Designed for non-technical person to use. Uses "Madgwich's Mayhony's DCM filter" and "FreeIMU" to perform posture detection. Stream from 4 shimmers at 102.4 Hz, for over 8 hours on a Nexus One.},
  Timestamp                = {2013.08.03}
}

@Article{Hargrove2010,
  Title                    = {Multiple Binary Classifications via Linear Discriminant Analysis for Improved Controllability of a Powered Prosthesis},
  Author                   = {Hargrove, L. and Scheme, E. and Englehart, K. and Hudgins, B.},
  Journal                  = {IEEE T Neural Syst Rehabil Eng},
  Year                     = {2010},
  Pages                    = {49--57},
  Volume                   = {18},

  Abstract                 = {This paper describes a novel pattern recognition based myoelectric control system that uses parallel binary classification and class specific thresholds. The system was designed with an intuitive configuration interface, similar to existing conventional myoelectric control systems. The system was assessed quantitatively with a classification error metric and functionally with a clothespin test implemented in a virtual environment. For each case, the proposed system was compared to a state-of-the-art pattern recognition system based on linear discriminant analysis and a conventional myoelectric control scheme with mode switching. These assessments showed that the proposed control system had a higher classification error (p < 0.001) but yielded a more controllable myoelectric control system (p < 0.001) as measured through a clothespin usability test implemented in a virtual environment. Furthermore, the system was computationally simple and applicable for real-time embedded implementation. This work provides the basis for a clinically viable pattern recognition based myoelectric control system which is robust, easily configured, and highly usable.},
  Owner                    = {jf2lin},
  Review                   = {compares LDA and multiple binary classifier (MBC)},
  Timestamp                = {2015.05.21}
}

@Article{Harris1990,
  Title                    = {Total Hip and Total Knee Replacement},
  Author                   = {Harris, William H. and Sledge, Clement B.},
  Journal                  = {New England Journal of Medicine},
  Year                     = {1990},
  Number                   = {11},
  Pages                    = {725-731},
  Volume                   = {323},

  Doi                      = {10.1056/NEJM199009133231106},
  Eprint                   = {http://www.nejm.org/doi/pdf/10.1056/NEJM199009133231106},
  Keywords                 = {physiotherapy},
  Timestamp                = {2012.06.21},
  Url                      = {http://www.nejm.org/doi/full/10.1056/NEJM199009133231106}
}

@Book{Hartenberg1964,
  Title                    = {Kinematic synthesis of linkages},
  Author                   = {Hartenberg, R. S. and Denavit, J.},
  Publisher                = {McGraw-Hill},
  Year                     = {1964},

  Timestamp                = {2012.02.02},
  Url                      = {http://en.scientificcommons.org/7515616}
}

@InProceedings{He2008,
  Title                    = {Activity recognition from acceleration data using AR model representation and SVM},
  Author                   = {He, Z.-Y. and Jin, L.-W.},
  Booktitle                = {International Conference on Machine Learning and Cybernetics},
  Year                     = {2008},
  Pages                    = {2245--2250},
  Volume                   = {4},

  Abstract                 = {In this paper, the autoregressive (AR) model of time-series is presented to recognize human activity from a tri-axial accelerometer data. Four orders of autoregressive model for accelerometer data is built and the AR coefficients are extracted as features for activity recognition. Classification of the human activities is performed with support vector machine (SVM). The average recognition results for four activities (running, still, jumping and walking) using the proposed AR-based features are 92.25%, which are better than using traditional frequently used time domains features (mean, standard deviation, energy and correlation of acceleration data) and FFT features. The results show that AR coefficients obvious discriminate different human activities and it can be extract as an effective feature for the recognition of accelerometer date.},
  Doi                      = {10.1109/ICMLC.2008.4620779},
  Keywords                 = {autoregressive processes;feature extraction;image classification;support vector machines;time series;acceleration data;autoregressive model;feature extraction;human activity classification;human activity recognition;support vector machine;time series;Acceleration;Accelerometers;Data mining;Feature extraction;Humans;Legged locomotion;Machine learning;Pattern recognition;Support vector machine classification;Support vector machines;Activity recognition;Autoregressive model;Feature extraction;SVM;Tri-axial accelerometer data},
  Timestamp                = {2014.12.21}
}

@Article{Heinze2010,
  Title                    = {Movement analysis by accelerometry of newborns and infants for the early detection of movement disorders due to infantile cerebral palsy},
  Author                   = {Heinze, F. and Hesels, K. and Breitbach-Faller, N. and Schmitz-Rode, T. and Disselhorst-Klug, C.},
  Journal                  = {Medical and Biological Engineering and Computing},
  Year                     = {2010},
  Pages                    = {765--772},
  Volume                   = {48},

  Abstract                 = {So far, developed diagnostic strategies for the early detection of movement disorders due to infantile cerebral palsy (ICP) in newborns are not easily applicable in clinical settings. They are either difficult to acquire or they are too expensive to be established in pediatric clinics and are not sufficiently usable to be integrated into daily routine. The aim of this study therefore was to develop a methodology that allows the objective diagnosis of developing movement disorders in newborns due to ICP. It should be applicable to pediatric offices and should easily integrate in daily routine. To achieve this, a simple to use and low-cost system based on accelerometers was developed to evaluate the newborns movement. Afterward, a classificator based on a decision tree algorithm was implemented to differentiate between healthy and pathological data in order to propose the most likely diagnosis. The developed methodology was validated in a clinical study with 19 healthy and 4 affected subjects that were evaluated at the first, third and fifths month after birth (corrected age). The overall detection rate of the developed methodology reached between 88 and 92% for all evaluated measurements. The developed methodology is simple to use, therefore is applicable for the objective diagnosis of developing movement disorders in newborns due to ICP and can be established in pediatric offices for use in daily routine.},
  Doi                      = {10.1007/s11517-010-0624-z},
  ISSN                     = {0140-0118 (Print) 1741-0444 (Online)},
  Keywords                 = {Accelerometry - Movement analysis - Infantile cerebral palsy - Diagnosis - Movement disorders},
  Publisher                = {Springer Berlin / Heidelberg},
  Review                   = {Currently, diagnosis of Infantile Cerebral Palsy is done based on visual observations of the spotaneous movements based on the infant. Seemingly effective, but fairly subjective. The medical field is using accelerometers more and more to quantify movement disorders. This group uses an attachable MMA7261QT (hooked up with wires to a sensor system), HP at 0.16 Hz and LP at 25 Hz, 100 Hz sample rate ADC. The high pass filter, apparently, removes gravity effects. They have an algorithm that uses only accel and velocity, and used curve fitting to reduce the impact of the noise...isn't that just LPF-ish?

Anyway. They took the data and applied all sorts of post-processing, like cross-correlation in acceleration between limbs, direction of accel, SD, etc. They've proven that they're better than a previous study. Yay.},
  Subject_collection       = {Engineering},
  Timestamp                = {2010.07.17},
  Url                      = {http://www.springerlink.com/content/c810u5731k6h5h54/}
}

@InProceedings{Helaoui2011,
  Title                    = {Recognizing interleaved and concurrent activities: A statistical-relational approach},
  Author                   = {Helaoui, R. and Niepert, M. and Stuckenschmidt, H.},
  Booktitle                = {Pervasive Computing and Communications (PerCom), 2011 IEEE International Conference on},
  Year                     = {2011},
  Month                    = {March},
  Pages                    = {1-9},

  Abstract                 = {A majority of the approaches to activity recognition in sensor environments are either based on manually constructed rules for recognizing activities or lack the ability to incorporate complex temporal dependencies. Furthermore, in many cases, the rather unrealistic assumption is made that the subject carries out only one activity at a time. In this paper, we describe the use of Markov logic as a declarative framework for recognizing interleaved and concurrent activities incorporating both input from pervasive light-weight sensor technology and common-sense background knowledge. In particular, we assess its ability to learn statistical-temporal models from training data and to combine these models with background knowledge to improve the overall recognition accuracy. To this end, we propose two Markov logic formulations for inferring the foreground activity as well as each activities' start and end times. We evaluate the approach on an established dataset. where it outperforms state-of-the-art algorithms for activity recognition.},
  Doi                      = {10.1109/PERCOM.2011.5767586},
  Keywords                 = {Markov processes;formal logic;statistical analysis;ubiquitous computing;Markov logic formulation;common-sense background knowledge;concurrent activity recognition;interleaved activity recognition;pervasive light-weight sensor technology;statistical-relational approach;statistical-temporal models;Computational modeling;Context;Hidden Markov models;Markov processes;Probabilistic logic;Radiofrequency identification;Training data},
  Timestamp                = {2014.12.22}
}

@Article{Herda2001,
  Title                    = {Using Skeleton-based Tracking to Increase the Reliability of Optical Motion Capture},
  Author                   = {Herda, L. and Fua, P. and Pl{\"a}nkers, R. and Boulic, R. and Thalmann, D.},
  Journal                  = {Human Movement Science},
  Year                     = {2001},
  Pages                    = {313--341},
  Volume                   = {20},

  Publisher                = {Elsevier},
  Timestamp                = {2014.10.29}
}

@InProceedings{Herzog2008,
  Title                    = {Motion imitation and recognition using parametric hidden Markov models},
  Author                   = {Herzog, D. and Ude, A. and Kruger, V.},
  Booktitle                = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  Year                     = {2008},
  Month                    = {Dec},
  Pages                    = {339-346},

  Abstract                 = {The recognition and synthesis of parametric movements play an important role in human-robot interaction. To understand the whole purpose of an arm movement of a human agent, both its recognition (e. g., pointing or reaching) as well as its parameterization (i. e., where the agent is pointing at) are important. Only together they convey the whole meaning of an action. Similarly, to imitate a movement, the robot needs to select the proper action and parameterize it, e. g., by the relative position of the object that needs to be grasped. We propose to utilize parametric hidden Markov models (PHMMs), which extend the classical HMMs by introducing a joint parameterization of the observation densities, to simultaneously solve the problems of action recognition, parameterization of the observed actions, and action synthesis. The proposed approach was fully implemented on a humanoid robot HOAP-3. To evaluate the approach, we focused on reaching and pointing actions. Even though the movements are very similar in appearance, our approach is able to distinguish the two movement types and discover the parameterization, and is thus enabling both, action recognition and action synthesis. Through parameterization we ensure that the synthesized movements can be applied to different configurations of the external world and are thus suitable for actions that involve the manipulation of objects.},
  Doi                      = {10.1109/ICHR.2008.4756002},
  Keywords                 = {hidden Markov models;human-robot interaction;humanoid robots;image motion analysis;robot vision;human-robot interaction;humanoid robot HOAP-3;joint parameterization;motion imitation;motion recognition;parametric hidden Markov models;Elbow;Hidden Markov models;Human robot interaction;Humanoid robots;Interpolation;Laboratories;Shape;Sternum;Thumb;Wrist},
  Review                   = {- continuous left-right HMM. uses a parametric HMM to generalize to novel movements
- uses EM on parametric HMM to get the best label},
  Timestamp                = {2014.12.21}
}

@Article{Hidler2011,
  Title                    = {ZeroG: overground gait and balance training system},
  Author                   = {Hidler, J. and Brennan, D. and Black, I. and Nichols, D. and Brady, K. and Nef, T.},
  Journal                  = {Journal of Rehabilitation Research and Development},
  Year                     = {2011},
  Pages                    = {287--98},
  Volume                   = {48},

  Abstract                 = {A new overground body-weight support system called ZeroG has been developed that allows patients with severe gait impairments to practice gait and balance activities in a safe, controlled manner. The unloading system is capable of providing up to 300 lb of static support and 150 lb of dynamic (or constant force) support using a custom-series elastic actuator. The unloading system is mounted to a driven trolley, which rides along an overhead rail. We evaluated the performance of ZeroG's unloading system, as well as the trolley tracking system, using benchtop and human-subject testing. Average root-mean-square and peak errors in unloading were 2.2 and 7.2 percent, respectively, over the range of forces tested while trolley tracking errors were less than 3 degrees, indicating the system was able to maintain its position above the subject. We believe training with ZeroG will allow patients to practice activities that are critical to achieving functional independence at home and in the community.},
  Keywords                 = {Lift assist},
  Timestamp                = {2011.12.28}
}

@Article{Hidler2011a,
  Title                    = {The Road Ahead for Rehabilitation Robotics},
  Author                   = {Hidler, J. and Lum, P. S.},
  Journal                  = {Journal of Rehabilitation Research and Development},
  Year                     = {2011},
  Pages                    = {vii--x},
  Volume                   = {48},

  Timestamp                = {2011.12.28}
}

@Article{Higgins1975,
  Title                    = {A Comparison of Complementary and Kalman Filtering},
  Author                   = {Higgins, W. T.},
  Journal                  = {IEEE Transactions on Aerospace and Electronic Systems},
  Year                     = {1975},
  Pages                    = {321--325},
  Volume                   = {AES-11},

  Abstract                 = {A technique used in the flight control industry for estimation when combining measurements is the complementary filter. This filter is usually designed without any reference to Wiener or Kalman filters, although it is related to them. This paper, which is mainly tutorial, reviews complementary filtering and shows its relationship to Kalman and Wiener filtering.},
  Doi                      = {10.1109/TAES.1975.308081},
  ISSN                     = {0018-9251},
  Timestamp                = {2012.06.28}
}

@InProceedings{Hirai1998,
  Title                    = {The development of Honda humanoid robot},
  Author                   = {Hirai, K. and Hirose, M. and Haikawa, Y. and Takenaka, T.},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {1998},
  Month                    = may,
  Pages                    = {1321 -1326 vol.2},
  Volume                   = {2},

  Abstract                 = {In this paper, we present the mechanism, system configuration, basic control algorithm and integrated functions of the Honda humanoid robot. Like its human counterpart, this robot has the ability to move forward and backward, sideways to the right or the left, as well as diagonally. In addition, the robot can turn in any direction, walk up and down stairs continuously. Furthermore, due to its unique posture stability control, the robot is able to maintain its balance despite unexpected complications such as uneven ground surfaces. As a part of its integrated functions, this robot is able to move on a planned path autonomously and to perform simple operations via wireless teleoperation },
  Doi                      = {10.1109/ROBOT.1998.677288},
  Keywords                 = {Honda humanoid robot;integrated functions;posture stability control;system configuration;uneven ground surfaces;walking robot;wireless teleoperation;legged locomotion;stability;telerobotics; ECE780, ZMP},
  Timestamp                = {2011.01.28}
}

@Article{Hjorth1970,
  Title                    = {{EEG} analysis based on time domain properties},
  Author                   = {Hjorth, B.},
  Journal                  = {Electroen Clin Neuro},
  Year                     = {1970},
  Pages                    = {306--10},
  Volume                   = {29},

  Abstract                 = {A method to describe the general characteristics of an \{EEG\} trace in a few quantitative terms is introduced. Its descriptive parameters are entirely based on time, but they can be derived also from the statistical moments of the power spectrum. Thus the method provides a bridge between a physical time domain interpretation and the conventional frequency domain description. Further, the parameters are based on the concept of variance, giving them an additive property so that the measured values pertain also to any basic elements from which a complex curve may be composed by superposition. The proposed method offers a way to on-line measurement of basic signal properties by means of a time-based calculation, requiring less complex equipment compared to conventional frequency analysis. The data-reducing capability of the parameters has been experimentally stated in the recording of “sleep profiles”.},
  Doi                      = {http://dx.doi.org/10.1016/0013-4694(70)90143-4},
  ISSN                     = {0013-4694},
  Owner                    = {jf2lin},
  Timestamp                = {2015.05.04}
}

@Article{Hodge2004,
  Title                    = {A survey of outlier detection methodologies},
  Author                   = {Hodge, Victoria J and Austin, Jim},
  Journal                  = {Artificial Intelligence Review},
  Year                     = {2004},
  Number                   = {2},
  Pages                    = {85--126},
  Volume                   = {22},

  Abstract                 = {Outlier detection has been used for centuries to detect and, where appropriate, remove anomalous observations from data. Outliers arise due to mechanical faults, changes in system behaviour, fraudulent behaviour, human error, instrument error or simply through natural deviations in populations. Their detection can identify system faults and fraud before they escalate with potentially catastrophic consequences. It can identify errors and remove their contaminating effect on the data set and as such to purify the data for processing. The original outlier detection methods were arbitrary but now, principled and systematic techniques are used, drawn from the full gamut of Computer Science and Statistics. In this paper, we introduce a survey of contemporary techniques for outlier detection. We identify their respective motivations and distinguish their advantages and disadvantages in a comparative review.},
  Publisher                = {Springer},
  Review                   = {Doesn't quite applyto what we need, but might be a useful reference in the future},
  Timestamp                = {2015.05.13}
}

@Article{Hol2007,
  Title                    = {Robust real-time tracking by fusing measurements from inertial and vision sensors},
  Author                   = {Hol, Jeroen D and Schön, Thomas B and Luinge, Henk and Slycke, Per J and Gustafsson, Fredrik},
  Journal                  = {Journal of RealTime Image Processing},
  Year                     = {2007},
  Number                   = {2-3},
  Pages                    = {149--160},
  Volume                   = {2},

  Abstract                 = {The problem of estimating and predicting position and orientation (pose) of a camera is approached by fusing measurements from inertial sensors (accelerometers and rate gyroscopes) and vision. The sensor fusion approach described in this contribution is based on non-linear filtering of these complementary sensors. This way, accurate and robust pose estimates are available for the primary purpose of augmented reality applications, but with the secondary effect of reducing computation time and improving the performance in vision processing. A real-time implementation of a multi-rate extended Kalman filter is described, using a dynamic model with 22 states, where 12.5 Hz correspondences from vision and 100 Hz inertial measurements are processed. An example where an industrial robot is used to move the sensor unit is presented. The advantage with this configuration is that it provides ground truth for the pose, allowing for objective performance evaluation. The results show that we obtain an absolute accuracy of 2 cm in position and 1 in orientation.},
  Keywords                 = {lab reading (eric)},
  Publisher                = {Springer},
  Review                   = {IMU + camera fusion system, using EKF, UKF and PF
They model the sensor bais in the states...},
  Timestamp                = {2011.11.16},
  Url                      = {http://www.springerlink.com/index/10.1007/s11554-007-0040-2}
}

@InProceedings{Hong2000,
  author    = {Hong, P. and Turk, M. and Huang, T. S.},
  title     = {Gesture Modeling and Recognition using Finite State Machines},
  booktitle = {IEEE International Conference on Automatic Face and Gesture Recognition},
  year      = {2000},
  pages     = {410--415},
  abstract  = {We propose a state-based approach to gesture learning and recognition. Using spatial clustering and temporal alignment, each gesture is defined to be an ordered sequence of states in spatial-temporal space. The 2D image positions of the centers of the head and both hands of the user are used as features; these are located by a color-based tracking method. From training data of a given gesture, we first learn the spatial information and then group the data into segments that are automatically aligned temporally. The temporal information is further integrated to build a finite state machine (FSM) recognizer. Each gesture has a FSM corresponding to it. The computational efficiency of the FSM recognizers allows us to achieve real-time on-line performance. We apply this technique to build an experimental system that plays a game of “Simon Says” with the user},
  doi       = {10.1109/AFGR.2000.840667},
  groups    = {Lit Review 2013-09},
  keywords  = {feature extraction;finite state machines;gesture recognition;image colour analysis;learning (artificial intelligence);real-time systems;sequences;tracking;2D image positions;FSM;color-based tracking method;feature location;finite state machines;gesture learning;gesture modeling;gesture recognition;hands;head;ordered state sequence;real-time on-line performance;spatial clustering;state-based approach;temporal alignment;Automata;Decision support systems;Fiber reinforced plastics},
  review    = {want to recognize and learn from video sequences. learning from 2D videos is hard due to movement variation and tracking error. We assume that the
trajectories of a gesture are set of points distributed
spatially. The distribution of the data can be represented
by a set of Gaussian spatial regions. A threshold is
selected to represent the spatial variance allowed for each
state. These thresholds determine the spatial variance of
the gesture. The number of the states and their coarse
spatial parameters are calculated by dynamic k-means
clustering on the training data of the gesture without
temporal information. Training is done offline. 

Sounds like they're using Forward algorithm with HMM as the FSM. Err. Not sure. An FSM is trained for each motion. 

Input is video images with face and hand tracking, in position. A "gesture" is stored as a 2D mean and covariance, distance threshold (not sure what this is - though calc from the state mean and sd), and length of action. Training is separated into it's spatial component and temporal component, to try to reduce the impact of spatial-temporal variations. Uses Mahalanobis distance to generate distance to windowed data, and k-means is used to determine the states. The temporal alignment is done by determining how many sample is in a given state, and lining them up along the state transitions. FSM is used to train the state information.

when data is coming in, state transition occurs by examining the FSM's state thresholds.

Tested by a "simon says" program, but no segmentation accuracy is reported.},
  timestamp = {2013.09.30},
}

@InCollection{Hong2006,
  author    = {Hong, S. and Bae, J. and Lee, S. C. and Kim, J. Y. and Lee, K. Y.},
  title     = {An Effective Method of Gait Stability Analysis Using Inertial Sensors},
  booktitle = {MICAI 2006: Advances in Artificial Intelligence},
  publisher = {Springer Berlin/Heidelberg},
  year      = {2006},
  editor    = {Gelbukh, A. and Reyes-Garcia, C. A.},
  volume    = {4293},
  series    = {Lecture Notes in Computer Science},
  pages     = {1220--1228},
  isbn      = {978-3-540-49026-5},
  abstract  = {This study aims to develop an effective measurement instrument and analysis method of gait stability, particularly focused on the motion of lower spine and pelvis during gait. Silicon micromechanical inertial instruments have been developed and body-attitude (pitch and roll) angles were estimated via closed-loop strapdown estimation filters, which results in improved accuracy of estimated attitude. Also, it is shown that the spectral analysis utilizing the Fast Fourier Transform (FFT) provides an efficient analysis method, which provides quantitative diagnoses for the gait stability. The results of experiments on various subjects suggest that the proposed system provides a simplified but an efficient tool for the evaluation of both gait stabilities and rehabilitation treatments effects.},
  doi       = {10.1007/11925231_117},
  groups    = {EMBC2013},
  timestamp = {2013.01.15},
  url       = {http://dx.doi.org/10.1007/11925231_117},
}

@Article{Hosseini-Suny2010,
  Title                    = {Model Reference Adaptive Control Design for a Teleoperation System with Output Prediction},
  Author                   = {Hosseini-Suny, K. and Momeni, H. and Janabi-Sharifi, F.},
  Journal                  = {Journal of Intelligent and Robotic Systems},
  Year                     = {2010},
  Number                   = {3-4},
  Pages                    = {319--339},
  Volume                   = {59},

  Abstract                 = {In this paper, a new control scheme is proposed to ensure stability and good performance of the teleoperation systems while a wide range of time delays in transmission line is allowed. For this purpose, a new algorithm is recommended for time delay estimation and plant output prediction in the presence of white and color noise. A model reference adaptive controller (MRAC) is designed for the master site using the predicted output of the plant. An independent MRAC is also designed and integrated for the slave site. The proposed control system indicates good stability and tracking performance.},
  Doi                      = {10.1007/s10846-010-9400-4},
  ISSN                     = {0921-0296 (Print) 1573-0409 (Online)},
  Keywords                 = {Teleoperation - Time-delay - MRAC - Master robot - Slave robot - Delay estimation - Output prediction},
  Publisher                = {Springer Netherlands},
  Review                   = {Skimmed a bit of it. Assumes to have a Laplace domain plant representation, and uses control diagrams/state-space type things to control this. Classic control, but outside my scope...},
  Subject_collection       = {Engineering},
  Timestamp                = {2010.08.02},
  Url                      = {http://www.springerlink.com/content/50181545v67r0663/}
}

@Article{Houmanfar2016,
  author    = {Houmanfar, R. and Karg, M. E. and Kuli\'{c}, D.},
  title     = {Movement Analysis of Rehabilitation Exercises: Distance Metrics for Measuring Patient Progress},
  journal   = {IEEE Systems Journal},
  year      = {2016},
  volume    = {10},
  number    = {3},
  pages     = {1014--1025},
  issn      = {1932-8184},
  abstract  = {Mobility improvement for patients is one of the primary concerns of physiotherapy rehabilitation. Providing the physiotherapist and the patient with a quantified and objective measure of progress can be beneficial for monitoring the patient's performance. In this paper, two approaches are introduced for quantifying patient performance. Both approaches formulate a distance between patient data and the healthy population as the measure of performance. Distance measures are defined to capture the performance of one repetition of an exercise or multiple repetitions of the same exercise. To capture patient progress across multiple exercises, a quality measure and overall score are defined based on the distance measures and are used to quantify the overall performance for each session. The effectiveness of these measures in detecting patient progress is evaluated on rehabilitation data recorded from patients recovering from knee or hip replacement surgery. The results show that the proposed measures are able to capture the trend of patient improvement over the course of rehabilitation. The trend of improvement is not monotonic and differs between patients.},
  doi       = {10.1109/JSYST.2014.2327792},
  file      = {Houmanfar2014_SJ.pdf:ASL\\Houmanfar2014_SJ.pdf:PDF},
  keywords  = {Biomedical measurement;Feature extraction;Hidden Markov models;Joints;Sociology;Statistics;Vectors;Biomedical monitoring;biomedical signal processing;computer aided diagnosis;human motion analysis;motion measurement;motion quality assessment;rehabilitation robotics},
  timestamp = {2014.07.24},
}

@Article{Howe2006,
  Title                    = {The Community Balance and Mobility Scale -- A balance measure for individuals with traumatic brain injury},
  Author                   = {Howe, J. A. and Inness, E. L. and Venturini, A. and Williams, J. I. and Verrier, M. C.},
  Journal                  = {Clinical Rehabilitation},
  Year                     = {2006},
  Pages                    = {885--895},
  Volume                   = {20},

  Abstract                 = {Objective: To provide evidence for the validity and reliability of a new outcome measure of balance, the Community Balance and Mobility Scale, developed for the ambulatory individual with traumatic brain injury. Design: A validity and reliability study. Setting: Acute care, in- and outpatient rehabilitation and day hospital settings. Subjects: Two convenience samples (n=36, 32) of ambulatory patients with traumatic brain injury. Main measures: The content and construct validity, test-retest, inter- and intra-rater reliability and internal consistency of the Community Balance and Mobility Scale. Results: Content validity was demonstrated by the involvement of patients with traumatic brain injury (n=7) and clinicians (n=17) in the process of item generation and by physical therapists’ ratings of item relevance. Further support is the correlation of the Community Balance and Mobility Scale scores with physical therapists’ global balance ratings of the patient (r=0.62). Construct validity was supported by the ability of the measure to differentiate between patients along the continuum of care and also by comparisons with maximal walking velocity (r=0.64). Patients who scored greater than or less than 50 on the balance measure demonstrated significantly different Community Integration Questionnaire scores (P=0.004). The Community Balance and Mobility Scale demonstrated intraclass correlation coefficients (ICCs) of 0.977, 0.977, 0.975 and Cronbach’s alpha of 0.96 for intra-, inter-, test-retest reliability and internal consistency, respectively. Conclusion: The Community Balance and Mobility Scale is a valid and reliable outcome measure for the ambulatory individual with traumatic brain injury.},
  Doi                      = {10.1177/0269215506072183},
  Eprint                   = {http://cre.sagepub.com/content/20/10/885.full.pdf+html},
  Timestamp                = {2012.06.21},
  Url                      = {http://cre.sagepub.com/content/20/10/885.short}
}

@Article{Hu1996,
  Title                    = {HMM based online handwriting recognition},
  Author                   = {Hu, J. and Brown, M. K. and Turin, W.},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {1996},
  Number                   = {10},
  Pages                    = {1039--1045},
  Volume                   = {18},

  Abstract                 = {Hidden Markov model (HMM) based recognition of handwriting is now quite common, but the incorporation of HMM's into a complex stochastic language model for handwriting recognition is still in its infancy. We have taken advantage of developments in the speech processing field to build a more sophisticated handwriting recognition system. The pattern elements of the handwriting model are subcharacter stroke types modeled by HMMs. These HMMs are concatenated to form letter models, which are further embedded in a stochastic language model. In addition to better language modeling, we introduce new handwriting recognition features of various kinds. Some of these features have invariance properties, and some are segmental, covering a larger region of the input pattern. We have achieved a writer independent recognition rate of 94.5% on 3,823 unconstrained handwritten word samples from 18 writers covering a 32 word vocabulary},
  Doi                      = {10.1109/34.541414},
  ISSN                     = {0162-8828},
  Keywords                 = {evolution grammar;handwritten character recognition;hidden Markov model;invariant features;online handwriting recognition;segmental features;stochastic language model;subcharacter stroke model;writer independent recognition;character recognition;computer vision;context-free grammars;feature extraction;hidden Markov models;image segmentation;real-time systems;},
  Timestamp                = {2011.06.09}
}

@Conference{Hung2004,
  Title                    = {Wearable Medical Devices for Tele-Home Healthcare},
  Author                   = {Hung, K. AND Zhang, Y. T. AND Tai, B.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2004},

  Abstract                 = {The world's ageing population and prevalence of chronic diseases have lead to high demand for tele-home healthcare, in which vital-signs monitoring is essential. An overview of state-of-art wearable technologies for remote patient-monitoring is presented, followed by case studies on a cuffless blood pressure meter, ring-type heart rate monitor, and Bluetooth™-based ECG monitor. Aim of our project is to develop a tele-home healthcare system which utilizes wearable devices, wireless communication technologies, and multisensor data fusion methods. As an important part of this system, a cuffless BP meter has been developed and tested on 30 subjects in a total of 71 trials over a period of five months. Preliminary results show a mean error (ME) of 1.82 mmHg and standard deviation of error (SDE) of 7.62 mmHg in systolic pressure; while ME and SDE in diastolic pressure are 0.45 mmHg and 5.27 mmHg, respectively.},
  Timestamp                = {2010.09.28}
}

@Article{Hunt1975,
  Title                    = {Coefficient of Restitution Interpreted as Damping in Vibroimpact},
  Author                   = {Hunt, K. H. and Crossley, F. R. E.},
  Journal                  = {Journal of Applied Mechanics},
  Year                     = {1975},
  Number                   = {2},
  Pages                    = {440-445},
  Volume                   = {42},

  Doi                      = {10.1115/1.3423596},
  Publisher                = {ASME},
  Timestamp                = {2011.02.17},
  Url                      = {http://link.aip.org/link/?AMJ/42/440/1}
}

@Article{Hurst1951,
  Title                    = {Long-term storage capacity of reservoirs},
  Author                   = {Hurst, H.},
  Journal                  = {T Am Soc Civ Eng},
  Year                     = {1951},
  Pages                    = {770--808},
  Volume                   = {116},

  Owner                    = {jf2lin},
  Timestamp                = {2015.05.04}
}

@InProceedings{Huynh2006,
  Title                    = {Towards Less Supervision in Activity Recognition from Wearable Sensors},
  Author                   = {Huynh, T. and Schiele, B.},
  Booktitle                = {Wearable Computers, 2006 10th IEEE International Symposium on},
  Year                     = {2006},
  Month                    = {Oct},
  Pages                    = {3-10},

  Abstract                 = {Activity Recognition has gained a lot of interest in recent years due to its potential and usefulness for context-aware wearable computing. However, most approaches for activity recognition rely on supervised learning techniques lim iting their applicability in real-world scenarios and their scalability to large amounts of activities and training data. State-of-the-art activity recognition algorithms can roughly be divided in two groups concerning the choice of the classifier, one group using generative models and the other discriminative approaches. This paper presents a method for activity recognition which combines a generative model with a discriminative classifier in an integrated approach. The generative part of the algorithm allows to extract and learn structure in activity data without any labeling or supervision. The discriminant part then uses a small but labeled subset of the training data to train a discriminant classifier. In experiments we show that this scheme enables to attain high recognition rates even though only a subset of the training data is used for training. Also the tradeoff between labeling effort and recognition performance is analyzed and discussed.},
  Doi                      = {10.1109/ISWC.2006.286336},
  ISSN                     = {1550-4816},
  Keywords                 = {learning (artificial intelligence);nonelectric sensing devices;pattern recognition;wearable computers;activity recognition;context-aware wearable computing;discriminative classifier;generative model;generative models;supervised learning techniques;wearable sensors;Computer science;Data mining;Labeling;Legged locomotion;Performance analysis;Supervised learning;Support vector machines;Training data;Wearable computers;Wearable sensors},
  Timestamp                = {2014.12.22}
}

@Article{Hwangbo2013,
  Title                    = {IMU Self-Calibration Using Factorization},
  Author                   = {Hwangbo, M. and Kim, J. S. and Kanade, T.},
  Journal                  = {IEEE Transactions on Robotics},
  Year                     = {2013},
  Number                   = {2},
  Pages                    = {493--507},
  Volume                   = {29},

  Abstract                 = {This paper presents a convenient self-calibration method for an inertial measurement unit (IMU) using matrix factorization. Using limited information about applied loads (accelerations or angular rates) available from natural references, the proposed method can linearly solve all the parameters of an IMU in any configuration of its inertial components. Our factorization-based calibration method exploits the bilinear form of an IMU measurement, which is the product of intrinsic calibration parameters and exerted loads. For a redundant IMU, we prove that partial knowledge of the loads, such as magnitude, can produce a linear solution space for a proper decomposition of the measurement. Theoretical analysis on this linear space reveals that a 1-D null space should be considered when load magnitudes are all equal (e.g., gravity loads). Degenerate load distributions are also geometrically identified to avoid singular measurement collection. Since a triad IMU has a lower number of sensor components than a 4-D parameter space, we propose an iterative factorization in which only initial bias is required. A wide convergence region of the bias can provide an automatic setting of the initial bias as the mean of the measurements. Performance of the proposed method is evaluated with respect to various noise levels and constraint types. Self-calibration capability is demonstrated using natural references, which are gravity for accelerometers and image stream from an attached camera for gyroscopes. Calibration results are globally optimal and identical to those of nonlinear optimization.},
  Doi                      = {10.1109/TRO.2012.2230994},
  ISSN                     = {1552-3098},
  Keywords                 = {accelerometers;calibration;convergence;gyroscopes;inertial systems;iterative methods;matrix algebra;nonlinear programming;1D null space;4D parameter space;IMU measurement;IMU self-calibration;acceleration;accelerometer;angular rate;bias convergence region;camera;constraint type;degenerate load distribution;factorization-based calibration method;gravity load;gyroscope;image stream;inertial measurement unit;intrinsic calibration parameter;iterative factorization;linear solution space;load magnitude;load partial knowledge;matrix factorization;measurement decomposition;noise level;nonlinear optimization;self-calibration capability;sensor components;singular measurement collection;triad IMU;Accelerometers;Calibration;Cameras;Gravity;Gyroscopes;Matrix decomposition;Robot sensing systems;Calibration and identification;factorization method;linear algorithm;redundant and triad inertial measurement unit (IMU);self-calibration},
  Timestamp                = {2013.06.13}
}

@Article{Ijspeert2012_DMP,
  Title                    = {Dynamical Movement Primitives: Learning Attractor Models for Motor Behaviors},
  Author                   = {Ijspeert, Auke Jan and Nakanishi, Jun and Hoffmann, Heiko and Pastor, Peter and Schaal, Stefan},
  Journal                  = {Neural Computation},
  Year                     = {2012},

  Month                    = nov,
  Number                   = {2},
  Pages                    = {328--373},
  Volume                   = {25},

  Booktitle                = {Neural Computation},
  Comment                  = {doi: 10.1162/NECO_a_00393},
  Doi                      = {10.1162/NECO_a_00393},
  ISSN                     = {0899-7667},
  Publisher                = {MIT Press},
  Timestamp                = {2014.07.15},
  Url                      = {http://dx.doi.org/10.1162/NECO_a_00393}
}

@InProceedings{Ijspeert2002,
  Title                    = {Movement imitation with nonlinear dynamical systems in humanoid robots},
  Author                   = {Ijspeert, A. J. and Nakanishi, J. and Schaal, S.},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2002},
  Pages                    = {1398--1403},
  Volume                   = {2},

  Abstract                 = {Presents an approach to movement planning, on-line trajectory modification, and imitation learning by representing movement plans based on a set of nonlinear differential equations with well-defined attractor dynamics. The resultant movement plan remains an autonomous set of nonlinear differential equations that forms a control policy (CP) which is robust to strong external perturbations and that can be modified on-line by additional perceptual variables. We evaluate the system with a humanoid robot simulation and an actual humanoid robot. Experiments are presented for the imitation of three types of movements: reaching movements with one arm, drawing movements of 2-D patterns, and tennis swings. Our results demonstrate (a) that multi-joint human movements can be encoded successfully by the CPs, (b) that a learned movement policy can readily be reused to produce robust trajectories towards different targets, (c) that a policy fitted for one particular target provides a good predictor of human reaching movements towards neighboring targets, and (d) that the parameter space which encodes a policy is suitable for measuring to which extent two trajectories are qualitatively similar},
  Doi                      = {10.1109/ROBOT.2002.1014739},
  Keywords                 = {attractor dynamics;attractor landscape;control policy;humanoid robots;imitation learning;learning algorithm;locally weighted regression technique;movement imitation;movement planning;movement plans;multi-joint human movements;nonlinear differential equations;nonlinear dynamical systems;online trajectory modification;learning by example;nonlinear dynamical systems;path planning;robot kinematics;robot programming;stability; ECE780},
  Timestamp                = {2011.02.16}
}

@Article{Ilg2004,
  author    = {Ilg, W. and Bakir, G. H. and Mezger, J. and Giese, M. A.},
  title     = {On the Representation, Learning and Transfer of Spatio-Temporal Movement Characteristics},
  journal   = {International Journal of Humanoid Robotics},
  year      = {2004},
  volume    = {1},
  pages     = {613--636},
  abstract  = {In this paper we present a learning-based approach for the modelling of complex movement sequences. Based on the method of Spatio-Temporal Morphable Models (STMMS. We derive a hierarchical algorithm that, in a first step, identifies automatically movement elements in movement sequences based on a coarse spatio-temporal description, and in a second step models these movement primitives by approximation through linear combinations of learned example movement trajectories. We describe the different steps of the algorithm and show how it can be applied for modelling and synthesis of complex sequences of human movements that contain movement elements with variable style. The proposed method is demonstrated on different applications of movement representation relevant for imitation learning of movement styles in humanoid robotics.},
  groups    = {STAT841, IROS2014, EMBC2014},
  keywords  = {Segmentation},
  review    = {Ilg2004

INTRODUCTION
- Need to be able to learn motion from small amounts of training data
- Need to learn a whole class of movement from small sample sets
- Spatio-Temporal Morphable Models (STMM) can do this
 - Weights spatial and temporal displacement fields
 - Used in many areas, like computer vision and graphics already
 - Applied to fields with short motions (one gait, one arm, etc)
- This paper expands STMM to represent motion primitives
 1) unsupervised movement primitive id
 2) their approx by STMM
 3) auto-concatenation of motion

HIERARCHICAL SPATIO-TEMPORAL MORPHABLE MODELS (HSTMM)
- Breaking down a complex motion into primitives is not new
- Need to look at both perception and generation
 - perception: robust identification of primitives
 - generation: primitives should dfeine generic blocks of motion
- want something robust and fast
 - using ZVC to get a general idea of where segments are
 - matching segments to primitives, using dynamic programming

Identifying Movement Primitives
- Need to look for primitives in nosiy data
- Use dynamic programming (breaking it down to smaller problems)
 - looking for matches between prototype movements and the search window by looking at key features
 - so we look at the various key features in our search window and key features (which are...?) in the prototype...
 - and match based on minimizing distance
 - what about extra/missing features?
 - so instead of making sure all the key features matches up, we only need to match a handful

Morphable Models
- Uses dynamic time warping (non-linear transformation of time data)
- look at movements of feature points (as oppose to all DOFs?)
- so spatial and temporal shifts allows comparison of motions from different objects and movement timing
 - minimizing weighted sum of quadratics (so least squares)
 - do this in two steps
 - dynamic programming: temporally sample system and optimize on that (discrete)
 - then take linear interpolation between sampled points and optimize that (continous)
 - however, after this transformation process, we could end up with disconts and artifacts
 - but we can address them
 - the results of the HSTMM segmentation gives us 'L' points in the data
 - resample the original data in each of the segment area, after shifting it so they start and end at zero (linearly)
 - "linear combination of elements" (not too sure what this means)
 - "rewarping and concatentation..." (not sure what this means either)

rest of the post talks about examples

Ilg \etal \cite{Ilg2004} employed DTW in a multi-tier fashion. The observation signal is dimensionally reduced by removing all data points that are not at a velocity zero, as velocity zeros denote turning points in the motion, and thus can be considered as key features of the motion. DTW is performed on this reduced dataset to align these key features. A tolerance is included to allow for missed key features, as the template and the observation may not have the same velocity zeros, to reduce the number of mapping singularities. Each window in these high-level segments is resampled to have the same number of data points. A finer alignment is performed in each of these windows. Assuming that the observed motion can be warped to the template with the proper temporal and spatial warping, the algorithm uses DTW to calculate an optimal temporal mapping path between the template and the observation, and applies some interpolated shifting around the suggested mapping path to minimize the temporal difference between the two signals. Once the optimal time warping is found, the spatial distance offset can be calculated. The temporal and spatial warping variables are also constrained to minimize the amount of warping required to obtain the best fit \cite{Giese1999}. The algorithm was implemented as part of a motion generation algorithm, and not specifically for segmentation, so segmentation and identification accuracy were not reported. Similar to previous DTW algorithms, this algorithm does not address the computational costs of using DP, and thus may not scale well to higher dimensions.},
  timestamp = {2011.01.17},
}

@Article{Inamura2004,
  Title                    = {Embodied Symbol Emergence Based on Mimesis Theory},
  Author                   = {Inamura, T. and Toshima, I. and Tanie, H. and Nakamura, Y.},
  Journal                  = {The International Journal of Robotics Research},
  Year                     = {2004},
  Number                   = {4-5},
  Pages                    = {363-377},
  Volume                   = {23},

  Abstract                 = {“Mimesis” theory focused in the cognitive science field and “mirror neurons” found in the biology field show that the behavior generation process is not independent of the behavior cognition process. The generation and cognition processes have a close relationship with each other. During the behavioral imitation period, a human being does not practice simple joint coordinate transformation, but will acknowledge the parents’ behavior. It understands the behavior after abstraction as symbols, and will generate its self-behavior. Focusing on these facts, we propose a new method which carries out the behavior cognition and behavior generation processes at the same time. We also propose a mathematical model based on hidden Markov models in order to integrate four abilities: (1) symbol emergence; (2) behavior recognition; (3) self-behavior generation; (4) acquiring the motion primitives. Finally, the feasibility of this method is shown through several experiments on a humanoid robot.},
  Doi                      = {10.1177/0278364904042199},
  Eprint                   = {http://ijr.sagepub.com/content/23/4-5/363.full.pdf+html},
  Keywords                 = {motion primitive},
  Timestamp                = {2011.01.06},
  Url                      = {http://ijr.sagepub.com/content/23/4-5/363.abstract}
}

@Book{ISO_11226-2000,
  Title                    = {Ergonomics: Evaluation of static working postures},
  Author                   = {ISO{~}11226:2000},
  Publisher                = {International Organization for Standardization},
  Year                     = {2000},

  Timestamp                = {2012.01.10}
}

@Article{Ito2004,
  Title                    = {On-line Imitative Interaction with a Humanoid Robot Using a Dynamic Neural Network Model of a Mirror System},
  Author                   = {Ito, M. and Tani, J.},
  Journal                  = {Adaptive Behavior},
  Year                     = {2004},
  Number                   = {2},
  Pages                    = {93--115},
  Volume                   = {12},

  Abstract                 = {This study presents experiments on the imitative interactions between a small humanoid robot and a user. A dynamic neural network model of a mirror system was implemented in a humanoid robot, based on the recurrent neural network model with parametric bias (RNNPB). The experiments showed that after the robot learns multiple cyclic movement patterns as embedded in the RNNPB, it can regenerate each pattern synchronously with the movements of a human who is demonstrating the corresponding movement pattern in front of the robot. Further, the robot exhibits diverse interactive responses when the user demonstrates novel cyclic movement patterns. Those responses were analyzed and categorized. We propose that the dynamics of coherence and incoherence between the robot’s and the user’s movements could enhance close interactions between them, and that they could also explain the essential psychological mechanism of joint attention.},
  Doi                      = {10.1177/105971230401200202},
  Eprint                   = {http://adb.sagepub.com/content/12/2/93.full.pdf+html},
  Keywords                 = {ECE780, Imitation Learning},
  Timestamp                = {2011.02.16},
  Url                      = {http://adb.sagepub.com/content/12/2/93.abstract}
}

@Article{Ivanov2000,
  author    = {Ivanov, Y. A. and Bobick, A. F.},
  title     = {Recognition of Visual Activities and Interactions by Stochastic Parsing},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year      = {2000},
  volume    = {22},
  pages     = {852--872},
  groups    = {Lit Review 2013-09},
  publisher = {IEEE},
  review    = {Stochastic Context-Free Grammars used. A probability term is attached to a production rule. 

Though. It seems like the algorithm is done with Early-Stolcke Parsing algorithm, where the system predict, scans and completes a string. ESP looks at the current position of the parse and hypothesize the possible continuation of the input, which essentially traces down branches of grammar trees. The input obs is than scanned, where the obs is compared against expected states and a probability is generated. The best match is selected. When a grammar branch is exhaused (ie we think we've completed a primitive), Viterbi is used to trace out the segments. 

[continue from Section 4 later]

Ivanov and Bobick \cite{Ivanov2000} employs the Earley-Stolcke Parser \cite{Stolcke1996}, which relies on stochastic context0free grammar. The system predicts, scans and completes strings in audio sequences, and applied it to motion segmentation. This parser looks at the current position of the observation data and hypothesize the possible continuation of the input by tracing down branches on the SCGC grammar trees. The observation input is then scanned, and compared against expected states and a likelihood of state advancement is generated. When a grammar branch is exhausted, a primitive may have been completed, and the Viterbi algorithm is used to trace out the segments.},
  timestamp = {2013.10.08},
}

@Article{Jagodzinski2000,
  Title                    = {Experimental and clinical assessment of the accuracy of knee extension measurement techniques},
  Author                   = {Jagodzinski, M. and Kleemann, V. and Angele, P. and Schönhaar, V. and Iselborn, K.W. and Mall, G. and Nerlich, M.},
  Journal                  = {Knee Surgery, Sports Traumatology, Arthroscopy},
  Year                     = {2000},
  Pages                    = {329--336},
  Volume                   = {8},

  Abstract                 = {The purpose of this study was to analyze the accuracy of commonly used techniques for the measurement of knee extension and to compare them with a new measurement device. The bars of an external fixator were used to determine reference knee extension angles of 15 human cadavers. These angles were compared with measurements of knee extension on radiographs limited to the knee joint. Extension was determined in various knee positions using a generic goniometer and a novel long arm goniometer. In a clinical study, two independent examiners categorized knee extension performance according to the IKDC. Sixteen knees with deficits in the range of motion were rated using a generic goniometer, a long arm goniometer and the novel extension measurement device. The radiological measurement of knee extension angles that were restricted to the shaft of femur and tibia had a systematic error of -5.2 &#45 1.9&#176; compared with the lines created by the centers of rotation. In the experimental setup, the mean absolute deviations were 3.92 &#45 1.41&#176; with a generic goniometer and 1.22 &#45 0.20&#176; with the extension measurement device. The variance of the measurements was significantly lower (2.64 &#45 0.28) than with the generic goniometer (23.72 &#45 4.39; P &lt;0.05). Correspondence in the IKDC rating was 63% using a standard goniometer, 50% with the long arm goniometer, and 96% using the novel device. Radiological measurements of knee extension limited to the area of the knee joint deviates systematically from measurements of the total axis of the bones. A precision goniometer that utilizes bony landmarks of the tibia and femur is superior in accuracy compared with standard and long arm goniometer techniques.},
  ISSN                     = {0942-2056},
  Issue                    = {6},
  Keyword                  = {Medicine},
  Publisher                = {Springer Berlin / Heidelberg},
  Timestamp                = {2012.09.29}
}

@Article{Jain2000,
  author    = {Jain, A. K. and Duin, R. P. W. and Mao, J.},
  title     = {Statistical Pattern Recognition: A Review},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year      = {2000},
  volume    = {22},
  pages     = {4--37},
  issn      = {0162-8828},
  abstract  = {The primary goal of pattern recognition is supervised or unsupervised classification. Among the various frameworks in which pattern recognition has been traditionally formulated, the statistical approach has been most intensively studied and used in practice. More recently, neural network techniques and methods imported from statistical learning theory have been receiving increasing attention. The design of a recognition system requires careful attention to the following issues: definition of pattern classes, sensing environment, pattern representation, feature extraction and selection, cluster analysis, classifier design and learning, selection of training and test samples, and performance evaluation. In spite of almost 50 years of research and development in this field, the general problem of recognizing complex patterns with arbitrary orientation, location, and scale remains unsolved. New and emerging applications, such as data mining, web searching, retrieval of multimedia data, face recognition, and cursive handwriting recognition, require robust and efficient pattern recognition techniques. The objective of this review paper is to summarize and compare some of the well-known methods used in various stages of a pattern recognition system and identify research topics and applications which are at the forefront of this exciting and challenging field},
  doi       = {10.1109/34.824819},
  groups    = {Lit Review 2013-09},
  keywords  = {Bayes methods;decision theory;learning (artificial intelligence);neural nets;parameter estimation;pattern recognition;classifier design;cluster analysis;complex patterns;cursive handwriting recognition;data mining;multimedia data retrieval;neural network techniques;pattern classes;pattern representation;performance evaluation;sensing environment;statistical learning theory;statistical pattern recognition;supervised classification;unsupervised classification;web searching;Data mining;Feature extraction;Information retrieval;Neural networks;Pattern analysis;Pattern recognition;Performance analysis;Research and development;Statistical learning;System testing},
  timestamp = {2013.10.04},
}

@Article{Jain1996,
  Title                    = {Artificial Neural Networks: A tutorial},
  Author                   = {Jain, A. K. and Mao, J. and Mohiuddin, K. M.},
  Journal                  = {Computer},
  Year                     = {1996},
  Number                   = {3},
  Pages                    = {31--44},
  Volume                   = {29},

  Publisher                = {IEEE},
  Timestamp                = {2014.01.22}
}

@Article{Janabi-Sharifi2010,
  Title                    = {A Kalman-Filter-Based Method for Pose Estimation in Visual Servoing},
  Author                   = {Janabi-Sharifi, F. and Marey, M.},
  Journal                  = {IEEE Transactions on Robotics},
  Year                     = {2010},
  Number                   = {5},
  Pages                    = {939 -947},
  Volume                   = {26},

  Abstract                 = {The problem of estimating position and orientation (pose) of an object in real time constitutes an important issue for vision-based control of robots. Many vision-based pose-estimation schemes in robot control rely on an extended Kalman filter (EKF) that requires tuning of filter parameters. To obtain satisfactory results, EKF-based techniques rely on #x201C;known #x201D; noise statistics, initial object pose, and sufficiently high sampling rates for good approximation of measurement-function linearization. Deviations from such assumptions usually lead to degraded pose estimation during visual servoing. In this paper, a new algorithm, namely iterative adaptive EKF (IAEKF), is proposed by integrating mechanisms for noise adaptation and iterative-measurement linearization. The experimental results are provided to demonstrate the superiority of IAEKF in dealing with erroneous a priori statistics, poor pose initialization, variations in the sampling rate, and trajectory dynamics.},
  Doi                      = {10.1109/TRO.2010.2061290},
  ISSN                     = {1552-3098},
  Keywords                 = {filtering},
  Review                   = {Hmm. It's for video-based motion capture},
  Timestamp                = {2010.10.09}
}

@InProceedings{Janus2005,
  Title                    = {Unsupervised Probabilistic Segmentation of Motion Data for Mimesis Modeling},
  Author                   = {Janus, B. and Nakamura, Y.},
  Booktitle                = {Proceedings of the IEEE International Conference on Advanced Robotics},
  Year                     = {2005},
  Pages                    = {411--417},

  Abstract                 = {Humanoid developments express the need for intelligent learning systems that can automatically realize behavior acquisition and symbol emergence. In the framework of mimesis model, we present an unsupervised dynamic HMM-based algorithm in order to analyze vectorial motion data. The efficiency of this algorithm is demonstrated by segmenting continuous sequence of real movements. We also propose to use it as the first level of an information treatment system by associating it with a recognition process. Unlike other existing segmentation-recognition system, our segmentation process does not need any learning of the parameters that increases the flexibility of the whole segmentation-recognition system and the range of its possible applications},
  Doi                      = {10.1109/ICAR.2005.1507443},
  Keywords                 = {behavior acquisition;information treatment system;intelligent learning systems;mimesis modeling;motion data segmentation;segmentation-recognition system;symbol emergence;unsupervised dynamic HMM-based algorithm;unsupervised probabilistic segmentation;hidden Markov models;humanoid robots;image motion analysis;image recognition;image segmentation;learning systems;probability;},
  Review                   = {Janus and Nakamura \cite{Janus2005} apply Kohlmorgen and Lemm's algorithm \cite{Kohlmorgen2002} to human movement data. HMM state changes occurred when the signal's distribution function is sufficiently different from the previous state, suggesting possible segmentation points at these state changes. This algorithm was verified on a dataset of a human subject performing various different full body exercises, captured with motion capture and translated to joint angles via inverse kinematics. However, segmentation accuracy was not provided.},
  Timestamp                = {2011.04.18}
}

@InProceedings{Jatoba2008,
  Title                    = {Context-aware mobile health monitoring: Evaluation of different pattern recognition methods for classification of physical activity},
  Author                   = {Jatoba, Luciana C. and Grossmann, Ulrich and Kunze, Chistophe and Ottenbacher, J. and Stork, W.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2008},
  Month                    = {Aug},
  Pages                    = {5250-5253},

  Abstract                 = {There are various applications of physical activity monitoring for medical purposes, such as therapeutic rehabilitation, fitness enhancement or the use of physical activity as context information for evaluation of other vital data. Physical activity can be estimated using acceleration sensor-systems fixed on a person's body. By means of pattern recognition methods, it is possible to identify with certain accuracy which movement is being performed. This work presents a comparison of different methods for recognition of daily-life activities, which will serve as basis for the development of an online activity monitoring system.},
  Doi                      = {10.1109/IEMBS.2008.4650398},
  ISSN                     = {1557-170X},
  Keywords                 = {Acceleration;Accelerometers;Biomedical monitoring;Electrocardiography;Frequency measurement;Information processing;Medical treatment;Patient monitoring;Pattern recognition;Sensor phenomena and characterization;Algorithms;Artificial Intelligence;Humans;Monitoring, Ambulatory;Motor Activity;Movement;Pattern Recognition, Automated;Remote Consultation;Telemetry},
  Review                   = {Activity recognition. Accelerometer and classifiers.},
  Timestamp                = {2014.12.21}
}

@InBook{Jenkins2007,
  Title                    = {Proceedings of the International Conference on Pervasive Computing},
  Author                   = {Jenkins, J. and Ellis, C.},
  Chapter                  = {Using Ground Reaction Forces from Gait Analysis: Body Mass as a Weak Biometric},
  Editor                   = {LaMarca, A. and Langheinrich, M. and Truong, K. N.},
  Pages                    = {251--267},
  Publisher                = {Springer Berlin Heidelberg},
  Year                     = {2007},

  Doi                      = {10.1007/978-3-540-72037-9_15},
  ISBN                     = {978-3-540-72037-9},
  Timestamp                = {2016.03.01}
}

@Article{Jenkins2004,
  Title                    = {PERFORMANCE-DERIVED BEHAVIOR VOCABULARIES: DATA-DRIVEN ACQUISITION OF SKILLS FROM MOTION},
  Author                   = {Jenkins, O. C. and Matari\'{c}, M. J.},
  Journal                  = {International Journal of Humanoid Robotics},
  Year                     = {2004},
  Number                   = {02},
  Pages                    = {237-288},
  Volume                   = {01},

  Doi                      = {10.1142/S0219843604000186},
  Eprint                   = {http://www.worldscientific.com/doi/pdf/10.1142/S0219843604000186},
  Timestamp                = {2014.12.20},
  Url                      = {http://www.worldscientific.com/doi/abs/10.1142/S0219843604000186}
}

@InProceedings{Jenkins2002,
  author    = {Jenkins, O. C. and Mataric, M.},
  title     = {Deriving Action and Behavior Primitives from Human Motion Data},
  booktitle = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year      = {2002},
  volume    = {3},
  pages     = {2551--2556},
  groups    = {Lit Review 2013-09},
  review    = {Use ISOMAP:
1) Building spatially local neighbourhoods
2) Compute shortest distances between all pairs
3) Perform PCA using D

Extend ISOMAP so that it includes temporal informatin as well. Weighting is added to neighbours that are temporally close. Action units are created and identified by bounding box clustering method. Action units are connected together and filled in by interpolation to form primitives. This procedure can be repeated to get a higher level of behavour embedding. Algorithm used for imitiation learned and a robot reproduced the motion.

Jenkins and Matari\'{c} \cite{Jenkins2002, Jenkins2003} perform segmentation by calculating the distance from a given data frame's Cartesian centroid of a given DOF to all the subsequent frames, and segmenting on the first local maximum, and iterating. To improve scalability, the spatial data is first dimensionally reduced with Isomap, then segmented. labelling is obtained by \emph{k}-NN.},
  timestamp = {2013.10.08},
}

@InProceedings{Jenkins2003,
  author    = {Jenkins, O. C. and Mataric, M. J.},
  title     = {Automated Derivation of Behavior Vocabularies for Autonomous Humanoid Motion},
  booktitle = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems},
  year      = {2003},
  pages     = {225--232},
  abstract  = {In this paper we address the problem of automatically deriving vocabularies of motion modules from human motion
data, taking advantage of the underlying spatio-temporal
structure in motion. We approach this problem with a
data-driven methodology for modularizing a motion stream
(or time-series of human motion) into a vocabulary of parameterized primitive motion modules and a set of metalevel behaviors characterizing extended combinations of the
primitives. Central to this methodology is the discovery of
spatio-temporal structure in a motion stream. We estimate
this structure by extending an existing nonlinear dimension
reduction technique, Isomap, to handle motion data with
spatial and temporal dependencies. The motion vocabularies derived by our methodology provide a substrate of autonomous behavior and can be used in a variety of applications. We demonstrate the utility of derived vocabularies for
the application of synthesizing new humanoid motion that
is structurally similar to the original demonstrated motion.},
  acmid     = {860612},
  doi       = {10.1145/860575.860612},
  groups    = {Lit Review 2013-09},
  isbn      = {1-58113-683-8},
  keywords  = {autonomous humanoid agents, humanoid robotics, kinematic motion segmentation, motion primitives, motion vocabularies, spectral dimension reduction},
  location  = {Melbourne, Australia},
  numpages  = {8},
  review    = {Want to auto-label human movement data. Uses spatial isomap.

Spatial isomap
1) bin spatial points together ("determine a local neighbourhood of nearby points") via k-nn
(don't quite follow the details here)
- basically, want to create a distance matrix D between data points and some neighbouring point
- this allows the isomap to be performed on this feature space similarity matrix D instead of some input space covariance matrix C (as is the case for PCA)
 - similar idea to Kernal PCA, where we only need the dot product to compute our similarity, as oppose to converting the entire input data space
 - they add temporal information by taking the Euclidean distance and warping the D matrix based on temporal neighbours
 - they like it because PCA only rotates the data, whereas isomap seems to do it more intelligently

After isomap warping, the segmentation is done by greedy algorithm:
1. current segment is the first frame
2. calculate distance between centroid from the current segment boundary (so t-1 frame) to every subsequent frame
3. pick first local maximum in centroid distance function

(so not online I guess) - results not reported



Jenkins and Matari\'{c} \cite{Jenkins2002, Jenkins2003} segments by performed by calculating the distance from the first frame's Cartesian centroid of a given DOF to all the subseqent frames, and segmenting on the first local maximum. Labeling and learning is done by performing dimensionality reduction using spatial Isomap by binning spatial data points together via \emph{k}-NN, computing the shortest distance between all point pairs using Dijkstra's algorithm, then preforming PCA. Although Isomap and PCA have the same general steps, Isomap is performed in the feature space, which is a higher dimensional space when compared to the input space, allowing for non-linearity in the input space. PCA works optimally if the input data is linear, or near linear. making Isomap a more flexible algorithm. Temporal information is accounted for by adding temporal-based weights to the distance metric. Similar activities are combined together by sweep-and-prune clustering. The focus of these paper is movement learning, and not segmentation, so no segmentation accuracy was reported.},
  timestamp = {2013.09.30},
}

@InProceedings{Jimenez-Mixco2013,
  Title                    = {Feasibility of a Wireless Health Monitoring System for Prevention and Health Assessment of Elderly People},
  Author                   = {Jimenez-Mixco, V. and Cabrera-Umpierrez, M. F. and Arredondo, M. T. and Maria Panou, F. A. and Struck, M. and Bonfiglio, S.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {The work presented in this paper comprises the methodology and results of a pilot study on the feasibility of a wireless health monitoring system designed under main EU challenges for the promotion of healthy and active ageing. The system is focused on health assessment, prevention and lifestyle promotion of elderly people. Over a hundred participants including elderly users and caregivers tested the system in four pilot sites across Europe. Tests covered several scenarios in senior centers and real home environments, including performance and usability assessment. Results indicated strong satisfactoriness on usability, usefulness and user friendliness, and the acceptable level of reliability obtained supports future investigation on the same direction for further improvement and transfer of conclusions to the real world in the healthcare delivery.},
  Keywords                 = {EMBC2013},
  Review                   = {Collect various different data from seniors: Sp02, glucose, BP, ECG, weight, activity lvl. 

Application is intended to be used by the senior, on a tablet PC. Provides coaching information, sensor results, and methods to contact the GP, as well as panic buttons.},
  Timestamp                = {2013.08.03}
}

@InProceedings{Joukov2015,
  Title                    = {Rhythmic EKF for pose estimation during gait},
  Author                   = {V. Joukov and V. Bonnet and M. Karg and G. Venture and D. Kuli\'{c}},
  Booktitle                = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  Year                     = {2015},
  Pages                    = {1167--1172},

  Doi                      = {10.1109/HUMANOIDS.2015.7363510},
  Keywords                 = {Kalman filters;legged locomotion;nonlinear filters;pose estimation;prosthetics;3 dimensional rhythmic lower body movement;active prosthetics;bipedal walking strategies;canonical dynamical system;exoskeletons;extended Kalman filter;human walking data;inertial measurement units;joint angles;joint kinematics;physical rehabilitation;pose estimation;rhythmic EKF;rhythmic motion;Acceleration;Accelerometers;Angular velocity;Kalman filters;Kinematics;Legged locomotion;Robot sensing systems},
  Timestamp                = {2017.03.01}
}

@InProceedings{Joukov2014_EMBC,
  Title                    = {Online Tracking of the Lower Body Joint Angles using {IMUs} for Gait Rehabilitation},
  Author                   = {Joukov, V. AND Karg, M. E. AND Kuli\'{c}, D.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2014},
  Pages                    = {2310--2313},

  Timestamp                = {2014.07.25}
}

@Article{Jovanov2005,
  Title                    = {A wireless body area network of intelligent motion sensors for computer assisted physical rehabilitation},
  Author                   = {Jovanov, E. and Milenkovic, A. and Otto, C. and de Groen, P.},
  Journal                  = {Journal of NeuroEngineering and Rehabilitation},
  Year                     = {2005},
  Number                   = {1},
  Pages                    = {6},
  Volume                   = {2},

  Abstract                 = {BACKGROUND:Recent technological advances in integrated circuits, wireless communications, and physiological sensing allow miniature, lightweight, ultra-low power, intelligent monitoring devices. A number of these devices can be integrated into a Wireless Body Area Network (WBAN), a new enabling technology for health monitoring.
METHODS:Using off-the-shelf wireless sensors we designed a prototype WBAN which features a standard ZigBee compliant radio and a common set of physiological, kinetic, and environmental sensors.
RESULTS:We introduce a multi-tier telemedicine system and describe how we optimized our prototype WBAN implementation for computer-assisted physical rehabilitation applications and ambulatory monitoring. The system performs real-time analysis of sensors' data, provides guidance and feedback to the user, and can generate warnings based on the user's state, level of activity, and environmental conditions. In addition, all recorded information can be transferred to medical servers via the Internet and seamlessly integrated into the user's electronic medical record and research databases.
CONCLUSION:WBANs promise inexpensive, unobtrusive, and unsupervised ambulatory monitoring during normal daily activities for prolonged periods of time. To make this technology ubiquitous and affordable, a number of challenging issues should be resolved, such as system design, configuration and customization, seamless integration, standardization, further utilization of common off-the-shelf components, security and privacy, and social issues.},
  Doi                      = {10.1186/1743-0003-2-6},
  ISSN                     = {1743-0003},
  Keywords                 = {Postural detection},
  Pubmedid                 = {15740621},
  Review                   = {- Don't want to use bluetooth and such: expensive and sophesticated
- Rehab sessions don't tend to last that long...30 min, twice a week. Need something that can follow the patient around and do more with rehab -> more biofeedback for rehab purposes
- Also serves as a monitor device. Uses a nearby PDA as a personal server
- Uses Zigbee, jams a whole lot of sensors onto a person
- Didn't notice it saying anything about how well it worked though},
  Timestamp                = {2010.09.29}
}

@Article{Jurman2007,
  Title                    = {Calibration and data fusion solution for the miniature attitude and heading reference system},
  Author                   = {David Jurman and Marko Jankovec and Roman Kamnik and Marko Topic},
  Journal                  = {Sensors and Actuators A: Physical},
  Year                     = {2007},
  Number                   = {2},
  Pages                    = {411--420},
  Volume                   = {138},

  Abstract                 = {Development, calibration and alignment of a miniature magnetic and inertial measurement unit, which is used as an attitude and heading reference system, are presented. Several guidelines were followed during the design process to make the magnetic and inertial measurement unit suitable for various kinds of applications, thus the system is designed both as small as possible but still modular, consisting of three inertial sensor units, a magnetic sensor unit and a control unit. Complete calibration and alignment procedure is described and an adaptive Kalman filter concept for fusing various sensors' attitude and heading data is introduced and discussed. The characteristics of the magnetic and inertial measurement unit as an attitude and heading reference system are evaluated. The algorithm showed remarkable performance in the orientation determination as the average root mean square error was less than 1.2 degrees over the entire appliable operating range.},
  Doi                      = {DOI: 10.1016/j.sna.2007.05.008},
  ISSN                     = {0924-4247},
  Keywords                 = {Inertial measurement unit, electronic compass, sensor calibration, data fusion, kalman filter},
  Review                   = {- Euler angles and KF
- mentions that we need to calc gyro bias very often
- seems to suggest that we can do this by hand, without extra equipment
 - need to rotate at a "known constant angular rate", but later on says "no knowledge about the angular velocity is needed...however, the angle of rotation needs to be known"},
  Timestamp                = {2011.07.19}
}

@InProceedings{Justino2001,
  Title                    = {Off-line signature verification using HMM for random, simple and skilled forgeries},
  Author                   = {Justino, E. J. R. and Bortolozzi, F. and Sabourin, R.},
  Booktitle                = {Proceedings of the 6th International Conference on Document Analysis and Recognition},
  Year                     = {2001},
  Pages                    = {1031--1034},

  Abstract                 = {The problem of signature verification is in theory a pattern recognition task used to discriminate two classes, original and forgery signatures. Even after many efforts in order to develop new verification techniques for static signature verification, the influence of the forgery types has not been extensively studied. This paper reports the contribution to signature verification considering different forgery types in an HMM framework. The experiments have shown that the error rates of the simple and random forgery signatures are very closed. This reflects the real applications in which the simple forgeries represent the principal fraudulent case. In addition, the experiments show promising results in skilled forgery verification by using simple static and pseudodynamic features},
  Doi                      = {10.1109/ICDAR.2001.953942},
  Keywords                 = {HMM framework;forgery;original signatures;pattern recognition;signature verification;skilled forgery verification;handwriting recognition;hidden Markov models;},
  Timestamp                = {2011.06.09}
}

@Article{Kadaba1990,
  Title                    = {Measurement of lower extremity kinematics during level walking},
  Author                   = {Kadaba, M. P. and Ramakrishnan, H. K. and Wootten, M. E.},
  Journal                  = {Journal of Orthopaedic Research},
  Year                     = {1990},
  Number                   = {3},
  Pages                    = {383--392},
  Volume                   = {8},

  Abstract                 = {Abstract A simple external marker system and algorithms for computing lower extremity joint angle motion during level walking were developed and implemented on a computer-aided video motion analysis system (VICON). The concept of embedded axes and Euler rotation angles was used to define the three-dimensional joint angle motion based on a set of body surface markers. Gait analysis was peformed on 40 normal young adults three times on three different test days at least 1 Week apart using the marker system. Angular motion of the hip, knee, and ankle joints and of the pelvis were obtained throughout a gait cycle utilizing the three-dimensional trajectories of markers. The effect of uncertainties in defining the embedded axis on joint angles was demonstrated using sensitivity analysis. The errors in the estimation of joint angle motion were quantified with respect to the degree of error in the construction of embedded axes. The limitations of the model and the marker system in evaluating pathologic gait are discussed. The relatively small number of body surface markers used in the system render it easy to implement for use in routine clinical gait evaluations. Additionally, data presented in this paper should be a useful reference for describing and comparing pathologic gait patterns.},
  Doi                      = {10.1002/jor.1100080310},
  ISSN                     = {1554-527X},
  Keywords                 = {Joint angles, Gait parameters, Biomechanical model, Sensitivity analysis, Helen Hayes marker},
  Timestamp                = {2011.07.18},
  Url                      = {http://dx.doi.org/10.1002/jor.1100080310}
}

@InProceedings{Kadone2005,
  Title                    = {Symbolic memory for humanoid robots using hierarchical bifurcations of attractors in nonmonotonic neural networks},
  Author                   = {Kadone, H. and Nakamura, Y.},
  Booktitle                = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2005},
  Pages                    = { 3548 - 3553},

  Abstract                 = {Bifurcations of attractors take place in associative neural networks with nonmonotonic activation functions, depending on the degree of correlations between stored patterns and the parameter of nonmonotonicity. We describe the bifurcations when auto-correlation based feature vectors of motion patterns of humanoid robots, which are hierarchically correlated, are stored. Also, we describe a memory system which utilizes the neural network dynamics and hierarchically maintains specific and conceptual memories of motions of humanoid robots. The level of abstraction is controlled by a parameter in the retrieval phase without changing the connection weights.h},
  Doi                      = {10.1109/IROS.2005.1545416},
  Keywords                 = {associative neural networks; autocorrelation based feature vectors; dynamical systems; hierarchical attractor bifurcation; humanoid robots; symbol emergence; symbolic memory; content-addressable storage; humanoid robots; neural nets; motion primitive},
  Timestamp                = {2011.01.07}
}

@InProceedings{Kahn2006,
  Title                    = {What is a Human? - Toward Psychological Benchmarks in the Field of Human-Robot Interaction},
  Author                   = {Kahn, P. H. and Ishiguro, H. and Friedman, B. and Kanda, T.},
  Booktitle                = {Proceedings of the 15th IEEE International Symposium on Robot and Human Interactive Communication},
  Year                     = {2006},
  Pages                    = {364 -371},

  Abstract                 = {In this paper, we move toward offering psychological benchmarks by which to measure success in building increasingly human-like robots. By psychological benchmarks we mean categories of interaction that capture conceptually fundamental aspects of human life, specified abstractly enough so as to resist their identity as a mere psychological instrument, but capable of being translated into testable empirical propositions. Six possible benchmarks are considered: autonomy, imitation, intrinsic moral value, moral accountability, privacy, and reciprocity. Finally, we discuss how getting the right group of benchmarks in human-robot interaction will, in future years, help inform on the foundational question of what constitutes essential features of being human},
  Doi                      = {10.1109/ROMAN.2006.314461},
  Keywords                 = {human-robot interaction;psychological benchmarks;testable empirical propositions;man-machine systems;psychology;robots; Human-robot interaction},
  Review                   = {- how do we measure the sucess of building a humanoid robot? this paper comes up with 6 criteria, based in psych theories

- autonomy
 - are humans autonomous? or are the things we know a result of our genes?
- imitation
 - is imitation passive? or is it learned activity?
 - Turing test
- intrinsic moral value
- moral accountability
 - should the humanoid be held to a moral standard?
- privacy
 - how would humanoids process private data of people?
- reciprocity
 - should the Golden rule be applied to them?},
  Timestamp                = {2011.02.09}
}

@InProceedings{Kaiser1990,
  Title                    = {On a simple algorithm to calculate the `energy' of a signal},
  Author                   = {Kaiser, J. F.},
  Booktitle                = {International Conference on Acoustics, Speech, and Signal Processing},
  Year                     = {1990},
  Pages                    = {381--384},
  Volume                   = {1},

  Doi                      = {10.1109/ICASSP.1990.115702},
  ISSN                     = {1520-6149},
  Keywords                 = {speech analysis and processing;invariance;noise properties;on-the-fly calculation;simple harmonic motion;speech processing;Algorithm design and analysis;Equations;Frequency;Oscillators;Signal analysis;Signal generators;Signal processing;Signal processing algorithms;Speech enhancement;Speech processing;Springs},
  Timestamp                = {2015.05.11}
}

@InProceedings{Kajita2003,
  Title                    = {Biped walking pattern generation by using preview control of zero-moment point},
  Author                   = {Kajita, S. and Kanehiro, F. and Kaneko, K. and Fujiwara, K. and Harada, K. and Yokoi, K. and Hirukawa, H.},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2003},
  Pages                    = {1620--1626},
  Volume                   = {2},

  Abstract                 = {We introduce a new method <span class='snippet'>of</span> a <span class='snippet'>biped</span> <span class='snippet'>walking</span> <span class='snippet'>pattern</span> <span class='snippet'>generation</span> <span class='snippet'>by</span> <span class='snippet'>using</span> a <span class='snippet'>preview</span> <span class='snippet'>control</span> <span class='snippet'>of</span> the <span class='snippet'>zero</span>-<span class='snippet'>moment</span> point (ZMP). First, the dynamics <span class='snippet'>of</span> a <span class='snippet'>biped</span> robot is modeled as a running cart on a table which gives a convenient representation to treat ZMP. After reviewing conventional methods <span class='snippet'>of</span> ZMP based <span class='snippet'>pattern</span> <span class='snippet'>generation</span>, we formalize the problem as the design <span class='snippet'>of</span> a ZMP tracking servo controller. It is shown that we can realize such controller <span class='snippet'>by</span> adopting the <span class='snippet'>preview</span> <span class='snippet'>control</span> theory that <span class='snippet'>uses</span> the future reference. It is also shown that a <span class='snippet'>preview</span> controller can be <span class='snippet'>used</span> to compensate the ZMP error caused <span class='snippet'>by</span> the difference between a simple model and the precise multibody model. The effectiveness <span class='snippet'>of</span> the proposed method is demonstrated <span class='snippet'>by</span> a simulation <span class='snippet'>of</span> <span class='snippet'>walking</span> on spiral stairs.},
  Doi                      = {10.1109/ROBOT.2003.1241826},
  Keywords                 = {ECE780, Gait and Trajectory},
  Timestamp                = {2011.02.04}
}

@InProceedings{Kajita2001,
  Title                    = {The 3D linear inverted pendulum mode: a simple modeling for a biped walking pattern generation},
  Author                   = {Kajita, S. and Kanehiro, F. and Kaneko, K. and Yokoi, K. and Hirukawa, H.},
  Booktitle                = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2001},
  Pages                    = {239 -246 vol.1},
  Volume                   = {1},

  Abstract                 = {For 3D walking control of a biped robot we analyze the dynamics of a 3D inverted pendulum in which motion is constrained to move along an arbitrarily defined plane. This analysis yields a simple linear dynamics, the 3D linear inverted pendulum mode (3D-LIPM). Geometric nature of trajectories under the 3D-LIPM and a method for walking pattern generation are discussed. A simulation result of a walking control using a 12-DOF biped robot model is also shown},
  Doi                      = {10.1109/IROS.2001.973365},
  Keywords                 = {12-DOF biped robot model;3D linear inverted pendulum dynamics;3D walking control;3D-LIPM;biped walking pattern generation;linear dynamics;legged locomotion;linear systems;nonlinear control systems;pendulums;robot dynamics; lab reading (Safwan)},
  Review                   = {novel: constraint plane and eq14-15 to linearlize and decouple eqn8/9
reviewer: random plantary motion reference},
  Timestamp                = {2011.02.28}
}

@InProceedings{Kalakrishnan2011,
  Title                    = {STOMP: Stochastic trajectory optimization for motion planning},
  Author                   = {M. Kalakrishnan and S. Chitta and E. Theodorou and P. Pastor and S. Schaal},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2011},
  Pages                    = {4569--4574},

  Abstract                 = {We present a new approach to motion planning using a stochastic trajectory optimization framework. The approach relies on generating noisy trajectories to explore the space around an initial (possibly infeasible) trajectory, which are then combined to produced an updated trajectory with lower cost. A cost function based on a combination of obstacle and smoothness cost is optimized in each iteration. No gradient information is required for the particular optimization algorithm that we use and so general costs for which derivatives may not be available (e.g. costs corresponding to constraints and motor torques) can be included in the cost function. We demonstrate the approach both in simulation and on a mobile manipulation system for unconstrained and constrained tasks. We experimentally show that the stochastic nature of STOMP allows it to overcome local minima that gradient-based methods like CHOMP can get stuck in.},
  Doi                      = {10.1109/ICRA.2011.5980280},
  ISSN                     = {1050-4729},
  Keywords                 = {collision avoidance;end effectors;mobile robots;optimisation;stochastic processes;STOMP;collision avoidance;cost function;end-effector;mobile manipulation system;stochastic trajectory optimization for motion planning;Acceleration;Cost function;Noise measurement;Optimal control;Planning;Trajectory},
  Timestamp                = {2017.03.01}
}

@Article{Kalman1960,
  Title                    = {A New Approach to Linear Filtering and Prediction Problems},
  Author                   = {Kalman, R. E.},
  Journal                  = {Journal of Basic Engineering},
  Year                     = {1960},
  Pages                    = {35--45},
  Volume                   = {82},

  Timestamp                = {2012.06.25}
}

@Article{Kanda2007,
  Title                    = {A two-month field trial in an elementary school for long-term human–robot interaction},
  Author                   = {Kanda, T. and Sato, R. and Saiwaki, N. and Ishiguro, H.},
  Journal                  = {IEEE Transactions on Robotics},
  Year                     = {2007},
  Number                   = {5},
  Pages                    = {962 -971},
  Volume                   = {23},

  Abstract                 = {Interactive robots participating in our daily lives should have the fundamental ability to socially communicate with humans. In this paper, we propose a mechanism for two social communication abilities: forming long-term relationships and estimating friendly relationships among people. The mechanism for long-term relationships is based on three principles of behavior design. The robot we developed, Robovie, is able to interact with children in the same way as children do. Moreover, the mechanism is designed for long-term interaction along the following three design principles: (1) it calls children by name using radio frequency identification tags; (2) it adapts its interactive behaviors for each child based on a pseudo development mechanism; and (3) it confides its personal matters to the children who have interacted with the robot for an extended period of time. Regarding the estimation of friendly relationships, the robot assumes that people who spontaneously behave as a group together are friends. Then, by identifying each person in the interacting group around the robot, it estimates the relationships between them. We conducted a two-month field trial at an elementary school. An interactive humanoid robot, Robovie, was placed in a classroom at the school. The results of the field trial revealed that the robot successfully continued interacting with many children for two months, and seemed to have established friendly relationships with them. In addition, it demonstrated reasonable performance in identifying friendships among children. We believe that these results demonstrate the potential of current interactive robots to establish social relationships with humans in our daily lives.},
  Doi                      = {10.1109/TRO.2007.904904},
  ISSN                     = {1552-3098},
  Keywords                 = {Robovie interactive humanoid robot;behavior design;elementary school;long-term human-robot interaction;pseudo development mechanism;radio frequency identification tag;social communication ability;humanoid robots;interactive systems;man-machine systems;radiofrequency identification;social aspects of automation; Human-robot interaction; ECE780},
  Review                   = {Stuck a robot into a elementary school. Most kids were initially interested, but lost interest after time. 

Kids likes hugs and when the robot called its name. It recognized kids via RFID in name tags, and changed behaviour based on length of interaction.},
  Timestamp                = {2011.02.09}
}

@Article{Kang1995,
  Title                    = {Toward automatic robot instruction from perception-temporal segmentation of tasks from human hand motion},
  Author                   = {Kang, S. B. and Ikeuchi, K.},
  Journal                  = {IEEE Transactions on Robotics and Automation},
  Year                     = {1995},
  Pages                    = {670--681},
  Volume                   = {11},

  Abstract                 = {This paper describes work on the temporal segmentation of grasping task sequences based on human hand motion. The segmentation process results in the identification of motion breakpoints separating the different constituent phases of the grasping task. A grasping task is composed of three basic phases: pregrasp phase, static grasp phase, and manipulation phase. We show that by analyzing the fingertip polygon area (which is an indication of the hand preshape) and the speed of hand movement (which is an indication of the hand transportation), we can divide a task into meaningful action segments such as approach object (which corresponds to the pregrasp phase), grasp object, manipulate object, place object, and depart (a special case of the pregrasp phase which signals the termination of the task). We introduce a measure called the volume sweep rate, which is the product of the fingertip polygon area and the hand speed. The profile of this measure is also used in the determination of the task breakpoints},
  Doi                      = {10.1109/70.466599},
  ISSN                     = {1042-296X},
  Keywords                 = {computational geometry;learning (artificial intelligence);path planning;robot programming;automatic robot instruction;fingertip polygon;grasping task sequences;hand movement;human hand motion;manipulation phase;motion breakpoint identification;perception;pregrasp phase;static grasp phase;temporal task segmentation;volume sweep rate;Anthropometry;Automatic programming;Education;Educational robots;Grasping;Humans;Orbital robotics;Robot programming;Robotics and automation;Virtual reality},
  Review                   = {- divide up grasp motion into three phase: pregrasp (trajectory, hand shape), grasp (hand contacts the object), manipulation (moving the object). does this by looking at the finger end effector positions and hand speed. They calculate the fingertip polygon (polygon drawn out by the fingers), and the volume sweep rate (the polygon at t and t+dt, and the vol between the two polygons). 
- segment on VSR curve fitting and hand speed turning points (thresholds and hieristics)

- no segment accuracy},
  Timestamp                = {2014.12.20}
}

@InProceedings{Kapp2010,
  Title                    = {Adaptive Incremental Learning with an Ensemble of Support Vector Machines},
  Author                   = {Kapp, M. N. and Sabourin, R. and Maupin, P.},
  Booktitle                = {International Conference on Pattern Recognition},
  Year                     = {2010},
  Pages                    = {4048--4051},

  Abstract                 = {The incremental updating of classifiers implies that their internal parameter values can vary according to incoming data. As a result, in order to achieve high performance, incremental learner systems should not only consider the integration of knowledge from new data, but also maintain an optimum set of parameters. In this paper, we propose an approach for performing incremental learning in an adaptive fashion with an ensemble of support vector machines. The key idea is to track, evolve, and combine optimum hypotheses over time, based on dynamic optimization processes and ensemble selection. From experimental results, we demonstrate that the proposed strategy is promising, since it outperforms a single classifier variant of the proposed approach and other classification methods often used for incremental learning.},
  Doi                      = {10.1109/ICPR.2010.984},
  ISSN                     = {1051-4651},
  Keywords                 = {learning (artificial intelligence);optimisation;support vector machines;adaptive incremental learning;dynamic optimization process;ensemble selection;support vector machine;Adaptation model;Data models;Databases;Heuristic algorithms;Optimization;Support vector machines;Training;Dynamic Particle Swarm Optimization;Ensemble of Classifiers;Support Vector Machines},
  Timestamp                = {2014.11.14}
}

@InProceedings{Karasawa2013,
  Title                    = {A Trial of Making Reference Gait Data for Simple Gait Evaluation System with Wireless Inertial Sensors},
  Author                   = {Karasawa, Y. and Teruyama, Y. and Watanabe, T.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {Recently, the use of wearable inertial sensors have been widely studied in the field of human movement analysis. Our research group developed a wearable motion measurement system using the wireless inertial sensors for rehabilitation training and daily exercise. However, there are few reference data to evaluate motor function. In this paper, reference data of joint and inclination angles of lower limb and that of gait event timing for gait evaluation were made by measurement with 4 healthy subjects in their twenties. Average values of inclination and joint angles and gait event timings were similar to those seen in literature. These suggest that the averaged data obtained in this paper can be used as reference data. Then, gait data of a healthy subject in his thirties were compared with the reference data. Most of angles and all the gait event timings were considered to be standard of 20’s. However, some angles of the healthy subject in his thirties were considered not to be the standard partly. These differences in evaluation were considered to depend on a level of similarity of movement to the reference data. It was expected to evaluate the level of similarity of movement from various parameters.},
  Keywords                 = {EMBC2013},
  Review                   = {Accel/gyro on feet, shank and thighs of both legs, and lumbar region (7 in total). 100 Hz. 4 healthy male, 15m of walking, 6 trials per subj. Want to create reference gait data. Joint angles obtained by KF (see their previous work). Also calculated foot flat, heel off, toe off, and heel contact, by thresholding.},
  Timestamp                = {2013.08.06}
}

@Article{Karg2010_SMC,
  Title                    = {Recognition of Affect Based on Gait Patterns},
  Author                   = {Karg, M. and Kuhnlenz, K. and Buss, M.},
  Journal                  = {IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics},
  Year                     = {2010},
  Number                   = {4},
  Pages                    = {1050--1061},
  Volume                   = {40},

  Abstract                 = {To provide a means for recognition of affect from a distance, this paper analyzes the capability of gait to reveal a person's affective state. We address interindividual versus person-dependent recognition, recognition based on discrete affective states versus recognition based on affective dimensions, and efficient feature extraction with respect to affect. Principal component analysis (PCA), kernel PCA, linear discriminant analysis, and general discriminant analysis are compared to either reduce temporal information in gait or extract relevant features for classification. Although expression of affect in gait is covered by the primary task of locomotion, person-dependent recognition of motion capture data reaches 95% accuracy based on the observation of a single stride. In particular, different levels of arousal and dominance are suitable for being recognized in gait. It is concluded that gait can be used as an additional modality for the recognition of affect. Application scenarios include monitoring in high-security areas, human-robot interaction, and cognitive home environments.},
  Doi                      = {10.1109/TSMCB.2010.2044040},
  ISSN                     = {1083-4419},
  Keywords                 = {feature extraction;gait analysis;motion estimation;pattern classification;principal component analysis;PCA;discrete affective state;feature extraction;linear discriminant analysis;motion capture data;person-dependent recognition;principal component analysis;temporal information;Affective computing;feature extraction;gait recognition;human motion analysis;pattern classification;Affect;Algorithms;Artificial Intelligence;Biometry;Gait;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Pattern Recognition, Automated;Photography;Reproducibility of Results;Sensitivity and Specificity;Video Recording},
  Timestamp                = {2014.08.02}
}

@Article{Karg2015,
  Title                    = {Clinical Gait Analysis: Comparing Explicit State Duration {HMMs} Using a Reference-Based Index},
  Author                   = {Karg, M. and Seiberl, W. and Kreuzpointner, F. and Haas, J.-P. and Kulic, D.},
  Journal                  = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  Year                     = {2015},
  Pages                    = {319--331},
  Volume                   = {23},

  Abstract                 = {In clinical gait analysis, the gait of a patient is recorded with optical motion capture and compared with a healthy reference group. High-dimensional gait datasets are difficult to interpret; machine learning can provide guidance regarding the most relevant gait phases and joint angles for visual analysis and quantify the difference between healthy and pathological gait. We propose an explicit state duration hidden Markov model (HMM) modeling the timeseries data of a subject or a group and the use of a reference-based measure that compares the most likely observations in each state. Based on this stochastic framework, the similarity between healthy and pathological gait can be quantified for each state, each joint angle, and each subject. This concept also includes an overall gait index useful for group comparison or the assessment of an individual's gait. For visualization, joint angle timeseries can be generated from the explicit state duration HMM. The accuracy of the explicit state duration HMM and the performance of the reference-based measures are evaluated on a dataset including strides of healthy subjects and patients suffering from arthritis.},
  Doi                      = {10.1109/TNSRE.2014.2362862},
  ISSN                     = {1534-4320},
  Keywords                 = {diseases;gait analysis;hidden Markov models;learning (artificial intelligence);medical diagnostic computing;stochastic processes;time series;HMM;arthritis;clinical gait analysis;explicit state duration;healthy reference group;joint angle timeseries;optical motion capture;reference-based index;stochastic framework;Data models;Hidden Markov models;Indexes;Joints;Pathology;Vectors;Visualization;Motion analysis;statistical analysis},
  Timestamp                = {2015.07.17}
}

@Article{Karg2014_TNSRE,
  Title                    = {Human Movement Analysis as a Measure for Fatigue: A Hidden Markov-Based Approach},
  Author                   = {Karg, M. and Venture, G. and Hoey, J. and Kuli\'{c}, D.},
  Journal                  = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  Year                     = {2014},
  Number                   = {3},
  Pages                    = {470--481},
  Volume                   = {22},

  Abstract                 = {Fatigue influences the way a training exercise is performed and alters the kinematics of the movement. Monitoring the increase of fatigue during rehabilitation and sport exercises is beneficial to avoid the risk of injuries. This study investigates the use of a parametric hidden Markov model (PHMM) to estimate fatigue from observing kinematic changes in the way the exercise is performed. The PHMM is compared to linear regression. A top-level hidden Markov model with variable state transitions incorporates knowledge about the progress of fatigue during the exercise and the initial condition of a subject. The approach is tested on a squat database recorded with optical motion capture. The estimates of fatigue for a single squat, a set of squats, and an entire exercise correlate highly with subjective ratings.},
  Doi                      = {10.1109/TNSRE.2013.2291327},
  ISSN                     = {1534-4320},
  Keywords                 = {hidden Markov models;kinematics;patient monitoring;patient rehabilitation;sport;PHMM;fatigue measurement;human movement analysis;kinematics;optical motion capture;parametric hidden Markov model;patient monitoring;patient rehabilitation;single squat database;sport exercises;training exercise;Fatigue;Hidden Markov models;Joints;Kinematics;Linear regression;Muscles;Training;Fatigue;linear regression;parametric hidden Markov model},
  Timestamp                = {2014.09.30}
}

@Article{Kasteren2010,
  Title                    = {An activity monitoring system for elderly care using generative and discriminative models},
  Author                   = {van Kasteren, T.L.M. and Englebienne, G. and Kröse, B.J.A.},
  Journal                  = {Personal and Ubiquitous Computing},
  Year                     = {2010},
  Number                   = {6},
  Pages                    = {489-498},
  Volume                   = {14},

  Doi                      = {10.1007/s00779-009-0277-9},
  ISSN                     = {1617-4909},
  Keywords                 = {Activity recognition; Machine learning; Wireless sensor networks},
  Language                 = {English},
  Publisher                = {Springer-Verlag},
  Timestamp                = {2014.12.21},
  Url                      = {http://dx.doi.org/10.1007/s00779-009-0277-9}
}

@InProceedings{Kaur2009,
  Title                    = {Comparison of the techniques used for segmentation of {EMG} signals},
  Author                   = {Kaur, G. and Arora, A. and Jain, V.},
  Booktitle                = {Proceedings of the WSEAS International Conference on Mathematical and Computational Methods in Science and Engineering},
  Year                     = {2009},
  Pages                    = {124--129},

  Owner                    = {jf2lin},
  Review                   = {Use EMG. want to locate instances of action potentials (primitive). no temporal acc reported.},
  Timestamp                = {2015.04.24}
}

@InProceedings{Kawano2007,
  Title                    = {Analyzing 3D Knee Kinematics Using Accelerometers, Gyroscopes and Magnetometers},
  Author                   = {Kawano, K. and Kobashi, S. and Yagi, M. and Kondo, K. and Yoshiya, S. and Hata, Y.},
  Booktitle                = {IEEE International Conference on System of Systems Engineering},
  Year                     = {2007},
  Pages                    = {1-6},

  Abstract                 = {Knee kinematics has been investigated to diagnose subjects with injured anterior cruciate ligament (ACL). Dejnabadi et al. presented a kinematics analysis method using accelerometers and gyroscopes. Although it can analyze the knee kinematics without accumulation of errors, it estimates only knee flexion/extension angle. Thus, this paper proposed a new method that can estimate all knee joint angles, flexion/extension, internal/external rotation, and varus/valgus angles. It is enabled by introducing earth magnetisms into Dejnabadi's method. The proposed method was validated by applying the proposed method a subject. And, the estimated angles were numerically evaluated by comparing the results with optical motion system.},
  Doi                      = {10.1109/SYSOSE.2007.4304332},
  Keywords                 = {accelerometers;biomedical measurement;biomedical transducers;gait analysis;gyroscopes;magnetometers;3D knee kinematic;Dejnabadi method;accelerometer;anterior cruciate ligament;earth magnetism;gait analysis;gyroscope;magnetometer;varus/valgus angle;Accelerometers;Gyroscopes;Kinematics;Knee;Ligaments;Magnetic analysis;Magnetic sensors;Magnetometers;Optical sensors;X-ray imaging;3-D knee kinematics;ACL reconstruction;accelerometer;gait analysis;gyroscope;magnetometer},
  Timestamp                = {2013.05.15}
}

@InProceedings{Kawasaki2007,
  Title                    = {Development of a Hand Motion Assist Robot for Rehabilitation Therapy by Patient Self-Motion Control},
  Author                   = {Kawasaki, H. and Ito, S. and Ishigure, Y. and Nishimoto, Y. and Aoki, T. and Mouri, T. and Sakaeda, H. and Abe, M.},
  Booktitle                = {Proceedings of the 10th IEEE International Conference on Rehabilitation Robotics},
  Year                     = {2007},
  Pages                    = {234 -240},

  Abstract                 = {This paper presents a new hand motion assist robot for rehabilitation therapy. The robot is an exoskeleton with 18 DOFs and a self-motion control, which allows the impaired hand of a patient to be driven by his or her healthy hand on the opposite side. To provide such potential that the impaired hand is able to recover its ability to the level of a functional hand, the hand motion assist robot is designed to support the flexion/extension and abduction/adduction motions of fingers and thumb independently as well as the opposability of the thumb. Moreover, it is designed to support a combination motion of the hand and the wrist. The design specifications and experimental results are shown.},
  Doi                      = {10.1109/ICORR.2007.4428432},
  Keywords                 = {abduction motion;adduction motion;extension motion;flexion motion;hand motion assist robot;patient self-motion control;rehabilitation therapy;thumb;biomechanics;medical robotics;patient rehabilitation;robot dynamics;Human-robot interaction},
  Review                   = {Built a hand exo-skeleton to assist motion and measure hand motion and rehabilitation},
  Timestamp                = {2011.02.09}
}

@Article{Kawase2004,
  Title                    = {Terahertz Imaging For Drug Detection And Large-Scale Integrated Circuit Inspection},
  Author                   = {Kawase, K.},
  Journal                  = {Optics and Photonic News},
  Year                     = {2004},
  Number                   = {10},
  Pages                    = {34--39},
  Volume                   = {15},

  Abstract                 = {Until fairly recently, the terahertz range was considered little more than the dark gap that separated the two halves of the electromagnetic spectrum. Now scientists have come to view it as a bridge rife with possibilities for new applications and research.},
  Keywords                 = {General; Other areas of optics},
  Publisher                = {OSA},
  Timestamp                = {2010.07.15},
  Url                      = {http://www.osa-opn.org/abstract.cfm?URI=OPN-15-10-34}
}

@InProceedings{kellokumpu2005human,
  Title                    = {Human activity recognition using sequences of postures.},
  Author                   = {Kellokumpu, Vili and Pietik{\"a}inen, Matti and Heikkil{\"a}, Janne},
  Booktitle                = {MVA},
  Year                     = {2005},
  Pages                    = {570--573},

  Review                   = {Another guy taking SVM outputs and feeding it into HMM, for activity recogn.},
  Timestamp                = {2015.02.06}
}

@InCollection{Kelly2009,
  Title                    = {Fast Relative Pose Calibration for Visual and Inertial Sensors},
  Author                   = {Kelly, Jonathan and Sukhatme, Gaurav},
  Booktitle                = {Experimental Robotics},
  Publisher                = {Springer Berlin / Heidelberg},
  Year                     = {2009},
  Editor                   = {Khatib, Oussama and Kumar, Vijay and Pappas, George},
  Pages                    = {515--524},
  Series                   = {Springer Tracts in Advanced Robotics},
  Volume                   = {54},

  Abstract                 = {Accurate vision-aided inertial navigation depends on proper calibration of the relative pose of the camera and the inertial measurement unit (IMU). Calibration errors introduce bias in the overall motion estimate, degrading navigation performance - sometimes dramatically. However, existing camera-IMU calibration techniques are difficult, time-consuming and often require additional complex apparatus. In this paper, we formulate the camera-IMU relative pose calibration problem in a filtering framework, and propose a calibration algorithm which requires only a planar camera calibration target. The algorithm uses an unscented Kalman filter to estimate the pose of the IMU in a global reference frame and the 6-DoF transform between the camera and the IMU. Results from simulations and experiments with a low-cost solid-state IMU demonstrate the accuracy of the approach.},
  Affiliation              = {University of Southern California Department of Computer Science},
  Review                   = {camera based. just need calibration target. can be done online},
  Timestamp                = {2011.07.19}
}

@TechReport{Kelly2015,
  author      = {M. P. Kelly},
  title       = {Transcription Methods for Trajectory Optimization},
  institution = {Cornell University},
  year        = {2015},
  owner       = {jf2lin},
  timestamp   = {2017.03.01},
  url         = {http://www.matthewpeterkelly.com/research/MattKelly__Transcription_Methods_for_Trajectory_Optimization.pdf},
}

@InProceedings{Keogh2001a,
  author    = {Keogh, E. and Chu, S. and Hart, D. and Pazzani, M.},
  title     = {An Online Algorithm for Segmenting Time Series},
  booktitle = {Proceedings of the IEEE International Conference on Data Mining},
  year      = {2001},
  pages     = {289--296},
  abstract  = {In recent years, there has been an explosion of interest in mining time-series databases. As with most computer science problems, representation of the data is the key to efficient and effective solutions. One of the most commonly used representations is piecewise linear approximation. This representation has been used by various researchers to support clustering, classification, indexing and association rule mining of time-series data. A variety of algorithms have been proposed to obtain this representation, with several algorithms having been independently rediscovered several times. In this paper, we undertake the first extensive review and empirical comparison of all proposed techniques. We show that all these algorithms have fatal flaws from a data-mining perspective. We introduce a novel algorithm that we empirically show to be superior to all others in the literature},
  doi       = {10.1109/ICDM.2001.989531},
  groups    = {Lit Review 2013-09},
  keywords  = {association rule mining;classification;clustering;data mining;data representation;empirical comparison;indexing;online algorithm;piecewise linear approximation;review;time series segmentation;time-series database mining;data mining;online operation;piecewise linear techniques;reviews;time series},
  review    = {They proposed a 2-tier on-line segmentation algorithm. They employ a sliding window and mean square error (MSE) for coarse segment estimation. Following coarse segmentation, a second window and additional distance metrics were used to determine the actual segment. Amft \etal \cite{Amft2005} extended this to a 3-tier system, by adding HMMs as an identification tool for 4 DOF arm motion identification. They report an average accuracy of 72\% (94\%, ignoring false positives and negatives) for 4 motion primitives.},
  timestamp = {2011.06.07},
}

@InBook{Keogh2004,
  Title                    = {Data Mining in Time Series Databases},
  Author                   = {Keogh, E. J. and Chu, S. and Hart, D. and Pazzani, M.},
  Chapter                  = {Segmenting Time Series: A Survey and Novel Approach},
  Pages                    = {1--22},
  Publisher                = {World Scientific Publishing},
  Year                     = {2004},
  Volume                   = {57},

  Abstract                 = {In recent years, there has been an explosion of interest in mining time series databases. As with most 
computer science problems, representation of the data is the key to efficient and effective solutions. One of 
the most commonly used representations is piecewise linear approximation. This representation has been 
used by various researchers to support clustering, classification, indexing and association rule mining of 
time series data. A variety of algorithms have been proposed to obtain this representation, with several 
algorithms having been independently rediscovered several times. In this paper, we undertake the first 
extensive review and empirical comparison of all proposed techniques. We show that all these algorithms 
have fatal flaws from a data mining perspective. We introduce a novel algorithm that we empirically show 
to be superior to all others in the literature.},
  Journal                  = {Data mining in time series databases},
  Review                   = {Keogh \etal \cite{Keogh2004} looked at different ways of segmenting by employing piecewise linear representation, which consists of representing the observed data with \emph{K} straight lines. The observation data is examined by a windowing technique, such as a sliding window, if on-line constraints are required, or by top-down or bottom-up window partitioning. The windowed data is estimated by linear interpolation or regression, and a segment is declared when the line produced by the linear interpolation exceeds some threshold. Keogh reports that sliding window and top-down approaches tend to over-segment any data with noise, making it difficult to use. Sliding window and bottom-up approaches can also become computationally expensive, based on the window sizing selected. They propose a sliding window bottom-up approach, where a large sliding window is used, and bottom-up approach is used inside the sliding window. This allows the system to retain its on-line nature, and also be computationally light. The segmentation accuracy was given as the MSE between the interpolated lines and the actual data, as a percentage of the poorest algorithm tested, so no temporal accuracy is reported. This algorithm may be difficult to generalize into rehabilitation motions},
  Timestamp                = {2013.09.18}
}

@Article{Keogh2003,
  Title                    = {On the Need for Time Series Data Mining Benchmarks: A Survey and Empirical Demonstration},
  Author                   = {Keogh, E. J. and Kasetty, S.},
  Journal                  = {Data Mining and Knowledge Discovery},
  Year                     = {2003},
  Pages                    = {349--371},
  Volume                   = {7},

  Abstract                 = {In the last decade there has been an explosion of interest in mining time series data. Literally hundreds of papers have introduced new algorithms to index, classify, cluster and segment time series. In this work we make the following claim. Much of this work has very little utility because the contribution made (speed in the case of indexing, accuracy in the case of classification and clustering, model accuracy in the case of segmentation) offer an amount of improvement that would have been completely dwarfed by the variance that would have been observed by testing on many real world datasets, or the variance that would have been observed by changing minor (unstated) implementation details.},
  Affiliation              = {University of California Riverside},
  ISSN                     = {1384-5810},
  Issue                    = {4},
  Keyword                  = {Computer Science},
  Keywords                 = {Dynamic time warping, segmentation},
  Publisher                = {Springer Netherlands},
  Timestamp                = {2011.04.01}
}

@InProceedings{Keogh2001b,
  Title                    = {Derivative Dynamic Time Warping},
  Author                   = {Keogh, E. J. AND Pazzani, M. J.},
  Booktitle                = {Proceedings of the SIAM International Conference on Data Mining},
  Year                     = {2001},
  Pages                    = {1--11},

  Abstract                 = {this paper we address both these problems by introducing a modification of DTW. The crucial difference is in the features we consider when attempting to find the correct warping. Rather than use the raw data, we consider only the (estimated) local derivatives of the data},
  Keywords                 = {dynamic time warping},
  Review                   = {Keogh2001b
Base algorithm: DTW
Templated? Yes
Details: Want to address singularity warping. DTW only considers y-axis points and not really any temporal or larger picture things. Instead of using Euclidean distance as the cost function, the cost function is now the square of the diffrence of the derivatives of the two functions. This incorporate time information. 
Verification: Used some ... pretty random sensor sets. But also they also inserted random "bumps" into the data to see if they match up, and generated their own metric. 
Error reported: Reported better results then DTW without


Keogh and Pazzani \cite{Keogh2001b} noted that classic DTW considers only the position data and does not account for higher level features. They proposed the Derivative DTW (DDTW), and examined the derivative of the data streams instead by using the square of the difference of the derivatives of the two signals instead of the Euclidean distance. This allows the algorithm to negate global effects such as signal bias. The derivative also allows more of the latent features to be emphasized. Using only the Euclidean distance, DTW will map two points of identical value together, even if one point is part of a falling trend and the other is part of a rising trend. Using the derivate will allow the larger pattern to be captured. This algorithm was verified on a set of space shuttle sensor readings, the currency exchange rate between the German Deutschmark and five other European currencies over the span of six months, as well as a set of electroencephlograph (EEG) measurements. All sets of data show similar trends but are non-identical. Comparison between DTW and DDTW shows that DTW tends to be overaggressive in the warping, while DDTW provides a more accurate mapping. No classification or segmentation accuracy values were ported. Although the DDTW algorithm outperforms standard DTW, they have similar runtime, meaning that it does not scale well to higher dimensions.

Keogh and Pazzani \cite{Keogh2001b} noted that classic DTW considers only the position data and does not account for higher level features. They proposed the derivative DTW (dDTW), and examined the derivative of the data streams by using the square of the difference of the derivatives of the two signals instead of the Euclidean distance. This allows the algorithm to negate global effects such as signal bias, and allows more of the latent features to be emphasized. Using only the Euclidean distance, DTW will map two points of identical value together, even if one point is part of a falling trend and the other is part of a rising trend. Using the derivative will allow the larger pattern to be captured. Comparison between DTW and dDTW shows that DTW tends to be overaggressive in the warping, while dDTW provides a more accurate mapping. No classification or segmentation accuracy values were ported.},
  Timestamp                = {2011.04.01}
}

@Article{Keshav2007,
  author    = {Keshav, S},
  title     = {How to read a paper},
  journal   = {ACM SIGCOMM Computer Communication Review},
  year      = {2007},
  volume    = {37},
  number    = {3},
  pages     = {83--84},
  groups    = {Lit Review 2013-09},
  publisher = {ACM},
  timestamp = {2013.10.09},
}

@InProceedings{Keshavarz2011,
  Title                    = {Imputing a convex objective function},
  Author                   = {A. Keshavarz and Y. Wang and S. Boyd},
  Booktitle                = {Proceedings of the IEEE International Symposium on Intelligent Control},
  Year                     = {2011},
  Pages                    = {613-619},

  Abstract                 = {We consider an optimizing process (or parametric optimization problem), i.e., an optimization problem that depends on some parameters. We present a method for imputing or estimating the objective function, based on observations of optimal or nearly optimal choices of the variable for several values of the parameter, and prior knowledge (or assumptions) about the objective. Applications include estimation of consumer utility functions from purchasing choices, estimation of value functions in control problems, given observations of an optimal (or just good) controller, and estimation of cost functions in a flow network.},
  Doi                      = {10.1109/ISIC.2011.6045410},
  ISSN                     = {2158-9860},
  Keywords                 = {convex programming;consumer utility function;control problem;convex objective function;cost function;flow network;optimizing process;parametric optimization problem;purchasing choices;value function;Convex functions;Cost function;Dynamic programming;Heuristic algorithms;Process control;Stochastic processes},
  Timestamp                = {2016.06.01}
}

@InProceedings{Khalil2010,
  Title                    = {Dynamic Modeling of Robots using Recursive Newton-Euler Techniques},
  Author                   = {Khalil, W.},
  Booktitle                = {Proceedings of the International Conference on Informatics in Control, Automation and Robotics},
  Year                     = {2010},
  Abstract                 = {This paper present the use of recursive Newton-Euler to model different robotics systems. The main advantages of this technique are the facility of implementation by numerical or symbolical programming and providing models with reduced number of operations. In this paper the inverse and direct dynamic models of different robotics systems will be presented. At first we start by rigid tree structure robots, then these algorithms will be generalized for closed loop robots, parallel robots, and robots with lumped elasticity. At the end the case of robots with moving base will be treated.},
  Timestamp                = {2012.06.12}
}

@Article{Khalil1997,
  Title                    = {Symoro+: A System for the Symbolic Modelling of Robots},
  Author                   = {Khalil, W. and Creusot, D.},
  Journal                  = {Robotica},
  Year                     = {1997},
  Number                   = {2},
  Pages                    = {153--161},
  Volume                   = {15},

  Owner                    = {jf2lin},
  Timestamp                = {2016.02.16}
}

@InProceedings{Khan2010,
  Title                    = {Accelerometer's position free human activity recognition using a hierarchical recognition model},
  Author                   = {Khan, A.M. and Lee, Y. -K and Lee, S.Y.},
  Booktitle                = {e-Health Networking Applications and Services (Healthcom), 2010 12th IEEE International Conference on},
  Year                     = {2010},
  Month                    = {July},
  Pages                    = {296-301},

  Abstract                 = {Monitoring of physical activities is a growing field with potential applications such as lifecare and healthcare. Accelerometry shows promise in providing an inexpensive but effective means of long-term activity monitoring of elderly patients. However, even for the same physical activity the output of any body-worn Triaxial Accelerometer (TA) varies at different positions of a subject's body, resulting in a high within-class variance. Thus almost all existing TA-based human activity recognition systems require firm attachment of TA to a specific body part, making them impractical for long-term activity monitoring during unsupervised free living. Therefore, we present a novel hierarchical recognition model that can recognize human activities independent of TA's position along a human body. The proposed model minimizes the high within-class variance significantly and allows subjects to carry TA freely in any pocket without attaching it firmly to a body-part. We validated our model using six daily physical activities: resting (sit/stand), walking, walk-upstairs, walk-downstairs, running, and cycling. Activity data is collected from four most probable body positions of TA: chest pocket, front trousers pocket, rear trousers pocket, and inner jacket pocket. The average accuracy of about 95% illustrates the effectiveness of the proposed method.},
  Doi                      = {10.1109/HEALTH.2010.5556553},
  Keywords                 = {accelerometers;biomechanics;biomedical measurement;medical signal processing;patient monitoring;body-worn triaxial accelerometer;cycling;daily physical activities;free human activity recognition;hierarchical recognition model;resting;running;walking downstairs;walking upstairs;Legged locomotion;Monitoring;Acceleromete;Autoregressive Models;Human activity recognition;Linear Discriminant Analysis},
  Review                   = {Accelerometer, neural network in normal activities},
  Timestamp                = {2014.12.22}
}

@InProceedings{Khatib1985,
  author    = {Khatib, O.},
  title     = {Real-time obstacle avoidance for manipulators and mobile robots},
  booktitle = {Proceedings of the IEEE International Conference on Robotics and Automation},
  year      = {1985},
  pages     = {500--505},
  abstract  = { This paper presents a unique real-time obstacle avoidance approach for manipulators and mobile robots based on the "artificial potential field" concept. In this approach, collision avoidance, traditionally considered a high level planning problem, can be effectively distributed between different levels of control, allowing real-time robot operations in a complex environment. We have applied this obstacle avoidance scheme to robot arm using a new approach to the general problem of real-time manipulator control. We reformulated the manipulator control problem as direct control of manipulator motion in operational space-the space in which the task is originally described-rather than as control of the task's corresponding joint space motion obtained only after geometric and kinematic transformation. This method has been implemented in the COSMOS system for a PUMA 560 robot. Using visual sensing, real-time collision avoidance demonstrations on moving obstacles have been performed.},
  doi       = {10.1109/ROBOT.1985.1087247},
  groups    = {EMBC2013},
  timestamp = {2012.02.13},
}

@Article{Khatib2004,
  Title                    = {Whole body dynamic behavior and control of human-like robots},
  Author                   = {Khatib, O. AND Sentis, L. AND Park, J. AND Warren, J.},
  Journal                  = {International Journal of Humanoid Robotics},
  Year                     = {2004},
  Number                   = {1},
  Pages                    = {29-43},
  Volume                   = {1},
  Abstract                 = {With the increasing complexity of humanoid mechanisms and their desired capabilities, there is a pressing need for a generalized framework where a desired whole-body motion behavior can be easily specified and controlled. Our hypothesis is that human motion results from simultaneously performing multiple objectives in a hierarchical manner, and we have analogously developed a prioritized, multiple-task control framework. The operational space formulation provides dynamic models at the task level and structures for decoupled task and posture control.

This formulation allows for posture objectives to be controlled without dynamically interfering with the operational task. Achieving higher performance of posture objectives requires precise models of their dynamic behaviors. In this paper we complete the picture of task descriptions and whole-body dynamic control by establishing models of the dynamic behavior of secondary task objectives within the posture space. Using these models, we present a whole-body control framework that decouples the interaction between the task and postural objectives and compensates for the dynamics in their respective spaces.},
  Doi                      = {10.1142/S0219843604000058},
  Keywords                 = {ECE780, Control},
  Review                   = {Humanoids are high dimensionality robots, and contains redundant joints. We can divide up the control problem into two components: task dynamic behaviour (primary task), and posture behaviour (secondary task). Using the general Lagrange dynamic equation, they obtain a Jacobian that maps between force and torque (or between task and joint space, respectively). The torque equations are than separated into two independent sections, with one being responsible for task dynamics and the other being responsible for posture. 

They successfully implemented two control cases. The first case allows for both the primary task and the secondary task to be met. The second case provides conflicting joint space instructions between the primary and secondary tasks, but was still able to produce minimal mean square error.},
  Timestamp                = {2011.02.09},
  Url                      = {http://www.worldscientific.com/doi/abs/10.1142/S0219843604000058}
}

@Article{Khoshelham2012,
  Title                    = {Accuracy and Resolution of Kinect Depth Data for Indoor Mapping Applications},
  Author                   = {K. Khoshelham and S. O. Elberink},
  Journal                  = {Sensors},
  Year                     = {2012},
  Number                   = {2},
  Pages                    = {1437--1454},
  Volume                   = {12},

  __markedentry            = {},
  Doi                      = {10.3390/s120201437},
  Owner                    = {jf2lin},
  Timestamp                = {2016.02.15}
}

@Article{Khreich2012,
  Title                    = {A Survey of Techniques for Incremental Learning of \{HMM\} Parameters},
  Author                   = {Khreich, W. and Granger, E. and Miri, A. and Sabourin, R.},
  Journal                  = {Information Sciences },
  Year                     = {2012},
  Pages                    = {105--130},
  Volume                   = {197},

  Abstract                 = {The performance of Hidden Markov Models (HMMs) targeted for complex real-world applications are often degraded because they are designed a priori using limited training data and prior knowledge, and because the classification environment changes during operations. Incremental learning of new data sequences allows to adapt \{HMM\} parameters as new data becomes available, without having to retrain from the start on all accumulated training data. This paper presents a survey of techniques found in literature that are suitable for incremental learning of \{HMM\} parameters. These techniques are classified according to the objective function, optimization technique and target application, involving block-wise and symbol-wise learning of parameters. Convergence properties of these techniques are presented along with an analysis of time and memory complexity. In addition, the challenges faced when these techniques are applied to incremental learning is assessed for scenarios in which the new training data is limited and abundant. While the convergence rate and resource requirements are critical factors when incremental learning is performed through one pass over abundant stream of data, effective stopping criteria and management of validation sets are important when learning is performed through several iterations over limited data. In both cases managing the learning rate to integrate pre-existing knowledge and new data is crucial for maintaining a high level of performance. Finally, this paper underscores the need for empirical benchmarking studies among techniques presented in literature, and proposes several evaluation criteria based on non-parametric statistical testing to facilitate the selection of techniques given a particular application domain.},
  Doi                      = {http://dx.doi.org/10.1016/j.ins.2012.02.017},
  ISSN                     = {0020-0255},
  Keywords                 = {Incremental learning},
  Timestamp                = {2014.11.14},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S002002551200120X}
}

@InProceedings{Kim2004,
  Title                    = {Initial calibration of an inertial measurement unit using an optical position tracking system},
  Author                   = {Kim, A. and Golnaraghi, M.F.},
  Booktitle                = {Proceedings of the Position Location and Navigation Symposium},
  Year                     = {2004},
  Month                    = {april},
  Pages                    = {960--101},

  Abstract                 = {A reliable calibration procedure of a standard six degree-of-freedom inertial measurement unit (IMU) is presented. Mathematical models are derived for the three accelerometers and three rate gyros, taking into account the sensor axis misalignments, accelerometer offsets, electrical gains, and biases inherent in the manufacture of an IMU. The inertial sensors are calibrated using data from a 3D optical tracking system that measures the position coordinates of markers attached to the IMU. Inertial sensor signals and optical tracking data are obtained by manually moving the IMU. Using vector methods, the quaternion corresponding to the IMU platform orientation is obtained, along with its acceleration, velocity, and position. Given this kinematics information, the sensor models are used in a nonlinear least squares algorithm to solve for the unknown calibration parameters. The calibration procedure is verified through extensive experimentation.},
  Doi                      = {10.1109/PLANS.2004.1308980},
  ISSN                     = { },
  Keywords                 = {accelerometer offsets; accelerometers; electrical biases; electrical gains; inertial measurement unit; inertial sensors; initial calibration; nonlinear least squares algorithm; optical position tracking system; rate gyros; sensor axis misalignments; Global Positioning System; calibration; inertial navigation; microsensors; optical sensors; optical tracking; IMU calibration},
  Review                   = {- Uses optotrak to provide ground truth on accel/ang velo data to calibrate},
  Timestamp                = {2011.07.19}
}

@Article{Kim2012a,
  Title                    = {Kinematic Data Analysis for Post Stroke Patients Following Bilateral Versus Unilateral Rehabilitation With an Upper Limb Wearable Robotic System},
  Author                   = {Kim, H. and Miller, L. and Fedulow, I. and Simkins, M. and Abrams, G. and Byl, N. and Rosen, J.},
  Journal                  = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  Year                     = {2012},
  Pages                    = {(pre-printing)},
  Volume                   = {99},

  Abstract                 = {Robot-assisted stroke rehabilitation has become popular as one approach to helping patients recover function post stroke. Robotic rehabilitation requires four important elements to match the robot to the patient: realistic biomechanical robotic elements, an assistive control scheme enabled through the human-robot interface, a task oriented rehabilitation program based on the principles of plasticity and objective assessment tools to monitor change. This paper reports on a randomized clinical trial utilizing a complete robot-assisted rehabilitation system for the recovery of upper limb function in patients post stroke. In this study, a seven degree of freedom (DOF) upper limb exoskeleton robot(UL-EXO7) is applied in a rehabilitation clinical trial for patients stable post stroke (greater than 6 months ). Patients had a Fugl-Meyer Score between 16- 39, were mentally alert (> 19 on the VA Mini Mental Status Exam) and were between 27 and 70 years of age. Patients were randomly assigned to three groups: bilateral robotic training, unilateral robotic training and usual care. This study is concerned with the changes in kinematics in the two robotic groups. Both patient groups played eight therapeutic video games over twelve sessions (90 minutes, two times a week). In each session, patients intensively played the different combination of video games that directly interacted with UL-EXO7 under the supervision of research assistant. At each session, all of the joint angle data was recorded for the evaluation of therapeutic effects. A new assessment metric is reported along with conventional metrics. The experimental result shows that both groups of patients showed consistent improvement with respect to the proposed and conventional metrics.},
  Timestamp                = {2012.11.12}
}

@InProceedings{Kim2008_emg,
  Title                    = {EMG-based Hand Gesture Recognition for Realtime Biosignal Interfacing},
  Author                   = {Kim, J. and Mastnik, S. and Andr{\'e}, E.},
  Booktitle                = {Proceedings of the International Conference on Intelligent User Interfaces},
  Year                     = {2008},
  Pages                    = {30--39},

  Abstract                 = {In this paper the development of an electromyogram (EMG) based interface for hand gesture recognition is presented. To recognize control signs in the gestures, we used a single channel EMG sensor positioned on the inside of the forearm. In addition to common statistical features such as variance, mean value, and standard deviation, we also calculated features from the time and frequency domain including Fourier variance, region length, zerocrosses, occurrences, etc. For realizing real-time classification assuring acceptable recognition accuracy, we combined two simple linear classifiers (k-NN and Bayes) in decision level fusion. Overall, a recognition accuracy of 94% was achieved by using the combined classifier with a selected feature set. The performance of the interfacing system was evaluated through 40 test sessions with 30 subjects using an RC Car. Instead of using a remote control unit, the car was controlled by four different gestures performed with one hand. In addition, we conducted a study to investigate the controllability and ease of use of the interface and the employed gestures.},
  Acmid                    = {1378778},
  Doi                      = {10.1145/1378773.1378778},
  ISBN                     = {978-1-59593-987-6},
  Keywords                 = {biosignal analysis, electromyogram, gesture recognition, human-computer interaction, neural interfacing},
  Location                 = {Gran Canaria, Spain},
  Numpages                 = {10},
  Owner                    = {jf2lin},
  Review                   = {Uses a single channel EMG to recognize 4 hand gestures to control an RC car. Motion is fist, fist with wrist left, fist with wrist right, and fist with wrist down. 

- threshold on rms to determine the start and end fo a signal (segmentation)
- for actual signal, used max, min, mean value, variance, signal length, rms. for freq signals, used fundamental freq, fourier varience, region length (partial length of the spectrum containing greater magnitude than mean value of total fourier coeff), percentage to max value, zero crossing

- used knn and bayes classifier, and has voting schemes btwn them
- calibrate with 10-20 samples of each gesture for subject. above 90% acc in classification rate. 

30 subjects.},
  Timestamp                = {2015.04.03}
}

@Article{Kimber1997,
  Title                    = {Acoustic segmentation for audio browsers},
  Author                   = {Kimber, D. and Wilcox, L.},
  Journal                  = {Computing Science and Statistics},
  Year                     = {1997},
  Pages                    = {295--304},

  Publisher                = {Citeseer},
  Review                   = {- Want to auto-annotate voice recordings
- Uses HMM. 32 states for speaker models, 3 states for silence, 64 states for music. Trained from labelled data. Segmentation performed by Viterbi and looking at the transition points for the max-likelihood state transitions
- Iterative resegmentation: using computed segments and re-train a HMM to improve (hopefully) accuracy
- If labelled data is not available, also tried dividing up the signal into small equally-spaced windows and clustered similar sounds together to merge windows, either by k-means or agglomerative cluster (same algorithm to Boreczky and Wilcox, 1998)


Kimber and Wilcox \cite{Kimber1997} want to auto-annotate voice recordings with hidden Markov models (HMM). In their HMM, they have 32 states for speaker models, 3 states for silence and 64 states for music, trained from labeled data. Segmentation is performed by the Viterbi algorithm and looking at the state transitions for the most likely state boundaries. When segments are computed, these computer segments are added to the labeled data and the HMM is re-trained in order to improve Viterbi accuracy. If labeled data is not available, such labeling is estimated by dividing up the time-varying signal into small equally-spaced windows and merged by \emph{k}-means or other clustering techniques. In a later work, Boreczky and Wilcox \cite{Boreczky1998} applies this to mel-frequency cepstrum (MFC) data, a measure of the power spectrum of a sound signal, as part of a video segmentation algorithm.},
  Timestamp                = {2013.08.29}
}

@Article{King1998,
  Title                    = {Inertial Navigation--Forty Years of Evolution},
  Author                   = {A. D. King},
  Journal                  = {General Electric Company Review},
  Year                     = {1998},
  Pages                    = {140--149},
  Volume                   = {3},

  Timestamp                = {2012.07.06},
  Url                      = {http://www.imar-navigation.de/downloads/papers/inertial_navigation_introduction.pdf}
}

@Book{Kirk2004,
  Title                    = {Optimal Control Theory: An Introduction},
  Author                   = {Kirk, D. E.},
  Publisher                = {Dover Publications},
  Year                     = {2004},

  Owner                    = {jf2lin},
  Timestamp                = {2017.01.03}
}

@Book{Kisner2007,
  Title                    = {Therapeutic Exercise: Foundations and Techniques},
  Author                   = {Kisner, C. and Colby, L. A.},
  Publisher                = {F. A. Davis Company},
  Year                     = {2007},

  Owner                    = {jf2lin},
  Timestamp                = {2015.11.22}
}

@Article{Kjellstroem2011,
  Title                    = {Visual Object-action Recognition: Inferring Object Affordances from Human Demonstration},
  Author                   = {Kjellstr\"{o}m, H. AND Romero, J. AND Kragic, D.},
  Journal                  = {Computer Vision and Image Understanding},
  Year                     = {2011},
  Number                   = {1},
  Pages                    = {81--90},
  Volume                   = {115},
  Abstract                 = {This paper investigates object categorization according to function, i.e., learning the affordances of objects from human demonstration. Object affordances (functionality) are inferred from observations of humans using the objects in different types of actions. The intended application is learning from demonstration, in which a robot learns to employ objects in household tasks, from observing a human performing the same tasks with the objects. We present a method for categorizing manipulated objects and human manipulation actions in context of each other. The method is able to simultaneously segment and classify human hand actions, and detect and classify the objects involved in the action. This can serve as an initial step in a learning from demonstration method. Experiments show that the contextual information improves the classification of both objects and actions.},
  Doi                      = {DOI: 10.1016/j.cviu.2010.08.002},
  ISSN                     = {1077-3142},
  Keywords                 = {Object recognition, ECE780},
  Review                   = {- categorize items by the function it serves, along with the item itself
- uses factorial CRF
- object recognition w/ SVM. stopped reading at this point since it's for computer vision},
  Timestamp                = {2011.03.05},
  Url                      = {http://www.sciencedirect.com/science/article/B6WCX-50TRXD4-1/2/cd1f44641cd86e3c1410da4072101899}
}

@Article{Kober2010,
  Title                    = {Imitation and Reinforcement Learning},
  Author                   = {Kober, J. and Peters, J.},
  Journal                  = {IEEE Robotics Automation Magazine},
  Year                     = {2010},
  Number                   = {2},
  Pages                    = {55 -62},
  Volume                   = {17},

  Abstract                 = {In this article, we present both novel learning algorithms and experiments using the dynamical system MPs. As such, we describe this MP representation in a way that it is straightforward to reproduce. We review an appropriate imitation learning method, i.e., locally weighted regression, and show how this method can be used both for initializing RL tasks as well as for modifying the start-up phase in a rhythmic task. We also show our current best-suited RL algorithm for this framework, i.e., PoWER. We present two complex motor tasks, i.e., ball-in-a-cup and ball paddling, learned on a real, physical Barrett WAM, using the methods presented in this article. Of particular interest is the ball-paddling application, as it requires a combination of both rhythmic and discrete dynamical systems MPs during the start-up phase to achieve a particular task.},
  Doi                      = {10.1109/MRA.2010.936952},
  ISSN                     = {1070-9932},
  Keywords                 = {ball paddling; ball-in-a-cup; discrete dynamical system; imitation learning; industrial robots; motor primitive; reinforcement learning; weighted regression; whole arm manipulator; discrete systems; learning (artificial intelligence); regression analysis; robots;},
  Timestamp                = {2010.07.12}
}

@Article{Koch2012,
  Title                    = {Optimization-based walking generation for humanoid robot},
  Author                   = {K. H. Koch and K. Mombaur and P. Soueres},
  Journal                  = {IFAC Proceedings Volumes},
  Year                     = {2012},
  Number                   = {22},
  Pages                    = {498--504},
  Volume                   = {45},

  Doi                      = {http://dx.doi.org/10.3182/20120905-3-HR-2030.00189},
  ISSN                     = {1474-6670},
  Keywords                 = {Optimal Control Humanoid robot HRP-2},
  Timestamp                = {2017.03.02}
}

@Conference{Koenig2006,
  author    = {Koenig, N. AND Matari\'{c}, M. J.},
  title     = {Behaviour-Based Segmentation of Demonstrated Tasks},
  booktitle = {Proceedings of the International Conference on Development and Learning},
  year      = {2006},
  abstract  = {Robot learning from demonstration presents several challenges. Given a task demoonstration, the robot must sense, understand and learn appropriate task attributes. We propose a method for automatic segmentation fo a complex demonstration into an ordered set of simpler behaviours. These behaviours present a significantly less complex domain for learning. Our method is based on empirically derived attributes of tasks and simple mathematical transformations that results in a fast and intuitive mechanism for automatic task segmentation. This method is validated on a simulated Pioneer 2 DX platofrm across four demonstrations that vary in environmental complexity, task complexity, and task strategy.},
  groups    = {STAT841, IROS2014, EMBC2014},
  keywords  = {Teaching, demonstration, behaviour segmentation, motion segmentation},
  review    = {Teaching by demonstration is straightforward and instinctive. We do it with other people all the time. But robot programming currently involves alot of programming and difficult. If we develop a robot system that can understand human motion, robot learning becomes a more versatile tool. 

Step one: Segmentation. If we can break a complex demonstration into easier-to-understand segments, the learning process becomes simplier. It is important that the segmentation algorithm be fast and capable of online processing (allows for segmentation during teaching). The algorithm should also be able to take in a diverse set of data. This paper does not talk about learning behaviours themselves; rather, the focus is on identifying where behaviours are in a demonstration sequence.

Once again, we want to focus on boundary points of segments. If that is possible, we can reduce a complex behaviour to simple behaviours. This is good since it makes the behaviour set easier to learn; it also allows the potential of reusing a given action for new tasks. Assume robot has no prior knowledge about demonstration, so all the info it needs will come from the demo itself. From the demo, it has access to sensory, model and processed data. This is a large set of data, so the teacher would need to provide a set of salient features that are relevant to the task. This tends to be from model-based data, since it's more intuitive for a human teacher to understand. Say we want to teach a robot to follow a wall. The critical features then would be...what is a wall? How to measure distance? So the teacher would need to point this out to the system. This will determine the resulting algorithm used. A cost function (such as ZVC) will be applied to each of these data streams, to guess where the segmentation points could be. 

(Not sure how they're determining the actual segmentation points. The language is unclear)

So the robot has access to snesory (physical sensors) and model (processed sensor data nd provided data, such as map of environment). The amount and type of information that the robot has available to it (and/or should focus on) must be determined prior to training. The paper focuses on mobline navigation and manipulation, but should be expandable to wider applications. We assume that environment layout is available to the robot. Also, that the robot can relocate, and detect manipulable objects. Ultimately, they want to implement behaviour-based approaches (so can issue commands like 'follow-wall' or 'locate-box'). They want the human-robot interface to be intuitive. They (tried) to make a pretty GUI. Basically, they don't want the teacher to focus on the kinematics and dynamics, but on the actual teaching task instead.


The user will use the GUI to send high level commands to the robot until it reaches the desired goal state. During this teaching process, the robot is storing all the salient information. Each set of data (remember, we're collecting data from multiple sensors) is processed individually, and has a cost function applied to it. The example cost function is variance in data. Peaks in variance marks a segmentation point (I think it's saying that the varience assessment is done +/- 5 data points from it) while ignoring all the variance betow the mean (drops the noise) of the variance graph. Each feature set is processed like so, so we're left with several sets of possible segmentation points. We want these segmentation points to lineup (empirically determined error margin on this to be 4 seconds). Of course, if only one feature was monitored, this check wouldn't exist. 

Pseudo-code (not sure if I understand this...read the above paragraph for clarifications): 
For all possible sequence in set...
 Apply cost function
 Is it below some threshold (the mean?)
 Find the segmentation points
end

So they put this code to test. Yay... okay. They used Gazebo (good 3D modelling app, rigid body dynamics). 
1. Teaching a robot how to explore an indoor environment. 
2. How to pick up and place colored boxes.

Oh. That wasn't that bad.},
  timestamp = {2009.10.13},
}

@InProceedings{Kohlmorgen2002,
  author    = {Kohlmorgen, J. and Lemm, S.},
  title     = {A Dynamic HMM for On-line Segmentation of Sequential Data},
  booktitle = {Proceedings of the Advances in Neural Information Processing Systems},
  year      = {2002},
  volume    = {14},
  pages     = {793--800},
  abstract  = {We propose a novel method for the analysis of sequential data that exhibits an inherent mode switching. In particular, the data might be a non-stationary time series from a dynamical system that switches between multiple operating modes. Unlike other approaches, our method processes the data incrementally and without any training of internal parameters. We use an HMM with a dynamically changing number of states and an on-line variant of the Viterbi algorithm that performs an unsupervised segmentation and classifcation of the data on-the-fly, i.e. the method is able to process incoming data in real-time. The main idea of the approach is to track and segment changes of the probability density of the data in a sliding window on the incoming data stream. The usefulness of the algorithm is demonstrated by an application to a switching dynamical system.},
  groups    = {STAT841, EMBC2014},
  keywords  = {motion segmentation},
  review    = {Signals can be pretty eratic and change abruptly. This makes hard-to-predict signals...hard to predict. So these guys's technique are based on density distribution instead of the data itself. They want to do the segmentation unsupervised. 

Procedure
- They map the data to a higher dimension. The idea is that...the data might be non-linear in the current (or lower projections) of dimensions, and putting it at a higher dimension might help with some data processing. 
- Then, we reduce the sample rate to reduce the amount of data for RT processing. 
- Then, using a sliding window, they estimate the PDF, since the density distribution is what they want to track
- When a new data entry is added, the sliding window shifts and a new PDF is calculated
- The difference between the two PDFs are calculated with a squared L2-norm (integrated sqaure error)

Offline-HMM
- So for a given sequence of data, we can generate a corresponding sequence of PDFs
- From these PDFs, we construct a HMM, with the PDFs as the system state
- The HMM is initalized with a standard uniform distribution
- Converted log likelihood into cost (easier numbers to work with) -> it's likely if the cost function is minimized
 - CAn rerun the operation a few times until we're at a good low cost function

Online-HMM
- Since we don't have all the data set anymore, we just have to update our data set whenver we have new data in, thus...
- (They implement some form of cutoff function, to remove old data. Re-read later)

Labeling algorithm
- Need a way to id segments with the same underlying distrubtions
- Do so with clustering

Verificiation
- Done against simulated data

As an alternative to looking at variance directly, segments can be declared by changes exhibited by its probability density function (PDF). Kohlmorgen and Lemm \cite{Kohlmorgen2002} use the hidden Markov model (HMM) and an online version of the Viterbi algorithm to perform segmentation. Typically, the Viterbi algorithm (See Section \ref{lbl:offline_supervised_viterbi}) requires the entire observation to be available before segmentation can occur, so backtracking can be used. Kohlmorgen modifies the Viterbi algorithm to be online, so that the most likely state is calculated by:
%
\begin{align}
 c_s(t) = d_{s, t} + \min {c_s{t-1} + C (1-\delta_{s, \bar{s}})}
\end{align}
%
\noindent where $c_s(t)$ denote the cost of the optimal state sequence from $W$ to $t$, subject to the constraint that it ends in state $s$ at time $t$. $d_{s, t}$ is the squared $L_2$-norm distance between the PDF of the state $s$ and current windowed data at time $t$. $C$ is a cost function that applies a penalty for switching to a new state $\bar{s}$ in a given Viterbi path, as facilitated by the Kronecker delta $\delta_{s, \bar{s}}$. At any given time, the optimal path can be determined by selecting the Viterbi path that results in the lowest cost $c_s$. A sliding window is used to calculate the PDF of the windowed data. The PDFs are used to train a HMM. The modified Viterbi algorithm is applied to determine the state transitions of the HMM, thus producing segment bounds for a given observation set.},
  timestamp = {2011.01.08},
}

@TechReport{Konrad2005,
  Title                    = {The {ABC} of {EMG}},
  Author                   = {Konrad, P.},
  Institution              = {Noraxon USA},
  Year                     = {2005},

  Owner                    = {jf2lin},
  Timestamp                = {2015.05.04},
  Volume                   = {1}
}

@Book{Konz2004,
  Title                    = {Work Design: Occupational Ergo, 6th Ed.},
  Author                   = {Konz, S. and Johnson, S.},
  Publisher                = {Holcomb Hathaway},
  Year                     = {2004},

  Timestamp                = {2012.01.25}
}

@Article{Kose-Bagci2009,
  Title                    = {Effects of Embodiment and Gestures on Social Interaction in Drumming Games with a Humanoid Robot},
  Author                   = {Kose-Bagci, H. AND Ferrari, E. AND Dautenhahn, K. AND Syrdal, D. S. AND Nehaniv, C. L.},
  Journal                  = {Advanced Robotics},
  Year                     = {2009},
  Pages                    = {1951-1996},
  Volume                   = {23},

  Abstract                 = {We present results from an empirical study investigating the effect of embodiment and minimal gestures in an interactive drumming game consisting of an autonomous child-sized humanoid robot (KASPAR) playing with child participants. In this study, each participant played three games with a humanoid robot that played a drum whilst simultaneously making (or not making) head gestures. The three games included the participant interacting with the real robot (physical embodiment condition), interacting with a hidden robot when only the sound of the robot is heard (disembodiment condition; note that the term 'disembodiment' is used in this paper specifically to refer to an experimental condition where a physical robot produces the sound cues, but is not visible to the participants), or interacting with a real-time image of the robot (virtual embodiment condition). We used a mixed design where repeated measures were used to evaluate embodiment effects and independent-groups measures were used to study the gestures effects. Data from the implementation of a human-robot interaction experiment with 66 children are presented, and statistically analyzed in terms of participants' subjective experiences and drumming performance of the human-robot pair. The subjective experiences showed significant differences for the different embodiment conditions when gestures were used in terms of enjoyment of the game, and perceived intelligence and appearance of the robot. The drumming performance also differed significantly within the embodiment conditions and the presence of gestures increased these differences significantly. The presence of a physical, embodied robot enabled more interaction, better drumming and turn-taking, as well as enjoyment of the interaction, especially when the robot used gestures.},
  Keywords                 = {Human-robot interaction},
  Review                   = {- participants were placed in three interaction games (drumming game, play and playback)
 - interacting with a robot directly
 - interacting with a robot indirectly (can only hear the sounds produced, but not see the robot itself)
 - interact with a image of a robot
- also, the robot made gesture at times, or not
 - people like to see the robot, as oppose to all other situations
 - gesture is good

- sample size was 38. Target audience was 8-12 yr olds
- ...a lot of statistical analysis},
  Timestamp                = {2011.02.09}
}

@TechReport{Kosinski2008,
  Title                    = {A literature review on reaction time},
  Author                   = {Kosinski, R. J.},
  Institution              = {Clemson University},
  Year                     = {2008},

  Journal                  = {Clemson University},
  Timestamp                = {2017.01.16},
  Volume                   = {10}
}

@InProceedings{Kotsiantis2007,
  Title                    = {Supervised Machine Learning: A Review of Classification Techniques},
  Author                   = {Kotsiantis, S. B.},
  Booktitle                = {Proceedings of the Conference on Emerging Artificial Intelligence Applications in Computer Engineering: Real Word AI Systems with Applications in eHealth, HCI, Information Retrieval and Pervasive Technologies},
  Year                     = {2007},

  Address                  = {Amsterdam, The Netherlands, The Netherlands},
  Pages                    = {3--24},
  Publisher                = {IOS Press},

  Acmid                    = {1566773},
  ISBN                     = {978-1-58603-780-2},
  Keywords                 = {Classifiers, Data Mining, Intelligent Data Analysis, Learning Algorithms},
  Numpages                 = {22},
  Timestamp                = {2016.12.20},
  Url                      = {http://dl.acm.org/citation.cfm?id=1566770.1566773}
}

@InProceedings{Kourogi2003,
  Title                    = {A Wearable Augmented Reality System with Personal Positioning Based on Walking Locomotion Analysis},
  Author                   = {Kourogi, M. and Kurata, T.},
  Booktitle                = {Proceedings of the 2nd IEEE/ACM International Symposium on Mixed and Augmented Reality},
  Year                     = {2003},

  Address                  = {Washington, DC, USA},
  Pages                    = {342--},
  Publisher                = {IEEE Computer Society},
  Series                   = {ISMAR '03},

  Abstract                 = {In this paper, we present a wearable Augmented Reality system with personal positioning based on walking locomotion analysis that allows a user to freely move around indoors and outdoors. The user is equipped with self-contained sensors, a wearable camera, an inertial head tracker and display. The system is based on the sensor fusion of esitmates for relative displacement caused by human walking locaomotion and estimates for absolute position and orientation within a Kalman filtering framework. The former is based on intensive analysis of human walking behaviour using self-contained sensors. The latter is based on image matching of video frames from a wearble camera with an image database that was prepared beforehand.},
  Acmid                    = {946814},
  ISBN                     = {0-7695-2006-5},
  Keywords                 = {postural detection},
  Review                   = {Figured out where the person is and where he is facing using IMU sensors and cameras, and fused them with Kalman.},
  Timestamp                = {2011.03.01},
  Url                      = {http://portal.acm.org/citation.cfm?id=946248.946814}
}

@InProceedings{Kozina2011,
  author    = {Kozina, S. and Lu\v{s}trek, M. and Gams, M.},
  title     = {Dynamic Signal Segmentation for Activity Recognition},
  booktitle = {Proc International Joint Conference on Artificial Intelligence},
  year      = {2011},
  pages     = {15--22},
  abstract  = {Activity recognition is an essential task in many
ambient assisted living applications. Activities are
commonly recognized using data streams from onbody sensors such as accelerometers. An important
subtask in activity recognition is signal segmentation: a procedure for dividing the data into intervals. These intervals are then used as instances for
machine learning. We present a novel signal segmentation method, which utilizes a segmentation
scheme based on dynamic signal partitioning. To
validate the method, experimental results including
6 activities and 4 transitions between activities from
11 subjects are presented. Using a Random forest
algorithm, an accuracy of 97.5% was achieved with
dynamic signal segmentation method, 94.8% accuracy with non-overlapping and 95.3% with overlapping sliding window method.},
  groups    = {Lit Review 2013-09, EMBC2014},
  review    = {Want to determine activities performed by looking at acceleration signal. 

Sliding window to detect large quick deceleration, where the start (max) and the end (min) of the decel exceeds some threshold. The threshold to exceed is a moving average. The max and min is calculated by taking the top and bottom 10% of the values windowed before, and the threshold is the difference. The threshold is multiplied by a multiplier that is the average of all the values observed so far, divided by the max-min. This is suppose to reduce big signal spikes from messing things up. 

The acceleration used for the signal calculation is the norm, so that a single threshold is needed, instead of multiple. 

A handful of features, such as the acceleration magnitude, variance, average acceleration, max-min accel, angle of change (arctan of the the accel/time), for a total of 18 features. These features were used in a random forest algorithm to classify. Though, only classification accuracy was reported, at 97%



Kozina \etal \cite{Kozina2011} segment and identify daily activities from a thigh mounted accelerometer and a chest mounted accelerometer. They use a sliding window and segment when the norm of the two accelerometers' decelerate by a given threshold. The threshold is the scaled difference between the $N$ previous average local maximas and $N$ previous average local minimas. Statistical accelerometer features is used in a random forest algorithm to label the underlying motion. 11 healthy subjects performed a pre-set exercise routine 5 times. The exercise routine contains 6 different primitives types such as walking, sitting or on all fours. In addition, 4 transitions between primitives, such as standing up, or sitting down, were also included. $Ver_{AllPoints}$ verification scheme is used, and $Acc_{Class}$ is 98\% if only the primitives were labelled, and 92\% if both the primitives and the transitions were examined.},
  timestamp = {2013.10.06},
}

@Article{Kruger2010,
  Title                    = {Learning Actions from Observations},
  Author                   = {Kr\"{u}ger, Volker and Herzog, Dennis L. and Baby, Sanmohan and Ude, Ale\u{s} and Kragic, Danica},
  Journal                  = {IEEE Robotics Automation Magazine},
  Year                     = {2010},
  Pages                    = {30--43},
  Volume                   = {17},

  Abstract                 = {In the area of imitation learning, one of the important research problems is action representation. There has been a growing interest in expressing actions as a combination of meaningful subparts called action primitives. Action primitives could be thought of as elementary building blocks for action representation. In this article, we present a complete concept of learning action primitives to recognize and synthesize actions. One of the main novelties in this work is the detection of primitives in a unified framework, which takes into account objects and actions being applied to them. As the first major contribution, we propose an unsupervised learning approach for action primitives that make use of the human movements as well as object state changes. As the second major contribution, we propose using parametric hidden Markov models (PHMMs) for representing the discovered action primitives. PHMMs represent movement trajectories as a function of their desired effect on the object, and we will discuss 1) how these PHMMs can be trained in an unsupervised manner, 2) how they can be used for synthesizing movements to achieve a desired effect, and 3) how they can be used to recognize an action primitive and the effect from an observed acting human.},
  Doi                      = {10.1109/MRA.2010.936961},
  ISSN                     = {1070-9932},
  Keywords                 = {action representation;human movements;imitation learning;parametric hidden Markov models;primitives detection;unsupervised learning approach;hidden Markov models;learning (artificial intelligence);robots;},
  Timestamp                = {2010.07.12}
}

@Article{Kruger2007,
  Title                    = {The Meaning of Action: A Review on Action Recognition and Mapping},
  Author                   = {Kr\"{u}ger, V. and Kragic, D. and Ude, A. and Geib, C.},
  Journal                  = {Advanced Robotics},
  Year                     = {2007},
  Pages                    = {1473--1501},
  Volume                   = {21},

  Abstract                 = {In this paper, we analyze the different approaches taken to date within the computer vision, robotics and artificial intelligence communities for the representation, recognition, synthesis and understanding of action. We deal with action at different levels of complexity and provide the reader with the necessary related literature references. We put the literature references further into context and outline a possible interpretation of action by taking into account the different aspects of action recognition, action synthesis and task-level planning.},
  Doi                      = {10.1163/156855307782148578},
  Eprint                   = { http://www.tandfonline.com/doi/pdf/10.1163/156855307782148578 },
  Timestamp                = {2014.12.18}
}

@Article{Kragic2005,
  Title                    = {Human-Machine Collaborative Systems for Microsurgical Applications},
  Author                   = {Kragic, D. and Marayong, P. and Li, M. and Okamura, A. M. and Hager, G. D.},
  Journal                  = {International Journal of Robotics Research},
  Year                     = {2005},
  Pages                    = {731--741},
  Volume                   = {24},

  Abstract                 = {Human-machine collaborative systems (HMCSs) are systems that amplify or assist human capabilities during the performance of tasks that require both human judgment and robotic precision. We examine the design and performance of HMCSs in the context of microsurgical procedures such as vitreo-retinal eye surgery. Three specific problems considered are: (1) development of systems tools for describing and implementing HMCSs, (2) segmentation of complex tasks into logical components given sensor traces of human task execution, and (3) measurement and evaluation of HMCS performance. These components can be integrated into a complete workstation with the ability to automatically “parse” traces of user activities into task models, which are loaded into an execution environment to provide the user with assistance using on-line recognition of task states. The major contributions of this work include an XML task graph modeling framework and execution engine, an algorithm for real-time segmentation of user actions using continuous hidden Markov models, and validation techniques for analyzing the performance of HMCSs.},
  Doi                      = {10.1177/0278364905057059},
  Eprint                   = {http://ijr.sagepub.com/content/24/9/731.full.pdf+html},
  Timestamp                = {2014.12.20}
}

@Article{Krebs2004,
  author    = {Krebs, H. and Ferraro, M. and Buerger, S. and Newbery, M. and Makiyama, A. and Sandmann, M. and Lynch, D. and Volpe, B. and Hogan, N.},
  title     = {Rehabilitation robotics: pilot trial of a spatial extension for MIT-Manus},
  journal   = {Journal of NeuroEngineering and Rehabilitation},
  year      = {2004},
  volume    = {1},
  number    = {1},
  pages     = {5--20},
  issn      = {1743-0003},
  abstract  = {BACKGROUND:Previous results with the planar robot MIT-MANUS demonstrated positive benefits in trials with over 250 stroke patients. Consistent with motor learning, the positive effects did not generalize to other muscle groups or limb segments. Therefore we are designing a new class of robots to exercise other muscle groups or limb segments. This paper presents basic engineering aspects of a novel robotic module that extends our approach to anti-gravity movements out of the horizontal plane and a pilot study with 10 outpatients. Patients were trained during the initial six-weeks with the planar module (i.e., performance-based training limited to horizontal movements with gravity compensation). This training was followed by six-weeks of robotic therapy that focused on performing vertical arm movements against gravity. The 12-week protocol includes three one-hour robot therapy sessions per week (total 36 robot treatment sessions).RESULTS:Pilot study demonstrated that the protocol was safe and well tolerated with no patient presenting any adverse effect. Consistent with our past experience with persons with chronic strokes, there was a statistically significant reduction in tone measurement from admission to discharge of performance-based planar robot therapy and we have not observed increases in muscle tone or spasticity during the anti-gravity training protocol. Pilot results showed also a reduction in shoulder-elbow impairment following planar horizontal training. Furthermore, it suggested an additional reduction in shoulder-elbow impairment following the anti-gravity training.CONCLUSION:Our clinical experiments have focused on a fundamental question of whether task specific robotic training influences brain recovery. To date several studies demonstrate that in mature and damaged nervous systems, nurture indeed has an effect on nature. The improved recovery is most pronounced in the trained limb segments. We have now embarked on experiments that test whether we can continue to influence recovery, long after the acute insult, with a novel class of spatial robotic devices. This pilot results support the pursuit of further clinical trials to test efficacy and the pursuit of optimal therapy following brain injury.},
  doi       = {10.1186/1743-0003-1-5},
  groups    = {EMBC2013},
  pubmedid  = {15679916},
  timestamp = {2012.11.12},
  url       = {http://www.jneuroengrehab.com/content/1/1/5},
}

@InProceedings{Krishnan2008,
  author    = {Krishnan, N. C. and Colbry, D. and Juillard, C. and Panchanathan, S.},
  title     = {Realtime Human Activity Recognition Using Tri-axial Accelerometers},
  booktitle = {Sensors, Signals and Information Processing Workshop},
  year      = {2008},
  abstract  = {In this paper we describe a real time system for detecting and recognizing lower body activities (walking, sitting, standing, running and lying down) using streaming data from tri-axial accelerometers. While there have been various attempts to solve this problem, what makes our system unique is that it uses a minimal set of sensors and works in real time. We have divided the system into three components: preprocessing, feature extraction and classication. This paper describes each component and addresses the issue of locating the sensors on a human body. We also discuss different elementary signal processing techniques that we experimented with to extract salient features from the sensory stream, bearing in mind the computation costs of each method. We used the AdaBoost algorithm built on decision stumps for classi?cation, and our system is able to recognize each activity (walking, sitting, standing, running, lying down) with 95% accuracy.},
  groups    = {Lit Review 2013-09, STAT841},
  keywords  = {motion segmentation},
  review    = {- uses accel only
- wireless accel/BT interface
- thought of using LPFs, but didn't seem to impact performace

- pulled statistical (mean, variance, correlation) and spectral (energy, entropy) features
- wavelets and Fourier apparently sucks
- they used something called AdaBoost which was better than SVM
 - AdaBoost = "adaptive boosting", a machine learning technique 
- data is separated into small equal-length segments, PCA'ed (kept onty the top 3 dim), and each window is classified by a pre-trained AdaBoost algorithm

Accuracy at 95% when looked at 3 subjects, doing wlaking/sitting/standing/running/lying down with accel on right ankle and left thigh


Krishnan \etal \cite{Krishnan2008} split walking, sitting and running data into small equally-spaced windows, and perform PCA dimensionality reduction to reduce the input data to 3 DOFs. Statistical and spectral features, such as mean, variance and energy, for each window are calculated and classified via a pre-trained AdaBoost with decision stumps, which are 1-node decision trees. 3 subjects performing walking, standing, sitting, running and lying down motions were used in a $Ver_{AllPoints}$ veriication scheme. $Acc_{Class}$ was reported to be 95\% over 3 subjects.},
  timestamp = {2011.01.27},
}

@InProceedings{Krishnan2015,
  Title                    = {Transition state clustering: Unsupervised surgical trajectory segmentation for robot learning},
  Author                   = {Krishnan, S. and Garg, A. and Patil, S. and Lea, C. and Hager, G. and Abbeel, P. and Goldberg, K.},
  Booktitle                = {Proceedings of the International Symposium of Robotics Research},
  Year                     = {2015},

  Timestamp                = {2017.02.06}
}

@InProceedings{Krishnapuram2004,
  Title                    = {On semi-supervised classification},
  Author                   = {Krishnapuram, Balaji and Williams, David and Xue, Ya and Carin, Lawrence and Figueiredo, M{\'a}rio and Hartemink, Alexander J},
  Booktitle                = {Advances in neural information processing systems},
  Year                     = {2004},
  Pages                    = {721--728},

  Abstract                 = {A graph-based prior is proposed for parametric semi-supervised classi-
fication. The prior utilizes both labelled and unlabelled data; it also in-
tegrates features from multiple views of a given sample (
e.g.
, multiple
sensors), thus implementing a Bayesian form of co-training. An EM
algorithm for training the classifier automatically adjusts the tradeoff be-
tween the contributions of: (a) the labelled data; (b) the unlabelled data;
and (c) the co-training information. Active label query selection is per-
formed using a mutual information based criterion that explicitly uses the
unlabelled data and the co-training information. Encouraging results are
presented on public benchmarks and on measured data from single and
multiple sensors},
  Review                   = {Has a lot of math, but seems to rely on distance based clustering and EM learning.},
  Timestamp                = {2015.05.12}
}

@Book{Kroemer2001,
  Title                    = {Ergonomics, 2nd Ed.},
  Author                   = {Kroemer, K. and Kroemer, H. and Kroemer-Elbert, K.},
  Publisher                = {Prentice-Hall},
  Year                     = {2001},

  Timestamp                = {2012.01.25}
}

@Article{Krstic1999,
  Title                    = {Inverse optimal stabilization of a rigid spacecraft},
  Author                   = {M. Krstic and P. Tsiotras},
  Journal                  = {IEEE Transactions on Automatic Control},
  Year                     = {1999},
  Number                   = {5},
  Pages                    = {1042--1049},
  Volume                   = {44},

  Abstract                 = {The authors present an approach for constructing optimal feedback control laws for regulation of a rotating rigid spacecraft. They employ the inverse optimal control approach which circumvents the task of solving a Hamilton-Jacobi equation and results in a controller optimal with respect to a meaningful cost functional. The inverse optimality approach requires the knowledge of a control Lyapunov function and a stabilizing control law of a particular form. For the spacecraft problem, they are both constructed using the method of integrator backstepping. The authors give a characterization of (nonlinear) stability margins achieved with the inverse optimal control law},
  Doi                      = {10.1109/9.763225},
  ISSN                     = {0018-9286},
  Keywords                 = {Lyapunov methods;aerospace control;control system synthesis;feedback;inverse problems;optimal control;space vehicles;stability criteria;control Lyapunov function;integrator backstepping;inverse optimal control;inverse optimal stabilization;nonlinear stability margins;optimal feedback control construction;rotating rigid spacecraft;Automatic control;Backstepping;Cost function;Equations;Feedback control;Lyapunov method;Optimal control;Robust stability;Space vehicles;Upper bound},
  Timestamp                = {2016.07.27}
}

@InProceedings{Kuehne2011,
  Title                    = {{HMDB}: A large video database for human motion recognition},
  Author                   = {H. Kuehne and H. Jhuang and E. Garrote and T. Poggio and T. Serre},
  Booktitle                = {International Conference on Computer Vision},
  Year                     = {2011},
  Pages                    = {2556--2563},

  Doi                      = {10.1109/ICCV.2011.6126543},
  ISSN                     = {1550-5499},
  Keywords                 = {image motion analysis;object recognition;social networking (online);video databases;HMDB;YouTube;action recognition databases;camera motion;computer vision research;digitized movies;human action datasets;human motion recognition;image categories;large video database;occlusion;static image datasets;video quality;viewpoint;Cameras;Databases;Humans;Motion pictures;Training;Visualization;YouTube},
  Timestamp                = {2017.01.16}
}

@InCollection{Kulic2011,
  author    = {Kuli\'{c}, D. and Kragic, D. and Kr\"{u}ger, V.},
  title     = {Learning Action Primitives},
  booktitle = {Visual Analysis of Humans},
  publisher = {Springer London},
  year      = {2011},
  editor    = {Moeslund, T. B. and Hilton, A. and Kr\"{u}ger, V. and Sigal, L.},
  pages     = {333--353},
  isbn      = {978-0-85729-996-3},
  abstract  = {The use of action primitives plays an important role in modeling human
and robot actions. Action primitives are motivated not only by neuro-biological findings, they also allow an efficient and effective action modeling from an informationtheoretic viewpoint. Different approaches for modeling action primitives have been
proposed. This chapter overviews the recent approaches for learning and modeling
action primitives for human and robot action and describes common approaches
such as stochastic methods and dynamical systems approaches. Active research
questions in the field are introduced, including temporal segmentation, dimensionality reduction, and the integration of action primitives into complex behaviors.},
  doi       = {10.1007/978-0-85729-997-0_17},
  groups    = {Lit Review 2013-09},
  language  = {English},
  review    = {Connections to biological models of movement primitives
- Mirror neurons
- Central pattern generation
- reaction reflexes
-> some papers trying to explain 

Have a fair amount of segmentation papers cited, but I've got them all already},
  timestamp = {2013.10.01},
}

@InProceedings{Kulic2009d,
  Title                    = {Whole body motion primitive segmentation from monocular video},
  Author                   = {Kuli\'{c}, D. and Dongheui Lee and Nakamura, Y.},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2009},
  Pages                    = {3166-3172},

  Abstract                 = {This paper proposes a novel approach for motion primitive segmentation from continuous full body human motion captured on monocular video. The proposed approach does not require a kinematic model of the person, nor any markers on the body. Instead, optical flow computed directly in the image plane is used to estimate the location of segment points. The approach is based on detecting tracking features in the image based on the Shi and Thomasi algorithm. The optical flow at each feature point is then estimated using the Lucas Kanade Pyramidal Optical Flow estimation algorithm. The feature points are clustered and tracked on-line to find regions of the image with coherent movement. The appearance and disappearance of these coherent clusters indicates the start and end points of motion primitive segments. The algorithm performance is validated on full body motion video sequences, and compared to a joint-angle, motion capture based approach. The results show that the segmentation performance is comparable to the motion capture based approach, while using much simpler hardware and at a lower computational effort.},
  Doi                      = {10.1109/ROBOT.2009.5152266},
  ISSN                     = {1050-4729},
  Keywords                 = {feature extraction;humanoid robots;image motion analysis;image segmentation;image sequences;mobile robots;pattern clustering;video signal processing;Lucas Kanade pyramidal optical flow estimation algorithm;Shi-Thomasi algorithm;coherent cluster;coherent movement;feature detection;feature tracking;image plane;location estimation;monocular video sequence;whole body motion primitive segmentation;Clustering algorithms;Computer vision;Hardware;Humans;Image motion analysis;Image segmentation;Kinematics;Optical computing;Tracking;Video sequences},
  Review                   = {Segmentation based on video. Uses optical flow.

If optical flow is evaluated on the entire image, many of the pixels will contain invalid estimates, due to lack of texture
or other unique features around a given pixel, occlusions between the two frames, depth discontinuities or reflection
highlights. To reduce computational burden and the number of invalid optical flow values, optical flow is not computed
for the entire image. Instead, the image is first searched for good features to track, using the Shi and Tomasi algorithm. 
This algorithm formally defines the feature’s quality based on how well it can be tracked.

Segment is declared when a cluster (in an image) starts/stops moves or changes directions. When a portion of the body is moving, optical flow occurs, which disappears at start/end of motion. 

Once reliable features are found in the image, the optical flow for those features is computed via the pyramidal version
of the Lucas Kanade algorithm [2], [27]. The Lucas Kanade algorithm solves the optical flow equation (Equation 2)
iteratively, using Newton-Raphson},
  Timestamp                = {2013.10.02}
}

@InProceedings{Kulic2008,
  Title                    = {Incremental learning of full body motion primitives for humanoid robots},
  Author                   = {D. Kuli\'{c} and D. Lee and C. Ott and Y. Nakamura},
  Booktitle                = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  Year                     = {2008},
  Pages                    = {326-332},

  __markedentry            = {},
  Doi                      = {10.1109/ICHR.2008.4756000},
  ISSN                     = {2164-0572},
  Keywords                 = {hidden Markov models;humanoid robots;learning systems;mobile robots;path planning;robot kinematics;trees (mathematics);continuous observation sequence;full body motion primitive graph incremental learning system;hidden Markov model;hierarchical tree structure representation;humanoid robot;inverse kinematic;motion generation;motion recognition;motion segmentation;stochastic segmentation;Abstracts;Clustering algorithms;Data mining;Hidden Markov models;Humanoid robots;Humans;Stochastic processes;Testing;Tree data structures;Tree graphs},
  Timestamp                = {2017.04.24}
}

@InProceedings{Kulic2010_IROS,
  Title                    = {Incremental Learning of Human Behaviors using Hierarchical Hidden {Markov} Models},
  Author                   = {Kuli\'{c}, D. and Nakamura, Y.},
  Booktitle                = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2010},
  Pages                    = {4649--4655},

  Abstract                 = {This paper proposes a novel approach for extracting a model of movement primitives and their sequential relationships during online observation of human motion. In the proposed approach, movement primitives, modeled as hidden Markov models, are autonomously segmented and learned incrementally during observation. At the same time, a higher abstraction level hidden Markov model is also learned, encapsulating the relationship between the movement primitives. For the higher level model, each hidden state represents a motion primitive, and the observation function is based on the likelihood that the observed data is generated by the motion primitive model. An approach for incremental training of the higher order model during online observation is developed. The approach is validated on a dataset of continuous movement data.},
  Doi                      = {10.1109/IROS.2010.5650813},
  ISSN                     = {2153-0858},
  Keywords                 = {behavioural sciences;hidden Markov models;learning (artificial intelligence);mobile robots;abstraction level;hierarchical hidden markov model;human behavior;human motion;incremental learning;observation function;online observation},
  Review                   = {Similar to Kulic2009_TRO but uses a different organization scheme.


Uses Kohlmorgen and Lemm to perform unsupervised segmentation, and create primitive HMMs out of each recognized movement. But the previous organizational scheme is deterministic, and thus was sensitive to errors. Instead, a higher level HMM is used to model the transitions between motion primitives; that is, each state correspond to a primitive, which loads a lower level model, where each state is a keypose. 

Procedure
- Kohlmorgen and Lemm 
 - Sliding windows produce PDFs, which are formulated into states
 - State transition model defined so that it's lowest cost to stay in the same state
 - Observation model defined to favour data similiarty from a high cost to switch to a new state -> solved by Viterbi
- Hierachical tree
 - Each node in tree represent a primitive and is modelled by an HMM
 - Factorial HMMs can be used instead, where multiple HMM chains are used to model, and are summed to produce the output
 - New motions observed are encoded into an HMM and compared to existing nodes, using KL. Existing primitives are merged, new primitives are added.
- Higher level HMM (new in this paper)
 - Ergodic model
 - Each node is a primitive -> but calls the lower level HMM for forward algorithm
 - Transitions between the primitives is learned by Baum-Welch
 - Made online by adding an equation that can update the state tx mtx and priors easily},
  Timestamp                = {2014.07.29}
}

@Article{Kulic2009b,
  Title                    = {Incremental Learning and Memory Consolidation of Whole Body Human Motion Primitives},
  Author                   = {Kuli\'{c}, D. and Nakamura, Y.},
  Journal                  = {Adaptive Behavior},
  Year                     = {2009},
  Number                   = {6},
  Pages                    = {484-507},
  Volume                   = {17},

  Abstract                 = {The ability to learn during continuous and on-line observation would be advantageous for humanoid robots, as it would enable them to learn during co-location and interaction in the human environment. However, when motions are being learned and clustered on-line, there is a trade-off between classification accuracy and the number of training examples, resulting in potential misclassifications both at the motion and hierarchy formation level. This article presents an approach enabling fast on-line incremental learning, combined with an incremental memory consolidation process correcting initial misclassifications and errors in organization, to improve the stability and accuracy of the learned motions, analogous to the memory consolidation process following motor learning observed in humans. Following initial organization, motions are randomly selected for reclassification, at both low and high levels of the hierarchy. If a better reclassification is found, the knowledge structure is reorganized to comply. The approach is validated during incremental acquisition of a motion database containing a variety of full body motions.},
  Doi                      = {10.1177/1059712309342487},
  Eprint                   = {http://adb.sagepub.com/content/17/6/484.full.pdf+html},
  Keywords                 = {motion primitive},
  Timestamp                = {2011.01.09},
  Url                      = {http://adb.sagepub.com/content/17/6/484.abstract}
}

@Conference{Kulic2008b,
  author    = {Kuli\'{c}, D. AND Nakamura, Y.},
  title     = {Scaffolding On-line Segmentation of Full Body Human Motion Patterns},
  booktitle = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year      = {2008},
  abstract  = {This paper develops an approach for on-line segmentation of whole body human motion patterns during human motion observation and learning. A Hidden Markov Model is used to represent the incoming data sequence, where each model state represents the probability density estimate over a window of the data. Based on the assumption that data belonging to the sam emotion primitive will have the sam eunderlying distribution, the segmentation is implemented by finding the optimum state sequence over the developed model. The basic algorithm is modified to add the capability for modifying the model based on known motion primitives. The inclusion of such scaffolding motion primitives can improve the performance of the basic segmentation algorithm. The modified algorithm is tested on a corpus of continuous human motion data to show the efficacy of the proposed approach.},
  groups    = {Lit Review 2013-09},
  keywords  = {motion segmentation},
  review    = {Previous works:
Mataric - Looked at velocity of joint angles
Pomplun - Used thresholding for joint angle velocities to determine segmentation point
Fod - Assumed there is a change in direction between motion primitives, so a Zero Velocity Crossing must be detected between primitivies
Lieberman - Automated threshold selection and added situational heuristics. However, the curse of dimentionality kicks in pretty hard there
Koenig - Segmentation algorithm based on variance of feature data
Kohlmorgen - Automatic online segmentation. Assumes data from the sam emotion primitive will have the same underlying distribution, so analyzes motions as probability densities in the format of HMM states. Works well when many joints are all moving, not so well when only a few are. 
Takano - Compares the error between motion data from an HMM and the observation. If the error is above a certain threshold, a segment point is declared

Objective:
Want a robot that can learn and interact with a human. Can catigorize motion primitives and group them together as appropriate
- Uses Kohlmorgen-Lemm's idea and convert everything to Gaussians
- Group these Gaussians together in HMM chains (or FHMM chains, if the motion is really complicated)
- Compare the HMM chains to existing templates, and group it with the most similar data available
- Within the grouping, clustering executed to determine if a new group needs to be formed or not},
  timestamp = {2009.11.12},
}

@Article{Kulic2009_TRO,
  author    = {Kuli\'{c}, D. and Takano, W. and Nakamura, Y.},
  title     = {Online Segmentation and Clustering From Continuous Observation of Whole Body Motions},
  journal   = {IEEE Transactions on Robotics},
  year      = {2009},
  volume    = {25},
  pages     = {1158--1166},
  issn      = {1552-3098},
  abstract  = {This paper describes a novel approach for incremental learning of human motion pattern primitives through online observation of human motion. The observed time series data stream is first stochastically segmented into potential motion primitive segments, based on the assumption that data belonging to the same motion primitive will have the same underlying distribution. The motion segments are then abstracted into a stochastic model representation and automatically clustered and organized. As new motion patterns are observed, they are incrementally grouped together into a tree structure, based on their relative distance in the model space. The tree leaves, which represent the most specialized learned motion primitives, are then passed back to the segmentation algorithm so that as the number of known motion primitives increases, the accuracy of the segmentation can also be improved. The combined algorithm is tested on a sequence of continuous human motion data that are obtained through motion capture, and demonstrates the performance of the proposed approach.},
  doi       = {10.1109/TRO.2009.2026508},
  groups    = {STAT841, IROS2014, EMBC2014},
  keywords  = {clustering algorithm;human motion pattern primitives;humanoid robots;incremental learning;online observation;online segmentation;stochastic model representation;stochastic segmentation;time series data stream;tree structure;humanoid robots;image motion analysis;image segmentation;intelligent robots;learning (artificial intelligence);pattern clustering;robot vision;stochastic processes;time series;trees (mathematics);},
  review    = {- online, stocastic segmentation, unsupervisied, HMM, clustering, tree
- uses Kohlmorgen and Lemm's segmentation method
 - embed data stream to a higher dimension
 - take density distribution of a moving window
 - "temp state"
 - distance between windowed distribution is calculated
 - observation probability based on state distance is calculated with HMM
 - Viterbi used to determine state transision matrix
 - segment based on state transistion
- scaffolding
 - known motion is inserted as a "perm state"
 - if distance between input data and "perm state" are small, label it as 


Kuli\'{c} \etal \cite{Kulic2009a} extended Kohlmorgen's algorithm \cite{Kohlmorgen2002} by clustering together previously segmented sequences to generate new templates in real-time. Once a segment window has been identified, the segment is modeled as a HMM. The Kullback-Leibler distance between the observed HMM and existing models is calculated. If the distance is small, then the observation HMM is merged into the corresponding existing HMM. If not, it is added to the template collection, and used to improve the segmentation. The algorithm was verified on an 18-minute full-body motion sequence, and shows good segmentation accuracy, but also suffers from false positives due to the algorithm oversegmenting motion sequences into smaller subsequences that were considered to be a single segment by the manual segmentation.},
  timestamp = {2011.02.12},
}

@Article{Kulic2008_IJRR,
  Title                    = {Incremental Learning, Clustering and Hierarchy Formation of Whole Body Motion Patterns using Adaptive Hidden Markov Chains},
  Author                   = {Kuli\'{c}, D. and Takano, W. and Nakamura, Y.},
  Journal                  = {The International Journal of Robotics Research},
  Year                     = {2008},
  Number                   = {7},
  Pages                    = {761-784},
  Volume                   = {27},

  Abstract                 = {This paper describes a novel approach for autonomous and incremental learning of motion pattern primitives by observation of human motion. Human motion patterns are abstracted into a dynamic stochastic model, which can be used for both subsequent motion recognition and generation, analogous to the mirror neuron hypothesis in primates. The model size is adaptable based on the discrimination requirements in the associated region of the current knowledge base. A new algorithm for sequentially training the Markov chains is developed, to reduce the computation cost during model adaptation. As new motion patterns are observed, they are incrementally grouped together using hierarchical agglomerative clustering based on their relative distance in the model space. The clustering algorithm forms a tree structure, with specialized motions at the tree leaves, and generalized motions closer to the root. The generated tree structure will depend on the type of training data provided, so that the most specialized motions will be those for which the most training has been received. Tests with motion capture data for a variety of motion primitives demonstrate the efficacy of the algorithm.},
  Doi                      = {10.1177/0278364908091153},
  Eprint                   = {http://ijr.sagepub.com/content/27/7/761.full.pdf+html},
  Keywords                 = {motion primitive},
  Review                   = {Previous works:
Mataric - Looked at velocity of joint angles
Pomplun - Used thresholding for joint angle velocities to determine segmentation point
Fod - Assumed there is a change in direction between motion primitives, so a Zero Velocity Crossing must be detected between primitivies
Lieberman - Automated threshold selection and added situational heuristics. However, the curse of dimentionality kicks in pretty hard there
Koenig - Segmentation algorithm based on variance of feature data
Kohlmorgen - Automatic online segmentation. Assumes data from the sam emotion primitive will have the same underlying distribution, so analyzes motions as probability densities in the format of HMM states. Works well when many joints are all moving, not so well when only a few are. 
Takano - Compares the error between motion data from an HMM and the observation. If the error is above a certain threshold, a segment point is declared

A lot of current works involves a priori/offline learning. 

Objective:
Want a robot that can learn and interact with a human. Can catigorize motion primitives and group them together as appropriate.
- Can use HMM (Viterbi)
 - or Factorial HMM?
 - Assumes that there are multiple processes that interact to create a single output
 - Each process has its own state transition model
 - The output of all the processes are combined to generate an output
 - Exact algorithm is computationally expensive
 - Instead, we'll use a signal HMM chain when the motions are easy to distingusish
 - And employ multiple chains when motions are similar to each other
- Model training (Baum-Welch) -> EM process 
Unsupervised Probabilistic Segmentation: Uses HMM (Viterbi). -> (not sure if understand the Kohlmorgen-Lemm algor). New motions are accounted for and can be inserted into the HMM
Scaffolding the Segmentation: Figure out how active a joint is},
  Timestamp                = {2011.01.07},
  Url                      = {http://ijr.sagepub.com/content/27/7/761.abstract}
}

@InProceedings{Kulic2009c,
  Title                    = {Detecting changes in motion characteristics during sports training},
  Author                   = {Kuli\'{c}, D. and Venture, G. and Nakamura, Y.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2009},
  Pages                    = {4011--4014},

  Abstract                 = {This paper proposes a stochastic approach for representing and analyzing the gradual changes that occur in human movement during sports training. Human movement primitives are described using factorial hidden Markov models, and compared using the Kullback-Liebler distance, a measure of information divergence between two models. This representation is combined with an automated segmentation and clustering approach to enable the system to autonomously extract and group together movement primitives from continuous observation of human movement data. The proposed system is tested on a human movement dataset obtained over 4 months during training for a marathon. Experimental results demonstrate that the system is able to detect gradual changes in the human movement.},
  Doi                      = {10.1109/IEMBS.2009.5333502},
  ISSN                     = {1557-170X},
  Keywords                 = {Kullback-Liebler distance;automated segmentation;clustering approach;factorial hidden Markov models;human movement;information divergence;motion characteristics;sports training;stochastic approach;biomechanics;hidden Markov models;image motion analysis;motion measurement;stochastic processes;Adult;Algorithms;Athletes;Automation;Biomechanics;Cluster Analysis;Computer Simulation;Equipment Design;Female;Humans;Markov Chains;Motion;Movement;Running;},
  Timestamp                = {2011.06.10}
}

@Article{Kulic2016_TRO,
  Title                    = {Anthropomorphic Movement Analysis and Synthesis: A Survey of Methods and Applications},
  Author                   = {D. Kuli\'{c} and G. Venture and K. Yamane and E. Demircan and I. Mizuuchi and K. Mombaur},
  Journal                  = {IEEE Transactions on Robotics},
  Year                     = {2016},
  Number                   = {4},
  Pages                    = {776--795},
  Volume                   = {32},

  Abstract                 = {The anthropomorphic body form is a complex articulated system of links/limbs and joints, simultaneously redundant and underactuated, and capable of a wide range of sophisticated movement. The human body and its movement have long been a topic of study in physiology, anatomy, biomechanics, and neuroscience and have served as inspiration for humanoid robot design and control. This survey paper reviews the literature on robotics research using anthropomorphic design principles as an inspiration, at both the design and control levels. Next, anthropomorphic body modeling, motion analysis, and synthesis techniques are overviewed. Finally, key applications arising at the intersection of robotics and human movement science are introduced. The survey ends with a discussion of open research questions and directions for future work.},
  Doi                      = {10.1109/TRO.2016.2587744},
  ISSN                     = {1552-3098},
  Keywords                 = {control system synthesis;humanoid robots;motion control;reviews;anatomy;anthropomorphic body form;anthropomorphic body modeling;anthropomorphic design principles;anthropomorphic movement analysis;biomechanics;complex articulated system;human movement science;humanoid robot control;humanoid robot design;literature review;motion analysis;neuroscience;physiology;redundant system;robotics research;sophisticated movement;synthesis techniques;underactuated system;Actuators;Dynamics;Elasticity;Humanoid robots;Muscles;Robot sensing systems;Anthropomorphic modeling;control;dynamics;kinematics;movement science},
  Timestamp                = {2017.01.03}
}

@Article{Kuniyoshi1994,
  Title                    = {Learning by watching: extracting reusable task knowledge from visual observation of human performance},
  Author                   = {Kuniyoshi, Y. and Inaba, M. and Inoue, H.},
  Journal                  = {IEEE Transactions on Robotics and Automation},
  Year                     = {1994},

  Month                    = {Dec},
  Number                   = {6},
  Pages                    = {799-822},
  Volume                   = {10},

  Abstract                 = {A novel task instruction method for future intelligent robots is presented, In our method, a robot learns reusable task plans by watching a human perform assembly tasks. Functional units and working algorithms for visual recognition and analysis of human action sequences are presented. The overall system is model based and integrated at the symbolic level. Temporal segmentation of a continuous task performance into meaningful units and identification of each operation is processed in real time by concurrent recognition processes under active attention control. Dependency among assembly operations in the recognized action sequence is analyzed, which results in a hierarchical task plan describing the higher level structure of the task. In another workspace with a different initial state, the system re-instantiates and executes the task plan to accomplish an equivalent goal. The effectiveness of our method is supported by experimental results with block assembly tasks},
  Doi                      = {10.1109/70.338535},
  ISSN                     = {1042-296X},
  Keywords                 = {assembling;image recognition;intelligent control;robot programming;robots;active attention control;block assembly tasks;concurrent recognition processes;human action sequences;human performance observation;intelligent robots;reusable task knowledge extraction;reusable task plans;robot programming;task instruction method;temporal segmentation;visual observation;visual recognition;Computational modeling;Education;Hardware;Humans;Intelligent robots;Manipulators;Robot programming;Robot sensing systems;Robotic assembly;Service robots},
  Timestamp                = {2014.12.22}
}

@Article{Kuo2002,
  Title                    = {Energetics of Actively Powered Locomotion Using the Simplest Walking Model},
  Author                   = {Kuo, A. D.},
  Journal                  = {Journal of Biomechanical Engineering},
  Year                     = {2002},
  Number                   = {1},
  Pages                    = {113-120},
  Volume                   = {124},

  Abstract                 = {We modified an irreducibly simple model of passive dynamic walking to walk on level ground, and used it to study the energetics of walking and the preferred relationship between speed and step length in humans. Powered walking was explored using an impulse applied at toe-off immediately before heel strike, and a torque applied on the stance leg. Although both methods can supply energy through mechanical work on the center of mass, the toe-off impulse is four times less costly because it decreases the collision loss at heel strike. We also studied the use of a hip torque on the swing leg that tunes its frequency but adds no propulsive energy to gait. This spring-like actuation can further reduce the collision loss at heel strike, improving walking energetics. An idealized model yields a set of simple power laws relating the toe-off impulses and effective spring constant to the speed and step length of the corresponding gait. Simulations incorporating nonlinear equations of motion and more realistic inertial parameters show that these power laws apply to more complex models as well.},
  Doi                      = {10.1115/1.1427703},
  Keywords                 = {biomechanics; gait analysis; physiological models; kinematics; muscle; ECE780},
  Publisher                = {ASME},
  Timestamp                = {2011.03.10},
  Url                      = {http://link.aip.org/link/?JBY/124/113/1}
}

@InProceedings{Lam2014_EMBC,
  Title                    = {Improving Rehabilitation Exercise Performance through Visual Guidance},
  Author                   = {Lam, A. W. K. AND HajYasien, A. AND Kuli\'{c}, D.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2014},
  Pages                    = {1735--1738},

  Timestamp                = {2014.07.25}
}

@Article{Lam2016_HCI,
  author    = {Lam, A. W. K. and Verona-Marin, D. and Li, Y. and Fergenbaum, M. and Kuli\'{c}, D.},
  title     = {Automated Rehabilitation System: Movement Measurement and Feedback for Patients and Physiotherapists in the Rehabilitation Clinic},
  journal   = {Human Computer Interaction},
  year      = {2016},
  volume    = {31},
  pages     = {294 -- 334},
  file      = {Lam2016_HCI.pdf:MyWork\\Lam2016_HCI.pdf:PDF},
  owner     = {jf2lin},
  timestamp = {2015.10.18},
}

@Article{Lan2015,
  Title                    = {Automated human motion segmentation via motion regularities},
  Author                   = {Lan, R. and Sun, H.},
  Journal                  = {The Visual Computer},
  Year                     = {2015},
  Pages                    = {35--53},
  Volume                   = {31},

  Doi                      = {10.1007/s00371-013-0902-5},
  ISSN                     = {0178-2789},
  Keywords                 = {Motion capture; Motion representation; Motion segmentation; Hierarchical clustering; Latent Dirichlet allocation; Topic mining},
  Language                 = {English},
  Publisher                = {Springer Berlin Heidelberg},
  Review                   = {Basically, want to segment movement data

"The key point is to extract motion regularities independent of motion types from a small set of unlabeled training samples." - want to extract a motion vocab (seq of motions that naturally flow togethre), and uses hierchical clustering to obtain this vocab. This vocab can be regarded as th eminimum set of poses thatconstituts ADL. compared "movements" to "words"
 
in addition, want to discover motion topic. uses the Latent Dirichlet allocation to find "group of words" based on the mo-vocab, and group similar types of movements (or seq of movements) together. This forms the segments. 

So for a given motion sequ ("mo-doc"), we convert the series into chunks based on mo-vocab, then group pieces together as mo-topic. a "local sematic coherence curve" calculates the change in mo-topic distribution, and by thresholding against this curve, we can segment motion seq into semantically coherent subsegments.
 
training
1) a 'model' pose for each 'mo-word' is made
2) LDA is trained. parameters estimated by Gibbs sampling, which is a Markov Chain Monte Carlo algorithm. 
3) LSCC is trained


procedure:
1) discretize the pose by replacing the current pose with the closest one, determined by clustering. discritizing the data makes it easier to work with
2) Use LDA (latent dirichlet allocation) to group sequences of movements together (this is a sub primitive) - this creates the frame
3) calculate the similarity (by some dist metrics - cosine similarity) between the current frame and the subsequent. at thresholds of this, a segment is declared. i guess this is the actual segment.

- don't think it's online. supervised offline?
- they use temporal accuracy assessment method!},
  Timestamp                = {2015.06.30},
  Url                      = {http://dx.doi.org/10.1007/s00371-013-0902-5}
}

@PhdThesis{Landry2004,
  Title                    = {Physical therapy services in Ontario: assessing a changing public/private mix},
  Author                   = {Landry, M. D.},
  School                   = {University of Toronto},
  Year                     = {2004},

  Keywords                 = {Physiotherapy},
  Timestamp                = {2011.12.23}
}

@Article{Landry2006,
  Title                    = {Assessing the consequences of delisting publicly funded community-based physical therapy on self-reported health in Ontario, Canada: a prospective cohort study},
  Author                   = {Landry, M. D. and Deber, R. B. and Jaglal, S. and Laporte, A and Holyoke, P and Devitt, R. Cott, C.},
  Journal                  = {International Journal of Rehabilitation Research},
  Year                     = {2006},
  Pages                    = {303--307},
  Volume                   = {29},

  Abstract                 = {In early 2005, Canada's most populous province (Ontario) partially delisted publicly funded community-based physical therapy services by restricting the eligibility criteria within designated clinics. The aim of this research was to assess the consequences of this policy decision using a prospective cohort design. In this study, we followed clients before and after delisting in order to assess change in access and self-reported health status. The results indicated that 81 of 113 (71.7%) participants who required physical therapy services continued to receive them after delisting because they remained eligible, were privately insured and/or were able to pay out-of-pocket. Twenty (17.7%) required services but did not receive them because they were uninsured or were not able to pay privately. The remaining participants were discharged at follow-up. Controlling for gender, age, employment and condition, clients who maintained access were 10 times more likely to report very good or excellent health status compared to those who did not receive services (odds ratio: 10.72; 95% confidence interval: 2.20-52.25). Given the association between poor self-reported health status and morbidity and mortality, future research needs to examine the long-term impact to determine the extent to which delisting may be associated with increased utilization of hospitals and family physicians.},
  Keywords                 = {Physiotherapy},
  Timestamp                = {2011.12.23}
}

@Article{Landry2007,
  Title                    = {Rehabilitation services after total joint replacement in Ontario, Canada: can 'prehabilitation' programs mediate an increasing demand?},
  Author                   = {Landry, M. D. and Jaglal, S. B. and Wodchis, W. P. and Cooper, N.S. and Cott, C. A.},
  Journal                  = {International Journal of Rehabilitation Research},
  Year                     = {2007},
  Pages                    = {297--303},
  Volume                   = {30},

  Abstract                 = {Total joint replacements (TJR) have emerged as a critical health policy issue. In particular, Canadian demand for these surgeries is forecast to grow annually by 8.7% in the next decade. Although the medical and surgical aspects of TJR have received considerable attention, very little research has explored the impact of increased TJR on the demand for rehabilitation services. In this study, we conducted seven focus group discussions across the province of Ontario (Canada) with multiple stakeholders (n=50) ranging from clinicians and administrators, to policy makers and researchers. Our results indicate that demand for rehabilitation following TJR is rising sharply and that there are three primary factors affecting such demand: (i) increase in the absolute number of TJR surgeries is increasing demand across the continuum of care; (ii) changing profile of clients whereby 'younger and active' groups are more willing to undergo surgery, and 'older and complex' groups are presenting with increased rates of medical complications and comorbidities; and (iii) widespread use of clinical pathways has increased requirements within the rehabilitation sector, but often without corresponding adjustments in levels of human resources. To align increasing demand with supply in the long term, participants offered strong support for health promotion and prevention programs, but they also highlighted the short-term benefits of implementing 'prehabilitation' programs for clients waiting for surgery. Overall, our results indicate that the demand for rehabilitation services after TJR is increasing and that innovative approaches to care delivery are required to align increasing demand with supply.},
  Keywords                 = {Physiotherapy},
  Timestamp                = {2011.12.23}
}

@Conference{Lang2005,
  Title                    = {Calibration of Hybrid Vision/Inertial Tracting Systems},
  Author                   = {Lang, P. and Pinz, A.},
  Booktitle                = {Proceedings of InerVis: Workshop on Integration of Vision and Inertial Sensors},
  Year                     = {2005},

  Abstract                 = {Within a hybrid vision / inertial tracking system proper calibration of the sensors and their relative pose is essential. We present a new method for 3-axis inertial sensor calibration based on model fitting and a method to find the rotation between vision and inertial system based on rotation differences. We achieve a coordinate system rotation mismatch of < 1 degree with respect to mechanical setup and sensor performance.},
  Keywords                 = {IMU calibration},
  Review                   = {- Don't understand exactly the underlying physics of IMUs, or is sometimes just a linearization/approximation. The measurements tend to some form of mapping or weight determination
 - weighting might be important instead of simple rotation since axes might not be perfectly ortho
- uses MATLAB's fmincon (constrained nonlinear optimizer)
- Can't assume that sensors are perfectly perpendicular, so need to use matrix forms of fitting functions (ie y = Kx+b)

- Accel
 - the horizontal axis must be zero at rest
 - norm must be 1g at rest
 - uses a cost opt minimzation

- Gyro
 - the axis being rotated must be equal the applied ang velo
 - all other axis should be zero

- they calculate rotation in vision space and compare it to rotation in inertial space

(come back, looks interesting)},
  Timestamp                = {2011.07.19}
}

@Article{Laptev2005,
  Title                    = {On Space-Time Interest Points},
  Author                   = {Laptev, Ivan},
  Journal                  = {International Journal of Computer Vision},
  Year                     = {2005},
  Note                     = {10.1007/s11263-005-1838-7},
  Pages                    = {107-123},
  Volume                   = {64},

  Abstract                 = {Local image features or interest points provide compact and abstract representations of patterns in an image. In this paper, we extend the notion of spatial interest points into the spatio-temporal domain and show how the resulting features often reflect interesting events that can be used for a compact representation of video data as well as for interpretation of spatio-temporal events.},
  Affiliation              = {IRISA/INRIA Campus Beaulieu 35042 Rennes Cedex France},
  ISSN                     = {0920-5691},
  Issue                    = {2},
  Keyword                  = {Computer Science},
  Keywords                 = {ECE780},
  Publisher                = {Springer Netherlands},
  Timestamp                = {2011.03.05},
  Url                      = {http://dx.doi.org/10.1007/s11263-005-1838-7}
}

@InProceedings{Laptev2008,
  author               = {Laptev, I. and Marszalek, M. and Schmid, C. and Rozenfeld, B.},
  title                = {Learning realistic human actions from movies},
  booktitle            = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year                 = {2008},
  pages                = {1--8},
  abstract             = {The aim of this paper is to address recognition of natural human actions in diverse and realistic video settings. This challenging but important subject has mostly been ignored in the past due to several problems one of which is the lack of realistic and annotated video datasets. Our first contribution is to address this limitation and to investigate the use of movie scripts for automatic annotation of human actions in videos. We evaluate alternative methods for action retrieval from scripts and show benefits of a text-based classifier. Using the retrieved action samples for visual learning, we next turn to the problem of action classification in video. We present a new method for video classification that builds upon and extends several recent ideas including local space-time features, space-time pyramids and multi-channel non-linear SVMs. The method is shown to improve state-of-the-art results on the standard KTH action dataset by achieving 91.8% accuracy. Given the inherent problem of noisy labels in automatic annotation, we particularly investigate and show high tolerance of our method to annotation errors in the training set. We finally apply the method to learning and classifying challenging action classes in movies and show promising results.},
  citeulike-article-id = {3429777},
  citeulike-linkout-0  = {http://dblp.uni-trier.de/rec/bibtex/conf/cvpr/LaptevMSR08},
  citeulike-linkout-1  = {http://dx.doi.org/10.1109/CVPR.2008.4587756},
  citeulike-linkout-2  = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4587756},
  day                  = {28},
  doi                  = {10.1109/CVPR.2008.4587756},
  groups               = {IROS2014},
  isbn                 = {978-1-4244-2242-5},
  journal              = {Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on},
  keywords             = {action, activity, crowd, crowdreview, descriptor, feature, features; ECE780},
  location             = {Anchorage, AK, USA},
  posted-at            = {2010-05-28 16:10:34},
  timestamp            = {2011.03.05},
  url                  = {http://dx.doi.org/10.1109/CVPR.2008.4587756},
}

@Article{Lara2013,
  Title                    = {A Survey on Human Activity Recognition using Wearable Sensors},
  Author                   = {Lara, O. D. and Labrador, M. A.},
  Journal                  = {IEEE Communications Surveys Tutorials},
  Year                     = {2013},
  Pages                    = {1192--1209},
  Volume                   = {15},

  Abstract                 = {Providing accurate and opportune information on people's activities and behaviors is one of the most important tasks in pervasive computing. Innumerable applications can be visualized, for instance, in medical, security, entertainment, and tactical scenarios. Despite human activity recognition (HAR) being an active field for more than a decade, there are still key aspects that, if addressed, would constitute a significant turn in the way people interact with mobile devices. This paper surveys the state of the art in HAR based on wearable sensors. A general architecture is first presented along with a description of the main components of any HAR system. We also propose a two-level taxonomy in accordance to the learning approach (either supervised or semi-supervised) and the response time (either offline or online). Then, the principal issues and challenges are discussed, as well as the main solutions to each one of them. Twenty eight systems are qualitatively evaluated in terms of recognition performance, energy consumption, obtrusiveness, and flexibility, among others. Finally, we present some open problems and ideas that, due to their high relevance, should be addressed in future research.},
  Doi                      = {10.1109/SURV.2012.110112.00192},
  ISSN                     = {1553-877X},
  Keywords                 = {image motion analysis;learning (artificial intelligence);mobile computing;wearable computers;energy consumption;human activity recognition;mobile devices;open problems;pervasive computing;recognition performance;response time;semi-supervised learning;two-level taxonomy;wearable sensors;Accelerometers;Feature extraction;Pervasive computing;Wearable sensors;Human-centric sensing;context awareness;machine learning;mobile applications},
  Timestamp                = {2014.12.08}
}

@Article{Lara2012,
  Title                    = {Centinela: A human activity recognition system based on acceleration and vital sign data },
  Author                   = {Lara, O. D. and P\'{e}rez, A. J. and Labrador, M. A. and Posada, J. D.},
  Journal                  = {Pervasive and Mobile Computing },
  Year                     = {2012},
  Pages                    = {717--729},
  Volume                   = {8},

  Abstract                 = {This paper presents Centinela, a system that combines acceleration data with vital signs to achieve highly accurate activity recognition. Centinela recognizes five activities: walking, running, sitting, ascending, and descending. The system includes a portable and unobtrusive real-time data collection platform, which only requires a single sensing device and a mobile phone. To extract features, both statistical and structural detectors are applied, and two new features are proposed to discriminate among activities during periods of vital sign stabilization. After evaluating eight different classifiers and three different time window sizes, our results show that Centinela achieves up to 95.7% overall accuracy, which is higher than current approaches under similar conditions. Our results also indicate that vital signs are useful to discriminate between certain activities. Indeed, Centinela achieves 100% accuracy for activities such as running and sitting, and slightly improves the classification accuracy for ascending compared to the cases that utilize acceleration data only. },
  Doi                      = {http://dx.doi.org/10.1016/j.pmcj.2011.06.004},
  ISSN                     = {1574-1192},
  Keywords                 = {Feature extraction},
  Timestamp                = {2014.12.21}
}

@InProceedings{Lartillot2007,
  Title                    = {A matlab toolbox for musical feature extraction from audio},
  Author                   = {Lartillot, O. and Toiviainen, P.},
  Booktitle                = {International Conference on Digital Audio Effects},
  Year                     = {2007},
  Pages                    = {237--244},

  Review                   = {- Wrote a MATLAB tookbox to extract musical features from audio files. Has segmentation tools
- The data is divided up into smaller frames. Built-in seg tools can be set to segment based on various features: MFCC (Cepstral coefficients, a frequency-based representation of the audio signal). Distance between each frame can be calculated based on these features and a similarity matrix can be construsted. A convolution on the diagonal of the matrix will rpdouce a novelty curve that indicates the temporal locations of significant texture changes. Peak detection is applied to this peak to find feature discontinities.

Lartillot and Toiviainen \cite{Lartillot2007} wrote a MATLAB toolbox to extract musical features from audio files, which contains some audio segmentation tools. The tool divides up the data is divided up into smaller frames, and can be set to segment by examining the MFCC (Cepstral coefficients, a frequency-based representation of the audio signal). Distance between each frame can be calculated based on these features and a similarity matrix can be constructed. A convolution on the diagonal of the matrix will produce a novelty curve that indicates the temporal locations of significant texture changes. Peak detection is applied to this peak to find feature discontinuities.

Lartillot and Toiviainen \cite{Lartillot2007} wrote a MATLAB toolbox to extract musical features from audio files, which contains some audio segmentation tools. The tool divides up the data is divided up into smaller frames, and can be set to segment by examining the mel-frequency cepstral coefficients (MFCC). Distance between each frame are calculated based on these features and a similarity matrix can be constructed. A convolution on the diagonal of this matrix will produce a novelty curve that indicates the temporal locations of significant texture changes. Peak detection is applied to this peak to find feature discontinuities.},
  Timestamp                = {2013.08.29}
}

@Article{Laskov2006,
  Title                    = {Incremental Support Vector Learning: Analysis, Implementation and Applications},
  Author                   = {Laskov, P. and Gehl, C. and Kr\"{u}ger, S. and M\"{u}ller, K.-R.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2006},
  Pages                    = {1909--1936},
  Volume                   = {7},

  Abstract                 = {Incremental Support Vector Machines (SVM) are instrumental in practical applications of online learning. This work focuses on the design and analysis of efficient incremental SVM learning, with the aim of providing a fast, numerically stable and robust implementation. A detailed analysis of convergence and of algorithmic complexity of incremental SVM learning is carried out. Based on this analysis, a new design of storage and numerical operations is proposed, which speeds up the training of an incremental SVM by a factor of 5 to 20. The performance of the new algorithm is demonstrated in two scenarios: learning with limited resources and active learning. Various applications of the algorithm, such as in drug discovery, online monitoring of industrial devices and and surveillance of network traffic, can be foreseen.},
  Acmid                    = {1248616},
  ISSN                     = {1532-4435},
  Issue_date               = {12/1/2006},
  Numpages                 = {28},
  Publisher                = {JMLR.org},
  Timestamp                = {2014.11.14},
  Url                      = {http://dl.acm.org/citation.cfm?id=1248547.1248616}
}

@InProceedings{Laudanski2011,
  Title                    = {A concurrent comparison of inertia sensor-based walking speed estimation methods},
  Author                   = {Laudanski, A. and Yang, S. and Li, Q.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2011},
  Month                    = {Aug},
  Pages                    = {3484-3487},

  Abstract                 = {This study performed a concurrent comparison of two walking speed estimation methods using shank- and foot-mounted inertial measurement units (IMUs). Based on the cyclic gait pattern of the stance leg during walking, data was segmented into a series of individual stride cycles. The angular velocity and linear accelerations of the shank and foot over each of these cycles were then integrated to determine the walking speed. The evaluation was performed on 10 healthy subjects during treadmill walking where known treadmill speeds were compared with the estimated walking speeds under normal and toe-out walking conditions. Results from the shank-mounted IMU sensor yielded more accurate walking speed estimates, with a maximum root mean square estimation error (RMSE) of 0.09 m/s in normal walking and 0.10 m/s in toe-out conditions; while the foot-mounted IMU sensors yielded a maximum RMSE of 0.14 m/s in normal walking and 0.26 m/s in toe-out conditions. Shank-mounted IMU sensors may prove to be of great benefit in accurately estimating walking speeds in patients whose gait is characterized by abnormal foot motions.},
  Doi                      = {10.1109/IEMBS.2011.6090941},
  ISSN                     = {1557-170X},
  Keywords                 = {biomedical equipment;biomedical measurement;gait analysis;sensors;abnormal foot motion;angular velocity;cyclic gait pattern;foot-mounted inertial measurement unit;individual stride cycles;inertia sensor-based walking speed estimation method;linear accelerations;maximum root mean square estimation error;normal walking;shank-mounted IMU sensor;shank-mounted inertial measurement unit;stance leg;toe-out walking;treadmill walking;walking speed;Acceleration;Accelerometers;Angular velocity;Estimation;Foot;Gyroscopes;Legged locomotion;Biosensing Techniques;Female;Humans;Male;Walking},
  Review                   = {As the first step, the continuous walking motion is
segmented into a series of stride cycles before the
displacements can be computed. For shank-mounted sensor,
it was determined by the time in the stance phase when the
shank is parallel to the direction of gravity.

Similarly, the foot sensor signals were also segmented by
using the gyroscope signal to detect the foot flat position of
each cycle.},
  Timestamp                = {2015.06.30}
}

@InProceedings{Lee2008a,
  Title                    = {Missing motion data recovery using factorial hidden markov models},
  Author                   = {Lee, Dongheui and Kulic, Dana and Nakamura, Yoshihiko},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2008},
  Organization             = {IEEE},
  Pages                    = {1722--1728},

  Timestamp                = {2013.10.08}
}

@Article{Lee2010,
  Title                    = {Unrestrained Measurement of Arm Motion Based on a Wearable Wireless Sensor Network},
  Author                   = {Lee, G. X. and Low, K. S. and Taher, T.},
  Journal                  = {IEEE Transactions on Instrumentation and Measurement},
  Year                     = {2010},
  Number                   = {5},
  Pages                    = {1309--1317},
  Volume                   = {59},

  Abstract                 = {Techniques that could precisely monitor human motion are useful in applications such as rehabilitation, virtual reality, sports science, and surveillance. Most of the existing systems require wiring that restrains the natural movement. To overcome this limitation, a wearable wireless sensor network using accelerometers has been developed in this paper to determine the arm motion in the sagittal plane. The system provides unrestrained movements and improves its usability. The lightweight and compact size of the developed sensor node makes its attachment to the limb easy. Experimental results have shown that the system has good accuracy and response rate when compared with a goniometer.},
  Doi                      = {10.1109/TIM.2010.2043974},
  ISSN                     = {0018-9456},
  Keywords                 = {accelerometer;goniometer;human motion monitoring;rehabilitation;sports science;surveillance;unrestrained arm motion measurement;virtual reality;wearable wireless sensor network;accelerometers;body sensor networks;gait analysis;goniometers;patient monitoring;patient rehabilitation;},
  Timestamp                = {2011.12.31}
}

@InProceedings{Lee2008,
  Title                    = {Robot Learning by Observation based on Bayesian Networks and Game Pattern Graphs for Human-Robot Game Interactions},
  Author                   = {Lee, H. and Kim, H. and Park, K.-H. and Park, J.-H.},
  Booktitle                = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2008},

  Keywords                 = {learning,cluster,pattern,graph,bayesian network,lab reading (Jane)},
  Timestamp                = {2011.06.08}
}

@Article{Lee1999,
  Title                    = {An HMM-based threshold model approach for gesture recognition},
  Author                   = {Lee, H.-K. and Kim, J. H.},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {1999},
  Pages                    = {961--973},
  Volume                   = {21},

  Abstract                 = {A new method is developed using the hidden Markov model (HMM) based technique. To handle nongesture patterns, we introduce the concept of a threshold model that calculates the likelihood threshold of an input pattern and provides a confirmation mechanism for the provisionally matched gesture patterns. The threshold model is a weak model for all trained gestures in the sense that its likelihood is smaller than that of the dedicated gesture model for a given gesture. Consequently, the likelihood can be used as an adaptive threshold for selecting proper gesture model. It has, however, a large number of states and needs to be reduced because the threshold model is constructed by collecting the states of all gesture models in the system. To overcome this problem, the states with similar probability distributions are merged, utilizing the relative entropy measure. Experimental results show that the proposed method can successfully extract trained gestures from continuous hand motion with 93.14% reliability},
  Doi                      = {10.1109/34.799904},
  ISSN                     = {0162-8828},
  Keywords                 = {feature extraction;hand gesture recognition;hidden Markov model;man computer interaction;pattern recognition;probability distributions;relative entropy;segmentation;state reduction;threshold model;computer vision;entropy;feature extraction;gesture recognition;hidden Markov models;image segmentation;interactive systems;probability;},
  Review                   = {Viterbi},
  Timestamp                = {2011.04.18}
}

@InProceedings{Lee2012,
  author    = {Lee, S. H. and Suh, I. H. and Calinon, S. and Johansson, R.},
  title     = {Learning Basis Skills by Autonomous Segmentation of Humanoid Motion Trajectories},
  booktitle = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  year      = {2012},
  abstract  = {Manipulation tasks are characterized by continuous motion trajectories containing a set of key phases. In
this paper, we propose a probabilistic method to autonomously
segment the motion trajectories for estimating the key phases
embedded in such a task. The autonomous segmentation process
relies on principal component analysis to adaptively project into
one of the low-dimensional subspaces, in which a Gaussian mixture model is learned based on Bayesian information criterion
and expectation-maximization algorithms. The basis skills are
estimated by a set of Gaussians approximating quasi-linear key
phases, and those times spent calculated from the segmentation
points between two consecutive Gaussians representing the local
changes of dynamics and directions of the trajectories. The
basis skills are then used to build novel motion trajectories
with possible motion alternatives and optional parts. After
sequentially reorganizing the basis skills, a Gaussian mixture
regression process is used to retrieve smooth motion trajectories.
Two experiments are presented to demonstrate the capability
of the autonomous segmentation approach},
  groups    = {Lit Review 2013-09},
  review    = {Want to segment data from obs data for imitiation learning purposes.

Training - motion reduced by PCA and used to train GMMs. The GMM represents the motion traj by multiple Gaussians. we want to model that without overfitting, so BIC is used to determine the number of states. Lower dim data is better represented by GMMs than higher dim data. The points where one Gaussian boundary ends and the next one begins is considered a segment. Task was used to teach robot movement. 

not online},
  timestamp = {2013.10.08},
}

@Article{Levy2008,
  Title                    = {Structural segmentation of musical audio by constrained clustering},
  Author                   = {Levy, M. and Sandler, M.},
  Journal                  = {IEEE Transactions on Audio, Speech, and Language Processing},
  Year                     = {2008},
  Number                   = {2},
  Pages                    = {318--326},
  Volume                   = {16},

  Abstract                 = {We describe a method of segmenting musical audio into structural sections based on a hierarchical labeling of spectral features. Frames of audio are first labeled as belonging to one of a number of discrete states using a hidden Markov model trained on the features. Histograms of neighboring frames are then clustered into segment-types representing distinct distributions of states, using a clustering algorithm in which temporal continuity is expressed as a set of constraints modeled by a hidden Markov random field. We give experimental results which show that in many cases the resulting segmentations correspond well to conventional notions of musical form. We show further how the constrained clustering approach can easily be extended to include prior musical knowledge, input from other machine approaches, or semi-supervision.},
  Publisher                = {IEEE},
  Review                   = {- Segmenting music with a hierachical timbre ("tone color" - a catch-all quality of musical note that distinguishes sounds from one instrement to another, when they are played at the same loudness and pitch)
- they build HMMs using 40 timbre-types as input DOFs. Use windows that are 3 times the length of one beat, while advancing the window by one beat at a time. Constant-Q (freq transform) is applied and PCA is applied to the resultant spectra. The first 20 PCA components is used as training for HMM (it seems that these PCA components are used as timbre...)
- to assess a wider range of signals, a 7-beat sliding window is histogramed, normalized, and clustered (how does one cluster a histogram...), giving the distribution of timbre-types, whereas the cluster assignments denote the segment boundaries.},
  Timestamp                = {2013.08.29}
}

@InProceedings{Levy2006,
  Title                    = {Extraction of High-Level Musical Structure From Audio Data and Its Application to Thumbnail Generation},
  Author                   = {Levy, M. and Sandler, M. and Casey, M.},
  Booktitle                = {IEEE International Conference on Acoustics, Speech and Signal Processing},
  Year                     = {2006},
  Volume                   = {5},

  Abstract                 = {A method for segmenting musical audio with a hierarchical timbre model is introduced. New evidence is presented to show that music segmentation can be recast as clustering of timbre features, and a new clustering algorithm is described. A prototype thumbnail-generating application is described and evaluated. Experimental results are given, including comparison of machine and human segmentations},
  Doi                      = {10.1109/ICASSP.2006.1661200},
  ISSN                     = {1520-6149},
  Keywords                 = {audio signal processing;feature extraction;audio data;hierarchical timbre model;high-level musical structure;musical audio segmentation;thumbnail generation;timbre features clustering;Algorithm design and analysis;Audio recording;Clustering algorithms;Cognition;Data mining;Educational institutions;Humans;Music information retrieval;Prototypes;Timbre},
  Review                   = {- Segmenting music with a hierachical timbre ("tone color" - a catch-all quality of musical note that distinguishes sounds from one instrement to another, when they are played at the same loudness and pitch)
- they build HMMs using 40 timbre-types as input DOFs. Use windows that are 3 times the length of one beat, while advancing the window by one beat at a time. Constant-Q (freq transform) is applied and PCA is applied to the resultant spectra. The first 20 PCA components is used as training for HMM (it seems that these PCA components are used as timbre...)
- to assess a wider range of signals, a 7-beat sliding window is histogramed, normalized, and clustered (how does one cluster a histogram...), giving the distribution of timbre-types, whereas the cluster assignments denote the segment boundaries.

Levy \etal \cite{Levy2006} segment music by examining the timbre. Timbre is typically known as tone colour, which describes the quality of the musical note that distinguishes sounds from one instrument to another, when they are played at the same loudness and pitch. Timbre-types are determined by taking a constant-Q frequency transform, with principal component analysis (PCA) applied subsequently. The first 20 PCA components are used as feature vectors for the 40-state HMM, with each state corresponding to a timbre-type. The Viterbi algorithm is used to segment these features, based on a previously trained model.

Levy \etal \cite{Levy2006} segment music by examining timbre, a sound-based feature. Once calculated, a 40-state HMM is trained for the observation data, and the Viterbi algorithm is used to segment the observation. This was tested on 14 songs with 196 hand-labelled segments. $Ver_{AllPoints}$ is used, with an average $Acc_{Class}$ of 87\% reported.},
  Timestamp                = {2013.09.07}
}

@InProceedings{Li2003,
  author    = {Li, M. and Okamura, A. M.},
  title     = {Recognition of Operator Motions for Real-time Assistance using Virtual Fixtures},
  booktitle = {Proceedings of the Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems},
  year      = {2003},
  pages     = {125--131},
  abstract  = {Hidden Markov Models (HMMs) are used for
automatic segmentation and recognition of user motions.
A new algorithm for real-time HMM recognition was
developed. The segmentation results are used to provide
appropriate assistance in a combined curve following and
object avoidance task. This assistance takes the form of a
virtual fixture, whose compliance can be altered online.
Recognition and assistance experiments were performed
using force and position data recorded from a
cooperative manipulation system, where a robot and a
human operator hold an instrument simultaneously.
Recognition accuracy exceeds 90%, even when the users
training the HMMs differ from those executing the task.
For a task consisting of both path following and
avoidance motions, an HMM-based virtual fixture
switches the compliance from low to high when the user is
trying to move away from the path. The HMM method
improves operator performance in comparison with a
constant virtual fixture and no virtual fixture.},
  groups    = {Lit Review 2013-09},
  review    = {Use left-right HMM models. Want real time continous regnition algorithm, so can't use standard Viterbi. Want to see if users can be forced to follow a given path for robot interaction. 
Given a window of observation, the lilelihood of observing this window and being in a given state and a given model is calculated, by a tunckated Viterbi algorithm. This is calculated for all the states across all the models. The window is labeled according to the motion with the highest sum likelihood. Tested this on a user interacting with a robot arm. They can either do nothing, follow a sine curve, or not follow a sine curve. 8 users trace out a motion. 93% accuracy.


I suppose this works well if the motions are very different, and don't have state overlap.

Li and Okamura \cite{Li2003} also uses a similar online Viterbi algorithm, and applied it to HMM models representing user movements as they try to guide a robotic arm through a given trajectory. Three different possible HMM states are modeled: no-movement, following the given trajectory and not following the trajectory. Manual segments were provided by the user and denotes when the user switch between each possible state. $Ver_{AllPoints}$ scheme was used, and $Acc_{class}$ is 94\%.},
  timestamp = {2013.10.08},
}

@Article{Li2008,
  Title                    = {A self-training semi-supervised SVM algorithm and its application in an EEG-based brain computer interface speller system},
  Author                   = {Li, Yuanqing and Guan, Cuntai and Li, Huiqi and Chin, Zhengyang},
  Journal                  = {Pattern Recognition Letters},
  Year                     = {2008},
  Number                   = {9},
  Pages                    = {1285--1294},
  Volume                   = {29},

  Abstract                 = {In this paper, we first present a self-training semi-supervised support vector machine (SVM) algorithm and its corresponding model
selection method, which are designed to train a classifier with small training data. Next, we prove the convergence of this algorithm. Two
examples are presented to demonstrate the validity of our algorithm with model selection. Finally, we apply our algorithm to a data set
collected from a P300-based brain computer interface (BCI) speller. This algorithm is shown to be able to significantly reduce training
effort of the P300-based BCI speller.},
  Timestamp                = {2014.10.24}
}

@InProceedings{Li2011,
  Title                    = {Local Shape Context Based Real-time Endpoint Body Part Detection and Identification from Depth Images},
  Author                   = {Li, Z. and Kuli\'{c}, D.},
  Booktitle                = {Canadian Conference on Computer and Robot Vision},
  Year                     = {2011},
  Pages                    = {219--226},

  Abstract                 = {For many human-robot interaction applications, accurate localization of the human, and in particular the endpoints such as the head, hands and feet, is crucial. In this paper, we propose a new Local Shape Context Descriptor specifically for describing the shape features of the endpoint body parts. The descriptor is computed from edge images obtained from depth data generated by a time-of-flight sensor. The proposed descriptor encodes the distance from a reference point to the nearest edges in uniformly sampled radial directions. Based on this descriptor, a new type of interest point is defined, and a hierarchical algorithm for searching good interest points is developed. The interest points are then classified as head, feet, hands and others based on learned models. The system is computationally efficient, and capable of handling large variations in translation, rotation, scaling and deformation of the body parts. The system is tested using videos containing a variety of motions from a publicly available dataset, and is shown to be capable of detecting and identifying endpoint body parts accurately at very high speed.},
  Doi                      = {10.1109/CRV.2011.36},
  Keywords                 = {edge detection;gesture recognition;image motion analysis;video signal processing;edge images;gesture recognition;human-robot interaction;local shape context descriptor;real-time endpoint body part detection;shape features;time-of-flight sensor;video processing;Context;Foot;Head;Humans;Image edge detection;Shape;Three dimensional displays;depth image;endpoint body part;gesture recognition;human motion capture;local shape context},
  Timestamp                = {2014.09.18}
}

@InProceedings{Li2010,
  Title                    = {Particle Filter Based Human Motion Tracking},
  Author                   = {Li, Z. and Kuli\'{c}, D.},
  Booktitle                = {International Conference on Control Automation Robotics Vision},
  Year                     = {2010},
  Pages                    = {555--560},

  Abstract                 = {This paper proposes a particle filter based marker-less upper body motion capture system, capable of running in realtime. This system is designed for a humanoid robot application, and thus a monocular image sequence is used as input. We first set up a model of the human body, a sub-model which includes 11 Degrees of Freedom is used for the upper body tracking. Considering the realtime processing requirements, two time efficient cues are implemented in the likelihood calculation, namely the edge cue and the distance cue. The system is tested using a publicly available database, which consists of both the videos and the ground truth data, enabling quantitative error analysis. The system successfully tracks the human through arbitrary upper body motion at 20 Hz.},
  Doi                      = {10.1109/ICARCV.2010.5707796},
  Keywords                 = {humanoid robots;image motion analysis;image sequences;maximum likelihood estimation;particle filtering (numerical methods);tracking;frequency 20 Hz;humanoid robot;likelihood calculation;marker-less upper body motion capture system;monocular image sequence;particle filter based human motion tracking;Humans;Image edge detection;Joints;Solid modeling;Tracking;Videos;human motion capture;marker-less;particle filter;quantitative error analysis;realtime},
  Timestamp                = {2014.09.18}
}

@InProceedings{Li2013,
  Title                    = {Daily Life Event Segmentation for Lifestyle Evaluation Based on Multi-Sensor Data Recorded by a Wearable Device},
  Author                   = {Li, Z. and Wei, Z. and Jai, W. and Sun, M.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},
  Pages                    = {2858--2861},

  __markedentry            = {},
  Abstract                 = {In order to evaluate people’s lifestyle for health maintenance, this paper presents a segmentation method based on multi-sensor data recorded by a wearable computer called eButton. This device is capable of recording more than ten hours of data continuously each day in multimedia forms. Automatic processing of the recorded data is a significant task. We have developed a two-step summarization method to segment large datasets automatically. At the first step, motion sensor signals are utilized to obtain candidate boundaries between different daily activities in the data. Then, visual features are extracted from images to determine final activity boundaries. It was found that some simple signal measures such as the combination of a standard deviation measure of the gyroscope sensor data at the first step and an image HSV histogram feature at the second step produces satisfactory results in automatic daily life event segmentation. This finding was verified by our experimental results.},
  Keywords                 = {EMBC2013},
  Review                   = {Want to monitor daily activities and when someone start and end an activity. Want automated methods to segment and identify the activities. This paper uses GPS, accel and gyro. 

Two-stage segmentation. 
1 - Look at the stdev of a window to gauge if the user is stationary of moving, and divided up into short segment (SS), long inactive segment (IS) and long active segment (AS). They then do image feature extraction to determine the motion, such as image histogram. Tested it.


Li \etal \cite{Li2013} want to monitor daily activities and when someone start and end an activity. They propose a multi-model algorithm that combines inertial measurement units (IMU) and image-based features in a two-step segmentation algorithm. The IMU segmentation is performed by examining the standard deviation of the sensors, and perform threshold-based segmentation. Segments are labeled as a short segment, long inactive segment, or a long active segment. Image feature extraction is performed to assign a more detailed label. A colour histogram is used for this purpose. Long active and inactive segments are divided up into 5 minute blocks. If the histogram distance between sequential blocks are higher than some threshold, a new boundary is declared. The system was tested on 6 subjects, recording daily activities over 2 days each. Labeled data was provided by the participant. The scheme reported 82\% recall and 69\% precision.

Li \etal \cite{Li2013} combine IMU and image data to monitor and segment daily activities. IMU segmentation is performed by examining the standard deviation of the sensors, separating high-movement novel activities from low-movement trivial ones, and the trivial segments are discarded. HSV histograms are used to provide detailed segments for the high-movement activities. If the histogram distance, assumed to be bin-to-bin distance, between two successive histograms are above some threshold, a segment is declared. The system was tested on 6 subjects, recording daily activities over 2 days each. Labelled data was provided by the participant by hand annotation. It appears that $Ver_{temporal}$ was employed, but no $t_{error}$ was given. Under different parameters, an $Acc_{F_1}$ of 69-75\% was reported.},
  Timestamp                = {2013.08.02}
}

@InProceedings{Liao2005,
  Title                    = {PapierCraft: a command system for interactive paper},
  Author                   = {Liao, C. and Guimbreti\'{e}re, F. and Hinckley, K.},
  Booktitle                = {Proceedings of the 18th annual ACM symposium on User interface software and technology},
  Year                     = {2005},

  Address                  = {New York, NY, USA},
  Pages                    = {241--244},
  Publisher                = {ACM},
  Series                   = {UIST '05},

  Acmid                    = {1095074},
  Doi                      = {http://doi.acm.org/10.1145/1095034.1095074},
  ISBN                     = {1-59593-271-2},
  Keywords                 = {distributed systems, paper interfaces, pens},
  Location                 = {Seattle, WA, USA},
  Numpages                 = {4},
  Timestamp                = {2010.11.05},
  Url                      = {http://doi.acm.org/10.1145/1095034.1095074}
}

@Conference{Lieberman2004,
  Title                    = {Improvements on Action Parsing and Action Interpolation for Learning through Demonstration},
  Author                   = {Lieberman, J. AND Breazeal, C.},
  Booktitle                = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  Year                     = {2004},
  Pages                    = {342--365},

  Abstract                 = {Programming humanoid robots with new motor skills through human demonstration is a promising approach to endowing humanoids with new capabilities in a relatively quick and intuitive manner. This paper presents an automated software system to enable our humanoid robot to learn a generalized dexterous motor skill from relatively few demonstrations provided by a human operator wearing a telemetry suit. Movement, end effectors, stereo vision, and tactile information are analyzed to automatically segment movement streams along goal-directed boundaries. Further combinatorial selection of subsets of markers allows final episodic boundary selection and time alignment of tasks. The task trials are then analyzed spatially using radial basis functions [FBFs] to interpolate between demonstrations using the position of the target object as the motion blending parameter. A secondary RBF solution, using end effector paths in the object coordinate frame, provides precise end-effector positioning and orienting relative to the object. Blending of these two solutions is shown to both preserve quality of motion while increasing accuracy and robustness of object manipulation.},
  Keywords                 = {motion segmentation},
  Review                   = {We want to be able to teach humanoid robots motor skills via human demonstration. Early on, they attempted "learning by demonstration", where the robot visually observes a human performing the task (task-level imitation). However, in more articulated (more segments) robots, this method takes a long time to compute, so a slightly alternative method is to have the robot do the observation and use that as guidence, but allows the robot to determine its own method to carry it out.


Another approach is to provide the robot information via a telemetry suit, which has been primarily optical and potentiometer-based. Fagg used it in junction with tactile feedback to gain information about object (to be grasped). Peters took this and performed motion segmentation, then reversed it to rederive the total movement. It's difficult to to see the limitations of these techniques, since the inputs were very clear and well-segmented, so more difficult animations were not tested. This paper promises better methods.

Baldwin/Baird tried to investigate discerning intentions from human actions. The ability to predict human intentions behind their actions is important. Similarly, this can be applied to humanoid robot motion. We want humanoid robots to be able to learn from human actions. A robot may have the capability to do something, but it might not know how to do so, from it's existing library of actions. Can they interpolate? Blend existing libraries? How much approximations? 

Several researchers have examined this topic. Mataric and Jenkin used mean-squared velocity and PCA (Principal Components Analysis) and finding motions that uses the least amount of energy. Mutli-dimensional scaling (MDS) has also been considered, but error toleration is a continual issue.


This paper: developed software for humaniod robots to learn general motor skills via demonstration via teleoperation suit (Movement, stereo vision, tactile information). Joint angle and effector motion measured. Motion is segmented. They look at things in a object coordinate space (origin at object), absolute world-coordinate (origin at robot base) and derives a measure of 'objectivity' to see how much of the motion is 'object-based' and how much is 'absolute-based'. 

The teleop suit used is a potentiometer-based system, measuring joint angles (accurate to 0.125 degrees), at 60 HZ. These human joint angles are translated to Euler angles, which is then transformed to robot motor angles. Tactile information was picked up via Force-Sensitive Resistors (FSR). Stereo vision camera utilized to allow the humanoid robot (code name Leonardo) to locate objects. The data is LPF'd and fed into a DH-convention kinematic model or analyze joint/end effector motions.

Each motion trial is segmented and time-aligned so that each segment was lined up. Simple time averaging isn't enough, since key features gets diluted out. So averaging isn't cool. Mataric used ZVC in mean-square velocity. This paper adds tactile feedback to improve robot-object interactions. This allows us to find all possible markers for episode separations. We now want to find some way of figuring out which markers are legit...

They take all the markers and determine which combination of markers results in minimally-sized boundaries. Want to make sure no episodes overlaps with another one, over each of the trials (Dang. It's not real-time...) -> time-scale so the markers on each of the trials line up (via Hermite polynomial spines). Correlation measurements are made, across all trials and combinations; each of these marker sets are assigned a rank (dang. very computationally expensive). Whichever combination of markers has the highest rank, that is decided to be the best fit. Once this has been done, the episode markers across the trials are time-averaged and melded together. Now we need to generalize this so that it's appliciable to not just to the example trials, but to all applications to the sample space. It's important for things to be precise, or else a pick-up task will not be sucessful.

They then switch over to a Maya model of Leonardo, since there is many differences between using a person model vs a robot (Leonardo) model. Calibration and geometric alignment is one. Motion type (the person doesn't move the same way the robot will) is another, especially since the user and the robot will not feel (haptic) the same when they contact an object. They fall on the Verb-Adverb theory and Radial Basis Functions to form the models...

Verb is a motion (ie grasping), whereas adverb is the parameter of motion that changes (ie object's position, that is to be grasped). Radial Basis produces motion animation from interpolation from input trials. Assume that all motion is some parametrization (so some form of) general motion function (this function is unknown). A function will be derived for each joint to determine end effector motion. Radial basis functions are a function of distance. 

...

(what i wrote in the lit review) Lieberman and Breazeal also expanded on the ZVC concept, demonstrating that the velocity threshold method can be complemented by other signal types, such as tactile contact. The segmenting velocity threshold was also modified so that it is dynamically determined as a function of the velocity as opposed to being a static value. This allows the threshold to account for speed changes in the motion. However, using a single velocity threshold means that DOFs that have large velocity valleys and peaks would dominate the auto-threshold determinations, thus hiding the segmentation points that would be best characterized by DOFs with small valleys and peaks. Also, at high dimensionality, the algorithm would likely report weaker performance since most of the DOFs are likely to be stationary, thus under-reporting the velocity value and leading to false positives. Lieberman applied this algorithm to a human demonstrator in a motion capture suit, to generate and segment motions for imitation learning purposes, so explicit segmentation metrics were not provided.},
  Timestamp                = {2009.10.12}
}

@Article{Lin2007,
  Title                    = {A note on Platt’s probabilistic outputs for support vector machines},
  Author                   = {Lin, H.-T. and Lin, C.-J. and Weng, R. C.},
  Journal                  = {Machine Learning},
  Year                     = {2007},
  Pages                    = {267--276},
  Volume                   = {68},

  Doi                      = {10.1007/s10994-007-5018-6},
  ISSN                     = {0885-6125},
  Keywords                 = {Support vector machine; Posterior probability},
  Language                 = {English},
  Publisher                = {Springer US},
  Review                   = {Fit a sigmoid to the decision function. The decision function is f(x), where sign(f(x)) gives us the SVM decision. Platt uses LM optimization to get sigmoid parameters, whereas Lin proposes Newton's method. Reduces numerical issues.},
  Timestamp                = {2015.02.05},
  Url                      = {http://dx.doi.org/10.1007/s10994-007-5018-6}
}

@MastersThesis{Lin2012_MASc,
  author    = {Lin, Jonathan F. S.},
  title     = {Automated Rehabilitation Exercise Motion Tracking},
  school    = {University of Waterloo},
  year      = {2012},
  abstract  = {Current physiotherapy practice relies on visual observation of the patient for diagnosis and assessment. The assessment process can potentially be automated to improve accuracy and reliability. This thesis proposes a method to recover patient joint angles and automatically extract movement profiles utilizing small and lightweight body-worn sensors. Joint angles are estimated from sensor measurements via the extended Kalman filter (EKF). Constant-acceleration kinematics is employed as the state evolution model. The forward kinematics of the body is utilized as the measurement model. The state and measurement models are used to estimate the position, velocity and acceleration of each joint, updated based on the sensor inputs from inertial measurement units (IMUs). Additional joint limit constraints are imposed to reduce drift, and an automated approach is developed for estimating and adapting the process noise during on-line estimation. Once joint angles are determined, the exercise data is segmented to identify each of the repetitions. This process of identifying when a particular repetition begins and ends allows the physiotherapist to obtain useful metrics such as the number of repetitions performed, or the time required to complete each repetition. A feature-guided hidden Markov model (HMM) based algorithm is developed for performing the segmentation. In a sequence of unlabelled data, motion segment candidates are found by scanning the data for velocity-based features, such as velocity peaks and zero crossings, which match the pre-determined motion templates. These segment potentials are passed into the HMM for template matching. This two-tier approach combines the speed of a velocity feature based approach, which only requires the data to be differentiated, with the accuracy of the more computationally-heavy HMM, allowing for fast and accurate segmentation. The proposed algorithms were verified experimentally on a dataset consisting of 20 healthy subjects performing rehabilitation exercises. The movement data was collected by IMUs strapped onto the hip, thigh and calf. The joint angle estimation system achieves an overall average RMS error of 4.27 cm, when compared against motion capture data. The segmentation algorithm reports 78% accuracy when the template training data comes from the same participant, and 74% for a generic template.},
  groups    = {My Work},
  timestamp = {2013.01.10},
  url       = {hdl.handle.net/10012/7191},
}

@Conference{Lin2016_HIPOCT,
  author    = {Lin, J. F.-S. and Bonnet, V. and Joukov, V. and Venture, G. and Kuli\'{c}, D.},
  title     = {Comparison of Kinematic and Dynamic Sensor Modalities and Derived Features for Human Motion Segmentation},
  booktitle = {Proceedings of the IEEE/NIH Strategic Conference on Healthcare Innovations and Point of Care Technologies},
  year      = {2016},
  pages     = {109--112},
  groups    = {My Work},
  owner     = {jf2lin},
  timestamp = {2016.12.05},
}

@Conference{Lin2016_ICHR,
  author    = {Lin, J. F.-S. and Bonnet, V. and Panchea, A. M. and Ramdani, N. and Venture, G. and Kuli\'{c}, D.},
  title     = {Human Motion Segmentation using Cost Weights Recovered from Inverse Optimal Control},
  booktitle = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  year      = {2016},
  pages     = {1107--1113},
  groups    = {My Work},
  owner     = {jf2lin},
  timestamp = {2016.12.05},
}

@Article{Lin2017_JRATE,
  author    = {Lin, J. F.-S. and Joukov, V. and Kuli\'{c}, D.},
  title     = {Classification-based Segmentation for Rehabilitation Exercise Monitoring},
  journal   = {Journal of Rehabilitation and Assistive Technologies Engineering},
  year      = {2017},
  note      = {in review},
  groups    = {My Work},
  owner     = {jf2lin},
  timestamp = {2016.12.09},
}

@InProceedings{Lin2014_EMBC,
  author    = {Lin, J. F.-S. and Joukov, V. and Kuli\'{c}, D.},
  title     = {Human Motion Segmentation by Data Point Classification},
  booktitle = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  year      = {2014},
  pages     = {9--13},
  groups    = {My Work},
  timestamp = {2014.06.18},
}

@InProceedings{Lin2014_ICHR,
  author    = {Lin, J. F.-S. and Joukov, V. and Kuli\'{c}, D.},
  title     = {Full-body Multi-primitive Segmentation using Classifiers},
  booktitle = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  year      = {2014},
  pages     = {874--880},
  groups    = {My Work},
  timestamp = {2014.08.12},
}

@Article{Lin2016_THMS,
  author    = {Lin, J. F.-S. and Karg, M. E. and Kuli\'{c}, D.},
  title     = {Movement Primitive Segmentation for Human Motion Modeling: A Framework for Analysis},
  journal   = {IEEE Transactions on Human-Machine Systems},
  year      = {2016},
  volume    = {46},
  pages     = {325--339},
  issn      = {2168-2291},
  abstract  = {Movement primitive segmentation enables long sequences of human movement observation data to be segmented into smaller components, termed movement primitives, to facilitate movement identification, modeling, and learning. It has been applied to exercise monitoring, gesture recognition, human-machine interaction, and robot imitation learning. This paper proposes a segmentation framework to categorize and compare different segmentation algorithms considering segment definitions, data sources, application-specific requirements, algorithm mechanics, and validation techniques. The framework is applied to human motion segmentation methods by grouping them into online, semionline, and offline approaches. Among the online approaches, distance-based methods provide the best performance, while stochastic dynamic models work best in the semionline and offline settings. However, most algorithms to date are tested with small datasets, and algorithm generalization across participants and to movement changes remains largely untested.},
  doi       = {10.1109/THMS.2015.2493536},
  groups    = {My Work},
  keywords  = {image motion analysis;image segmentation;algorithm mechanics;application-specific requirements;data sources;distance-based methods;exercise monitoring;gesture recognition;human motion modeling;human movement observation data sequences;human-machine interaction;movement identification;movement learning;movement modeling;movement primitive segmentation;robot imitation learning;segment definitions;segmentation algorithms;stochastic dynamic models;validation techniques;Algorithm design and analysis;Cameras;Data collection;Databases;Image segmentation;Manuals;Motion segmentation;Algorithm design and analysis;classification algorithms;machine learning algorithms;physiology;time series analysis},
  timestamp = {2016.06.20},
}

@Article{Lin2012_TNSRE,
  author    = {Lin, J. F.-S. and Kuli\'{c}, D.},
  title     = {On-line Segmentation of Human Motion for Automated Rehabilitation Exercise Analysis},
  journal   = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  year      = {2014},
  volume    = {22},
  pages     = {168--180},
  abstract  = {To enable automated analysis of rehabilitation movements, an approach for accurately identifying and segmenting movement repetitions is required. This paper proposes an approach for on-line, automated segmentation and identification of movement segments from continuous time-series data of human movement. The proposed approach uses a two stage identification and recognition process, based on velocity features and stochastic modeling of each motion to be identified. In the first stage, motion segment candidates are identified based on a characteristic sequence of velocity features such as velocity peaks and zero velocity crossings. In the second stage, Hidden Markov models are used to accurately identify segment locations from the identified candidates. The proposed approach is capable of on-line segmentation and identification, enabling interactive feedback in rehabilitation applications. The approach is validated on a 20 person rehabilitation movement dataset.},
  doi       = {10.1109/TNSRE.2013.2259640},
  groups    = {STAT841, IROS2014, EMBC2014, My Work},
  timestamp = {2012.10.10},
}

@InProceedings{Lin2013_EMBC,
  author    = {Lin, J. F.-S. and Kuli\'{c}, D.},
  title     = {Human Pose Recovery for Rehabilitation Using Ambulatory Sensors},
  booktitle = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  year      = {2013},
  pages     = {4799--4802},
  address   = {Osaka, Japan},
  groups    = {My Work},
  timestamp = {2013.04.11},
}

@InProceedings{Lin2012_EMBC,
  author    = {Lin, J. F.-S. and Kuli\'{c}, D.},
  title     = {Segmenting Human Motion for Automated Rehabilitation Exercise Analysis},
  booktitle = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  year      = {2012},
  pages     = {2881--2884},
  address   = {San Diego, USA},
  abstract  = {This paper proposes an approach for the automated segmentation and identification of movement segments from continuous time series data of human movement, collected through motion capture of ambulatory sensors. The proposed approach uses a two stage identification and recognition process, based on velocity and stochastic modeling of each motion to be identified. In the first stage, motion segment candidates are identified based on a unique sequence of velocity features such as velocity peaks and zero velocity crossings. In the second stage, Hidden Markov models are used to accurately identify segment locations from the identified candidates. The approach is capable of on-line segmentation and identification, enabling interactive feedback in rehabilitation applications. The approach is validated on a rehabilitation movement dataset, and achieves a segmentation accuracy of 89%.},
  doi       = {10.1109/EMBC.2012.6346565},
  groups    = {My Work},
  timestamp = {2012.05.28},
}

@Article{Lin2012_PMEA,
  author    = {Lin, J. F.-S. and Kuli\'{c}, D.},
  title     = {Human Pose Recovery using Wireless Inertial Measurement Units},
  journal   = {Physiological Measurement},
  year      = {2012},
  volume    = {33},
  pages     = {2099--2115},
  doi       = {10.1088/0967-3334/33/12/2099},
  groups    = {EMBC2013, STAT841, My Work},
  timestamp = {2012.08.20},
}

@Conference{Lin2011_IROS,
  author    = {Lin, J. F.-S. and Kuli\'{c}, D.},
  title     = {Automatic Human Motion Segmentation and Identification using Feature Guided HMM for Physical Rehabilitation Exercises},
  booktitle = {Proceedings of the IEEE International Conference on Intelligent Robots and Systems, Workshop on Robotics for Neurology and Rehabilitation},
  year      = {2011},
  pages     = {33--36},
  address   = {San Francisco, CA},
  abstract  = {Fast and accurate motion segmentation and identification methods are required to enable real-time assessment and feedback for physical rehabilitation. Exercise motions exhibit cyclic patterns that can be characterized by simple features, such as zero-velocity crossings or velocity peaks. In this paper, these features are used as framing windows for simultaneous motion segmentation and identification via Hidden Markov models. Comparisons to other segmentation methods show that feature guiding increases the segmentation accuracy and greatly reduces the runtime needed to perform the segmentation.},
  groups    = {My Work},
  keywords  = {Motion segmentation, motion primitive},
  review    = {Appeared in: Workshop on Robotics for Neurology and Rehabilitation
Sept. 25-30, 2011.},
  timestamp = {2011.07.08},
}

@InProceedings{Lin2011_SAIS,
  author    = {Lin, J. F.-S. and Kuli\'{c}, D.},
  title     = {Motion Segmentation with Inertial Measurements using Feature Guided HMM},
  booktitle = {Proceedings of the Symposium on Advanced Intelligent Systems},
  year      = {2011},
  abstract  = {Motion segmentation and identification methods tend to assume that joint angle data are readily available for processing. The standard data acquisition method, motion capture, is not feasible for real-world deployment, such as in physical rehabilitation clinics, due to space, environment and cost constraints. In this paper, a feature-guided Hidden Markov model segmentation algorithm is adapted to segment and identify human motion from acceleration and gyroscopic data instead of position data. Acceleration and gyroscopic data are readily obtainable through small lightweight sensors, and would serve as a more appropriate sensor system for a rehabilitation clinic than a motion capture system.},
  groups    = {My Work},
  review    = {December 1 - 2, 2011},
  timestamp = {2011.12.30},
}

@Conference{Lin2016_SWIT,
  author    = {Lin, J. F.-S. and Samadani, A. and Kuli\'{c}, D.},
  title     = {Segmentation by Data Point Classification Applied to Forearm Surface EMG},
  booktitle = {Proceedings of the EAI International Summit of Smart City 360},
  year      = {2016},
  volume    = {166},
  pages     = {153--165},
  publisher = {Springer International Publishing},
  comment   = {International Conference on Smart Wearable Devices and IoT for Health and Wellbeing Applications},
  doi       = {10.1007/978-3-319-33681-7_13},
  groups    = {My Work},
  owner     = {jf2lin},
  timestamp = {2015.10.18},
}

@Book{Ling2012,
  Title                    = {Crafting Your Research Future: A Guide to Successful Master's and Ph.D. Degrees in Science \& Engineering},
  Author                   = {Ling, C. X. and Yang, Q.},
  Publisher                = {Morgan \& Claypool Publishers},
  Year                     = {2012},

  Abstract                 = {What is it like to be a researcher or a scientist? For young people, including graduate students and junior faculty members in universities, how can they identify good ideas for research? How do they conduct solid research to verify and realize their new ideas? How can they formulate their ideas and research results into high-quality articles, and publish them in highly competitive journals and conferences? What are effective ways to supervise graduate students so that they can establish themselves quickly in their research careers? In this book, Ling and Yang answer these questions in a step-by-step manner with specific and concrete examples from their first-hand research experience.},
  Doi                      = {10.2200/S00412ED1V01Y201203ENG018},
  Timestamp                = {2012.11.16}
}

@Article{Liu2010,
  Title                    = {Unsupervised action classification using space-time link analysis},
  Author                   = {Liu, Haowei and Feris, Rogerio and Krueger, Volker and Sun, Ming-Ting},
  Journal                  = {Journal on Image and Video Processing},
  Year                     = {2010},
  Pages                    = {2},
  Volume                   = {2010},

  Publisher                = {Hindawi Publishing Corp.},
  Timestamp                = {2013.10.08}
}

@Article{Liu2009_handgesture,
  Title                    = {uWave: Accelerometer-based personalized gesture recognition and its applications },
  Author                   = {Liu, J. and Zhong, L. and Wickramasuriya, J. and Vasudevan, V.},
  Journal                  = {Pervasive Mob Comput},
  Year                     = {2009},
  Pages                    = {657--75},
  Volume                   = {5},

  Abstract                 = {The proliferation of accelerometers on consumer electronics has brought an opportunity for interaction based on gestures. We present uWave, an efficient recognition algorithm for such interaction using a single three-axis accelerometer. uWave requires a single training sample for each gesture pattern and allows users to employ personalized gestures. We evaluate uWave using a large gesture library with over 4000 samples for eight gesture patterns collected from eight users over one month. uWave achieves 98.6% accuracy, competitive with statistical methods that require significantly more training samples. We also present applications of uWave in gesture-based user authentication and interaction with 3D mobile user interfaces. In particular, we report a series of user studies that evaluates the feasibility and usability of lightweight user authentication. Our evaluation shows both the strength and limitations of gesture-based user authentication.},
  Doi                      = {http://dx.doi.org/10.1016/j.pmcj.2009.07.007},
  ISSN                     = {1574-1192},
  Keywords                 = {Gesture recognition},
  Owner                    = {jf2lin},
  Timestamp                = {2015.04.27}
}

@Article{Liu2014,
  Title                    = {Fusion of Inertial and Depth Sensor Data for Robust Hand Gesture Recognition},
  Author                   = {Kui Liu and Chen Chen and Jafari, R. and Kehtarnavaz, N.},
  Journal                  = {Sensors Journal, IEEE},
  Year                     = {2014},

  Month                    = {June},
  Number                   = {6},
  Pages                    = {1898-1903},
  Volume                   = {14},

  Abstract                 = {This paper presents the first attempt at fusing data from inertial and vision depth sensors within the framework of a hidden Markov model for the application of hand gesture recognition. The data fusion approach introduced in this paper is general purpose in the sense that it can be used for recognition of various body movements. It is shown that the fusion of data from the vision depth and inertial sensors act in a complementary manner leading to a more robust recognition outcome compared with the situations when each sensor is used individually on its own. The obtained recognition rates for the single hand gestures in the Microsoft MSR data set indicate that our fusion approach provides improved recognition in real-time and under realistic conditions.},
  Doi                      = {10.1109/JSEN.2014.2306094},
  ISSN                     = {1530-437X},
  Keywords                 = {computer vision;gesture recognition;hidden Markov models;image sensors;inertial systems;sensor fusion;Microsoft MSR;body movement recognition;hidden Markov model;inertial sensor data fusion;robust hand gesture recognition;vision depth sensor data fusion;Gesture recognition;Hidden Markov models;Sensor fusion;Sensor systems;Training;Wireless sensor networks;Sensor fusion;fusion of inertial and depth sensor data;hand gesture recognition},
  Review                   = {A gesture recog paper. No seg.},
  Timestamp                = {2015.06.29}
}

@Article{Liu1998a,
  author    = {Liu, Z. and Wang, Y. and Chen, T.},
  title     = {Audio feature extraction and analysis for scene segmentation and classification},
  journal   = {Journal of VLSI Signal Processing Systems for Signal, Image and Video Technology},
  year      = {1998},
  volume    = {20},
  pages     = {61--79},
  abstract  = {Understanding of the scene content of a video sequence is very important for content-based indexing and retrieval of multimedia databases. Research in this area in the past several years has focused on the use of speech recognition and image analysis techniques. As a complimentary effort to the prior work, we have focused on using the associated audio information (mainly the nonspeech portion) for video scene analysis. As an example, we consider the problem of discriminating five types of TV programs, namely commercials, basketball games, football games, news reports, and weather forecasts. A set of low-level audio features are proposed for characterizing semantic contents of short audio clips. The linear separability of different classes under the proposed feature space is examined using a clustering analysis. The effective features are identified by evaluating the intracluster and intercluster scattering matrices of the feature space. Using these features, a neural net classifier was successful in separating the above five types of TV programs. By evaluating the changes between the feature vectors of adjacent clips, we also can identify scene breaks in an audio sequence quite accurately. These results demonstrate the capability of the proposed audio features for characterizing the semantic content of an audio sequence.},
  groups    = {STAT841},
  publisher = {Springer},
  review    = {- Want to perform initial segmentation on audio signals to help video segmentation
- Features are extracted from 1-second moving windows
- Look at volume: mean volume is not important, but relative relation in volume loudness does. Can calulate the volume standard deviation and range. Silence is determined by threshold
- Also look at frequency spikes at around 4 Hz (characteristic energy peak of speech)
- Pitch also a good feature. Can be calculated as a function of signal amplitude. Want to find local minimums. Can also find voice-or-music ratios and calculate the ratio of voice or music to the entire clip.

- Frequency analysis can be conducted as well, looking at the energy distribution in difference frequency bands
- To analyze: look at mean and variance, clustering, amount of scatter


Liu \etal \cite{Liu1998a} want to perform initial segmentation on audio signals to help with the more complex task of video segmentation. Features were extracted from 1 second moving windows. Segmentation was performed by looking at several different features: (1) Relative volume. Mean volume was not determined to be important since that could vary between different television programs, but relative volume between windowed data can be used. If the volume's standard deviation and range varies greatly, it suggests a potential segment point. Silence can be determined by volume thresholds and the zero-crossing rate. (2) Frequency spikes. If the windowed data has large frequency content at around 4 Hz, which is the characteristic energy peak of speech, it is possible that it is heavier in speech contents. Energy distribution in different frequency bands can also help label the observation data. (3) Pitch. Pitch can be calculated as a function of signal amplitude, and can also help with data characterization. Voice-or-music ratios can also be used for this purpose.

Liu \etal \cite{Liu1998a} derived several audio-based features, such as relative volume, frequency amplitude and pitch, from audio tracks that accompanied video data. These features were clustered via Isodata to determine which features were separable. Neural net is trained based on the Isodata results, and is used to label the observation under a 1 second long sliding window.},
  timestamp = {2013.08.29},
}

@InProceedings{Longstaff2010,
  Title                    = {Improving activity classification for health applications on mobile devices using active and semi-supervised learning},
  Author                   = {Longstaff, B. and Reddy, S. and Estrin, D.},
  Booktitle                = {International Conference on Pervasive Computing Technologies for Healthcare},
  Year                     = {2010},
  Pages                    = {1--7},

  Abstract                 = {Mobile phones' increasing ubiquity has created many opportunities for personal context sensing. Personal activity is an important part of a user's context, and automatically recognizing it is vital for health and fitness monitoring applications. Recording a stream of activity data enables monitoring patients with chronic conditions affecting ambulation and motion, as well as those undergoing rehabilitation treatments. Modern mobile phones are powerful enough to perform activity classification in real time, but they typically use a static classifier that is trained in advance or require the user to manually add training data after the application is on his/her device. This paper investigates ways of automatically augmenting activity classifiers after they are deployed in an application. It compares active learning and three different semi-supervised learning methods, self-learning, En-Co-Training, and democratic co-learning, to determine which show promise for this purpose. The results show that active learning, En-Co-Training, and democratic co-learning perform well when the initial classifier's accuracy is low (75-80%). When the initial accuracy is already high (90%), these methods are no longer effective, but they do not hurt the accuracy either. Overall, active learning gave the highest improvement, but democratic co-learning was almost as good and does not require user interaction. Thus, democratic co-learning would be the best choice for most applications, since it would significantly increase the accuracy for initial classifiers that performed poorly.},
  Doi                      = {10.4108/ICST.PERVASIVEHEALTH2010.8851},
  Keywords                 = {learning (artificial intelligence);mobile computing;patient monitoring;patient rehabilitation;active learning;activity classification;democratic co-learning;en-co-training;health applications;mobile devices;patients monitoring;personal context sensing;rehabilitation treatments;semi supervised learning;Biomedical monitoring;Cardiac disease;Cardiovascular diseases;Machine learning algorithms;Mobile handsets;Patient monitoring;Semisupervised learning;Smart phones;Training data;User interfaces},
  Review                   = {- want an adaptive classifier for activity recognition. examines a few different types:

self-learning: classifier label. high confidence observation is added back into the training set
co-learning: multiple classifiers trained on the same data. the different classifiers could vote on new data points, then all classifiers are retrained under a common dataset. or perhaps each the classifier maintains its own dataset. can be used in a boosting scheme},
  Timestamp                = {2014.12.22}
}

@Article{Lopes2005,
  Title                    = {Visual learning by imitation with motor representations},
  Author                   = {Lopes, M. and Santos-Victor, J.},
  Journal                  = {Systems, Man, and Cybernetics, Part B: Cybernetics, IEEE Transactions on},
  Year                     = {2005},

  Month                    = {June},
  Number                   = {3},
  Pages                    = {438-449},
  Volume                   = {35},

  Abstract                 = {We propose a general architecture for action (mimicking) and program (gesture) level visual imitation. Action-level imitation involves two modules. The viewpoint transformation (VPT) performs a "rotation" to align the demonstrator's body to that of the learner. The visuo-motor map (VMM) maps this visual information to motor data. For program-level (gesture) imitation, there is an additional module that allows the system to recognize and generate its own interpretation of observed gestures to produce similar gestures/goals at a later stage. Besides the holistic approach to the problem, our approach differs from traditional work in i) the use of motor information for gesture recognition; ii) usage of context (e.g., object affordances) to focus the attention of the recognition system and reduce ambiguities, and iii) use iconic image representations for the hand, as opposed to fitting kinematic models to the video sequence. This approach is motivated by the finding of visuomotor neurons in the F5 area of the macaque brain that suggest that gesture recognition/imitation is performed in motor terms (mirror) and rely on the use of object affordances (canonical) to handle ambiguous actions. Our results show that this approach can outperform more conventional (e.g., pure visual) methods.},
  Doi                      = {10.1109/TSMCB.2005.846654},
  ISSN                     = {1083-4419},
  Keywords                 = {gesture recognition;humanoid robots;image representation;image sequences;learning (artificial intelligence);psychology;robot kinematics;robot vision;F5 area;VMM map;VPT;action-level imitation;anthropomorphic robot;gesture recognition system;iconic image representation;kinematic model;macaque brain;motor data;motor information;motor representation;program level visual imitation;video sequence;viewpoint transformation;visual learning;visuo-motor map;visuomotor coordination;visuomotor neuron;Cognitive robotics;Focusing;Humans;Image recognition;Image representation;Mirrors;Neurons;Robot kinematics;Robot sensing systems;Video sequences;Anthropomorphic robots;imitation;learning;visuomotor coordination;Algorithms;Artificial Intelligence;Biomimetics;Bionics;Computer Simulation;Hand;Hand Strength;Humans;Image Interpretation, Computer-Assisted;Models, Biological;Motor Skills;Movement;Pattern Recognition, Automated;Robotics;Vision},
  Timestamp                = {2014.12.21}
}

@Conference{Lorincz2009,
  Title                    = {Mercury: A Wearable Sensor Network Platform for High-fidelity Motion Analysis},
  Author                   = {Lorincz, K. and Chen, B. R. and Challen, G. W. and Chowdhury, A. R. and Patel, S. and Bonato, P. and Welsh, M.},
  Booktitle                = {Proceedings of the ACM Conference on Embedded Networked Sensor Systems},
  Year                     = {2009},
  Pages                    = {183--196},

  Abstract                 = {This paper describes Mercury, a wearable, wireless sensor platform for motion analysis of patients being treated for neuromotor disorders, such as Parkinson’s Disease, epilepsy, and stroke. In contrast to previous systems intended for short-term use in a laboratory, Mercury is designed to support long-term, longitudinal data collection on patients in hospital and home settings. Patients wear up to 8 wireless nodes equipped with sensors for monitoring movement and physiological conditions. Individual nodes compute high-level features from the raw signals, and a base station performs data collection and tunes sensor node parameters based on energy availability, radio link quality, and application specific policies. 

Mercury is designed to overcome the core challenges of long battery lifetime and high data fidelity for long-term studies where patients wear sensors continuously 12 to 18 hours a day. This requires tuning sensor operation and data transfers based on energy consumption of each node and processing data under severe computational constraints. Mercury provides a high-level programming interface that allows a clinical researcher to rapidly build up different policies for driving data collection and tuning sensor lifetime. We present the Mercury architecture and a detailed evaluation of two applications of the system for monitoring patients with Parkinson’s Disease and epilepsy.},
  Doi                      = {10.1145/1644038.1644057},
  Keywords                 = {Postural detection; wireless sensor networks},
  Review                   = {Mercury is a sensor suite solution for body motion measurements. Want to target hospital and home settings. 
- uses 8 Intel SHIMMER wireless accel/gyro systems
- Battery life is a concern
- Must be able to tolerate patient motion
- 100Hz+ from sensors -> writes to local flash -> transmit to base station

- However, constant transmission would drain battery life too quicky. Instead, the SHIMMER uC would perform some feature extraction and transmit the features instead of the actual raw data. This allows for a big picture, but lower data moved. More likely to move into a real-time/near-real-time system.
- Also, turn off gyro when not moving, as detected by accel

Overall, it seems like they have built a pretty good system. However, it doesn't talk about how they're doing their motion analysis. Suspect that they're using non-kinematic metics, such as FFT or PSD, as well as directly looking at accel.},
  Timestamp                = {2010.05.17}
}

@InProceedings{Losch2007,
  Title                    = {Feature Set Selection and Optimal Classifier for Human Activity Recognition},
  Author                   = {Losch, M. and Schmidt-Rohr, S. and Knoop, S. and Vacek, S. and Dillmann, R.},
  Booktitle                = {IEEE International Symposium on Robot and Human Interactive Communication},
  Year                     = {2007},
  Pages                    = {1022--1027},

  Abstract                 = {Human activity recognition is an essential ability for service robots and other robotic systems which are in interaction with human beings. To be proactive, the system must be able to evaluate the current state of the user it is dealing with. Also future surveillance systems will benefit from robust activity recognition if realtime constraints are met, allowing to automate tasks that have to be fulfilled by humans yet. In this paper, a thorough analysis of features and classifiers aimed at human activity recognition is presented. Based on a set of 10 activities, the use of different feature selection algorithms is evaluated, as well as the results different classifiers (SVMs, Neural Networks, Bayesian Classifiers) provide in this context. Also the interdependency between feature selection method and chosen classifier is investigated. Furthermore, the optimal number of features to be used for an activity is examined.},
  Doi                      = {10.1109/ROMAN.2007.4415232},
  Keywords                 = {feature extraction;human computer interaction;image classification;object recognition;robot vision;service robots;user interfaces;feature set selection;human activity recognition;human-robot interaction;optimal classifier;service robots;surveillance system;Bayesian methods;Computer science;Hidden Markov models;Human robot interaction;Neural networks;Object detection;Robotics and automation;Service robots;Surveillance;Tracking},
  Timestamp                = {2014.12.20}
}

@InProceedings{Low2009,
  Title                    = {A wearable wireless sensor network for human limbs monitoring},
  Author                   = {Low, K. S. and Lee, G. X. and Taher, T.},
  Booktitle                = {Proceedings of the Instrumentation and Measurement Technology Conference},
  Year                     = {2009},
  Pages                    = {1332--1336},

  Abstract                 = {In many applications, it is desired to monitor the human body motion to provide useful information for applications such as rehabilitation, virtual reality, sports science etc. Most existing inertial/magnetic systems used for body motion tracking today come with wiring which restrains the natural movement. In this paper, a wearable wireless sensor network using accelerometers has been developed for monitoring the human motion. The wireless feature of our system allows for unrestrained movements and improves the usability of the system. Moreover, the use of lightweight sensor nodes makes it easy for attachment to the limbs and poses little hindrance to natural movements. The developed system is also portable and low in cost compared to sophisticated visual tracking systems utilizing multiple cameras. The low power consumption of the sensor nodes also makes it suitable for long term monitoring. A prototype has been developed and experimental results show that the system has reasonable performance.},
  Doi                      = {10.1109/IMTC.2009.5168662},
  ISSN                     = {1091-5281},
  Keywords                 = {accelerometer;human limbs monitoring;human motion monitoring;lightweight sensor node;multiple camera;prototype;unrestrained movement;visual tracking system;wearable wireless sensor network;accelerometers;biomechanics;biomedical telemetry;cameras;tracking;wireless sensor networks;},
  Timestamp                = {2011.12.31}
}

@Article{Lu2004,
  author    = {Lu, C. and Ferrier, N. J.},
  title     = {Repetitive Motion Analysis: Segmentation and Event Classification},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year      = {2004},
  volume    = {26},
  pages     = {258--263},
  issn      = {0162-8828},
  abstract  = {Acquisition, analysis, and classification of repetitive human motion for the assessment of postural stress is of central importance to ergonomics practitioners. We present a two-threshold, multidimensional segmentation algorithm to automatically decompose a complex motion into a sequence of simple linear dynamic models. No a priori assumptions were made about the number of models that comprise the full motion or about the duration of the task cycle. A compact motion representation is obtained for each segment using parameters of a damped harmonic dynamic model. Event classification was performed using cluster analysis with the model parameters as input. Experiments demonstrate the technique on complex motion.},
  doi       = {10.1109/TPAMI.2004.1262196},
  groups    = {Lit Review 2013-09, STAT841},
  keywords  = {biomechanics;ergonomics;image classification;image motion analysis;image representation;image segmentation;image sequences;pattern clustering;automatic decomposition;cluster analysis;complex motion;damped harmonic dynamic model;ergonomics practitioners;event classification;linear dynamic models sequence;model parameters;motion representation;multidimensional segmentation algorithm;postural stress assessment;repetitive human motion;repetitive motion analysis;Employment;Ergonomics;Event detection;Humans;Injuries;Motion analysis;Motion measurement;Multidimensional systems;Performance analysis;Stress;Algorithms;Arm;Artificial Intelligence;Cluster Analysis;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Leg;Models, Biological;Motion;Movement;Pattern Recognition, Automated;Periodicity;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;Subtraction Technique},
  review    = {Want to auto-segment ergonomics videos to detect RSI. 

Second order AR model used to model motion data. 

wiki - In statistics and signal processing, an autoregressive (AR) model is a representation of a type of random process; as such, it describes certain time-varying processes in nature, economics, etc. The autoregressive model specifies that the output variable depends linearly on its own previous values. It is a special case of the more general ARMA model of time series.

The AR model uses two matrices to describe the AR equ'n: A (for deterministic part of the model) and B (for stocastic part of the model). The motion segmentation problem wants to detect when the A matrix changes significantly, signifying a change in the dynamical parameters of the system. Procedure is this:

1. LPF to smmoth data, then zero-mean the obs 
2. Apply least squares to determine the values of the AR matrices that describes the model
3. Frobenius norm of the difference between the parameter matrices between the current and previous time step is calculated. RLS is applied to the norm to determine deviation

This proposes segment potentials. To refine the segmentation...

1. diff the segment points to figure out the distance between each segment point, and keep the ones with the n highest distances (confusion. are we not expecting repetetive motion? if so, wouldn't we want motions with the least amount of distance?). Calculate the fitting error (against what source?) and if the error is too high, increase n. This step is suppose to remove situations where large number of seg points appear in a short period of time, which is usually noise.


A damped harmonic model is used to fit the observation data. to compare motions, the parameters used to fit the obs to templates can be examined.


Segmentation accuracy not reported. The paper focuses on classification, and reports a confusin matrix.. 95% accuracy in classification


Lu and Ferrier \cite{Lu2004} uses an auto-regressive (AR) model to represent the data. The AR model uses two matrices: the $A$ matrix, for the deterministic component of the model, and the $B$ matrix, for the stochastic part. When the $A$ matrix changes significantly, the dynamical properties of the system have changed, thus a segment should be declared. Recursive least squares (RLS) is applied to the data to estimate the AR model, and the Frobenius norm of the difference of the $A$ between the current and previous time step is assessed. RLS is applied to the Frobenius norm to determine when deviation occurs, thus a segment. To reduce over-segmentation, segment points that are close together are removed. The algorithm was applied to joint angle data from karate motions, and produced a classification accuracy of 95\%. No segmentation accuracy was reported.},
  timestamp = {2013.10.02},
}

@Article{Lu2011,
  Title                    = {The development of an upper limb stroke rehabilitation robot: identification of clinical practices and design requirements through a survey of therapists},
  Author                   = {Lu, E. C. and Wang, R. H. and Hebert, D. and Boger, J. and Galea, M. P. and Mihailidis, A.},
  Journal                  = {Disability and Rehabilitation: Assistive Technology},
  Year                     = {2011},
  Number                   = {5},
  Pages                    = {420--431},
  Volume                   = {6},

  Abstract                 = {Purpose. Timely and adequate rehabilitation after a stroke is crucial to maximising recovery. A way of increasing treatment access could be through robots, which would aid therapists in providing post-stroke rehabilitation. This research sought to discover the needs and preferences of therapists with respect to a robot that focuses on upper limb rehabilitation. Understanding requirements for devices could help to increase integration into clinical practice.

Methods. An international online survey was distributed through professional organisations and e-mail list services to therapists. The survey contained 85 items covering topics such as therapist background and treatment approach, rehabilitation aims and robotic rehabilitation device attributes.

Results. Data were analysed for 233 respondents, most of whom were physiotherapists and occupational therapists from Australia, Canada and USA. Top attributes included: facilitating a variety of arm movements, being usable while seated, giving biofeedback to clients, having virtual activities specific to daily living, being useful in-home and having resistance adjustable to client needs. In addition, the device should cost under 6000 USD.

Conclusions. Findings from this survey provide guidance for technology developers regarding therapists' specifications for a robotic device for upper limb rehabilitation. In addition, findings offer a better understanding of how acceptance of such devices may be facilitated.},
  Doi                      = {10.3109/17483107.2010.544370},
  Eprint                   = {http://informahealthcare.com/doi/pdf/10.3109/17483107.2010.544370},
  Keywords                 = {robot rehabilitation, stroke},
  Timestamp                = {2011.12.27},
  Url                      = {http://informahealthcare.com/doi/abs/10.3109/17483107.2010.544370}
}

@InProceedings{Lu2001b,
  Title                    = {A Robust Audio Classification and Segmentation Method},
  Author                   = {Lu, L. and Jiang, H. and Zhang, H. J.},
  Booktitle                = {Proceedings of the ACM international conference on Multimedia},
  Year                     = {2001},
  Pages                    = {203--211},

  Review                   = {- Uses SVM to learn class boundaries of 5 different classes: silence, music, speech, background noise, non-pure speech},
  Timestamp                = {2013.08.29}
}

@InProceedings{Lu2001,
  author    = {Lu, L. and Li, S. Z. and Zhang, H.-J.},
  title     = {Content-based Audio Segmentation using Support Vector Machines},
  booktitle = {IEEE International Conference on Multimedia and Expo},
  year      = {2001},
  volume    = {1},
  pages     = {749--752},
  abstract  = {Audio exists at everywhere, but is often out-of-order. It is
necessary to arrange them into regularized classes in order
to use them more easily. It is also useful, especially in
video content analysis, to segment an audio stream
according to audio types. In this paper, we present our
work in applying support vector machines (SVMs) in
audio segmentation and classification. Five audio classes
are considered: silence, music, background sound, pure
speech, and non-pure speech which includes speech over
music and speech over noise. A SVM learns optimal class
boundaries from training data to best separate between
two classes. A sound clip is segmented by classifying
each sub-clip of one second into one of these five classes.
Experiments on a database composed of clips of 14870
seconds in total length show that the average accuracy rate
for the SVM method is much better than that of the
traditional Euclidean distance based (nearest neighbor)
method.},
  groups    = {STAT841},
  review    = {Audio clips are divided in non-overlapping clips of 1 sec length, and then divided again into fourty 25 ms lengths. MFCC features are calculated for each of the 25ms windows so we can get the mean and SD of the feature traj. Other features like zero-corssing and short time energy are also used. They've got a lot of features they'r eusing. More than I'm writing down. From the 40 clips, an overall feature vector is created (so a giant, 40x8 vector). They use kernal SVM to deal with non-linearity separable-ness in the data.

Heuritistics is used to divide each 1s window audio into silence/non-silence (based on energy information, thresholded). For the non-silence, a binary tree is used. 2 two-class SVM is used (4 classes total). The "winner" of first tier is compared for another 2-class SVM comparison. So when a class switch is observed, it is a segment. It performed at 96.65% accuracy.

It sounds like they needed a large feature vector to do this. Probably had to choose SVM since it's fast. But might be difficult to scale up. Also, it would not be able to leave regions unclassified, so high FP?

Lu \etal \cite{Lu2001} divided the observation audio clips into 250 millisecond long windows and used features such as MFCC, zero crossing and short time energy in a kernel SVM algorithm to segment. Each of these windows are labelled as one of 4 different classes, to denote different different types of sounds. A tree scheme is used, where 2 two-class SVMs are used in the first step. The 'winner'of the first tier is then compared at another two-class SVM. See Figure \ref{fig:Lu2001_SVMTree}. When a class switch is observed, a segment is declared. It performed at 97\% accuracy. A system like this would be difficult to scale upwards, since the more templates there are, the more SVM assessments are required.},
  timestamp = {2013.10.08},
}

@Article{Lu2002,
  author    = {Lu, L. and Zhang, H. J. and Jiang, H.},
  title     = {Content analysis for audio classification and segmentation},
  journal   = {IEEE Transactions on Speech and Audio Processing},
  year      = {2002},
  volume    = {10},
  pages     = {504--516},
  abstract  = {We present our study of audio content analysis for classification and segmentation, in which an audio stream is segmented according to audio type or speaker identity. We propose a robust approach that is capable of classifying and segmenting an audio stream into speech, music, environment sound, and silence. Audio classification is processed in two steps, which makes it suitable for different applications. The first step of the classification is speech and nonspeech discrimination. In this step, a novel algorithm based on K-nearest-neighbor (KNN) and linear spectral pairs-vector quantization (LSP-VQ) is developed. The second step further divides nonspeech class into music, environment sounds, and silence with a rule-based classification scheme. A set of new features such as the noise frame ratio and band periodicity are introduced and discussed in detail. We also develop an unsupervised speaker segmentation algorithm using a novel scheme based on quasi-GMM and LSP correlation analysis. Without a priori knowledge, this algorithm can support the open-set speaker, online speaker modeling and real time segmentation. Experimental results indicate that the proposed algorithms can produce very satisfactory results.},
  groups    = {STAT841},
  publisher = {IEEE},
  review    = {- Uses k-NN, and a few other things to segment. 
- Also have unsupervised speaker segmentation alg using GMM

Lu \etal \cite{Lu2002} developed an audio classification and segmentation algorithm based on \emph{k}-nearest-neighbour (\emph{k}-NN) and linear spectral pairs-vector quantization (LSP-VQ), as well as examining several different features. These features are (1) high zero-crossing rate ratio, the ratio of number of frames that has more than 1.5 zero crossings within a 1 second window, (2) low short-time energy, the ratio of the number of frames who short-time energy are less than half of the average short time energy in 1 second window, (3) spectrum flux, the average variation value of spectrum between two adjacent frames in a 1 second window, (4) linear spectral pairs (KSP) divergence distance, calculated from the mean and covariance of windows, (5) band periodicity, how often frequencies of a given sub-band appears and (6) noise frame ratio, the ratio of noise frames in a given audio clip. This paper wants to classify audio clips, at 1 second window at a time, into one of four classes: speech, music, environment sound and silence. The audio stream is classify into speech or non-speech by \emph{k}-NN and LSP-VQ, based on the features examined. If speech is detected, in order to further refine the results, the LSP distance is calculated between the audio signal and pre-trained model codebooks, to narrow down the type of audio. If non-speech audio is detected, additional metrics are ran to determine if it is silence, music or environmental noise. Segmentation is achieved by determining where these classification label changes occur. GMMs are also utilized to further segment speech data.

Lu \etal \cite{Lu2002} developed an audio classification and segmentation algorithm based on \emph{k}-NN. Several features are examined, including the linear spectral pairs-vector quantization (LSP-VQ), zero-crossing rate ratio, low short-time energy, spectrum flux, band periodicity, and noise frame ratio. This paper wants to classify audio clips, at 1 second window at a time, into one of four classes: speech, music, environment sound and silence. The audio stream is classify into speech or non-speech by \emph{k}-NN on the LSP-VQ feature. If speech is detected, in order to further refine the results, the LSP distance is calculated between the audio signal and pre-trained model codebooks, to narrow down the type of audio. If non-speech audio is detected, threshold-based metrics are used on the other listed features are ran to determine if it is silence, music or environmental noise. Segmentation is achieved by determining where these classification label changes occur. %Tritschler and Gopinath's BIC algorithm \cite{Tritschler1999} is used to further segment speech data by determining when the active speaker shifts to another one.},
  timestamp = {2013.08.29},
}

@Article{Luh1980,
  Title                    = {On-line Computational Scheme for Mechanical Manipulators},
  Author                   = {Luh, J. Y. S. and Walker, M. W. and Paul, R. P. C.},
  Journal                  = {Journal of Dynamic Systems, Measurement and Control},
  Year                     = {1980},
  Pages                    = {69--76},
  Volume                   = {102},

  Abstract                 = {Industrial robots are mechanical manipulators whose dynamic characteristics are highly nonlinear. To control a manipulator which carries a variable or unknown load and moves along a planned path, it is required to compute the forces and torques needed to drive all its joints accurately and frequently at an adequate sampling frequency (no less than 60 Hz for the arm considered). This paper presents a new approach of computation based on the method of Newton-Euler formulation which is independent of the type of manipulator-configuration. This method involves the successive transformation of velocities and accelerations from the base of the manipulator out to the gripper, link by link, using the relationships of moving coordinate systems. Forces are then transformed back from the gripper to the base to obtain the joint torques. Theoretically the mathematical model is "exact".},
  Keywords                 = {Mechanical manipulators | Industrial robots | Newton-Euler formulations | Velocity transformation | Acceleration transformations},
  Timestamp                = {2012.09.14}
}

@Article{Luinge2005,
  author      = {Luinge, H. and Veltink, P.},
  title       = {Measuring orientation of human body segments using miniature gyroscopes and accelerometers},
  journal     = {Medical and Biological Engineering and Computing},
  year        = {2005},
  volume      = {43},
  pages       = {273--282},
  issn        = {0140-0118},
  abstract    = {In the medical field, there is a need for small ambulatory sensor systems for measuring the kinematics of body segments. Current methods for ambulatory measurement of body orientation have limited accuracy when the body moves. The aim of the paper was to develop and validate a method for accurate measurement of the orientation of human body segments using an inertial measurement unit (IMU). An IMU containing three single-axis accelerometers and three single-axis micromachined gyroscopes was assembled in a rectangular box, sized 20x20x30 mm. The presented orientation estimation algorithm continuously corrected orientation estimates obtained by mathematical integration of the 3D angular velocity measured using the gyroscopes. The correction was performed using an inclination estimate continuously obtained using the signal of the 3D accelerometer. This reduces the integration drift that originates from errors in the angular velocity signal. In addition, the gyroscope offset was continuously recalibrated. The method was realised using a Kalman filter that took into account the spectra of the signals involved as well as a fluctuating gyroscope offset. The method was tested for movements of the pelvis, trunk and forearm. Although the problem of integration drift around the global vertical continuously increased in the order of 0.5s -1, the inclination estimate was accurate within 3 RMS. It was shown that the gyroscope offset could be estimated continuously during a trial. Using an initial offset error of 1 rads -1, after 2 min the offset error was roughly 5% of the original offset error. Using the Kalman filter described, an accurate and robust system for ambulatory motion recording can be realised.},
  affiliation = {University of Twente Signals Systems Group, Department of Electrical Engineering Enschede The Netherlands Enschede The Netherlands},
  groups      = {EMBC2013},
  issue       = {2},
  keyword     = {Medicine},
  keywords    = {Postural Detection},
  publisher   = {Springer Berlin / Heidelberg},
  review      = {Luinge2005
Motion type: Various upperbody motions
Recovery methodology: Use strapdown integration on gyroscopes to get rotational angle. The forward movement estimated from this rotation is subtracted from the accelerometer signal, leaving only the gyroscope. The gravity vector is trig'ed to get angle to ground. 
Verification technique:
Subject demographics: 
Error reported:},
  timestamp   = {2011.03.01},
}

@Article{Luinge2004,
  Title                    = {Inclination measurement of human movement using a 3-D accelerometer with autocalibration},
  Author                   = {Luinge, H.J. and Veltink, P.H.},
  Journal                  = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  Year                     = {2004},
  Pages                    = {112--121},
  Volume                   = {12},

  Abstract                 = {In the medical field, accelerometers are often used for measuring inclination of body segments and activity of daily living (ADL) because they are small and require little power. A drawback of using accelerometers is the poor quality of inclination estimate for movements with large accelerations. This paper describes the design and performance of a Kalman filter to estimate inclination from the signals of a triaxial accelerometer. This design is based on assumptions concerning the frequency content of the acceleration of the movement that is measured, the knowledge that the magnitude of the gravity is 1 g and taking into account a fluctuating sensor offset. It is shown that for measuring trunk and pelvis inclination during the functional three-dimensional activity of stacking crates, the inclination error that is made is approximately 2 deg; root-mean square. This is nearly twice as accurate as compared to current methods based on low-pass filtering of accelerometer signals.},
  Doi                      = {10.1109/TNSRE.2003.822759},
  ISSN                     = {1534-4320},
  Keywords                 = {1 g;3-D accelerometer;Kalman filter;activity of daily living;autocalibration;fluctuating sensor offset;functional three-dimensional activity;human movement;inclination measurement;low-pass filtering;pelvis inclination;stacking crates;triaxial accelerometer;trunk inclination;Kalman filters;accelerometers;biomechanics;biomedical transducers;medical signal processing;Acceleration;Algorithms;Calibration;Gravitation;Humans;Lifting;Monitoring, Ambulatory;Movement;Posture;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;Spine;Task Performance and Analysis;Thorax;Transducers;},
  Timestamp                = {2012.09.10}
}

@InProceedings{Luprano2013,
  Title                    = {HeartCycle: Advanced Sensors for Telehealth Applications (I)},
  Author                   = {Luprano, J. and de Carvalho, P. and Eilebrecht, B. and Kortelainen, J. and Muehlsteff, J. and Sipila, A. and Sola, J. and Teichmann, D. and Ulbrich, M.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {Current treatment of Cardiovascular Disease (CVD) – the most frequent cause of hospitalization for people over 65 – involves changes of diet and lifestyle, requiring in addition physical exercise to support these. Nowadays, patients receive sporadic feedback at doctor visits, or later on, when facing symptoms. The HeartCycle project aimed at providing 1) daily monitoring, 2) close follow up, 3) help on treatment routine and 4) decreasing non-compliance to treatment regimes. The present paper illustrates a new toolbox of advanced sensors developed within the HeartCycle project. On-going clinical studies support these developments.},
  Keywords                 = {EMBC2013},
  Review                   = {Want an automated system to provide feedback to patients about their cardio state, motivational tools, vital sign sensor. 

ECG, BCG, BP (from heart/lung and PPM sounds), SpO2. Used flexible sensors},
  Timestamp                = {2013.08.05}
}

@InProceedings{Lv2006,
  author      = {Lv, F. and Nevatia, R.},
  title       = {Recognition and Segmentation of 3-{D} Human Action Using {HMM} and Multi-class {AdaBoost}},
  booktitle   = {Proceedings of the European Conference on Computer Vision},
  year        = {2006},
  pages       = {359--372},
  abstract    = {Our goal is to automatically segment and recognize basic human actions, such as stand, walk and wave hands, from a sequence of joint positions or pose angles. Such recognition is difficult due to high dimensionality of the data and large spatial and temporal variations in the same action. We decompose the high dimensional 3-D joint space into a set of feature spaces where each feature corresponds to the motion of a single joint or combination of related multiple joints. For each feature, the dynamics of each action class is learned with one HMM. Given a sequence, the observation probability is computed in each HMM and a weak classifier for that feature is formed based on those probabilities. The weak classifiers with strong discriminative power are then combined by the Multi-Class AdaBoost (AdaBoost.M2) algorithm. A dynamic programming algorithm is applied to segment and recognize actions simultaneously. Results of recognizing 22 actions on a large number of motion capture sequences as well as several annotated and automatically tracked sequences show the effectiveness of the proposed algorithms.},
  affiliation = {Institute for Robotics and Intelligent Systems, University of Southern California, Los Angeles, CA 90089-0273},
  groups      = {STAT841},
  keywords    = {HMM, AdaBoost, Segmentation},
  review      = {- Given 3D joint positions, recognize action
- joint pos from mocap
- action recog is hard, given the high dimensionality (67D)

Algorithm
- HMM is used to learn some primative
 - the motion is decomposed to essential DOFs (not all 67D, see page 5)
 - HMM observation matrix is extracted, and a weak classifier is created
- These HMM weak classifiers are tied into a multiclass AdaBoost
- Dynamic programming used to segment and recognize motion simultanouously

- Uses 23 joints' coord (not joint angle) - "pose vector"
- classified as "stationary pose (sitting)", " transistion pose" or "periodic pose (walking)"
- using the full pose vector may mask relevant info in the large pose
- uses Forward-Backward...as in it's not online?
- (reread) implementation details in HMM

Lv and Nevatia \cite{Lv2006} used HMM templates as classifiers in an AdaBoost algorithm. Features such as joint angles and joint Cartesian coordinates were used. HMM templates are generated for $M$ action types and $N$ features, resulting in $M \times N$ number of classifiers. Multi-class AdaBoost was employed to weigh the discriminative powers of each of the HMM classifiers. Segmentation was determined by dynamic programming. The observation data is split into two, with the first window starting at some minimum length $l_{min}$, and increased per iteration. Both ends of the data are ran through the AdaBoost classifiers, and the window configuration that resulted in the highest likelihood was selected. The algorithm is run multiple times, with the starting point of the first window advancing at each run. The algorithm was verified on various upper-body motions, and was shown to be robust even when a large number of features are examined. However, this method requires a large computational cost for both training and segmenting, due to the usage of dynamic programming, and thus cannot be used online.},
  timestamp   = {2011.04.18},
}

@InProceedings{Lymberis2003,
  Title                    = {Smart wearables for remote health monitoring, from prevention to rehabilitation: current research and development, future challenges},
  Author                   = {Lymberis, A.},
  Booktitle                = {Proceedings of the 4th Annual IEEE Conference on Information Technology Applications in Biomedicine},
  Year                     = {2003},
  Pages                    = {272--275},

  Abstract                 = {Telemedicine has significantly broaden its scope the last few years. In the 90's, it was mainly used by healthcare providers, regardless time and location, for second opinion and patient consultation. Today it elaborates solutions for remote health monitoring to support prevention, early diagnosis, disease management, treatment and home rehabilitation. Remote health monitoring could lead to a significant reduction of total cost in healthcare by avoiding unnecessary hospitalisations and ensuring that those who need urgent care get it sooner. Latest developments in micro- and nanotechnologies as well as in information processing and wireless communication offer, today, the possibility for smart miniaturisation and non-invasive biomedical measurement as well as for wearable sensing, processing and communication. Although developing specific systems and applications to address specific user needs, the "smart health wearable" research and industrial community faces a number of common critical issues, e.g. biomedical sensors, scenarios of use (linked to the business scenarios), data security and confidentiality, risk analysis, user interface, medical knowledge/decision support, dissemination, user acceptance and awareness, business models and exploitation. Beyond technology, which seems providing proof of concept, real future challenges such as clinical validation and impact assessment of the newly developed smart wearable applications, are ahead. This paper review the current status in research and development of smart wearable health applications, developed especially under the EU research activities and analyse the outstanding issues and future challenges to be achieved in the future.},
  Doi                      = {10.1109/ITAB.2003.1222530},
  ISSN                     = { },
  Journal                  = {Information Technology Applications in Biomedicine, 2003. 4th International IEEE EMBS Special Topic Conference on},
  Keywords                 = { biomedical sensors; business models; business scenarios; confidentiality; data security; disease management; disease treatment; early diagnosis; healthcare providers; home rehabilitation; industrial community; information processing; medical knowledge/decision support; microtechnologies; nanotechnologies; noninvasive biomedical measurement; patient consultation; prevention; rehabilitation; remote health monitoring; review; risk analysis; second opinion; smart health wearable research; smart miniaturisation; telemedicine; total cost; user acceptance; user interface; wearable health applications; wireless communication; intelligent sensors; patient monitoring; patient rehabilitation; radio access networks; remote sensing; telemedicine; user interfaces;},
  Review                   = {- 'continuity of health' is becoming more common. people are asking for health advice, etc
- important for health care giver to have access to all sorts of health data like health record, accounting, logistics, or remote monitoring of vital signs or whatnot, so diagnosis and treatment can go over okay
- Sensors should be...
 - light weight
 - lowre power consumption
 - reasonable price
 - usable by unskilled people
 - embedded processing
 - alarming capability
 - capable of uninterrupted connection with remote medical centre constantly
- goes on to say these things should be included:
 - holds patient data
 - user friendly user interface
 - data storage and backup storage solution
 - telecommunication, link between the wearable and health provider
 - embedded medical decision
 - telemedicine service - should transmit good quality medical data
 - legal and ethical issues considered...user confidentiality protected
 - patient safety
 - standardisation and interoperability
 - validation plan (must be able to field test)
 - risk analysis
 - biomedical sensors},
  Timestamp                = {2010.09.28}
}

@Article{Mulling2013,
  Title                    = {Learning to select and generalize striking movements in robot table tennis},
  Author                   = {M{\"u}lling, Katharina and Kober, Jens and Kroemer, Oliver and Peters, Jan},
  Journal                  = {The International Journal of Robotics Research},
  Year                     = {2013},
  Number                   = {3},
  Pages                    = {263--279},
  Volume                   = {32},

  Abstract                 = {Learning new motor tasks from physical interactions is an important goal for both robotics and machine learning. However,
when moving beyond basic skills, most monolithic machine learning approaches fail to scale. For more complex skills,
methods that are tailored for the domain of skill learning are needed. In this paper, we take the task of learning table
tennis as an example and present a new framework that allows a robot to learn cooperative table tennis from physical
interaction with a human. The robot first learns a set of elementary table tennis hitting movements from a human table
tennis teacher by kinesthetic teach-in, which is compiled into a set of motor primitives represented by dynamical systems.
The robot subsequently generalizes these movements to a wider range of situations using our mixture of motor primitives
approach. The resulting policy enables the robot to select appropriate motor primitives as well as to generalize between
them. Finally, the robot plays with a human table tennis partner and learns online to improve its behavior. We show that
the resulting setup is capable of playing table tennis using an anthropomorphic robot arm.},
  Publisher                = {SAGE Publications},
  Timestamp                = {2013.10.07}
}

@TechReport{Muller2007,
  Title                    = {Documentation Mocap Database {HDM05}},
  Author                   = {M. M\"{u}ller and T. R\"{o}der and M. Clausen and B. Eberhardt and B. Kr\"{u}ger and A. Weber},
  Institution              = {Universit\"{a}t Bonn},
  Year                     = {2007},
  Number                   = {CG-2007-2},

  ISSN                     = {1610-8892},
  Timestamp                = {2015.01.23}
}

@Article{Ma2006,
  Title                    = {A motion capture library for the study of identity, gender, and emotion perception from biological motion},
  Author                   = {Ma, Y. and Paterson, H. M. and Pollick, F. E.},
  Journal                  = {Behavior Research Methods},
  Year                     = {2006},
  Number                   = {1},
  Pages                    = {134--141},
  Volume                   = {38},

  Abstract                 = {We present the methods that were used in capturing a library of human movements for use in computeranimated displays of human movement. The library is an attempt to systematically tap into and represent the wide range of personal properties, such as identity, gender, and emotion, that are available in a person's movements. The movements from a total of 30 nonprofessional actors (15 of them female) were captured while they performed walking, knocking, lifting, and throwing actions, as well as their combination in angry, happy, neutral, and sad affective styles. From the raw motion capture data, a library of 4,080 movements was obtained, using techniques based on Character Studio (plug-ins for 3D Studio MAX, AutoDesk, Inc.), MATLAB (The Math Works, Inc.), or a combination of these two. For the knocking, lifting, and throwing actions, 10 repetitions of the simple action unit were obtained for each affect, and for the other actions, two longer movement recordings were obtained for each affect. We discuss the potential use of the library for computational and behavioral analyses of movement variability, of human character animation, and of how gender, emotion, and identity are encoded and decoded from human movement.},
  Doi                      = {10.3758/BF03192758},
  ISSN                     = {1554-3528},
  Timestamp                = {2017.01.16},
  Url                      = {http://dx.doi.org/10.3758/BF03192758}
}

@InProceedings{MacDorman2006,
  Title                    = {Subjective ratings of robot video clips for human likeness, familiarity, and eeriness: An exploration of the uncanny valley},
  Author                   = {MacDorman, K. F.},
  Booktitle                = {Proceedings of the ICCS/CogSci Long Symposium:Toward Social Mechanisms of Android Science},
  Year                     = {2006},

  Address                  = {Vancouver, Canada},
  Pages                    = {26-29},

  Keywords                 = {Lab reading (Cecille)},
  Timestamp                = {2011.03.23}
}

@Article{Madevska-Bogdanova2004,
  Title                    = {Probabilistic \{SVM\} outputs for pattern recognition using analytical geometry },
  Author                   = {Ana Madevska-Bogdanova and Dragan Nikolik and Leopold Curfs},
  Journal                  = {Neurocomputing },
  Year                     = {2004},
  Number                   = {0},
  Pages                    = {293--303},
  Volume                   = {62},

  Abstract                 = {We present an alternative way of interpreting and modifying the outputs of the support vector machine (SVM) classifiers. Stemming from the geometrical interpretation of the \{SVM\} outputs as a distance of individual patterns from the hyperplane, allows us to calculate its posterior probability, i.e. to construct a probability-based measure of belonging to one of the classes, depending on the vector's relative distance from the hyperplane. We illustrate the results by providing suitable analysis of three classification problems and comparing them with an already published method for modifying \{SVM\} outputs.},
  Doi                      = {http://dx.doi.org/10.1016/j.neucom.2003.03.002},
  ISSN                     = {0925-2312},
  Keywords                 = {Support vector machines},
  Review                   = {Reads like Platt. Not too sure what the difference is.},
  Timestamp                = {2015.02.06},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0925231204002334}
}

@Article{Mahomed2008,
  Title                    = {Inpatient Compared with Home-Based Rehabilitation Following Primary Unilateral Total Hip or Knee Replacement: A Randomized Controlled Trial},
  Author                   = {Mahomed, N. N. and Davis, A. M. and Hawker, G. and Badley, E. and Davey, J. R. and Syed, K. A. and Coyte, P. C. and Gandhi, R. and Wright, J. G.},
  Journal                  = {The Journal of Bone and Joint Surgery (American)},
  Year                     = {2008},
  Pages                    = {673--680},
  Volume                   = {90},

  Abstract                 = {Background: Home-based rehabilitation is increasingly utilized to reduce health-care costs; however, with a shorter hospital stay, the possibility arises for an increase in adverse clinical outcomes. We evaluated the effectiveness and cost of care of home-based compared with inpatient rehabilitation following primary total hip or knee joint replacement.

Methods: We randomized 234 patients, using block randomization techniques, to either home-based or inpatient rehabilitation following total joint replacement. All patients followed standardized care pathways and were evaluated, with use of validated outcome measures (Western Ontario and McMaster Universities Osteoarthritis Index [WOMAC], Short Form-36, and patient satisfaction), prior to surgery and at three and twelve months following surgery. The primary outcome was the WOMAC function score at three months after surgery.

Results: The mean length of stay (and standard deviation) in the acute care hospital was 6.3 ± 2.5 days for the group designated for inpatient rehabilitation prior to transfer to that facility compared with 7.0 ± 3.0 days for the home-based rehabilitation group prior to discharge home (p = 0.06). The mean length of stay in inpatient rehabilitation was 17.7 ± 8.6 days. The mean number of postoperative home-based rehabilitation visits was eight. The prevalence of postoperative complications up to twelve months postoperatively was similar in both groups, which each had a 2% rate of dislocation and a 3% rate of clinically important deep venous thrombosis. The prevalence of infection was 0% in the home-based group and 2% in the inpatient group. None of these differences was clinically important. Both groups showed substantial improvements at three and twelve months, with no significant differences between the groups with respect to WOMAC, Short Form-36, or patient satisfaction scores (p > 0.05). The total episode-of-care costs (in Canadian dollars) for the inpatient rehabilitation and home-based rehabilitation arms were $14,532 and $11,082, respectively (p < 0.01).

Conclusions: Despite concerns about early hospital discharge, there was no difference in pain, functional outcomes, or patient satisfaction between the group that received home-based rehabilitation and the group that had inpatient rehabilitation. On the basis of our findings, we recommend the use of a home-based rehabilitation protocol following elective primary total hip or knee replacement as it is the more cost-effective strategy.

Level of Evidence: Therapeutic Level I. See Instructions to Authors for a complete description of levels of evidence.},
  Keywords                 = {physiotherapy},
  Timestamp                = {2012.06.21}
}

@InProceedings{Mandery2016c,
  Title                    = {Using language models to generate whole-body multi-contact motions},
  Author                   = {C. Mandery and J. Borr\'{a}s and M. J\"{o}chner and T. Asfour},
  Booktitle                = {IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2016},
  Month                    = {Oct},
  Pages                    = {5411-5418},

  Doi                      = {10.1109/IROS.2016.7759796},
  Keywords                 = {humanoid robots;legged locomotion;motion control;natural language processing;human locomotion tasks;human motion data;humanoid robots;language models;motion capture recordings;natural language processing;planning algorithm;pose transitions;probabilistic n-gram language model;whole-body multicontact motions;whole-body poses;Dynamics;Foot;Legged locomotion;Motion segmentation;Planning;Shape},
  Timestamp                = {2017.01.17}
}

@InProceedings{Mandery2015b,
  Title                    = {Analyzing Whole-Body Pose Transitions in Multi-Contact Motions},
  Author                   = {C. Mandery and J. Borr\'{a}s and M. J\"{o}chner and T. Asfour},
  Booktitle                = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  Year                     = {2015},
  Pages                    = {1020--1027},

  Timestamp                = {2017.01.02}
}

@Article{Mandery2016b,
  Title                    = {Unifying Representations and Large-Scale Whole-Body Motion Databases for Studying Human Motion},
  Author                   = {C. Mandery and \"{O}. Terlemez and M. Do and N. Vahrenkamp and T. Asfour},
  Journal                  = {IEEE Transactions on Robotics},
  Year                     = {2016},
  Number                   = {4},
  Pages                    = {796--809},
  Volume                   = {32},

  Timestamp                = {2017.01.02}
}

@InProceedings{Mandery2015,
  Title                    = {The KIT Whole-Body Human Motion Database},
  Author                   = {C. Mandery and O. Terlemez and M. Do and N. Vahrenkamp and T. Asfour},
  Booktitle                = {Proceedings of the IEEE International Conference on Advanced Robotics},
  Year                     = {2015},
  Pages                    = {329--336},

  Timestamp                = {2016.12.20}
}

@Article{Manns2017,
  Title                    = {Motion Optimization and Parameter Identification for a Human and Lower Back Exoskeleton Model},
  Author                   = {P. Manns and M. Sreenivasa and M. Millard and K. Mombaur},
  Journal                  = {IEEE Robotics and Automation Letters},
  Year                     = {2017},
  Number                   = {3},
  Pages                    = {1564--1570},
  Volume                   = {2},

  Abstract                 = {Designing an exoskeleton to reduce the risk of low-back injury during lifting is challenging. Computational models of the human-robot system coupled with predictive movement simulations can help to simplify this design process. Here, we present a study that models the interaction between a human model actuated by muscles and a lower back exoskeleton. We provide a computational framework for identifying the spring parameters of the exoskeleton using an optimal control approach and forward-dynamics simulations. This is applied to generate dynamically consistent bending and lifting movements in the sagittal plane. Our computations are able to predict motions and forces of the human and exoskeleton that are within the torque limits of a subject. The identified exoskeleton could also yield a considerable reduction of the peak lower back torques as well as the cumulative lower back load during the movements. This letter is relevant to the research communities working on human-robot interaction, and can be used as a basis for a better human-centered design process.},
  Doi                      = {10.1109/LRA.2017.2676355},
  ISSN                     = {2377-3766},
  Keywords                 = {human-robot interaction;identification;optimal control;robot dynamics;computational framework;computational models;consistent bending;forward-dynamics simulations;human model;human-centered design process;human-robot interaction;human-robot system;lifting movements;low-back injury;lower back exoskeleton model;motion optimization;optimal control;parameter identification;predictive movement simulations;sagittal plane;spring parameters;Biological system modeling;Computational modeling;Exoskeletons;Muscles;Optimization;Springs;Torque;Prosthetics and exoskeletons;optimization and optimal control;physically assistive devices},
  Timestamp                = {2017.04.21}
}

@Article{Masuda2005,
  Title                    = {An unconstrained monitoring system for home rehabilitation: A wireless heart/respiratory rate sensor accessible to home-visit therapists},
  Author                   = {Masuda, Y. and Sekimoto, M. and Nambu, M. and Higashi, Y. and Fujimoto, T. and Chihara, K. and Tamura, T.},
  Journal                  = {IEEE Engineering in Medicine and Biology Magazine},
  Year                     = {2005},
  Pages                    = {43--47},
  Volume                   = {24},

  Abstract                 = {This study described a niche telemedicine framework for home healthcare. The framework aims to transmit small but sufficient amounts of data for daily monitoring of residential subjects' basic health status. As a proof of concept, an unconstrained monitoring system of heart/respiration rates using wireless telecommunication as an application for home-visit rehabilitation therapists was developed. The system allows a nomadic home-visit therapist to acquire the health information of a patient remotely - from anywhere at any time. It consists of a sensory system for the patient and a viewer system for the therapist. A TCP/IP network connects the subsystems using a physical communication infrastructure. The proposed system showed its usefulness for both the therapist and the patient in planning and evaluating daily rehabilitation training.},
  Keywords                 = {Rehabilitation},
  Review                   = {- Want a home rehab system, which has very different types of resources available to it when compared to the hosptial. Can't have high running cost. To reduce it's footprint, the home healthcare system will need the following:
 - exploits existing telecommunication infrastructure
 - minimal measurement and transmission
 - minimal and simple hardware
 - nonconstraining and silent operation

- They want to make a heart/respiration monitor using wireless technology, for a home-visit physio to check on remotely
 - Hmm. They claim it's easy to monitor heart rate. They have a dude lie on a cushion that measures pressure changes and somehow translate that to BP/HR
 - They're transfering information via cellphone...
 - Well. Supposely it works well. Used PDAs and web-based tech

- Didn't pay too much more attention, since the technology is outdated},
  Timestamp                = {2010.10.11}
}

@Article{Matsubara2013,
  Title                    = {Bilinear Modeling of {EMG} Signals to Extract User-Independent Features for Multiuser Myoelectric Interface},
  Author                   = {Matsubara, T. and Morimoto, J.},
  Journal                  = {IEEE T Biomed Eng},
  Year                     = {2013},
  Pages                    = {2205--13},
  Volume                   = {60},

  Abstract                 = {In this study, we propose a multiuser myoelectric interface that can easily adapt to novel users. When a user performs different motions (e.g., grasping and pinching), different electromyography (EMG) signals are measured. When different users perform the same motion (e.g., grasping), different EMG signals are also measured. Therefore, designing a myoelectric interface that can be used by multiple users to perform multiple motions is difficult. To cope with this problem, we propose for EMG signals a bilinear model that is composed of two linear factors:1) user dependent and 2) motion dependent. By decomposing the EMG signals into these two factors, the extracted motion-dependent factors can be used as user-independent features. We can construct a motion classifier on the extracted feature space to develop the multiuser interface. For novel users, the proposed adaptation method estimates the user-dependent factor through only a few interactions. The bilinear EMG model with the estimated user-dependent factor can extract the user-independent features from the novel user data. We applied our proposed method to a recognition task of five hand gestures for robotic hand control using four-channel EMG signals measured from subject forearms. Our method resulted in 73% accuracy, which was statistically significantly different from the accuracy of standard non-multiuser interfaces, as the result of a two-sample t-test at a significance level of 1%.},
  Owner                    = {jf2lin},
  Review                   = {models the motion blinearly, to account for 1) differences in motion and 2) differences between subjects. SVM is used to classify the motion. outperforms standard svm

window size 128 samples, shifting by 25 samples},
  Timestamp                = {2015.05.21}
}

@InProceedings{Matsushita2013,
  Title                    = {Algorithm for Selecting Appropriate Transfer Support Equipment and a Robot Based on User Physical Ability},
  Author                   = {Matsushita, S. and Fujie, M. G.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {In this present paper, we propose an algorithm for selecting appropriate transfer support equipment and robot based on the physical ability of the user. In addition, we describe the relationship between physical human features and the burden during standing when using a standing support robot. Although a number of care support devices have been developed, assistive robots are not yet popular because users do not know which devices are appropriate for their needs or physical abilities. In this study, we focus on a transfer support device and propose an algorithm for selecting transfer support equipment and a robot that suits the user’s physical ability. We investigated the relationship between standing support equipment including a robot and the physical burden during standing, which is a basic transfer motion. Experimentally, we analyzed and calculated the knee and ankle joint moments and discussed the relationship between standing support equipment and knee and ankle joint moments during standing; we also investigated and the relationship between physical human features and the knee joint moment during standing. Our results identified standing support equipment that was appropriate to the user’s physical ability. We found that it was effective to provide an up/down seat to persons having low residual ability; a standing support robot is appropriate for people having less residual ability in the knees, and a railing is suitable for people having low residual ability in the ankles.},
  Keywords                 = {EMBC2013},
  Timestamp                = {2013.08.02}
}

@InProceedings{Maurer2006,
  Title                    = {Activity recognition and monitoring using multiple sensors on different body positions},
  Author                   = {Maurer, U. and Smailagic, A. and Siewiorek, D.P. and Deisher, M.},
  Booktitle                = {International Workshop on Wearable and Implantable Body Sensor Networks},
  Year                     = {2006},
  Pages                    = {113--116},

  Abstract                 = {The design of an activity recognition and monitoring system based on the eWatch, multi-sensor platform worn on different body positions, is presented in this paper. The system identifies the user's activity in realtime using multiple sensors and records the classification results during a day. We compare multiple time domain feature sets and sampling rates, and analyze the tradeoff between recognition accuracy and computational complexity. The classification accuracy on different body positions used for wearing electronic devices was evaluated},
  Doi                      = {10.1109/BSN.2006.6},
  Keywords                 = {computational complexity;condition monitoring;medical signal processing;patient monitoring;sensor fusion;time-domain analysis;activity monitoring;activity recognition;body positions;computational complexity;eWatch platform;multiple sensor platform;multiple time domain feature sets;recognition accuracy;sampling rates;user activity;Accelerometers;Cellular phones;Computer science;Computerized monitoring;Flash memory;Hardware;Sensor arrays;Sensor systems;Wearable sensors;Wrist},
  Timestamp                = {2014.12.21}
}

@Article{Mayagoitia2002,
  Title                    = {Accelerometer and rate gyroscope measurement of kinematics: an inexpensive alternative to optical motion analysis systems},
  Author                   = {Ruth E. Mayagoitia and Anand V. Nene and Peter H. Veltink},
  Journal                  = {Biomechanics},
  Year                     = {2002},
  Number                   = {4},
  Pages                    = {537--542},
  Volume                   = {35},

  Abstract                 = {A general-purpose system to obtain the kinematics of gait in the sagittal plane based on body-mounted sensors was developed. It consisted of four uniaxial seismic accelerometers and one rate gyroscope per body segment. Tests were done with 10 young healthy volunteers, walking at five different speeds on a treadmill. In order to study the system's accuracy, measurements were made with an optic, passive-marker system and the body-mounted system, simultaneously. In all the comparison cases, the curves obtained from the two systems were very close, showing root mean square errors representing <7% full range in 75% of the cases (overall mean 6.64%, standard deviation 4.13%) and high coefficients of multiple correlation in 100% of cases (overall mean 0.9812, standard deviation 0.02). Calibration of the body-mounted system is done against gravity. The body-mounted sensors do not hinder natural movement. The calculation algorithms are computationally demanding and only are applicable off-line. The body-mounted sensors are accurate, inexpensive and portable and allow long-term recordings in clinical, sport and ergonomics settings.},
  Doi                      = {DOI: 10.1016/S0021-9290(01)00231-7},
  ISSN                     = {0021-9290},
  Keywords                 = {Accelerometer, Gyroscope, Gait kinematics, Portable gait analysis, Knee moment, postural detection},
  Review                   = {- Want to get body angles
- They just...did vector addition and integration...},
  Timestamp                = {2011.07.19},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021929001002317}
}

@Book{Maybeck1979,
  Title                    = {Stochastic models, estimation, and control},
  Author                   = {Maybeck, P. S.},
  Publisher                = {Academic Press, Inc},
  Year                     = {1979},
  Series                   = {Mathematics in Science and Engineering},
  Volume                   = {141},

  Timestamp                = {2010.09.29}
}

@Article{McConnell2001,
  Title                    = {The Western Ontario and McMaster Universities Osteoarthritis Index (WOMAC): a review of its utility and measurement properties},
  Author                   = {McConnell, Sara and Kolopack, Pamela and Davis, Aileen M.},
  Journal                  = {Arthritis Care and Research},
  Year                     = {2001},
  Number                   = {5},
  Pages                    = {453--461},
  Volume                   = {45},

  Doi                      = {10.1002/1529-0131(200110)45:5<453::AID-ART365>3.0.CO;2-W},
  ISSN                     = {1529-0131},
  Keywords                 = {physiotherapy},
  Timestamp                = {2012.06.21},
  Url                      = {http://dx.doi.org/10.1002/1529-0131(200110)45:5<453::AID-ART365>3.0.CO;2-W}
}

@Conference{McDonnell2008,
  Title                    = {Evaluating the emotional content of human motions on real and virtual characters},
  Author                   = {McDonnell, R. and Jorg, S. and McHugh, J. and Newell, F. and O'Sullivan, C.},
  Booktitle                = {Proceedings of the 5th Symposium on Applied Perception in Graphics and Visualization},
  Year                     = {2008},

  Address                  = {New York, NY, USA},
  Pages                    = {67--74},
  Publisher                = {ACM},

  Abstract                 = {In order to analyze the emotional content of motions portrayed by different characters, we created real and virtual replicas of an actor exhibiting six basic emotions: sadness, happiness, surprise, fear, anger and disgust. In addition to the video of the real actor, his actions were applied to five virtual body shapes: a low and high resolution virtual counterpart, a cartoon-like character, a wooden mannequin, and a zombie-like character (Figure 1). Participants were asked to rate the actions based on a list of 41 more complex emotions. We found that the perception of emotional actions is highly robust and to the most part independent of the character's body.},
  Doi                      = {http://doi.acm.org/10.1145/1394281.1394294},
  ISBN                     = {978-1-59593-981-4},
  Location                 = {Los Angeles, California},
  Timestamp                = {2010.07.09}
}

@InCollection{McDowell2005,
  Title                    = {Anthropometric Reference Data for Children and Adults: U. S. Population, 1999-2002},
  Author                   = {McDowell, M. A. and Fryar, C. D. and Hirsch, R. and Ogden, C. L.},
  Booktitle                = {Advance Data from Vital and Health statistics; no 361},
  Publisher                = {Centers for Disease Control and Prevention},
  Year                     = {2005},

  Abstract                 = {This report presents national anthropometric reference data based on health examination survey results from the National Health and Nutrition Examination Survey (NHANES), 1999–2002, for all ages of the U.S. population (1,2). Weighted population means, standard errors of the means, and selected percentiles are presented for the total U.S. population by sex, race or ethnic group, and age in years or age group. Findings for some population groups are reported in a way that is comparable with results reported from National Health Examination Surveys (NHES) and NHANES conducted between 1960 and 1994 (3–9). These data add to the knowledge about trends in child growth and development and are used to monitor prevalent conditions in the U.S. population such as overweight and obesity (10–13).},
  Timestamp                = {2012.01.05}
}

@InCollection{McGlynn2011,
  Title                    = {An Ensemble Dynamic Time Warping Classifier with Application to Activity Recognition},
  Author                   = {McGlynn, David and Madden, MichaelG.},
  Booktitle                = {Research and Development in Intelligent Systems XXVII},
  Publisher                = {Springer London},
  Year                     = {2011},
  Editor                   = {Bramer, Max and Petridis, Miltos and Hopgood, Adrian},
  Pages                    = {339-352},

  Abstract                 = {This paper proposes a new ensemble classifier based on Dynamic Time Warping (DTW), and demonstrates how it can be used to combine information from multiple time-series sensors, to relate them to the activities of the person wearing them. The training data for the system comprises a set of short time samples for each sensor and each activity, which are used as templates for DTW, and time series for each sensor are classified by assessing their similarity to these templates. To arrive at a final classification, results from separate classifiers are combined using a voting ensemble. The approach is evaluated on data relating to six different activities of daily living (ADLs) from the MIT Placelab dataset, using hip, thigh and wrist sensors. It is found that the overall average accuracy in recognising all six activities ranges from 45.5% to 57.2% when using individual sensors, but this increases to 84.3% when all three sensors are used together in the ensemble. The results compare well with other published results in which different classification algorithms were used, indicating that the ensemble DTW classification approach is a promising one.},
  Doi                      = {10.1007/978-0-85729-130-1_26},
  ISBN                     = {978-0-85729-129-5},
  Language                 = {English},
  Timestamp                = {2014.12.22}
}

@Misc{MeasurandDataglove,
  Title                    = {Shapehand Dataglove},

  Author                   = {{Measurand Inc.}},
  HowPublished             = {www.shapehand.com},
  Year                     = {2009},

  Owner                    = {jf2lin},
  Timestamp                = {2016.12.06}
}

@InProceedings{Meier2012,
  Title                    = {Movement Segmentation and Recognition for Imitation Learning},
  Author                   = {Meier, F. and Theodorou, E. and Stulp, F. and Schaal, S.},
  Booktitle                = {International Conference on Artificial Intelligence and Statistics},
  Year                     = {2012},
  Pages                    = {761--769},

  Abstract                 = {Extends on Meier2011. 

- Segment points occur on velocity and acceleration crossings
- Also want to create new DMP primitives if novel motions are detected

To add to the template library, we need to determine 1) the segment points to use to train the new template and 2) the tau and g for the new movement, since the ending segment point we have may not be the one corresponding to the actual primitive (due to noise and other imperfections). However, we know that tau would be similar in magnitude to the phase value towards the end of the motion, and they extropolate to a point where the velocity/accel is zero to set the model tau. They then do some inference magic to figure out the best segment points to use. 

Tested this against DTW, on a bunch of simple shapes (circles) on a tablet, as well as on human movement data doing random motions. Hard accuracy numbers for human movement data is not given.},
  Timestamp                = {2014.07.15}
}

@InProceedings{Meier2011,
  Title                    = {Movement Segmentation using a Primitive Library},
  Author                   = {Meier, F. and Theodorou, E. and Stulp, F. and Schaal, S.},
  Booktitle                = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2011},
  Pages                    = {3407--3412},

  Abstract                 = {Segmenting complex movements into a sequence of primitives remains a difficult problem with many applications in the robotics and vision communities. In this work, we show how the movement segmentation problem can be reduced to a sequential movement recognition problem. To this end, we reformulate the original Dynamic Movement Primitive (DMP) formulation as a linear dynamical system with control inputs. Based on this new formulation, we develop an Expectation-Maximization algorithm to estimate the duration and goal position of a partially observed trajectory. With the help of this algorithm and the assumption that a library of movement primitives is present, we present a movement segmentation framework. We illustrate the usefulness of the new DMP formulation on the two applications of online movement recognition and movement segmentation.},
  Doi                      = {10.1109/IROS.2011.6094676},
  ISSN                     = {2153-0858},
  Keywords                 = {Covariance matrix;Equations;Libraries;Motion segmentation;Noise;Trajectory},
  Review                   = {Goal: want to determine number of segments performed in Y, the start/end time of each segment, and identify each primitive. 
Assumes: a library for all the expected motion exist. also assumes that t=1 is the start of the first primitive, so only interested in finding the ending of each given primitive

They chose (rythmic) DMP as it represents the motion as a parameter of duration/phase (tau) and goal position (g), and thus can be used to make good templates to deal with temporal-adjacent primitives that have been smoothed together ("co-articulation"). This allows diffrent versions of the same movement to be represented by the same template. The templates consist of a handful of weights (w and delta g) to represent the desired motion

So unlike typical DMP problems (tau and g are known and we need to generate w and delta g), we now have a reversed problem, where the template itself is known (w and delta g), but the actual movement is not known yet (ie tau and g are unknown). Want the DMP-generated trajectory P and the observed trajectory Y to have min error. So we want to estimate tau and g as a syst ident problem, and take the similiarity measure between P and Y.

They formulate the DMP equations as part of a KF, where the only variables that changes are tau, g, and the noise covar for KF. This variables are used in an EM to determine where is a good point to 'end' the segment window. When the current time exceeds the anticipated tau, the window is is locked, and the length is swept for the highest LL to declare as segment. 

Tested by writting letters on a tablet.},
  Timestamp                = {2014.07.15}
}

@Article{Mertz2012,
  Title                    = {The Next Generation of Exoskeletons: Lighter, Cheaper Devices Are in the Works},
  Author                   = {Mertz, L.},
  Journal                  = {IEEE Pulse},
  Year                     = {2012},
  Number                   = {4},
  Pages                    = {56--61},
  Volume                   = {3},

  Publisher                = {IEEE},
  Timestamp                = {2012.11.12}
}

@Misc{Rebel2006,
  Title                    = {Recursive Bayesian Estimation Library ({ReBEL}) and Toolkit for {MATLAB}},

  Author                   = {van der Merwe, R. and Wan, E. A.},
  HowPublished             = {Software available at \url{http://choosh.csee.ogi.edu/rebel/}},
  Note                     = {Last accessed on 2011/01/03},
  Year                     = {2006},

  Institution              = {Oregon Health and Science University},
  Timestamp                = {2012.11.16},
  Url                      = {choosh.csee.ogi.edu/rebel/}
}

@Article{Mihelj2006,
  Title                    = {Inverse Kinematics of Human Arm Based on Multisensor Data Integration},
  Author                   = {Mihelj, M.},
  Journal                  = {Journal of Intelligent and Robotic Systems},
  Year                     = {2006},
  Pages                    = {139-153},
  Volume                   = {47},

  Abstract                 = {The paper considers a technique for computation of the inverse kinematic model of the human arm. The approach is based on measurements of the hand position and orientation as well as acceleration and angular rate of the upper arm segment. A quaternion description of orientation is used to avoid singularities in representations with Euler angles. A Kalman filter is designed to integrate sensory data from three different types of sensors. The algorithm enables estimation of human arm posture, which can be used in trajectory planning for rehabilitation robots, evaluation of motion of patients with movement disorders, and generation of virtual reality environments.},
  Affiliation              = {University of Ljubljana Faculty of Electrical Engineering Tržaška c. 25 SI-1000 Ljubljana Slovenia Tržaška c. 25 SI-1000 Ljubljana Slovenia},
  ISSN                     = {0921-0296},
  Issue                    = {2},
  Keyword                  = {Engineering},
  Keywords                 = {Postural Detection},
  Publisher                = {Springer Netherlands},
  Review                   = {- Uses quaternions to avoid singularities
- Measures arm motion, fixed shoulder
- Good results. Hard to follow since didn't understand quaternion math},
  Timestamp                = {2011.03.01},
  Url                      = {http://dx.doi.org/10.1007/s10846-006-9079-8}
}

@Article{Milner-Brown1975,
  Title                    = {The relation between the surface electromyogram and muscular force},
  Author                   = {Milner-Brown, H. S. and Stein, R. B.},
  Journal                  = {The Journal of Physiology},
  Year                     = {1975},
  Pages                    = {549--569},
  Volume                   = {246},

  Abstract                 = {1. Motor units in the first dorsal interosseus muscle of normal human subjects were recorded by needle electrodes, together with the surface electromyogram (e.m.g.). The wave form contributed by each motor unit to the surface e.m.g. was determined by signal averaging. 2. The peak-to-peak amplitude of the wave form contributed to the surface e.m.g. by a motor unit increased approximately as the square root of the threshold force at which the unit was recruited. The peak-to-peak duration of the wave form was independent of the threshold force. 3. Large and small motor units are uniformly distributed throughout this muscle, and the muscle fibres making up a motor unit may be widely dispersed. 4. The rectified surface e.m.g. was computed as a function of force, based on the sample of motor units recorded. The largest contribution of motor unit recruitment occurs at low force levels, while the contribution of increased firing rate becomes more important at higher force levels. 5. Possible bases for the common experimental observation that the mean rectified surface e.m.g. varies linearly with the force generated by a muscle are discussed. E.m.g. potentials and contractile responses may both sum non-linearly at moderate to high force levels, but in such a way that the rectified surface e.m.g. is still approximately linearly related to the force produced by the muscle.},
  Doi                      = {10.1113/jphysiol.1975.sp010904},
  ISSN                     = {1469-7793},
  Timestamp                = {2015.07.14},
  Url                      = {http://dx.doi.org/10.1113/jphysiol.1975.sp010904}
}

@Article{Min2008,
  Title                    = {Extraction and temporal segmentation of multiple motion trajectories in human motion},
  Author                   = {Min, J. and Kasturi, R. and Camps, O.},
  Journal                  = {Image Vision Computing},
  Year                     = {2008},
  Pages                    = {1621--1635},
  Volume                   = {26},

  Abstract                 = {A new method for extraction and temporal segmentation of multiple motion trajectories in human motion is presented. The proposed method extracts motion trajectories generated by body parts without any initialization or any assumption on color distribution. Motion trajectories are very compact and representative features for activity recognition. Tracking human body parts (hands and feet) is inherently difficult because the body parts which generate most of the motion trajectories are relatively small compared to the human body. This problem is overcome by using a new motion segmentation method: at every frame, candidate motion locations are detected and set as significant motion points (SMPs). The motion trajectories are obtained by combining these SMPs and the color-optical flow based tracker results. These motion trajectories are inturn used as features for temporal segmentation of specific activities from continuous video sequences. The proposed approach is tested on actual ballet step sequences. Experimental results show that the proposed method can successfully extract and temporally segment multiple motion trajectories from human motion.},
  Acmid                    = {1414257},
  Address                  = {Newton, MA, USA},
  Doi                      = {10.1016/j.imavis.2008.03.006},
  ISSN                     = {0262-8856},
  Issue                    = {12},
  Keywords                 = {Activity recognition, Motion detection, Motion segmentation, Motion tracking, Motion trajectories, Temporal segmentation},
  Numpages                 = {15},
  Publisher                = {Butterworth-Heinemann},
  Review                   = {On vision segmentation. Didn't read},
  Timestamp                = {2011.01.27},
  Url                      = {http://portal.acm.org/citation.cfm?id=1414093.1414257}
}

@InProceedings{Mitra2000,
  Title                    = {Data Condensation in Large Databases by Incremental Learning with Support Vector Machines},
  Author                   = {Mitra, P. and Murthy, C. A. and Pal, S. K.},
  Booktitle                = {Proceedings of the International Conference on Pattern Recognition},
  Year                     = {2000},
  Pages                    = {708-711 vol.2},
  Volume                   = {2},

  Abstract                 = {An algorithm for data condensation using support vector machines (SVM) is presented. The algorithm extracts data points lying close to the class boundaries, which form a much reduced but critical set for classification. The problem of large memory requirements for training SVM in batch mode is circumvented by adopting an active incremental learning algorithm. The learning strategy is motivated from the condensed nearest neighbor classification technique. Experimental results presented show that such active incremental learning enjoy superiority in terms of computation time and condensation ratio, over related methods},
  Doi                      = {10.1109/ICPR.2000.906173},
  ISSN                     = {1051-4651},
  Keywords                 = {computational complexity;data warehouses;learning (artificial intelligence);learning automata;pattern classification;SVM;active incremental learning algorithm;batch mode training;class boundaries;computation time;condensed nearest neighbor classification technique;data condensation;data point extraction;incremental learning;large databases;large memory requirements;pattern classification;support vector machines;Data mining;Databases;Machine intelligence;Machine learning;Machine learning algorithms;Nearest neighbor searches;Quadratic programming;Sampling methods;Support vector machine classification;Support vector machines},
  Review                   = {Trains from a subset. Samples the rest of the data. Of the falsely classified, add them to the training pool, and retrain. Sounds like boosting.},
  Timestamp                = {2014.10.24}
}

@Article{Mitra2007,
  Title                    = {Gesture Recognition: A Survey},
  Author                   = {Mitra, S. and Acharya, T.},
  Journal                  = {IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews},
  Year                     = {2007},
  Pages                    = {311--324},
  Volume                   = {37},

  Abstract                 = {Gesture recognition pertains to recognizing meaningful expressions of motion by a human, involving the hands, arms, face, head, and/or body. It is of utmost importance in designing an intelligent and efficient human-computer interface. The applications of gesture recognition are manifold, ranging from sign language through medical rehabilitation to virtual reality. In this paper, we provide a survey on gesture recognition with particular emphasis on hand gestures and facial expressions. Applications involving hidden Markov models, particle filtering and condensation, finite-state machines, optical flow, skin color, and connectionist models are discussed in detail. Existing challenges and future research possibilities are also highlighted},
  Doi                      = {10.1109/TSMCC.2007.893280},
  ISSN                     = {1094-6977},
  Keywords                 = {face recognition;finite state machines;gesture recognition;hidden Markov models;human computer interaction;image colour analysis;image sequences;condensation;connectionist models;facial expressions;finite-state machines;gesture recognition;hand gestures;hidden Markov models;intelligent human-computer interface;optical flow;particle filtering;skin color;Arm;Face recognition;Filtering;Handicapped aids;Hidden Markov models;Humans;Magnetic heads;Manifolds;Optical filters;Virtual reality;Face recognition;facial expressions;hand gestures;hidden Markov models (HMMs);optical flow;soft computing},
  Timestamp                = {2014.12.09}
}

@InProceedings{Mizuuchi2007,
  Title                    = {An advanced musculoskeletal humanoid Kojiro},
  Author                   = {Mizuuchi, I. and Nakanishi, Y. and Sodeyama, Y. and Namiki, Y. and Nishino, T. and Muramatsu, N. and Urata, J. and Hongo, K. and Yoshikai, T. and Inaba, M.},
  Booktitle                = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  Year                     = {2007},
  Pages                    = {294--299},

  Abstract                 = {We have been promoting a project of musculoskeletal humanoids. The project aims at the long-term goal of human-symbiotic robots as well as the mid-term goal of necessary design and control concepts for musculoskeletal robots. This paper presents the concepts and aim of the project and also shows the outline of our latest results about development of new musculoskeletal humanoid Kojiro, which is the succeeding version of our previous Kotaro.},
  Doi                      = {10.1109/ICHR.2007.4813883},
  Keywords                 = {human-symbiotic robots;musculoskeletal humanoid Kojiro;musculoskeletal robots;humanoid robots; ECE780},
  Review                   = {- Want a safe robot
- Complex structure
 - Hard to train/control
 - But flexible. Human spine is pretty flexible

- Using brushless DC motors
- Want to get over a previous generation (Kotaro)
 - High DOF, attention to spine
 - more sensoring
 - want mechanical softness
Q: how would control systems change between a non-complient system and a passively-complient system?
Q: how does wire-actuators work?
 - got better motors
 - hard control problem
Q: is there some tension/force method to measure deformity (or other better account for compliant components)?
Q: would a learning method really work? how much compliant deformation would we be expecting? is it significant enough that the model should be trained online?
Q: what is a "mobile-phone camera sensor"? Is there such things as 3D encoders?},
  Timestamp                = {2011.03.22}
}

@Article{Mo2012,
  Title                    = {Wireless Design of a Multi-Sensor System for Physical Activity Monitoring},
  Author                   = {Mo, L. and Liu, S. and Gao, R. and John, D. and Staudenmayer, J. and Freedson, P.},
  Journal                  = {IEEE Transactions on Biomedical Engineering},
  Year                     = {2012},

  Month                    = { },
  Number                   = {99},
  Pages                    = {1},
  Volume                   = {PP},

  Abstract                 = {Real-time monitoring of human physical activity (PA) is important for assessing the intensity of activity and exposure to environmental pollutions. A wearable multi-senor integrated measurement system (WIMS) has been designed for real-time measurement of the energy expenditure and breathing volume of human subjects under free-living conditions. To address challenges posted by the limited battery life and data synchronization requirement among multiple sensors in the system, the ZigBee communication platform has been explored for energy-efficient design. Two algorithms have been developed (Multi-Data-Packaging and Slot-Data-Synchronization) and coded into a microcontroller-based sensor circuitry for real-time control of wireless data communication. Experiments have shown that the design enables continued operation of the wearable system for up to 68 hours, with the maximum error for data synchronization among the various sensor nodes being less than 24 ms. Experiment under free-living conditions have shown that the WIMS is able to correctly recognize the activity intensity level 86% of the time. The results demonstrate the effectiveness of the energy-efficient wireless design for human physical activity monitoring.},
  Doi                      = {10.1109/TBME.2012.2208458},
  ISSN                     = {0018-9294},
  Review                   = {Shimmer competitor?},
  Timestamp                = {2012.07.18}
}

@Article{Moeslund2006,
  author    = {Moeslund, T. B. and Hilton, A. and Kr\"{u}ger, V.},
  title     = {A survey of advances in vision-based human motion capture and analysis},
  journal   = {Computer Vision and Image Understanding},
  year      = {2006},
  volume    = {104},
  pages     = {90--126},
  issn      = {1077-3142},
  abstract  = {This survey reviews advances in human motion capture and analysis from 2000 to 2006, following a previous survey of papers up to 2000 [T.B. Moeslund, E. Granum, A survey of computer vision-based human motion capture, Computer Vision and Image Understanding, 81(3) (2001) 231-268.]. Human motion capture continues to be an increasingly active research area in computer vision with over 350 publications over this period. A number of significant research advances are identified together with novel methodologies for automatic initialization, tracking, pose estimation, and movement recognition. Recent research has addressed reliable tracking and pose estimation in natural scenes. Progress has also been made towards automatic understanding of human actions and behavior. This survey reviews recent trends in video-based human capture and analysis, as well as discussing open problems for future research to achieve automatic visual analysis of human movement.},
  comment   = {Special Issue on Modeling People: Vision-based understanding of a person's shape, appearance, movement and behaviour},
  doi       = {DOI: 10.1016/j.cviu.2006.08.002},
  groups    = {Lit Review 2013-09, IROS2014},
  keywords  = {Review,Human motion,Initialization,Tracking,Pose estimation,Recognition},
  timestamp = {2011.06.11},
}

@TechReport{Moler1996,
  Title                    = {Floating Points: IEEE Standard unifes arithmetic model},
  Author                   = {Moler, C.},
  Institution              = {Mathworks Inc},
  Year                     = {1996},

  Abstract                 = {N/A},
  Review                   = {Talks about how MATLAB uses 64-bit floating-point values for both floats and ints. eps() gives the accuracy to the next floating-point value. Since the floating-point is represented by (1+f) * 2^e, if the value cannot be represented as a base-2 value, we get round errors. A good example of this is pi. 

For example, sind(90) != sin(pi)

Tips:
- Instead of using A == B (where A and B are not integers...integers are exact, as long as they're smaller than 2^52), consider using (A - B < threshold). The comparison algorithm (such as the isequal command), due to roundoff error, causes all sorts of problems. 

- For trig functions, take advantage of periodicity and shift the argument into the [0, pi] range (better yet, shift it into the [0, pi/4] range, if possible) since MATLAB uses Taylor series to calculate trig functions. It is more accurate (and faster) to calculate trig functions in that [0, pi] range. If the intermediate range values gets really big, then we lose precision. This shifting technique is called 'argument reduction'

- Use integers or symbolics as much as possible. They are more accuractly stored (how? I have no idea. MATLAB stores both int and float the same way)

- Arrange the order of operations in a way that small numbers operate on each other first before onto larger numbers -> delay the loss of precision as much as possible

"Simply put, if you have an algorithm that is sensitive to floating point innacuracies, you have a bad algorithm. They are inescapable and just have to be contained."

Other reads:
http://www.mathworks.com/company/newsletters/news_notes/clevescorner/winter02_cleve.html
http://www.mathworks.com/access/helpdesk/help/techdoc/matlab_prog/f2-12135.html
http://www.mathworks.com/support/solutions/en/data/1-16FOQ/index.html?solution=1-16FOQ},
  Timestamp                = {2009.11.30},
  Url                      = {http://www.mathworks.com/company/newsletters/news_notes/pdf/Fall96Cleve.pdf}
}

@InProceedings{Mombaur2008,
  Title                    = {An optimal control model unifying holonomic and nonholonomic walking},
  Author                   = {K. Mombaur and J. P. Laumond and E. Yoshida},
  Booktitle                = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  Year                     = {2008},
  Pages                    = {646--653},

  Doi                      = {10.1109/ICHR.2008.4756020},
  ISSN                     = {2164-0572},
  Keywords                 = {humanoid robots;mobile robots;optimal control;optimisation;path planning;robot dynamics;HRP2 robot;holonomic walking;humanoid robot;natural locomotion path generation;nonholonomic walking;optimal control;optimization;path planning;single dynamic model;Computational modeling;Humanoid robots;Humans;Industrial control;Legged locomotion;Mobile robots;Optimal control;Path planning;Robot sensing systems;Service robots},
  Timestamp                = {2017.03.02}
}

@Article{Mombaur2010,
  Title                    = {From human to humanoid locomotion—an inverse optimal control approach},
  Author                   = {Mombaur, K. and Truong, A. and Laumond, J.-P.},
  Journal                  = {Autonomous Robots},
  Year                     = {2010},
  Pages                    = {369--383},
  Volume                   = {28},

  Doi                      = {10.1007/s10514-009-9170-7},
  ISSN                     = {0929-5593},
  Keywords                 = {Inverse optimal control; Natural locomotion path; Optimal locomotion; Motion capture; Humanoid robot},
  Language                 = {English},
  Publisher                = {Springer US},
  Review                   = {Want to use inverse control as a way to transfer biological motions to robots.

The optimal control form they use is min some objective function wrt to state the control, such that the start and the end window have no error, and tominimize the error to the measurements via least squares. Performs this on human motion.},
  Timestamp                = {2015.11.06}
}

@InProceedings{Mombaur2001,
  Title                    = {Human-like actuated walking that is asymptotically stable without feedback},
  Author                   = {K. D. Mombaur and H. G. Bock and J. P. Schloder and R. W. Longman},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2001},
  Pages                    = {4128--4133},
  Volume                   = {4},

  Keywords                 = {asymptotic stability;legged locomotion;optimal control;optimisation;robot kinematics;bipedal walking robots;design parameters;human-like actuated walking;instantaneous switching;open-loop stabilization;optimal control problem;periodic torque histories;point feet;stable actuated open-loop gaits;standard gait;two-legged kneed walking robot;two-level optimization procedure;Design optimization;Feedback;Foot;History;Humans;Interference;Legged locomotion;Optimal control;Robots;Torque},
  Timestamp                = {2017.03.04}
}

@InProceedings{Moreno2003,
  Title                    = {A new SVM approach to speaker identification and verification using probabilistic distance kernels.},
  Author                   = {Moreno, Pedro J and Ho, Purdy},
  Booktitle                = {Interspeech},
  Year                     = {2003},

  Review                   = {Uses GMM kernels and KL distance. Algorithm trained with EM.},
  Timestamp                = {2015.02.06}
}

@Article{Moscheni1998,
  Title                    = {Spatio-temporal segmentation based on region merging},
  Author                   = {Moscheni, F. and Bhattacharjee, S. and Kunt, M.},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {1998},
  Number                   = {9},
  Pages                    = {897--915},
  Volume                   = {20},

  Abstract                 = {This paper proposes a technique for spatio-temporal segmentation to identify the objects present in the scene represented in a video sequence. This technique processes two consecutive frames at a time. A region-merging approach is used to identify the objects in the scene. Starting from an oversegmentation of the current frame, the objects are formed by iteratively merging regions together. Regions are merged based on their mutual spatio-temporal similarity. We propose a modified Kolmogorov-Smirnov test for estimating the temporal similarity. The region-merging process is based on a weighted, directed graph. Two complementary graph-based clustering rules are proposed, namely, the strong rule and the weak rule. These rules take advantage of the natural structures present in the graph. Experimental results on different types of scenes demonstrate the ability of the proposed technique to automatically partition the scene into its constituent objects},
  Publisher                = {IEEE},
  Review                   = {- video segmentation
- segments into smaller peices
- uses region-merging to merge things that are similar "spatiotemporally" together
- uses Kolmogorov-Smirnov test to assess temporal similarity},
  Timestamp                = {2013.08.29}
}

@Manual{CortexManual2010,
  Title                    = {Cortex 2.0 Reference Manual},
  Author                   = {{Motion Analysis Corporation}},
  Year                     = {2010},

  Timestamp                = {2012.11.17}
}

@Misc{MotionAnalysisCortex,
  Title                    = {Eagle Cameras and Cortex},

  Author                   = {{Motion Analysis Corporation}},
  HowPublished             = {www.motionanalysis.com},
  Year                     = {1999},

  Timestamp                = {2015.01.29}
}

@InBook{Mountain2006,
  Title                    = {Designing Accessible Technology},
  Author                   = {G. A. Mountain AND P. M. Ware AND J. Hammerton AND S. J. Mawson4, H. Zheng AND R. Davies AND N. Black AND H. Zhou AND H. Hu AND N. Harris AND C. Eccleston},
  Chapter                  = {Chapter 14: The SMART Project: A User Led Approach to Developing Applications for Domiciliary Stroke Rehabilitation},
  Editor                   = {Springer},
  Pages                    = {135-144},
  Publisher                = {Springer London},
  Year                     = {2006},

  Review                   = {Research shows that organized stroke care improves outcomes. Rehab should occur as soon as possible, after stroke. This article look sat home-based rehab and how sensor technology and computer interface can help. Rehab exercises are identified from stroke recovery therapists, and include things like sit to stand, upper limb grasping.

They took motion data (Codamotion, a 3D camera system) and looked at the kinematics, which is outlined in another article, apparently. They want to present kinematic motion data to patients to guide them in exercise.},
  Timestamp                = {2010.07.08},
  Url                      = {http://www.springerlink.com/content/h1k80823r4715084/}
}

@InProceedings{Mouri2007,
  Title                    = {Development of robot hand for therapist education/training on rehabilitation},
  Author                   = {Mouri, T. and Kawasaki, H. and Nishimoto, Y. and Aoki, T. and Ishigure, Y.},
  Booktitle                = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2007},
  Pages                    = {2295--2300},

  Abstract                 = {Students studying to become therapists have few opportunities for repeated training for the rehabilitation of contracture joints. This paper proposes the concept of a robot hand system for repeated rehabilitation training. A novel robot hand and artificial skin are developed in collaboration with doctors and therapists. Development of the robot hand is based on new design concepts aimed at imitating a human hand with a disability. The joint torque of a disabled person can be estimated by distributed tactile sensors. A model of contracture joints with tendon adhesion is introduced. The robot hand in imitation of contracture joints is governed by the force control based on torque control. The effectiveness of the proposed method is demonstrated experimentally.},
  Doi                      = {10.1109/IROS.2007.4399377},
  Keywords                 = {contracture joints;disabled person;distributed tactile sensors;force control;repeated rehabilitation training;robot hand system;tendon adhesion;therapist education;torque control;biomedical education;computer based training;force control;manipulators;patient rehabilitation;tactile sensors;torque control; human-robot interaction},
  Review                   = {- Develope a robotic hand that can imitate a disabled person, to train physio students
 - Had several DOFs with artifical silicon skin
- A physio tested it. Found that the resistance force imitates an actual hand, tho they want more testing},
  Timestamp                = {2011.02.09}
}

@InProceedings{Mueen2010,
  author    = {Mueen, A. and Keogh, E.},
  title     = {Online Discovery and Maintenance of Time Series Motifs},
  booktitle = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2010},
  pages     = {1089--1098},
  groups    = {Lit Review 2013-09},
  review    = {Expands previous algorithm. 

z-normalize all subseq to remove baseline and amplitude scaling. But may not be able to do this online since we don't have access to the full dataset. Using a sliding obs window.},
  timestamp = {2013.10.08},
}

@InProceedings{Mueen2009,
  author    = {Mueen, A. and Keogh, E. and Zhu, Q. and Cash, S. and Westover, B.},
  title     = {Exact Discovery of Time Series Motifs},
  booktitle = {SIAM International Conference on Data Mining},
  year      = {2009},
  pages     = {473--484},
  groups    = {Lit Review 2013-09},
  review    = {Want to find matching motifs in a long seq of obs. Euclidean distance. Uses early abandoning: when searching for the nearest neighbour for a given time seq Q, whe nthe cum sum goes beeyond the "best so far", the search is terminated, since the target time seq can't be similar to Q. So can quickly calculate inter-timeseq distances and remove out the obviously large-distance pairs (perhaps in a alternative dim or feature space to speed it up) to reduce the search space.

The brute force way to do this is to loop through all the combinations and caulcate the distance between them. Run time of m^2. Not effective, so will prune the search space. We can employ a reference time series "Qref", and employ triangle inequality in saying that d(Qref, Qi) - d(Qred, Qj) < d(Qi, Qj). So if we know the two terms to the left, ti's much cheaper than taking the distance itself. So they calculate the distance ot the Qref for every snippet to improve the searching time for matching motifs between two arb sequences. Can only pull up distances that are a certain distance from each other, thus early abandoning. Also can use multiple reference seq.

[doesn't seem to have a segmentation component...]

---

- time-series motifs (two sets of movements that are siilar to each other), online. 
- applied to EEG
- want to find repeated patterns in obs, used Euclidean
- use early abandonment -> if current distances is above some threshold, stop considering current template as a match
- looks at the distance in some dim reduced space
- can brute force a match over all windows, ie i = 1->N, j = i+1->N
- uses triangle inequ: d(ref, Di)-d(ref, Dj) < d(Di, Dj) to trim off distance calc, instead of brute force
- tested on EEG},
  timestamp = {2013.10.02},
}

@Article{Multon1999,
  Title                    = {Computer Animation of Human Walking: a Survey},
  Author                   = {Multon, F. and Debunne, G.},
  Journal                  = {Visualization and Computer Animation},
  Year                     = {1999},
  Pages                    = {39--54},
  Volume                   = {10},

  Abstract                 = {This paper surveys the set of techniques developed in Computer Graphics for animating human walking. We first focus on the evolution from purely kinematic "knowledge based" methods to approaches that incorporate dynamics constraints, or use dynamics simulations to generate motion. We lastly review the recent advances on motion editing, that enable the control of complex animations by interactively blending and tuning synthetic or captured motions.},
  Keywords                 = {computer animation, human walking, motion synthesis and control, kinematics, dynamics, motion},
  Location                 = {http://www.scientificcommons.org/42966301},
  Timestamp                = {2011.06.07}
}

@Article{Munin1998,
  Title                    = {Early inpatient rehabilitation after elective hip and knee arthroplasty},
  Author                   = {Munin, M. C. and Rudy, T. E. and Glynn, N. W. and Crossett, L. S. and Rubash, H. E.},
  Journal                  = {Journal of the American Medical Association},
  Year                     = {1998},
  Number                   = {11},
  Pages                    = {847-852},
  Volume                   = {279},

  Abstract                 = {Context.— Inpatient rehabilitation after elective hip and knee arthroplasty is often necessary for patients who cannot function at home soon after surgery, but how soon after surgery inpatient rehabilitation can be initiated has not been studied.

Objective.— To test the hypothesis that high-risk patients undergoing elective hip and knee arthroplasty would incur less total cost and experience more rapid functional improvement if inpatient rehabilitation began on postoperative day 3 rather than day 7, without adverse consequences to the patients.

Design.— Randomized controlled trial conducted from 1994 to 1996.

Setting.— Tertiary care center.

Participants.— A total of 86 patients undergoing elective hip or knee arthroplasty and who met the following criteria for being high risk: 70 years of age or older and living alone, 70 years of age or older with 2 or more comorbid conditions, or any age with 3 or more comorbid conditions. Of the 86 patients, 71 completed the study.

Interventions.— Random assignment to begin inpatient rehabilitation on postoperative day 3 vs postoperative day 7.

Main Outcome Measures.— Total length of stay and cost from orthopedic and rehabilitation hospital admissions, functional performance in hospitals using a subset of the functional independence measure, and 4-month follow-up assessment using the RAND 36-item health survey I and the functional status index.

Results.— Patients who completed the study and began inpatient rehabilitation on postoperative day 3 exhibited shorter mean (±SD) total length of stay (11.7±2.3 days vs 14.5±1.9, P<.001), lower mean (±SD) total cost ($25891±$3648 vs $27762±$3626, P<.03), more rapid attainment of short-term functional milestones between days 6 and 10 (36.2±14.4 m ambulated vs 21.4±13.3 m, P<.001; 4.8±0.8 mean transfer functional independence measure score vs 4.3±0.7, P<.01), and equivalent functional outcome at 4-month follow-up.

Conclusion.— These data showed that high-risk individuals were able to tolerate early intensive rehabilitation, and this intervention yielded faster attainment of short-term functional milestones in fewer days using less total cost.},
  Doi                      = {10.1001/jama.279.11.847},
  Keywords                 = {physiotherapy},
  Timestamp                = {2012.06.21},
  Url                      = { + http://dx.doi.org/10.1001/jama.279.11.847}
}

@Article{Muradore2011,
  Title                    = {Robotic Surgery},
  Author                   = {Muradore, R. and Bresolin, D. and Geretti, L. and Fiorini, P. and Villa, T.},
  Journal                  = {IEEE Robotics Automation Magazine},
  Year                     = {2011},
  Pages                    = {24--32},
  Volume                   = {18},

  Abstract                 = {In this article, we discuss formal methods for the verification of properties of control systems designed for autonomous robotic systems. In the last few decades, robotics played a relevant role in the progress of surgery. The use of robots in the operating rooms has given rise to new terminologies: robot-assisted surgery, medical robotics, rehabilitation robotics, telesurgery, robotic assistive systems, and so on [15], [25], [5]. Since robotic surgery is a relatively new field of investigation, there are no established methods for bringing new concepts and operational procedures to the surgical practice, in spite of the interest and pressing requests of the medical community.},
  Doi                      = {10.1109/MRA.2011.942112},
  ISSN                     = {1070-9932},
  Timestamp                = {2011.09.13}
}

@InProceedings{Murali2016,
  Title                    = {TSC-DL: Unsupervised trajectory segmentation of multi-modal surgical demonstrations with Deep Learning},
  Author                   = {A. Murali and A. Garg and S. Krishnan and F. T. Pokorny and P. Abbeel and T. Darrell and K. Goldberg},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2016},
  Pages                    = {4150--4157},

  Abstract                 = {The growth of robot-assisted minimally invasive surgery has led to sizable datasets of fixed-camera video and kinematic recordings of surgical subtasks. Segmentation of these trajectories into locally-similar contiguous sections can facilitate learning from demonstrations, skill assessment, and salvaging good segments from otherwise inconsistent demonstrations. Manual, or supervised, segmentation can be prone to error and impractical for large datasets. We present Transition State Clustering with Deep Learning (TSC-DL), a new unsupervised algorithm that leverages video and kinematic data for task-level segmentation, and finds regions of the visual feature space that correlate with transition events using features constructed from layers of pre-trained image classification Deep Convolutional Neural Networks (CNNs). We report results on three datasets comparing Deep Learning architectures (AlexNet and VGG), choice of convolutional layer, dimensionality reduction techniques, visual encoding, and the use of Scale Invariant Feature Transforms (SIFT). We find that the deep architectures extract features that result in up-to a 30.4% improvement in Silhouette Score (a measure of cluster tightness) over the traditional “shallow” features from SIFT. We also present cases where TSC-DL discovers human annotator omissions. Supplementary material, data and code is available at: http://berkeleyautomation.github.io/tsc-dl/.},
  Doi                      = {10.1109/ICRA.2016.7487607},
  Keywords                 = {control engineering computing;convolution;feature extraction;image classification;image segmentation;learning (artificial intelligence);medical image processing;medical robotics;neural nets;pattern clustering;robot vision;surgery;transforms;video signal processing;TSC-DL unsupervised algorithm;dimensionality reduction;feature extraction;fixed-camera video;image classification deep convolutional neural networks;learning from demonstrations;multimodal surgical demonstrations;robot-assisted minimally invasive surgery;scale invariant feature transforms;surgical subtask kinematic recordings;task-level segmentation;transition state clustering with deep learning;unsupervised trajectory segmentation;visual encoding;visual feature space;Feature extraction;Hidden Markov models;Kinematics;Machine learning;Motion segmentation;Visualization},
  Timestamp                = {2017.01.02}
}

@Misc{Murphy1998,
  Title                    = {Bayes Net Toolbox for MATLAB},

  Author                   = {Murphy, K.},
  HowPublished             = {Software available at \url{http://code.google.com/p/bnt/}},
  Note                     = {Last accessed on 2012/04/27},
  Year                     = {1998},

  Keywords                 = {HMM},
  Timestamp                = {2011.04.17},
  Url                      = {code.google.com/p/bnt/}
}

@InProceedings{Myers1980,
  Title                    = {An investigation of the use of dynamic time warping for word spotting and connected speech recognition},
  Author                   = {Myers, C. and Rabiner, L. and Rosenberg, A.},
  Booktitle                = {Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing},
  Year                     = {1980},
  Pages                    = {173--177},

  Abstract                 = { Several variations on algorithms for dynamic time warping have been proposed for speech processing applications. In this paper two general algorithms that have been proposed for word spotting and connected word recognition are studied. These algorithms are called the fixed range method and the local minimum method. The characteristics and properties of these algorithms are discussed. It is shown that, in several simple performance evaluations, the local minimum method performed considerably better then the fixed range method. Explanations of this behavior are given and an optimized method of applying the local minimum algorithm to word spotting and connected word recognition is described.},
  Doi                      = {10.1109/ICASSP.1980.1171067},
  Keywords                 = {Dynamic Time Warping},
  Timestamp                = {2011.06.07}
}

@InProceedings{Naik2008,
  Title                    = {Multi run {ICA} and surface {EMG} based signal processing system for recognising hand gestures},
  Author                   = {Naik, G. and Kumar, D. and Palaniswami, M.},
  Booktitle                = {ICCIT},
  Year                     = {2008},
  Pages                    = {700--5},

  Abstract                 = {Hand gesture identification is a complex problem, where more number of muscles will be involved even for a simple hand movement. Surface electromyography (sEMG) is an indicator of muscle activity and related to body movement and posture. In the recent past sEMG had been used with various statistical signal processing technique to identify different hand gestures, but since the hand actions require simultaneous muscle contractions reliability issues exist. Recently Blind source separation (BSS) techniques like Independent Component Analysis (ICA) had been used to tackle this problem. In this paper, a novel method is proposed to enhance the performance of ICA of sEMG by decomposing the signal into components originating from different muscles. First, we use FastICA algorithm to generate random mixing matrix, and the best mixing matrix is chosen based on the highest Signal to interference ratio(SIR) of mixing matrix. Pattern classification of the separated signal is performed in the second step with a back propagation neural network. The proposed model-based approach is able to overcome the ambiguity problems (order and magnitude problem) of BSS methods by selecting an apriori mixing matrix based on known hand muscle anatomy. Testing was conducted using several single shot experiments conducted with seven subjects. The results indicate that the system is able to classify six different hand gestures with 99% accuracy.},
  Doi                      = {10.1109/CIT.2008.4594760},
  Keywords                 = {blind source separation;electromyography;gesture recognition;independent component analysis;signal processing;FastICA algorithm;best mixing matrix;blind source separation;body movement;hand gesture identification;hand gesture recognition;independent component analysis;multirun ICA based signal processing system;muscle activity;random mixing matrix;statistical signal processing;surface EMG based signal processing system;surface electromyography;Blind source separation;Electromyography;Independent component analysis;Interference;Matrix decomposition;Muscles;Signal generators;Signal processing;Signal processing algorithms;Source separation},
  Owner                    = {jf2lin},
  Review                   = {- applied independent component analysis, and identified primitives via ANN
- 7 subjects, 4 channels, 6 hand primitives
- feature: RMS},
  Timestamp                = {2015.04.03}
}

@Article{Nakamura1986,
  Title                    = {Inverse Kinematic Solutions With Singularity Robustness for Robot Manipulator Control},
  Author                   = {Nakamura, Y. and Hanafusa, H.},
  Journal                  = {Journal of Dynamic Systems, Measurement, and Control},
  Year                     = {1986},
  Number                   = {3},
  Pages                    = {163-171},
  Volume                   = {108},

  Abstract                 = {The singularity problem is an inherent problem in controlling robot manipulators with articulated configuration. In this paper, we propose to determine the joint motion for the requested motion of the endeffector by evaluating the feasibility of the joint motion. The determined joint motion is called an inverse kinematic solution with singularity robustness, because it denotes feasible solution even at or in the neighborhood of singular points. The singularity robust inverse (SR-inverse) is introduced as an alternative to the pseudoinverse of the Jacobian matrix. The SR-inverse of the Jacobian matrix provides us with an approximating motion close to the desired Cartesian trajectory of the endeffector, even when the inverse kinematic solution by the inverse or the pseudoinverse of the Jacobian matrix is not feasible at or in the neighborhood of singular points. The properties of the SR-inverse are clarified by comparing it with the inverse and the pseudoinverse. The computational complexity of the SR-inverse is considered to discuss its implementability. Several simulation results are also shown to illustrate the singularity problem and the effectiveness of the inverse kinematic solution with singularity robustness.},
  Publisher                = {ASME},
  Review                   = {Talks abou tthe singularity robust algorithm, for inversing matrices such as the Jacobian.},
  Timestamp                = {2010.04.02}
}

@Article{Nakamura2000,
  Title                    = {Dynamics computation of structure-varying kinematic chains and its application to human figures},
  Author                   = {Nakamura, Y. and Yamane, K.},
  Journal                  = {IEEE Transactions on Robotics and Automation},
  Year                     = {2000},

  Month                    = apr,
  Number                   = {2},
  Pages                    = {124 -134},
  Volume                   = {16},

  Abstract                 = {This paper discusses the dynamics computation of structure-varying kinematic chains which imply mechanical link systems whose structure may change from open kinematic chain to closed one and vice versa. The proposed algorithm can handle and compute the dynamics and motions of any rigid link systems in a seamless manner without switching among algorithms. The computation is developed on the foundation of the dynamics computation algorithms established in robotics, which is superior in efficiency due to explicit use of the generalized coordinates to those used in the general-purpose motion analysis softwares. Although the structure-varying kinematic chains are commonly found in computing human and animal motions, the computation of their dynamics has not been discussed in literature. The developed computation will provide a general algorithm for the computation of motion and control of humanoid robots and computer graphics human figures},
  Doi                      = {10.1109/70.843167},
  ISSN                     = {1042-296X},
  Keywords                 = {closed kinematic chain;computer graphics human figures;human figures;humanoid robots;mechanical link systems;open kinematic chain;structure-varying kinematic chain dynamics;computer graphics;mobile robots;robot dynamics; ECE780},
  Review                   = {- want to generate human-realistic motion, different than robotic stuff
 - kinematic changes...if a person grips a bar, it forms aclosed kinematic chain
 - need somethign to handle high DOF and changing dynamics, esp closed kinematic chains
 - current algorithms are very computationally heavy
- uses d'Alembert and virtual work principle
- relates links: 'closed loop angles' to 'all angles' and 'virtually cut joints'
- Lagrange type equations},
  Timestamp                = {2011.01.12}
}

@Article{Nakanishi2004,
  Title                    = {Learning from demonstration and adaptation of biped locomotion},
  Author                   = {Nakanishi, J. and Morimoto, J. and Endo, G. and Cheng, G. and Schaal, S and Kawato, M.},
  Journal                  = {Robotics and Autonomous Systems},
  Year                     = {2004},
  Note                     = {Robot Learning from Demonstration},
  Number                   = {2-3},
  Pages                    = {79 - 91},
  Volume                   = {47},

  Abstract                 = {In this paper, we introduce a framework for learning biped locomotion using dynamical movement primitives based on non-linear oscillators. Our ultimate goal is to establish a design principle of a controller in order to achieve natural human-like locomotion. We suggest dynamical movement primitives as a central pattern generator (CPG) of a biped robot, an approach we have previously proposed for learning and encoding complex human movements. Demonstrated trajectories are learned through movement primitives by locally weighted regression, and the frequency of the learned trajectories is adjusted automatically by a novel frequency adaptation algorithm based on phase resetting and entrainment of coupled oscillators. Numerical simulations and experimental implementation on a physical robot demonstrate the effectiveness of the proposed locomotion controller.},
  Doi                      = {DOI: 10.1016/j.robot.2004.03.003},
  ISSN                     = {0921-8890},
  Keywords                 = {Biped locomotion, ECE780, Gait and Trajectory, motion primitive},
  Timestamp                = {2011.02.04},
  Url                      = {http://www.sciencedirect.com/science/article/B6V16-4CDS4CR-1/2/9459cc5a3ffd698062cb80decdf734fb}
}

@Article{Nebot1999,
  Title                    = {Initial calibration and alignment of low-cost inertial navigation units for land vehicle applications},
  Author                   = {Nebot, Eduardo and Durrant-Whyte, Hugh},
  Journal                  = {Journal of Robotic Systems},
  Year                     = {1999},
  Number                   = {2},
  Pages                    = {81--92},
  Volume                   = {16},

  Abstract                 = {Abstract This work presents an efficient initial calibration and alignment algorithm for a 6-degrees of freedom inertial measurement unit (IMU) to be used in land vehicle applications. Error models for the gyros and accelerometers are presented with a study of their perturbation in trajectory prediction. A full inertial error model is also presented to determine the sensors needed for full observability of the different perturbation parameters. Finally, dead-reckoning experimental results are presented based on the initial alignment and calibration parameters obtained with the algorithms presented. The results show that the proposed algorithms provide accurate position and velocity information for an extended period of time using nonaided IMU},
  Doi                      = {10.1002/(SICI)1097-4563(199902)16:2<81::AID-ROB2>3.0.CO;2-9},
  ISSN                     = {1097-4563},
  Keywords                 = {IMU calibration},
  Review                   = {- Noise throws off INS (inertial navigation system - 3 accel, 3 gyro)
- Need to reset the INS while the unit is stationary, to perform in-flight calibration, such as using GPS
- Uses different types of accel/gyro, making it not useful for general use IMU. Probably more for specific type of navigations
- Strapdown: "all gyro/accel are fixed to a common chassis, and are not actively controlled on gimbals to align themselves in a pre-specified direction" -> no moving parts
- Lots of equations. could be helpful},
  Timestamp                = {2011.07.19},
  Url                      = {http://dx.doi.org/10.1002/(SICI)1097-4563(199902)16:2<81::AID-ROB2>3.0.CO;2-9}
}

@InBook{Newell1998,
  Title                    = {Motor Behavior and Human Skill: A Multidisciplinary Approach},
  Author                   = {Newell, K. M. and Slifkin, A. B.},
  Chapter                  = {The Nature of Movement Variability},
  Editor                   = {Piek, J. P.},
  Pages                    = {143--160},
  Publisher                = {Human Kinetics},
  Year                     = {1998},

  Timestamp                = {2015.07.16}
}

@Article{Ng2005_TUG,
  author    = {Shamay S. Ng and Christina W. Hui-Chan},
  title     = {The Timed Up and Go Test: Its Reliability and Association With Lower-Limb Impairments and Locomotor Capacities in People With Chronic Stroke},
  journal   = {Archives of Physical Medicine and Rehabilitation},
  year      = {2005},
  volume    = {86},
  number    = {8},
  pages     = {1641--1647},
  issn      = {0003-9993},
  doi       = {http://dx.doi.org/10.1016/j.apmr.2005.01.011},
  groups    = {EMBC2014},
  keywords  = {Muscle spasticity},
  timestamp = {2014.01.27},
  url       = {http://www.sciencedirect.com/science/article/pii/S0003999305002194},
}

@TechReport{NIH2003,
  Title                    = {Consensus Development Conference Statement},
  Author                   = {{NIH Consensus Development Conference on Total Knee Replacement}},
  Institution              = {National Institutes of Health},
  Year                     = {2003},

  Keywords                 = {Physiotherapy},
  Timestamp                = {2011.12.29}
}

@Misc{NintendoWiiBalanceBoard,
  Title                    = {Nintendo Wii Balance Board},

  Author                   = {{Nintendo Corporation Ltd.}},
  HowPublished             = {www.nintendo.com/consumer/downloads/wiiBalanceBoard.pdf},
  Year                     = {2007},

  Owner                    = {jf2lin},
  Timestamp                = {2016.12.21}
}

@Article{Nishimura2010,
  Title                    = {Multiaxial Haar-Like Feature and Compact Cascaded Classifier for Versatile Recognition},
  Author                   = {Nishimura, J. and Kuroda, T.},
  Journal                  = {Sensors Journal, IEEE},
  Year                     = {2010},

  Month                    = {Nov},
  Number                   = {11},
  Pages                    = {1786-1795},
  Volume                   = {10},

  Abstract                 = {A versatile recognition algorithm has been proposed to process image, sound, and 3-D acceleration signals with a common framework at low calculation cost. Firstly, a novel 1-D Haar-like feature is used to roughly extract frequency information from temporal signals. Biaxial and mean-embedded Haar-like features are proposed to extract the standard deviation and the interaxial correlation from 3-D acceleration signals. Secondly, two techniques are proposed to build a compact cascaded classifier. Redundant feature selection (RFS) incorporates the features which are already selected in previous stage classifiers to reduce the calculation cost. A dynamic look-up table (DLUT) is proposed to construct a look-up table-based weak classifier with the smallest possible number of bins. A train loss function is by globally optimized using dynamic programming. The proposed algorithm is tested experimentally on speech/nonspeech classification and human activity recognition. The proposed algorithm yields a speech/nonspeech classification performance comparable to the state-of-art method called MFCC while reducing the calculation cost by 100 times. The algorithm also achieves human activity recognition accuracy of 96.1% with calculation cost reduction of 84% compared with the state-of-art method based on C4.5 decision-tree classifier using the basic statistical features. The proposed algorithm has been employed to build the versatile recognition processor.},
  Doi                      = {10.1109/JSEN.2010.2049740},
  ISSN                     = {1530-437X},
  Keywords                 = {image classification;image recognition;ubiquitous computing;3-D acceleration signals;MFCC;compact cascaded classifier;dynamic look-up table;image processing;multiaxial Haar-like feature classifier;pervasive computing;redundant feature selection;speech classification;ubiquitous computing;versatile recognition algorithm;Acceleration;Costs;Data mining;Dynamic programming;Frequency;Humans;Image recognition;Signal processing;Speech;Table lookup;Cascaded classifier;Haar-like feature;versatile recognition},
  Timestamp                = {2014.12.22}
}

@Book{Nocedal1999,
  Title                    = {Numerical Optimization},
  Author                   = {Nocedal, J. and Wright, S. J.},
  Publisher                = {Springer},
  Year                     = {1999},

  Owner                    = {jf2lin},
  Timestamp                = {2015.10.15}
}

@Book{Norkin2009,
  Title                    = {Measurement of Joint Motion: A Guide to Goniometry, 4th Edition},
  Author                   = {Norkin, C. C. and White, D. J.},
  Publisher                = {F. A. Davis Company},
  Year                     = {2009},

  Timestamp                = {2012.01.11}
}

@Article{Norris2008,
  Title                    = {Shortlist B: a Bayesian model of continuous speech recognition.},
  Author                   = {Norris, D. and McQueen, J. M.},
  Journal                  = {Psychological review},
  Year                     = {2008},
  Number                   = {2},
  Pages                    = {357},
  Volume                   = {115},

  Abstract                 = {A Bayesian model of continuous speech recognition is presented. It is based on Shortlist (D. Norris, 1994; D. Norris, J. M. McQueen, A. Cutler, & S. Butterfield, 1997) and shares many of its key assumptions: parallel competitive evaluation of multiple lexical hypotheses, phonologically abstract prelexical and lexical representations, a feedforward architecture with no online feedback, and a lexical segmentation algorithm based on the viability of chunks of the input as possible words. Shortlist B is radically different from its predecessor in two respects. First, whereas Shortlist was a connectionist model based on interactive-activation principles, Shortlist B is based on Bayesian principles. Second, the input to Shortlist B is no longer a sequence of discrete phonemes; it is a sequence of multiple phoneme probabilities over 3 time slices per segment, derived from the performance of listeners in a large-scale gating study. Simulations are presented showing that the model can account for key findings: data on the segmentation of continuous speech, word frequency effects, the effects of mispronunciations on word recognition, and evidence on lexical involvement in phonemic decision making. The success of Shortlist B suggests that listeners make optimal Bayesian decisions during spoken-word recognition.},
  Publisher                = {American Psychological Association},
  Review                   = {- Bayesian model for ASR},
  Timestamp                = {2013.08.29}
}

@InProceedings{Noury2013,
  Title                    = {ActimedARM – Design of a Wearable System to Monitor Daily Actimetry},
  Author                   = {Noury, N. and Perriot, B. and Collet, J. and Grenier, E. and Cerny, M. and Massot, B. and McAd},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {We developed a low power kinematic sensor, ActimedARM, incorporating tri-axis accelerometer and magnetometer, a microcontroller ARM3, a ZigBee wireless communication and µSD memory storage. With embedded algorithms it can detect in real time the postures of the subject. A preliminary assessment conducted on 12 subjects reached a 97% correct classification rate. The device exhibits 32 days of autonomy on a 3600 mAh capacity battery, which makes it convenient for field experiments in true daily life.},
  Keywords                 = {EMBC2013},
  Review                   = {Accel, mag - mounted on the side of the body. Determines posture by trig. If thinks is walking, look at freq analysis. Detect orientation by mag. Tested on 12 healthy.},
  Timestamp                = {2013.08.05}
}

@Unpublished{Nowlan2009,
  Title                    = {Human Indentification via Gait Recognition Using Accelerometer Gyro Forces},
  Author                   = {Nowlan, M. F.},
  Note                     = {End of term project for CPSC 536 (Networked Embedded Systems and Sensor Networks) at Yale University},

  Month                    = {12},
  Year                     = {2009},

  Abstract                 = {Many applications, both cooperative and hostile, require the ability to identify humans. This paper proposes a method that exploits the biometric property of human gait to identify people. A single sensor composed of an accelerometer and gyroscope is used to record gait characteristics. Using a Direct Form II Transpose, gait cycles are extracted and compressed to their characteristic features. Using simple classifiers on these feature vectors, this approach achieves 95% accuracy in classifying gait cycles to individuals. This model-driven approach uniquely exploits the physics of human gait through the use of gyroscope forces and proves its viability for smart environment applications.},
  Review                   = {They used a Wiimote + Motion Plus (so Accel + Gyro) and strapped it on one's leg while in gait motion. Supposely, each person's gait is unique, thus forming a "gait signature" of sorts.},
  Timestamp                = {2010.07.15},
  Url                      = {http://cs-www.cs.yale.edu/homes/mfn3/proj/mfn_gait_id.pdf}
}

@Article{O’Donovan2007,
  Title                    = {An inertial and magnetic sensor based technique for joint angle measurement},
  Author                   = {O'Donovan, K. J. and Kamnik, R. and O'Keeffe, D. T. and Lyons, G. M.},
  Journal                  = {Journal of Biomechanics},
  Year                     = {2007},
  Pages                    = {2604--2611},
  Volume                   = {40},

  Abstract                 = {This paper describes the design and evaluation of a miniature kinematic sensor based three dimensional (3D) joint angle measurement technique. The technique uses a combination of rate gyroscope, accelerometer and magnetometer sensor signals. The technique enables 3D inter-segment joint angle measurement and could be of benefit in a variety of applications which require monitoring of joint angles. The technique is not dependent on a fixed reference coordinate system and thus may be suitable for use in a dynamic system such as a moving vehicle. The technique was evaluated by applying it to joint angle measurement of the ankle joint. Experimental results show that accurate measurement of ankle joint angles is achieved by the technique during a variety of lower leg exercises including walking.},
  Doi                      = {10.1016/j.jbiomech.2006.12.010},
  ISSN                     = {0021-9290},
  Keywords                 = {Joint angle measurement; Gyroscope; Accelerometer; Magnetometer},
  Review                   = {O'Donovan2007 (cited by 46)
Cited by: 46
Motion type: Assorted. Various heel rotation and leg rotation. OVerlaps on leg extension. 
Recovery methodology: MARG sensor (mag, accel, gyro). Has several sensors, detects segment motion when the acceleration felt by two segments differ. angle obtained by integrating gyro. 
Verification method: Mocap, Evart 3D
Subject demographics: 2 healthy male
Error reported: RMS deg. Reported error in a graph and not a table, making it hard to figure out specific value. Looks like around 0.5 deg for leg ext.},
  Timestamp                = {2012.02.03},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021929007000103}
}

@Article{Oberg1994,
  Title                    = {{EMG} mean power frequency: Obtaining a reference value},
  Author                   = {Oberg, T. AND Sandsjo, L. AND Kadefors, R.},
  Journal                  = {Clinical Biomechanics},
  Year                     = {1994},
  Pages                    = {253--257},
  Volume                   = {9},

  Abstract                 = {Normalization of the electromyographic mean power frequency is generally performed on the basis of single estimates. Random variation of reference values based on such single estimates can seriously impair data reported in normalized form. In the present study we have examined five procedures for calculation of an initial reference value: calibration contractions at 0-kg (repeated) and 2-kg hand load, and regression routines at 0-kg and 2-kg hand load. There was a large between-subject variation if all different routines were considered, a moderate between-routine variation, and a quite small within-subject variation. The correlation between the different routines was high. At the same load level calibration and regression routines gave equivalent results, but the variability was less at the higher load level. The variations found are of such a magnitude that it is necessary to reduce the influence of random variation. Procedure proposed for reduction of this variability is repeated calibration measurements. A preferred test position for the trapezius muscle is straight arm, 90° of abduction in the scapular plane, 2-kg hand load.},
  Owner                    = {jf2lin},
  Review                   = {Using only a single collection run to form the reference values (ie MVC) can be fairly erronous. Instead, they took a bunch of subjects and tried a few different ways to calculate the reference value (tested in different situations, rest length, etc). Found some large between subject variations, moderate between routine variations, and small within-subject variations.

Instead of using MVC, they had the person hold a 2-kg weight and recorded for 10 seconds. This eventually becomes the recommmended standard. The combinations they did is 0-kg and 2-kg, and short (10s) vs prolonged (5 min) contraction. 

Individual reference values are necessary. There's no 'global reference MPF value' that we can divide all subjects by. They tried just some static positions (calibration contraction) vs a sequence of movements (regression procedure). More or less the same. As such, the calibration contraction is promoted as it is simplier. If repeated calibration trials are to be collected, ensure enough rest is granted (use a ratio of 1 contraction time to 2 resting time). If you double the amount of trials, you half the confidence interval (so the more trials, the better)},
  Timestamp                = {2009.12.07}
}

@Article{Oblak2010,
  Title                    = {Universal Haptic Drive: A Robot for Arm and Wrist Rehabilitation},
  Author                   = {Oblak, J. and Cikajlo, I. and Matjacic, Z.},
  Journal                  = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  Year                     = {2010},

  Month                    = {june },
  Number                   = {3},
  Pages                    = {293 -302},
  Volume                   = {18},

  Abstract                 = {In this paper we present a universal haptic drive (UHD), a device that enables rehabilitation of either arm ( #x201C;ARM #x201D; mode) or wrist ( #x201C;WRIST #x201D; mode) movement in two degrees-of-freedom. The mode of training depends on the selected mechanical configuration, which depends on locking/unlocking of a passive universal joint. Actuation of the device is accomplished by utilizing a series elastic actuation principle, which enables use of off-the-shelf mechanical and actuation components. A proportional force control scheme, needed for implementation of impedance control based movement training, was implemented. The device performance in terms of achievable lower and upper bound of viable impedance range was evaluated through adequately chosen sinusoidal movement in eight directions of a planar movement for the #x201C;ARM #x201D; mode and in eight directions of a combined wrist flexion/extension and forearm pronation/supination movement for the #x201C;WRIST #x201D; mode. Additionally, suitability of the universal haptic drive for movement training was tested in a series of training sessions conducted with a chronic stroke subject. The results have shown that reliable and repeatable performance can be achieved in both modes of operation for all tested directions.},
  Doi                      = {10.1109/TNSRE.2009.2034162},
  ISSN                     = {1534-4320},
  Keywords                 = {UHD;actuation component;arm rehabilitation;chronic stroke;degrees-of-freedom;impedance control;movement training;off-the-shelf mechanical component;passive universal joint;planar movement;proportional force control;robot;series elastic actuation principle;sinusoidal movement;training sessions;universal haptic drive;wrist rehabilitation;force control;haptic interfaces;medical robotics;patient rehabilitation;proportional control;training;universal joints;},
  Timestamp                = {2010.07.12}
}

@InProceedings{Ochoa-Diaz2013,
  Title                    = {An EKF-Based Approach for Estimating Leg Stiffness During Walking},
  Author                   = {Ochoa-Diaz, C. and Menegaz, H. M. and Bo, A. P. L. and Borges, G. A.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {The spring-like behavior is an inherent condition for human walking and running. Since leg stiffness is a parameter that cannot be directly measured, many techniques has been proposed in order to estimate it, most of them using force data. This paper intents to address this problem using an Extended Kalman Filter (EKF) based on the Spring-Loaded Inverted Pendulum (SLIP) model. The formulation of the filter only uses as measurement information the Center of Mass (CoM) position and velocity, no a priori information about the stiffness value is known. From simulation results, it is shown that the EKF-based approach can generate a reliable stiffness estimation for walking.},
  Keywords                 = {EMBC2013},
  Timestamp                = {2013.08.06}
}

@InProceedings{Ofli2013,
  Title                    = {Berkeley {MHAD}: A Comprehensive Multimodal Human Action Database},
  Author                   = {Ofli, F. and Chaudhry, R. and Kurillo, G. and Vidal, R. and Bajcsy, R.},
  Booktitle                = {IEEE Workshop on Applications of Computer Vision},
  Year                     = {2013},
  Pages                    = {53--60},

  Abstract                 = {Over the years, a large number of methods have been proposed to analyze human pose and motion information from images, videos, and recently from depth data. Most methods, however, have been evaluated on datasets that were too specific to each application, limited to a particular modality, and more importantly, captured under unknown conditions. To address these issues, we introduce the Berkeley Multimodal Human Action Database (MHAD) consisting of temporally synchronized and geometrically calibrated data from an optical motion capture system, multi-baseline stereo cameras from multiple views, depth sensors, accelerometers and microphones. This controlled multimodal dataset provides researchers an inclusive testbed to develop and benchmark new algorithms across multiple modalities under known capture conditions in various research domains. To demonstrate possible use of MHAD for action recognition, we compare results using the popular Bag-of-Words algorithm adapted to each modality independently with the results of various combinations of modalities using the Multiple Kernel Learning. Our comparative results show that multimodal analysis of human motion yields better action recognition rates than unimodal analysis.},
  Doi                      = {10.1109/WACV.2013.6474999},
  ISSN                     = {1550-5790},
  Keywords                 = {image motion analysis;learning (artificial intelligence);pose estimation;visual databases;Berkeley MHAD;accelerometer;action recognition;bag-of-words algorithm;depth sensor;human pose information;microphone;motion information;multibaseline stereo camera;multimodal analysis;multimodal human action database;multiple kernel learning;optical motion capture system;Accelerometers;Cameras;Databases;Humans;Microphones;Synchronization;Videos},
  Timestamp                = {2015.01.13}
}

@InProceedings{Ogawara2001,
  Title                    = {Acquiring hand-action models by attention point analysis},
  Author                   = {Ogawara, K. and Iba, S. and Tanuki, T. and Kimura, H. and Ikeuchi, K.},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2001},
  Pages                    = {465-470 vol.1},
  Volume                   = {1},

  Abstract                 = {This paper describes our current research on learning task level representations by a robot through observation of human demonstrations. We focus on human hand actions and represent such hand actions in symbolic task models. We propose a framework of such models by efficiently integrating multiple observations based on attention points; we then evaluate the model by using a human-form robot. We propose a two-step observation mechanism. At the first step, the system roughly observes the entire sequence of the human demonstration, builds a rough task model and extracts attention points (APs). The attention points indicate the time and position in the observation sequence that requires further detailed analysis. At the second step, the system closely examines the sequence around the APs and the obtained attribute values for the task model, such as what to grasp, which hand to be used, or what is the precise trajectory of the manipulated object. We implemented this system on a human form robot and demonstrated its effectiveness.},
  Doi                      = {10.1109/ROBOT.2001.932594},
  ISSN                     = {1050-4729},
  Keywords                 = {learning by example;manipulator dynamics;robot vision;stereo image processing;attention point analysis;hand-action models;human demonstration;human-form robot;learning by example;observation mechanism;robot vision;stereo vision;task model;Assembly systems;Automatic control;Automatic programming;Cameras;Humans;Robot vision systems;Robotic assembly;Robotics and automation},
  Timestamp                = {2014.12.22}
}

@InProceedings{Ogawara2002,
  Title                    = {Generation of a task model by integrating multiple observations of human demonstrations},
  Author                   = {Ogawara, K. and Takamatsu, J. and Kimura, H. and Ikeuchi, K.},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2002},
  Pages                    = {1545-1550 vol.2},
  Volume                   = {2},

  Abstract                 = {This paper describes a new approach on how to teach a robot everyday manipulation tasks under the "learning from observation" framework. Most of the approaches so far assume that a demonstration can be well understood from a single demonstration. However, a single demonstration contains ambiguity, in that interactions which are essential to complete a task cannot be discerned without prior task dependent knowledge, which should be obtained from observation. To address these issues, we propose a technique to integrate multiple observations of demonstrations. The demonstrations differ, but are virtually the same task. The shared interactions among all the demonstrations are considered to be essential and we form a task model from their symbolic representations. Then the relative trajectories corresponding to each essential interaction are generalized by calculating their mean and variance and are also stored in the task model, which is used to reproduce a skilled behavior. We examine this approach by using a human-form robot, which successfully imitates human demonstrations of everyday tasks.},
  Doi                      = {10.1109/ROBOT.2002.1014763},
  Keywords                 = {computer vision;dynamic programming;image matching;learning by example;robot programming;stereo image processing;dynamic programming;human demonstrations;learning from observation;robot programming;skilled behavior;stereo vision system;symbolic representations;task model;template matching;Data mining;Educational robots;Humans;Motion detection;Object detection;Service robots},
  Timestamp                = {2014.12.22}
}

@InProceedings{Ogura2006,
  Title                    = {Development of a new humanoid robot WABIAN-2},
  Author                   = {Ogura, Y. and Aikawa, H. and Shimomura, K. and Morishima, A. and Lim, H.-O. and Takanishi, A.},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2006},
  Month                    = may,
  Pages                    = {76 -81},

  Abstract                 = {A new humanoid robot-WABIAN-2- that can be used as a human motion simulator is proposed in this paper. Its trunk is designed in order to permit rotation, and forward, backward, and sideway movement. Further, its arms are designed to support its complete weight when pushing a walk-assist machine. Moreover, it can lean on a walk-assist machine by forearm control using trunk motion. Basic walking experiments with WABIAN-2 are conducted with and without a walk-assist machine, thereby confirming its effectiveness},
  Doi                      = {10.1109/ROBOT.2006.1641164},
  ISSN                     = {1050-4729},
  Keywords                 = {WABIAN-2;biped robot;forearm control;human motion simulator;humanoid robot;walk-assist machine;handicapped aids;humanoid robots;legged locomotion;medical robotics;motion control; ECE780},
  Review                   = {Want to use humanoid robots to rest rehab/welfare instructions
- can get torque/angle data from robots
- test for dangerous setups 

- humans have more redundant DOFs, so they're capable of wider range of motion
 - WABIAN = 34DOF system
Q: is 34 DOF considered high?
- want to test a walking assistive system, so medical deployment was kept in mind for design
- current mechanical components cannot replicate a human, so will imitate instead
 - measured the ranges of motions (ROM) of humans
Q: is it important that mass distrubtion is human-like as well? If so, would it be better to break the battery down into several modules, instead of a single large backpack, and distrubte the mass throughout the robot?
Q: What is the significance of showing a pen with Figure 8 and 9? Are motor controllers typically very big?
Q: It seems like they focused WABIAN's development specifically towards a walking assist. Very few mention were made to legs, where a large amount of rehab efforts are generally pointed. Is the Wabian capable to simulating humans in lower body rehabilitation as well?
Q: How difficult is it to measure qualitative data from people with disabilities (For Wabian to simulate)? All the motion data were built based from healthy subjects. Is physically disabled (such as leg injury) people adaquently modelled by just changing the range of motion?},
  Timestamp                = {2011.03.22}
}

@Article{Okamura2010,
  Title                    = {Medical and Health-Care Robotics},
  Author                   = {Okamura, A. M. and Mataric, M. J. and Christensen, H. I.},
  Journal                  = {IEEE Robotics Automation Magazine},
  Year                     = {2010},
  Number                   = {3},
  Pages                    = {26--37},
  Volume                   = {17},

  Abstract                 = {The aim of this article is to propose some of the most important capabilities and technical achievements of medical and health-care robotics needed to improve human health and well-being. The paper describes application areas, societal drivers, motivating scenarios, desired system capabilities, and fundamental research areas that should be considered in the design of medical and health-care robots.},
  Doi                      = {10.1109/MRA.2010.937861},
  ISSN                     = {1070-9932},
  Keywords                 = {health care robot;medical robot;societal driver;telerobotic system;health care;medical robotics;socio-economic effects;telerobotics;},
  Review                   = {summary paper on medical robotics
- face of robotics is quickly changing
- was once used for dirty/messy/dangerous jobs that no one wanted
- now is doing surgery and interacting with people
- actually, robots have proven to be good at a wide variety of tasks already
- lots of old people coming. can robots take care of them?

SURGERY
- typically teleop by a surgeon
- technology could increase to develop: augmented reality
- lastly, a robot can performed routine surgery, with human planning and supervision

PROTHESIS
- typically limited in function, or just an exoskeleton support
- still has a lon gways to go

ROBOT-ASSISTED RECOVERY AND REHAB
- robot therapy!
 - robot can perform lengthy and personalized therapy without tire
 - can acquire data to quantify recovery
 - can facilitate exercise resources not possible by a human therapist

BEHAVIORAL THERAPY
- Robot monitoring, care, encouragement, feedback

SPECIAL NEEDS
- Mobility aid

(to finish)},
  Timestamp                = {2010.10.20}
}

@Article{Okamura2010a,
  Title                    = {Medical and Health-Care Robotics},
  Author                   = {A. M. Okamura and M. J. Mataric and H. I. Christensen},
  Journal                  = {IEEE Robotics Automation Magazine},
  Year                     = {2010},

  Month                    = {Sept},
  Number                   = {3},
  Pages                    = {26-37},
  Volume                   = {17},

  Doi                      = {10.1109/MRA.2010.937861},
  ISSN                     = {1070-9932},
  Keywords                 = {health care;medical robotics;socio-economic effects;telerobotics;health care robot;medical robot;societal driver;telerobotic system;History;Medical robotics;Patient rehabilitation;Rehabilitation robotics;Robot sensing systems;Surgery},
  Timestamp                = {2017.04.24}
}

@Article{Opitz1999,
  Title                    = {Popular Ensemble Methods: An Empirical Study},
  Author                   = {Opitz, D. and Maclin, R.},
  Journal                  = {Journal of Artificial Intelligence Research},
  Year                     = {1999},
  Pages                    = {169--198},
  Volume                   = {11},

  Timestamp                = {2014.10.29}
}

@Article{Ormoneit2001,
  Title                    = {Learning and tracking cyclic human motion},
  Author                   = {Ormoneit, D. and Sidenbladh, H. and Black, M. J. and Hastie, T.},
  Journal                  = {Advances in Neural Information Processing Systems},
  Year                     = {2001},
  Pages                    = {894--900},

  Publisher                = {MIT; 1998},
  Review                   = {automated segmentation in cyclic periodic motions. want to maximize signal-noise ratio by finding a cycle length (p) that does that. Noise is the variance in the signal, signal is the signal intensity. Once this is found, curve fitting is used to find the the segments. Offline, evidently.},
  Timestamp                = {2014.12.22}
}

@TechReport{Orr1996,
  Title                    = {Introduction to Radial Basis Function Networks},
  Author                   = {Orr, M. J. L.},
  Institution              = {Centre for Cognitive Science, University of Edinburgh},
  Year                     = {1996},

  Timestamp                = {2014.01.27}
}

@Article{Oshima2010,
  Title                    = {Classifying household and locomotive activities using a triaxial accelerometers},
  Author                   = {Oshima, Y. AND Kawaguchi, K. AND Tanaka, S. AND Ohkawara, K. AND Hikihara, Y. AND Ishikawa-Takata, K. AND Tabata, I.},
  Journal                  = {Gait and Posture},
  Year                     = {2010},
  Pages                    = {370-374},
  Volume                   = {31},

  Abstract                 = {The purpose of this study was to develop a new algorithm for classifying physical activity into either locomotive or household activities using a triaxial accelerometer. Sixty-six volunteers (31 men and 35 women) participated in this study and were separated randomly into validation and cross-validation groups. All subjects performed 12 physical activities (personal computer work, laundry, dishwashing, moving a small load, vacuuming, slow walking, normal walking, brisk walking, normal walking while carrying a bag, jogging, ascending stairs and descending stairs) while wearing a triaxial accelerometer in a controlled laboratory setting. Each of the three signals from the triaxial accelerometer was passed through a second-order Butterworth high-pass filter to remove the gravitational acceleration component from the signal. The cut-off frequency was set at 0.7 Hz based on frequency analysis of the movements conducted. The ratios of unfiltered to filtered total acceleration (TAU/TAF) and filtered vertical to horizontal acceleration (VAF/HAF) were calculated to determine the cut-off value for classification of household and locomotive activities. When the TAU/TAF discrimination cut-off value derived from the validation group was applied to the cross-validation group, the average percentage of correct discrimination was 98.7%. When the VAF/HAF value similarly derived was applied to the cross-validation group, there was relatively high accuracy but the lowest percentage of correct discrimination was 63.6% (moving a small load). These findings suggest that our new algorithm using the TAU/TAF cut-off value can accurately classify household and locomotive activities.},
  Review                   = {So people typically try to filter out gravitational accel in order to get body posture information. But should also think about the type of activities that the person is doing while in a given posture, and so we can use gravitational information to figure that out. The goal is to determine energy expenature.

They collected age, height, and weight data. Wearing a triaxial accel on their waist, they proceed to perform a few minutes of random actities in a controlled lab setting (ie computer work, laundry, dishwashing, slow walking, stair climbing, etc).

The accel device dumps things onto flash memory or something. 4GB storage, sampled at 32Hz. 2nd order Butterworth HPF (to remove gravity...), cutoff was hand-determined. Power spectrum was taken via FFT and normalized. Apparently there was a report that you should sample human data for 5 to 10 seconds. They also calculated a bunch of ratios, like horizontal-to-total accel. They fed things into SSPP.

They saw that for walking, peak power appeared at 1 Hz, and increased in frequency with increasing pace.

Okay. So they compare the unfiltered (so has gravity) to the filtered (no gravity) data and that ratio they used to classify activities. It works well, apparently, to figure out if a given person is just walking around, or is lifting things (so is decent at catigorizing activity types, but can't really use it to figure out anything specific about the activity itself). Since the device is on the waist, there isn't too much they can do. They can only sort-of tell upperbody posture. But it's a proof-of-concept, I suppose},
  Timestamp                = {2010.03.10},
  Url                      = {http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6T6Y-4YB84KR-1&_user=10&_coverDate=03%2F31%2F2010&_rdoc=1&_fmt=high&_orig=search&_sort=d&_docanchor=&view=c&_searchStrId=1242937585&_rerunOrigin=google&_acct=C000050221&_version=1&_urlVersion=0&_userid=10&md5=cada550756d92f49eecd0e2c1c7242ae}
}

@InProceedings{Ott2008,
  Title                    = {Motion capture based human motion recognition and imitation by direct marker control},
  Author                   = {Ott, C. and Lee, D. and Nakamura, Y.},
  Booktitle                = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  Year                     = {2008},
  Pages                    = {399--405},

  Abstract                 = {This paper deals with the <span class='snippet'>imitation</span> of <span class='snippet'>human</span> <span class='snippet'>motions</span> <span class='snippet'>by</span> a humanoid robot <span class='snippet'>based</span> on marker point measurements from a 3D <span class='snippet'>motion</span> <span class='snippet'>capture</span> system. For imitating the humanpsilas <span class='snippet'>motion</span>, we propose a Cartesian control approach in which a set of control points on the humanoid is selected <span class='snippet'>and</span> the robot is virtually connected to the measured marker points via translational springs. The forces according to these springs drive a simplified simulation of the robot dynamics, such that the real robot <span class='snippet'>motion</span> can finally be generated <span class='snippet'>based</span> on joint position controllers effectively managing joint friction <span class='snippet'>and</span> other uncertain dynamics. This procedure allows to make the robot follow the marker points without the need of explicitly computing inverse kinematics. For the implementation of the marker control on a humanoid robot, we combine it with a center of gravity <span class='snippet'>based</span> balancing controller for the lower body joints. We integrate the marker control <span class='snippet'>based</span> <span class='snippet'>motion</span> <span class='snippet'>imitation</span> with the mimesis model, which is a mathematical model for <span class='snippet'>motion</span> learning, <span class='snippet'>recognition</span>, <span class='snippet'>and</span> generation <span class='snippet'>based</span> on hidden Markov models (HMMs). Learning, <span class='snippet'>recognition</span>, <span class='snippet'>and</span> generation of <span class='snippet'>motion</span> primitives are all performed in marker coordinates paving the way for extending these concepts to task space problems <span class='snippet'>and</span> object manipulation. Finally, an experimental evaluation of the presented concepts using a 38 degrees of freedom humanoid robot is discussed.},
  Doi                      = {10.1109/ICHR.2008.4755984},
  Keywords                 = {ECE780, Control},
  Review                   = {This paper uses motion from human motion capture, and fits the motion to a robot. They do so by applying virtual springs that applies attraction forces between the motion capture data and a simplified robot model, and insert the joint trajectories into the robot. These trajectories are than encoded by HMMs. They note that this is motivated by mirror neurons in the brain. 

For simplicity, they focus only on upper body motions. The lower body was set to maintain overall stability by keeping ZMP within the support polygon.},
  Timestamp                = {2011.02.09}
}

@Article{Oudeyer2006,
  Title                    = {Discovering communication},
  Author                   = {Oudeyer, P.-y. and Kaplan, F.},
  Journal                  = {Connection Science},
  Year                     = {2006},
  Pages                    = {189-206},
  Volume                   = {18},

  Abstract                 = {What kind of motivation drives child language development? This article presents a computational model and a robotic experiment to articulate the hypothesis that children discover communication as a result of exploring and playing with their environment. The considered robotic agent is intrinsically motivated towards situations in which it optimally progresses in learning. To experience optimal learning progress, it must avoid situations already familiar but also situations where nothing can be learned. The robot is placed in an environment in which both communicating and non-communicating objects are present. As a consequence of its intrinsic motivation, the robot explores this environment in an organized manner focusing first on noncommunicative activities and then discovering the learning potential of certain types of interactive behavior. In this experiment, the agent ends up being interested by communication through vocal interactions without having a specific drive for communication.},
  Keywords                 = {human-robot interaction},
  Review                   = {Why do kids learn language? Is it...
- Evolution advantage from being able to socially communicate? But language is extremely complicated and children doesn't just learn basic skill
- To communicate a need? But you don't need sopheticated level of language understanding for that
- Intrinsically interesting? From play and curiosity? This paper explores this hypothesis

Want to create a system where robotic agents are just curious and exploring
- avoid situations where nothing can be learned, or familiar situations
- stuck a bunch of objects in the space. things that communicates and things that doesn't
 - the robot starts off inspecting the non-comm ones...and but gets interested in comm

Intelligent Adaptive Curiosity
- Initially, robot groups all objects around it in the same region
- After exploring, create new groups to categorize object
 - The robot interacts with objects until it is able to predict the consequences -> new category formed
 - So the robot has sensors (which it perceives things from) but also attempts to predict future values of the sensors
 - Learning is defined as the reduction of this error between sensors and guesses
 - So situations where the robot has learned as much as possible (error decreases and plateaus) and non-learnable situations given its abilitites (always bad prediction) is times where it moves on

- The robot does not know what kind of sensors/motors it has. All it knows is that it has some channels of input and some channels of output
 - Figuring out what these are is up to the robot

(A bunch of prediction model math, catigorization splitting criterion and action selection algorithm)

Test situation
A "child" (untrained) Sony AIBO was placed in a playmat with toys. An "adult" (trained) robot is there too, deslgined to vocally respond to the robot. 
- Robot can contorl pan and tilt of robot's head. 
- Can control front arm motion, leg motion, and vocalization
- Can detect sound and pressure and camera (camera just tells it if there's an object in front of it, for interaction). Can feel things inside the mouth
- So robot can bite and bash and bark, and knows where objects are
- Adult will imitate (return bark) the child robot if the robot is looking at the adult

Analysis
0. Random exploring and boy babbling. Trying to figure out what it is capable of
1. Focuses on developing indiivdual actuators, which is the largest niche of learning at that phase
2. Interact with objects (figures out what it can bite and bash)
3. Bark and listen at the adult (more difficult. Biting has instant feedback. Barking will not have instant feedback},
  Timestamp                = {2011.02.09}
}

@Conference{Ouwekerk2006,
  Title                    = {SAND: A modular application development platform for miniature wireless sensors},
  Author                   = {Ouwekerk, M. AND Pasveer, F. AND Engin, N.},
  Booktitle                = {Proceedings of the International Workshop on Wearable and Implantable Body Sensor Networks},
  Year                     = {2006},

  Abstract                 = {A modular application development platform for miniature wireless sensor/actuator devices called Small Autonomous Network Devices (SANDs) is described. As an application example a system power breakdown of a real-time ECG analysis is presented. The application development SANDs have a volume of about one cubic centimeter. 

Based upon testing and optimization the schematics and specifications are obtained for the mass-production SANDs. Utilizing System in Package (SiP) technology the volume can be reduced up to five times. These devices can be used in a truly unnoticeable and unobtrusive way to serve as the smallest components of a personal health care monitoring system or an ambient intelligence system.},
  Keywords                 = {wireless sensor networks},
  Review                   = {Talks about power usage and duty cycle of a small wireless sensor system. The system they developed is rather small, size of a penny.


Power consumption breakdown...
By components: Wireless (43%), DSP (46%), Sensors (11%)
By process: Analyze (37%), Transmission (27%), Listening (19%), Standby (17%)},
  Timestamp                = {2010.05.17}
}

@Article{Parkka2006,
  Title                    = {Activity classification using realistic data from wearable sensors},
  Author                   = {P\"{a}rkk\"{a}, J. and Ermes, M. and Korpip\"{a}\"{a}, P. and M\"{a}ntyj\"{a}rvi, J. and Peltola, J. and Korhonen, I.},
  Journal                  = {Information Technology in Biomedicine, IEEE Transactions on},
  Year                     = {2006},

  Month                    = {Jan},
  Number                   = {1},
  Pages                    = {119-128},
  Volume                   = {10},

  Abstract                 = {Automatic classification of everyday activities can be used for promotion of health-enhancing physical activities and a healthier lifestyle. In this paper, methods used for classification of everyday activities like walking, running, and cycling are described. The aim of the study was to find out how to recognize activities, which sensors are useful and what kind of signal processing and classification is required. A large and realistic data library of sensor data was collected. Sixteen test persons took part in the data collection, resulting in approximately 31 h of annotated, 35-channel data recorded in an everyday environment. The test persons carried a set of wearable sensors while performing several activities during the 2-h measurement session. Classification results of three classifiers are shown: custom decision tree, automatically generated decision tree, and artificial neural network. The classification accuracies using leave-one-subject-out cross validation range from 58 to 97% for custom decision tree classifier, from 56 to 97% for automatically generated decision tree, and from 22 to 96% for artificial neural network. Total classification accuracy is 82% for custom decision tree classifier, 86% for automatically generated decision tree, and 82% for artificial neural network},
  Doi                      = {10.1109/TITB.2005.856863},
  ISSN                     = {1089-7771},
  Keywords                 = {biomedical equipment;biomedical measurement;data analysis;decision trees;gait analysis;medical computing;neural nets;pattern classification;risk analysis;2 h;artificial neural network;automatic classification;automatically generated decision tree;custom decision tree;cycling;everyday activity classification;health risk;health-enhancing physical activity;healthier lifestyle;leave-one-subject-out cross validation;realistic data library;running;walking;wearable sensors;Artificial neural networks;Biomedical measurements;Cancer;Cardiovascular diseases;Classification tree analysis;Decision trees;Energy measurement;Legged locomotion;Testing;Wearable sensors;Activity classification;context awareness;physical activity;wearable sensors},
  Timestamp                = {2014.12.21}
}

@Article{Paliwal1982,
  Title                    = {A modification over Sakoe and Chiba's dynamic time warping algorithm for isolated word recognition},
  Author                   = {Paliwal, K. K. and Agarwal, A. and Sinha, S. S.},
  Journal                  = {Signal Processing},
  Year                     = {1982},
  Number                   = {4},
  Pages                    = {329 - 333},
  Volume                   = {4},

  Abstract                 = {A modification over Sakoe and Chiba's dynamic time warping algorithm for isolated word recognition is proposed. It is shown that this modified algorithm works better without any slope constraint. Also, this algorithm not only consumes less computation time but also improves the word recognition accuracy.},
  Doi                      = {DOI: 10.1016/0165-1684(82)90009-3},
  ISSN                     = {0165-1684},
  Keywords                 = {Speech, dynamic time warping},
  Timestamp                = {2011.04.01},
  Url                      = {http://www.sciencedirect.com/science/article/B6V18-48V25G5-48/2/747daf2839392266326abddb08722904}
}

@PhdThesis{Panchea2015_thesis,
  Title                    = {Inverse Optimal Control for Redundant Systems of Biological Motion},
  Author                   = {Panchea, A. M.},
  School                   = {Universite d'Orl\'{e}ans},
  Year                     = {2015},

  Owner                    = {jf2lin},
  Timestamp                = {2016.01.20}
}

@InProceedings{Panchea2015_ACC,
  Title                    = {Towards solving inverse optimal control in a bounded-error framework},
  Author                   = {A. M. Panchea and N. Ramdani},
  Booktitle                = {American Control Conference},
  Year                     = {2015},
  Pages                    = {4910--4915},

  Abstract                 = {In this paper, we apply inverse optimal control approaches in order to recover the cost function that can explain given observations, for a class of constrained optimization problems. The inverse optimal control was recently solved in an approximately optimal framework, meaning that the interest is in finding the proper criteria suitable for the system for which the decisions are approximately optimal. This method benefits of computational time efficiency and simplicity while solving the inverse optimal control problem, by simplifying the initial optimization problem into least square ones, easier than the first one. We focused on solving problems where systems and observations are both imperfect and uncertain. First, we test this method when working with uncertain observations, and results show that the method is sensitive to model uncertainties, encountering bias problems. Being inspired by the approximately optimal approach, we, secondly, use the idea given by this approach and propose a bounded-error approach to inverse optimal control; where all uncertainty and disturbances acting on observation or modeling are assumed bounded but otherwise unknown. A set membership algorithm is then proposed that compute bounds on the set of criteria that make the uncertain observations optimal. Then we show that the bounds computed for the criterion contains the actual solution.},
  Doi                      = {10.1109/ACC.2015.7172103},
  ISSN                     = {0743-1619},
  Keywords                 = {least squares approximations;optimal control;optimisation;bounded-error framework;constrained optimization problems;cost function;inverse optimal control approach;set membership algorithm;Cost function;Noise;Optimal control;Robots;Trajectory;Uncertainty},
  Timestamp                = {2016.05.20}
}

@Article{Pandy2001,
  author    = {Pandy, M. G.},
  title     = {Computer modeling and simulation of human movement},
  journal   = {Annual Review of Biomedical Engineering},
  year      = {2001},
  volume    = {3},
  pages     = {245--273},
  abstract  = {Recent interest in using modeling and simulation to study movement is driven by the belief that this approach can provide insight into how the nervous system and muscles interact to produce coordinated motion of the body parts. With the computational resources available today, large-scale models of the body can be used to produce realistic simulations of movement that are an order of magnitude more complex than those produced just 10 years ago. This chapter reviews how the structure of the neuromusculoskeletal system is commonly represented in a multijoint model of movement, how modeling may be combined with optimization theory to simulate the dynamics of a motor task, and how model output can be analyzed to describe and explain muscle function. Some results obtained from simulations of jumping, pedaling, and walking are also reviewed to illustrate the approach.},
  groups    = {IROS2014, EMBC2014},
  keywords  = {Biomechanics, Postural Analysis, kinesiology},
  timestamp = {2011.06.07},
}

@Article{Pandy1995,
  Title                    = {Optimal Control of Non-ballistic Muscular Movements: A Constraint-Based Performance Criterion for Rising From a Chair},
  Author                   = {Pandy, M. G. and Garner, B. A. and Anderson, F. C.},
  Journal                  = {Journal of Biomechanical Engineering},
  Year                     = {1995},
  Number                   = {1},
  Volume                   = {117},

  Doi                      = {10.1115/1.2792265},
  Owner                    = {jf2lin},
  Timestamp                = {2017.04.17}
}

@Conference{Pansera2009,
  author    = {Pansera, M. AND Estrada, J. J. AND Pastor, L. AND Cancela, J. AND Greenlaw, R. AND Arredondo, M. T.},
  title     = {Multi-parametric system for the continuous assessment and monitoring of motor status in Parkinson's disease: an entropy-based gait comparison},
  booktitle = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  year      = {2009},
  abstract  = {Abstract— A “Multi-parametric system for the continuous assessment and monitoring of motor status in Parkinson's disease” (PERFORM), is an FP7 project from the European Commission that aims at providing an innovative and reliable tool, able to evaluate, monitor and manage patients suffering from motor neurodegenerative diseases. The current work is related to a module of the project that is in charge of assessing PD patients during locomotion. These initial analyses of gait are based on analyses of Sample Entropy in the acceleration 
signals. Four PD patients are compared to four healthy using a set of five wireless sensors located in the limbs and in the trunk. 

A metric to assess the level of symmetry during locomotion, an important clinical feature, is proposed. Results show considerable differences between the patients and the subjects, both for sample entropy (in 3 of the 5 sensors) and in the gait asymmetry index (left vs. right limbs). Future work is proposed including age-matched subjects and a larger sample.},
  groups    = {EMBS2009},
  review    = {- They want to develop a system that will be able to monitor motor neurodegenaterive diseases, such as Parkinson's. 
- Based on wearable micro-sensors and integrate the signals 
- PD people tends to fall alot, even when compared to other fall-prone populations. Use acceleration to determine gait motion so the system can return the same kind of assessment that a physian will
- For PD, it has been noted that the disease tend to onset on only one side of the body, so this would need to be taken into account
- Make use of "entropy analysis" to evaluate human gait
- 3-axis accel (Intel's SHIMMER platform, which appears to be a wireless beacon that accepts wireless accel sensors) placed on arm and trunk in a walking exercise
- They tie it onto the person via elastic band -_- seriously? but it's 100 Hz!
- They LPF the accel data at 3Hz

- Um. Lots of math for entropy analysis
Not that useful. Look into Intel SHIMMER though.},
  timestamp = {2009.10.30},
}

@Article{Papadopoulos2016,
  Title                    = {Generation of human walking paths},
  Author                   = {Papadopoulos, A. V. and Bascetta, L. and Ferretti, G.},
  Journal                  = {Autonomous Robots},
  Year                     = {2016},
  Number                   = {1},
  Pages                    = {59--75},
  Volume                   = {40},

  Abstract                 = {This work investigates the way humans plan their paths in a goal-directed motion, assuming that a person acts as an optimal controller that plans the path minimizing a certain (unknown) cost function. Taking this viewpoint, the problem can be formulated as an inverse optimal control one, i.e., starting from control and state trajectories one wants to figure out the cost function used by a person while planning the path. The so-obtained model can be used to support the design of safe human--robot interaction systems, as well as to plan human-like paths for humanoid robots. To test the envisaged ideas, a set of walking paths of different volunteers were recorded using a motion capture facility. The collected data were used to compare two solutions to the inverse optimal control problem coming from the literature to a novel one. The obtained results, ranked using the discrete Fr{\'e}chet distance, show the effectiveness of the proposed approach.},
  Doi                      = {10.1007/s10514-015-9443-2},
  ISSN                     = {1573-7527},
  Timestamp                = {2016.07.27}
}

@InProceedings{Park2013,
  Title                    = {Inverse optimal control for humanoid locomotion},
  Author                   = {Park, Taesung and Levine, Sergey},
  Booktitle                = {Robotics Science and Systems-Workshop on Inverse Optimal Control and Robotic Learning from Demonstration},
  Year                     = {2013},

  Timestamp                = {2015.11.06}
}

@Article{Passalent2009,
  Title                    = {Wait Times for Publicly Funded Outpatient and Community Physiotherapy and Occupational Therapy Services: Implications for the Increasing Number of Persons with Chronic Conditions in Ontario, Canada},
  Author                   = {Passalent, L. A. and Landry, M. D. and Cott, C. A.},
  Journal                  = {Physiotherapy Canada},
  Year                     = {2009},
  Pages                    = {5--14},
  Volume                   = {61},

  Abstract                 = {Background: Timely access to publicly funded health services has emerged as a priority policy issue across the continuum of care from hospitals to the home and community sector. The purpose of this study was to examine wait lists and wait times for publicly funded outpatient and community occupational therapy (OT) and physical therapy (PT) services.

Methods: A mailed self-administered questionnaire was sent in December 2005 to all publicly funded sites across Ontario that deliver outpatient or community OT or PT services (N=374). Descriptive statistics were used to describe the study sample and to examine wait lists and wait times by setting and client condition.

Results: Overall response rate was 57.2% (n=214). More than 10,000 people were reported to be waiting for OT or PT services across Ontario. Of these, 16% (n=1,664) were waiting for OT and 84% (n=8,842) for PT. Of those waiting for OT, 59% had chronic conditions and half were waiting for home care rehabilitation services. Of those waiting for PT, 73% had chronic conditions and 81% were waiting at hospital outpatient departments.

Conclusions: Individuals with chronic conditions experience excessive wait times for outpatient and community OT and PT services in Ontario, particularly if they are waiting for services in hospital outpatient departments.},
  Doi                      = {10.3138/physio.61.1.5},
  Keywords                 = {Education, Physiotherapy, Geriatrics and Aging, Surgery, Health Care, Gerontology, Case Studies, Anatomy, Diabetes, Rehabilitation, Sports Medicine, Statistics for Life Sciences, Medicine, Health Sciences, Surgical Orthopedics, Transplant Surgery, Traumatic Surgery, Ultrasound, Head and Neck Surgery, Health Administration, Health Informatics & Health Administration, Performance and Reliability, health informatics & health admin, Cardiovascular and Respiratory Systems, Geriatrics and Physical Therapy},
  Timestamp                = {2011.12.23}
}

@InProceedings{Pastor2009,
  Title                    = {Learning and generalization of motor skills by learning from demonstration},
  Author                   = {Pastor, Peter and Hoffmann, H. and Asfour, T. and Schaal, S.},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2009},
  Pages                    = {763-768},

  Abstract                 = {We provide a general approach for learning robotic motor skills from human demonstration. To represent an observed movement, a non-linear differential equation is learned such that it reproduces this movement. Based on this representation, we build a library of movements by labeling each recorded movement according to task and context (e.g., grasping, placing, and releasing). Our differential equation is formulated such that generalization can be achieved simply by adapting a start and a goal parameter in the equation to the desired position values of a movement. For object manipulation, we present how our framework extends to the control of gripper orientation and finger position. The feasibility of our approach is demonstrated in simulation as well as on the Sarcos dextrous robot arm. The robot learned a pick-and-place operation and a water-serving task and could generalize these tasks to novel situations.},
  Doi                      = {10.1109/ROBOT.2009.5152385},
  ISSN                     = {1050-4729},
  Keywords                 = {Anthropomorphism;Differential equations;Fingers;Grippers;Humans;Labeling;Libraries;Robotics and automation;Robots;Robustness},
  Timestamp                = {2013.09.19}
}

@Article{Pate2004,
  Title                    = {Physical Activity Among Children Attending Preschools},
  Author                   = {Pate, R. R. and Pfeiffer, K. A. and Trost, S. G. and Ziegler, P. and Dowda, M.},
  Journal                  = {Pediatrics},
  Year                     = {2004},
  Number                   = {5},
  Pages                    = {1258-1263},
  Volume                   = {114},

  Abstract                 = {Objectives. Obesity rates are increasing among children of all ages, and reduced physical activity is a likely contributor to this trend. Little is known about the physical activity behavior of preschool-aged children or about the influence of preschool attendance on physical activity. The purpose of this study was to describe the physical activity levels of children while they attend preschools, to identify the demographic factors that might be associated with physical activity among those children, and to determine the extent to which children's physical activity varies among preschools. Methods. A total of 281 children from 9 preschools wore an Actigraph (Fort Walton Beach, FL) accelerometer for an average of 4.4 hours per day for an average of 6.6 days. Each child's height and weight were measured, and parents of participating children provided demographic and education data. Results. The preschool that a child attended was a significant predictor of vigorous physical activity (VPA) and moderate-to-vigorous physical activity (MVPA). Boys participated in significantly more MVPA and VPA than did girls, and black children participated in more VPA than did white children. Age was not a significant predictor of MVPA or VPA. Conclusions. Children's physical activity levels were highly variable among preschools, which suggests that preschool policies and practices have an important influence on the overall activity levels of the children the preschools serve.},
  Doi                      = {10.1542/peds.2003-1088-L},
  Eprint                   = {http://pediatrics.aappublications.org/cgi/reprint/114/5/1258.pdf},
  Review                   = {They strapped accelerometers onto preschool kids. To measure activity levels. Seems like all they wanted was a correlation study.},
  Timestamp                = {2010.12.23},
  Url                      = {http://pediatrics.aappublications.org/cgi/content/abstract/114/5/1258}
}

@Conference{Patel2007,
  Title                    = {Analysis of Feature Space for Monitoring Persons with Parkinson's Disease With Application to a Wireless Wearable Sensor System},
  Author                   = {Patel, S. and Lorincz, K. and Hughes, R. and Huggins, N. and Growdon, J. H. and Welsh, M. and Bonato, P.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2007},
  Month                    = {22-26},
  Pages                    = {6290 -6293},

  Abstract                 = {We present work to develop a wireless wearable sensor system for monitoring patients with Parkinson's disease (PD) in their homes. For monitoring outside the laboratory, a wearable system must not only record data, but also efficiently process data on-board. This manuscript details the analysis of data collected using tethered wearable sensors. Optimal window length for feature extraction and feature ranking were calculated, based on their ability to capture motor fluctuations in persons with PD. Results from this study will be employed to develop a software platform for the wireless system, to efficiently process on-board data.},
  Doi                      = {10.1109/IEMBS.2007.4353793},
  ISSN                     = {1557-170X},
  Keywords                 = {Parkinson's disease;feature space;on-board data process;person monitoring;wireless wearable sensor system;biosensors;diseases;medical computing;patient monitoring;wearable computers;},
  Timestamp                = {2010.06.08}
}

@Article{Pawelzik1996,
  Title                    = {Annealed Competition of Experts for a Segmentation and Classification of Switching Dynamics},
  Author                   = {Pawelzik, K. and Kohlmorgen, J. and M{\"u}ller, K.-R.},
  Journal                  = {Neural Computation},
  Year                     = {1996},
  Number                   = {2},
  Pages                    = {340--356},
  Volume                   = {8},
  Abstract                 = {We present a method for the unsupervised segmentation of data streams

originating from different unknown sources that alternate in time. We 
use an architecture consisting of competing neural networks. Memory

is included to resolve ambiguities of input-output relations. To obtain

maximal specialization, the competition is adiabatically increased dur- 
ing training. Our method achieves almost perfect identification and

segmentation in the case of switching chaotic dynamics where input

manifolds overlap and input-output relations are ambiguous. Only

a small dataset is needed for the training procedure. Applications to 
time series from complex systems demonstrate the potential relevance

of our approach for time series analysis and short-term prediction.},
  Publisher                = {MIT Press},
  Timestamp                = {2013.10.07}
}

@InProceedings{Pei2013,
  Title                    = {Robot-Aided Motion Planning for Knee Joint Rehabilitation with Two Robot-Manipulators},
  Author                   = {Pei, Y. and Kim, Y. and Obinata, G. and Genda, E. and Stefanov, D.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {In this paper, we propose a simultaneous design method of motion and external force trajectories for knee joint rehabilitation based on the biomechanical analysis of the lower limb. In this method we assume to use two robots manipulators which provide forces and moments at shank and thigh. We developed a 7 degree of freedom musculoskeletal model of lower limb with 19 muscles. The valuation function of rehabilitation efficiency e has been maximized by Genetic Algorithm (GA) that refers to the musculoskeletal model and tunes motion trajectory of the robots and forces acting on the shank and thigh.},
  Keywords                 = {EMBC2013},
  Timestamp                = {2013.08.05}
}

@InProceedings{Perrin1997,
  Title                    = {Calculation of the direct dynamic model of walking robots: comparison between two methods},
  Author                   = {Perrin, B. and Chevallereau, C. and Verdier, C.},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {1997},
  Month                    = apr,
  Pages                    = {1088 -1093 vol.2},
  Volume                   = {2},

  Abstract                 = {In this paper, two methods to calculate the direct dynamic model (DDM) of walking robots are presented. These methods derive from the Walker-Orin (1982) method and from the Featherstone (1983) method, generally used to compute the DDM of robot manipulators. The comparison is made on the number of operations for each method and for walking robots: a biped robot and a quadruped robot. It is shown that Featherstone's method is better than Walker-Orin's one},
  Doi                      = {10.1109/ROBOT.1997.614280},
  Keywords                 = {Featherstone method;Newton-Euler iterations;Walker-Orin method;biped robot;direct dynamic model;inertia matrix;quadruped robot;walking robots;Newton method;acceleration control;legged locomotion;matrix algebra;mobile robots;motion control;robot dynamics; ECE780},
  Review                   = {In high velocity robots, dynamics cannot be ignored. This paper looks at two different Direct Dynamics models (DDM) and compares them. The two papers that compared are from Walker and Orin (Luh, 1980) and Featherstone (Featherstone, 1983). These two papers are implemented and tested on a biped and a quadruped robot. 

The paper gives the Lagrange formulation for Walker and Orin, and showed how various components of the formulation can be solved for by using the Newton-Euler method. Although Walker and Orin builds off of established robot dynamics methodology, Walker and Orin also suffers from scalability issue, due to the need to invert large inertial matrices. 

In contrast, Featherstone’s piecewise calculations does not require such inversions. A set of equations are given to calculate link velocities, inertial matrices and joint accelerations. Although faster, Featherstone’s method could result in singular matrices being inverted, whereas Walker and Orin’s method does not suffer from this issue (inertial matrices do not have singularities).},
  Timestamp                = {2011.01.12}
}

@Article{Perry2007,
  Title                    = {Upper-limb powered exoskeleton design},
  Author                   = {Perry, J. C. and Rosen, J. and Burns, S.},
  Journal                  = {IEEE/ASME Transactions on Mechatronics},
  Year                     = {2007},
  Number                   = {4},
  Pages                    = {408--417},
  Volume                   = {12},

  Publisher                = {IEEE},
  Timestamp                = {2012.11.12}
}

@Article{Peters2008,
  Title                    = {Learning to Control in Operational Space},
  Author                   = {Peters, J. and Schaal, S.},
  Journal                  = {The International Journal of Robotics Research},
  Year                     = {2008},
  Number                   = {2},
  Pages                    = {197-212},
  Volume                   = {27},

  Abstract                 = {One of the most general frameworks for phrasing control problems for complex, redundant robots is operational-space control. However, while this framework is of essential importance for robotics and well understood from an analytical point of view, it can be prohibitively hard to achieve accurate control in the face of modeling errors, which are inevitable in complex robots (e.g. humanoid robots). In this paper, we suggest a learning approach for operational-space control as a direct inverse model learning problem. A first important insight for this paper is that a physically correct solution to the inverse problem with redundant degrees of freedom does exist when learning of the inverse map is performed in a suitable piecewise linear way. The second crucial component of our work is based on the insight that many operational-space controllers can be understood in terms of a constrained optimal control problem. The cost function associated with this optimal control problem allows us to formulate a learning algorithm that automatically synthesizes a globally consistent desired resolution of redundancy while learning the operational-space controller. From the machine learning point of view, this learning problem corresponds to a reinforcement learning problem that maximizes an immediate reward. We employ an expectation-maximization policy search algorithm in order to solve this problem. Evaluations on a three degrees-of-freedom robot arm are used to illustrate the suggested approach. The application to a physically realistic simulator of the anthropomorphic SARCOS Master arm demonstrates feasibility for complex high degree-of-freedom robots. We also show that the proposed method works in the setting of learning resolved motion rate control on a real, physical Mitsubishi PA-10 medical robotics arm.},
  Doi                      = {10.1177/0278364907087548},
  Eprint                   = {http://ijr.sagepub.com/content/27/2/197.full.pdf+html},
  Keywords                 = {ECE780, Control},
  Review                   = {Existing methods for operational space control is difficult to use. They typically require exact parameters (which is difficult to obtain) to work well, and it is often difficult to account for unmodelled non-linearities. This paper wants to derive the control dynamics directly, instead of using analytical methods, by learning techniques.


This paper provides an example showing a robot without being specific for null-space behaviour, and showed that it can result in large accelerations or instability. The control system employs LWPR as a control model and augments it with EM “rewards” to converge to unique solutions.},
  Timestamp                = {2011.02.09},
  Url                      = {http://ijr.sagepub.com/content/27/2/197.abstract}
}

@InProceedings{Peters2003,
  Title                    = {Reinforcement Learning for Humanoid Robotics},
  Author                   = {Peters, J. and Vijayakumar, S. and Schaal, S.},
  Booktitle                = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  Year                     = {2003},

  Timestamp                = {2013.09.19}
}

@InProceedings{Petkos2007,
  Title                    = {Load estimation and control using learned dynamics models},
  Author                   = {Petkos, G. and Vijayakumar, S.},
  Booktitle                = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2007},
  Pages                    = {1527--1532},

  Abstract                 = {Classic adaptive control methods for handling varying <span class='snippet'>loads</span> rely on an analytically derived model of the robot's dynamics. However, in many situations, it is not feasible or easy to obtain an accurate analytic model of the robot's dynamics. An alternative to analytically deriving the dynamics is learning the dynamics from movement data. This paper describes a <span class='snippet'>load</span> <span class='snippet'>estimation</span> technique that uses the learned instead of analytically derived dynamics. We study examples where the various inertial parameters of the <span class='snippet'>load</span> are estimated from the learned models, their effectiveness in control is evaluated along with their robustness in light of imperfect, intermediate dynamic models.},
  Doi                      = {10.1109/IROS.2007.4399373},
  Review                   = {- How can we use adaptive control to pick up loads? Picking up things changes dynamics of the system. Two ways of this happening:
- q, dq, ddq sensing: special case of parameter estimation. The whole 10 parameters thing. 
 - however, not all parameters can be identified
 - some params are not excited, while others are linearly dependent
 - could get equations analytically, but often complicated
 - so we'll numerically learn it instead
- another way to do this is to look at torque sensing and map input torque to model
 - need to use a PD controller, then switched a "composite" controller (PD + model)

- so the paper combines these to figure out load weight
 - so convert a nx10*n param system to a 11 model system (10 for the last link, 1 for the rest of the robot)
- estimates model accuracy by looking at the ratio between fdfwd (which the model generates) term and fdbk load},
  Timestamp                = {2011.02.03}
}

@Article{Petric2011,
  Title                    = {On-line Frequency Adaptation and Movement Imitation for Rhythmic Robotic Tasks},
  Author                   = {Petri{\v{c}}, T. and Gams, A. and Ijspeert, A. J. and {\v{Z}}lajpah, L.},
  Journal                  = {The International Journal of Robotics Research},
  Year                     = {2011},
  Number                   = {14},
  Pages                    = {1775--1788},
  Volume                   = {30},

  Publisher                = {SAGE Publications},
  Timestamp                = {2014.07.29}
}

@InProceedings{Peyrard2002,
  author    = {Peyrard, N. and Bouthemy, P.},
  title     = {Content-Based Video Segmentation using Statistical Motion Models},
  booktitle = {British Machine Vision Conference},
  year      = {2002},
  pages     = {1--10},
  abstract  = {We present in this paper an original approach for content-based video segmentation using motion information. The method is generic and does not
require any knowledge about the type of the processed video. Its relies on
the analysis of the temporal evolution of the dynamic content of the video.
The motion content is characterised by a probabilistic Gibbsian modelling of
the distribution of local motion-related measurements. The designed statistical framework provides a well formalised similarity measure according to
motion activity that we exploit to derive criteria for segmentation decision.
Then, the considered merging criteria are sequentially applied between every
two successive temporal units of the video to progressively form homogeneous segments in term of motion content. Experiments on real video documents demonstrate the ability of the proposed approach to provide a concise
and meaningful overview of a video.},
  groups    = {Lit Review 2013-09},
  review    = {Want to segment vidoes. Don't want to just segment shots, because content might be contious over several shots.This approach doesn't do that. Instead, they're looking at motion content analysis. They'll use a non-parametrical statical motion model, without the usage of a priori knowledge.

Calculate the flow of a given pixel p at a given time k by looking at the intensity gradient (ie the diff?), then a spatial region around this p is averaged, to determine the flow magnitude, then quantized.


Basically, at each time window, it looks at the current window and the next and compute the motion model (temporal Gibbsian model M) and motion quantitiy map (h) for each window, then calculate the KL distance between them.


Peyrard and Bouthemy \cite{Peyrard2002} wanted to perform temporal segmentation on video data. Segmentation is performed by taking two windows in the observation, and generating a temporal Gibbsian model out of the two windows. The KL distance is then measured between them. If the KL distance is low enough, the two windows are merged and considered one segment. Otherwise, a segment is applied.},
  timestamp = {2013.10.07},
}

@Article{Pfister2014,
  Title                    = {Comparative abilities of Microsoft Kinect and Vicon 3D motion capture for gait analysis},
  Author                   = {A. Pfister and A. M. West and S. Bronner and J. A. Noah},
  Journal                  = {Journal of Medical Engineering \& Technology},
  Year                     = {2014},
  Number                   = {5},
  Pages                    = {274--280},
  Volume                   = {38},

  __markedentry            = {},
  Abstract                 = {AbstractBiomechanical analysis is a powerful tool in the evaluation of movement dysfunction in orthopaedic and neurologic populations. Three-dimensional (3D) motion capture systems are widely used, accurate systems, but are costly and not available in many clinical settings. The Microsoft Kinect™ has the potential to be used as an alternative low-cost motion analysis tool. The purpose of this study was to assess concurrent validity of the Kinect™ with Brekel Kinect software in comparison to Vicon Nexus during sagittal plane gait kinematics. Twenty healthy adults (nine male, 11 female) were tracked while walking and jogging at three velocities on a treadmill. Concurrent hip and knee peak flexion and extension and stride timing measurements were compared between Vicon and Kinect™. Although Kinect measurements were representative of normal gait, the Kinect™ generally under-estimated joint flexion and over-estimated extension. Kinect™ and Vicon hip angular displacement correlation was very low and error was large. Kinect™ knee measurements were somewhat better than hip, but were not consistent enough for clinical assessment. Correlation between Kinect™ and Vicon stride timing was high and error was fairly small. Variability in Kinect™ measurements was smallest at the slowest velocity. The Kinect™ has basic motion capture capabilities and with some minor adjustments will be an acceptable tool to measure stride timing, but sophisticated advances in software and hardware are necessary to improve Kinect™ sensitivity before it can be implemented for clinical use.},
  Doi                      = {10.3109/03091902.2014.909540},
  Eprint                   = { 
 http://www.tandfonline.com/doi/pdf/10.3109/03091902.2014.909540
 
},
  Timestamp                = {2016.02.15}
}

@Article{Phinyomark2013,
  Title                    = {{EMG} feature evaluation for improving myoelectric pattern recognition robustness},
  Author                   = {Phinyomark, A. and Quaine, F. and Charbonnier, S. and Serviere, C. and Tarpin-Bernard, F. and Laurillau, Y.},
  Journal                  = {Expert Systems with Applications},
  Year                     = {2013},
  Pages                    = {4832--4840},
  Volume                   = {40},

  Abstract                 = {In pattern recognition-based myoelectric control, high accuracy for multiple discriminated motions is presented in most of related literature. However, there is a gap between the classification accuracy and the usability of practical applications of myoelectric control, especially the effect of long-term usage. This paper proposes and investigates the behavior of fifty time-domain and frequency-domain features to classify ten upper limb motions using electromyographic data recorded during 21 days. The most stable single feature and multiple feature sets are presented with the optimum configuration of myoelectric control, i.e. data segmentation and classifier. The result shows that sample entropy (SampEn) outperforms other features when compared using linear discriminant analysis (LDA), a robust classifier. The averaged test classification accuracy is 93.37%, when trained in only initial first day. It brings only 2.45% decrease compared with retraining schemes. Increasing number of features to four, which consists of SampEn, the fourth order cepstrum coefficients, root mean square and waveform length, increase the classification accuracy to 98.87%. The proposed techniques achieve to maintain the high accuracy without the retraining scheme. Additionally, this continuous classification allows the real-time operation.},
  Owner                    = {jf2lin},
  Review                   = {looked at a lot of different features. 

LDa is chosen classifier. 
1 subject, 4 channels, forearm, 11 primitives. 121 sets of data over 21 days were collected.},
  Timestamp                = {2015.05.21}
}

@Article{Plappert2016,
  Title                    = {The {KIT} Motion-Language Dataset},
  Author                   = {M. Plappert and C. Mandery and T. Asfour},
  Journal                  = {Big Data},
  Year                     = {2016},

  Month                    = {dec},
  Number                   = {4},
  Pages                    = {236--252},
  Volume                   = {4},

  Doi                      = {10.1089/big.2016.0028},
  Timestamp                = {2017.01.02},
  Url                      = {http://dx.doi.org/10.1089/big.2016.0028}
}

@InBook{Platt2000,
  Title                    = {Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods},
  Author                   = {Platt, J.},
  Chapter                  = {Advances in Large Margin Classifiers},
  Pages                    = {61--74},
  Publisher                = {Cambridge, MA},
  Year                     = {2000},
  Number                   = {3},
  Volume                   = {10},

  Review                   = {Related work:
Wahba - modify the SVM training to minimize the LL during training. Can use regularization term to control the model complexity. 
Vapnik - Fit a distance function using cosine basis functions. But need to solve a linear system for each new input x
Hastie - Fit Guassians to the distance

SVM produces an uncalibrated value that is not a probability. Want to fit a sigmoid to the output decision value from the SVM, which we would need to train for. Training data is (p, t), where p is sigmoid response to the distance, and t is a function of the label. Want to minimize the LL of the training data, given the decision function of SVM and the ground truth label., as the cross-entropy error (the logit function). Regularization can be used to prevent overfitting. Effectively MAP.

Duan and Keerthi, 2005 - showed that Platt's method works good in multiclass applications.},
  Timestamp                = {2015.02.05}
}

@InCollection{Pollick2010,
  Title                    = {In Search of the Uncanny Valley},
  Author                   = {Pollick, F. E.},
  Booktitle                = {User Centric Media},
  Publisher                = {Springer Berlin Heidelberg},
  Year                     = {2010},
  Editor                   = {Akan, Ozgur and Bellavista, Paolo and Cao, Jiannong and Dressler, Falko and Ferrari, Domenico and Gerla, Mario and Kobayashi, Hisashi and Palazzo, Sergio and Sahni, Sartaj and Shen, Xuemin and Stan, Mircea and Xiaohua, Jia and Zomaya, Albert and Coulson, Geoffrey and Daras, Petros and Ibarra, Oscar Mayora},
  Pages                    = {69-78},
  Series                   = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering},
  Volume                   = {40},

  Abstract                 = {Recent advances in computer animation and robotics have lead to greater and greater realism of human appearance to be obtained both on screen and in physical devices. A particular issue that has arisen in this pursuit is whether increases in realism necessarily lead to increases in acceptance. The concept of the uncanny valley suggests that high, though not perfect, levels of realism will result in poor acceptance. We review this concept and its psychological basis.},
  Affiliation              = {University of Glasgow Department of Psychology Glasgow UK},
  ISBN                     = {978-3-642-12630-7},
  Keyword                  = {Computer Science},
  Keywords                 = {human-robot interaction},
  Review                   = {- Want to look at the uncanny valley
 - research was slow for 30 years since Mori (original researcher)
 - but now technology is good enough to consider it
 - uncanny valley shaped design for many years

- possible psych explations of uncanny
 - we percepive "real" in a certain way -> our preception and what we think should happen do not align
 - we have schemas for humans and robots...and humanoids break out schemas, so we get wierded out

- looked at...
 - dubbed speech -> people seem to perfer subtitles to dubbing
 - clowns -> not much research on why people are scared of clowns. looks happy, but don't always behave happy?
 - Capgras syndrome (belief that people/things are replaced with duplicates, that the 'true' essence is gone)},
  Timestamp                = {2011.02.09}
}

@Conference{Pomplun2000,
  author    = {Pomplun, M. and Matari\'{c}, M.},
  title     = {Evaluation Metrics and Results of Human Arm Movement Imitation},
  booktitle = {Proceedings of IEEE/RAS International Conference on Humanoid Robotics},
  year      = {2000},
  abstract  = {We present a psychophysical study of human arm movement imitation,and an approach to analyzing the resulting data, which can be applied to human or humanoid movement analysis. We describe a joint-space based segmentation and comparison algorithm that allow us to evaluate the performance of 11 different subjects on a series of arm movement imitation tasks. The results provide analytical evidence for the strong interference effects of simultaneous rehearsal during observation. Additionally, the results also demonstrate that repeated imitation in these tasks did not affect the subjects’ performance.},
  groups    = {STAT841},
  keywords  = {motion segmentation},
  review    = {Data input: FastTrak motion tracking

Wanted to look at effects of rehearsal in human arm motion imitation (the original motion was video-recorded and replayed for each subject). The more significant part is the comparison algorithm between the sample and the subject. They used RMS on distance, but different velocity meant distance traveled over some time would be different between the two, so they did time scaling on the data points so both sets of motion were executed over the same amount of time. 

The imitated motion consists of several smaller actions, which was segmented based on "velocity turning points" (since velocity of a limb segment would approach zero in order to change direction). In the event that some segment was just slow and the algorithm splits that into several segments, the segments were combined by testing combinations of segments and see which one lead to the smallest total temporal deviations between the sample and the subject. They also had a "minimum time", the shortest possible duration for a segment.

Anyway, ANOVA shows that there is a significant difference between rehearsed and non-rehearsed actions.



Pomplun and Matari\'{c} \cite{Pomplun2000} employed zero-velocity crossings (ZVCs) to identify points where the velocity value changes sign, denoting when a joint segment direction change, as segment points. If multiple joints are examined simultaneously, segment points can be declared by thresholding the sum of squares of the velocities. A minimum threshold for segments was included, to prevent spurious ZVCs from creating large numbers of false positives. Although a fast algorithm, ZVC tends to over-segment, particularly with noisy data or with increasing number of DOFs. Since ZVC does not consider motion templates, it is difficult to determine which crossing points can be safely ignored. In addition, the ZVC algorithm does not provide a method for motion identification. Pomplun suggests that a distance metric can be used, but these metrics are sensitive to spatial and temporal variations, and may not provide reliable movement labels. The algorithm was used to assess a 11-subject study on human imitation learning, where video clips of arm motions were shown to the participants. The participants were either instructed to practice the observed motion before data collection, or not. The collected data was segmented and compared against the demonstrator's motions. Since the study was on the impact of rehearsing on the ability to accurately reproduce a motion, segmentation accuracy of the algorithm was not explicitly reported.},
  timestamp = {2009.09.11},
}

@Article{Poppe2010,
  Title                    = {A Survey on Vision-based Human Action Recognition},
  Author                   = {Poppe, R.},
  Journal                  = {Image and Vision Computing },
  Year                     = {2010},
  Pages                    = {976--990},
  Volume                   = {28},

  Abstract                 = {Vision-based human action recognition is the process of labeling image sequences with action labels. Robust solutions to this problem have applications in domains such as visual surveillance, video retrieval and human–computer interaction. The task is challenging due to variations in motion performance, recording settings and inter-personal differences. In this survey, we explicitly address these challenges. We provide a detailed overview of current advances in the field. Image representations and the subsequent classification process are discussed separately to focus on the novelties of recent research. Moreover, we discuss limitations of the state of the art and outline promising directions of research.},
  Doi                      = {http://dx.doi.org/10.1016/j.imavis.2009.11.014},
  ISSN                     = {0262-8856},
  Keywords                 = {Human action recognition},
  Timestamp                = {2014.12.18}
}

@Article{Potkonjak2011,
  Title                    = {Human-and-Humanoid Postures Under External Disturbances: Modeling, Simulation, and Robustness. Part 1: Modeling},
  Author                   = {Potkonjak, Veljko and Tzafestas, Spyros and Vukobratovic, Miomir and Milojevic, Milena and Jovanovic, Milos},
  Journal                  = {Journal of Intelligent and Robotic Systems},
  Year                     = {2011},
  Note                     = {10.1007/s10846-010-9517-5},
  Pages                    = {191-210},
  Volume                   = {63},

  Abstract                 = {It is a well-known fact that the growth of technology has radically changed our approach to biosciences and medicine. What is interesting is that in the last decade we have witnessed a reverse influenceâ€”a trend towards biologically inspired solutions to technical problems. This leads to a true symbiosis between bio and technical sciences. A good example is the intersection and overlapping of three distinct fields: sports, medicine, and robotics. This paper intends to apply sophisticated methods developed for mathematical modeling of humanoid robots in real human motions, particularly in posture stabilization and selection of appropriate postures for different situation in sports and every day life. A general simulation system is realized: following a deductive principle, the algorithm considers particular human/humanoid motions (like those occurring in different sports) as being just special cases of a general motion and impact theory. Simulation includes the interaction with the environment. Simulating a human/humanoid dynamics in a given task, all relevant characteristics could be found: trajectories, velocities and accelerations, loads of joints, power requirements, energy consumption, contact forces including ground reactions, impact effects, etc. Simulation is used in solving a problem that is important for both humans and humanoid robots, namely, the behavior of a posture (keeping stability or collapsing) when subject to different disturbances. Although posture is mainly a static term, maintaining its balance in the presence of disturbances is a truly dynamic problem. Typical postures from every day life and sports are considered, such as: upright standing, squat (and partial squat), and three karate postures. Two sorts of disturbances are applied to eventually, compromise the posture: external impulse and permanent external force. This paper does not aim to suggest some new control strategy but to develop the dynamic model and simulation algorithm, and apply them to compare the robustness of different postures to external disturbances.},
  Affiliation              = {Faculty of Electrical Engineering, University of Belgrade, Bulevar Kralja Aleksandra 73, 11000 Belgrade, Serbia},
  ISSN                     = {0921-0296},
  Issue                    = {2},
  Keyword                  = {Engineering},
  Publisher                = {Springer Netherlands},
  Timestamp                = {2011.07.20},
  Url                      = {http://dx.doi.org/10.1007/s10846-010-9517-5}
}

@Article{Powell1995,
  Title                    = {The Activities-specific Balance Confidence (ABC) Scale},
  Author                   = {Powell, Lynda Elaine and Myers, Anita M.},
  Journal                  = {The Journals of Gerontology Series A: Biological Sciences and Medical Sciences},
  Year                     = {1995},
  Number                   = {1},
  Pages                    = {M28-M34},
  Volume                   = {50A},

  Abstract                 = {Background. This study provides a replication of the Falls Efficacy Scale (FES) and a head-to-head comparison with the Activities-specific Balance Confidence (ABC) Scale designed to include a wider continuum of activity difficulty and more detailed item descriptors.Methods. Items tor the newly developed 16-item ABC Scale were generated by 15 clinicians and 12 elderly outpatients. Psychometric testing involved 60 community seniors (aged 65-95) self-classified as either high or low in mobility confidence according to their perceived need for a walking aid and personal assistance to ambulate outdoors.Results. Both the FES and ABC scales were found to be internally consistent and demonstrated good test-retest reliability, convergent and criterion validity. Scalogram analyses indicated a stronger cumulative scale in the case of the ABC and skewness in the distribution of FES scores. While both scales were able to discriminate between the two mobility groups, the ABC scale was a more efficient discriminator and yielded a wider range of responses.Conclusions. The present study provided additional psychometric support for the FES. However, the greater item responsiveness of the ABC scale makes it more suitable to detect loss of balancing confidence in more highly functioning seniors. Greater situation-specificity of items may also assist clinicians in targeting appropriate interventions.},
  Doi                      = {10.1093/gerona/50A.1.M28},
  Eprint                   = {http://biomedgerontology.oxfordjournals.org/content/50A/1/M28.full.pdf+html},
  Keywords                 = {physiotherapy},
  Timestamp                = {2012.06.21},
  Url                      = {http://biomedgerontology.oxfordjournals.org/content/50A/1/M28.abstract}
}

@InProceedings{Pozdnoukhov2006,
  Title                    = {Semi-supervised kernel methods for regression estimation},
  Author                   = {Pozdnoukhov, A. and Bengio, S.},
  Booktitle                = {IEEE International Conference on Acoustics, Speech and Signal Processing},
  Year                     = {2006},
  Pages                    = {577--580},
  Volume                   = {5},

  Review                   = {They ... randomly removed some data label in training? It seems very unclear at how they did it...},
  Timestamp                = {2015.05.13}
}

@Book{Priddy2005,
  Title                    = {Artificial neural networks: an introduction},
  Author                   = {Priddy, K. L. and Keller, P. E.},
  Publisher                = {SPIE Press},
  Year                     = {2005},
  Volume                   = {68},

  Timestamp                = {2016.12.21}
}

@Article{Priess2015,
  Title                    = {Solutions to the Inverse LQR Problem With Application to Biological Systems Analysis},
  Author                   = {Priess, M.C. and Conway, R. and Jongeun Choi and Popovich, J.M. and Radcliffe, C.},
  Journal                  = {IEEE Transactions on Control Systems Technology},
  Year                     = {2015},
  Number                   = {2},
  Pages                    = {770--777},
  Volume                   = {23},

  Abstract                 = {In this brief, we present a set of techniques for finding a cost function to the time-invariant linear quadratic regulator (LQR) problem in both continuous- and discrete-time cases. Our methodology is based on the solution to the inverse LQR problem, which can be stated as: does a given controller K describe the solution to a time-invariant LQR problem, and if so, what weights Q and R produce K as the optimal solution? Our motivation for investigating this problem is the analysis of motion goals in biological systems. We first describe an efficient linear matrix inequality (LMI) method for determining a solution to the general case of this inverse LQR problem when both the weighting matrices Q and R are unknown. Our first LMI-based formulation provides a unique solution when it is feasible. In addition, we propose a gradient-based, least-squares minimization method that can be applied to approximate a solution in cases when the LMIs are infeasible. This new method is very useful in practice since the estimated gain matrix K from the noisy experimental data could be perturbed by the estimation error, which may result in the infeasibility of the LMIs. We also provide an LMI minimization problem to find a good initial point for the minimization using the proposed gradient descent algorithm. We then provide a set of examples to illustrate how to apply our approaches to several different types of problems. An important result is the application of the technique to human subject posture control when seated on a moving robot. Results show that we can recover a cost function which may provide a useful insight on the human motor control goal.},
  Doi                      = {10.1109/TCST.2014.2343935},
  ISSN                     = {1063-6536},
  Keywords                 = {biology;least squares approximations;linear matrix inequalities;linear quadratic control;minimisation;position control;LMI method;LMI minimization problem;biological systems analysis;cost function;gain matrix;gradient-based least-squares minimization method;human subject posture control;inverse LQR problem;linear matrix inequality;motion goals analysis;moving robot;time-invariant LQR problem;time-invariant linear quadratic regulator;weighting matrix;Biological systems;Cost function;Equations;Inverse problems;Minimization;Motor drives;Noise measurement;Biological system modeling;inverse optimal control problem;system identification},
  Owner                    = {jf2lin},
  Review                   = {What if we assume motion differences between people in different states (healthy vs injuried) are due to control function differences? Quickly explains what LQR is, then examines inverse LQR. Uses a method called linear matrix inequality (LMI) to test for if an optimal solution is possible, then solve for Q and R if it is. If a solution does not exist, then a gradient descent method is proposed. Tested against a person doing...a seated balance test? So ensure unique solutions, a constraint on Q/R is used. The solution is formulated as a cnvex optimization problem. For the balance test, they model a 2-DOF system (4 DOF total including velo), then recon the joint angle and found a good fit. Used some MATLAB function to find parameters... but they couldn't finda close LMI solution so gradient descent was used. 

- has related works that we can take a look at [5-8].},
  Timestamp                = {2015.11.06}
}

@Article{Pronobis2010,
  Title                    = {The More You Learn, the Less You Store: Memory-controlled Incremental SVM for Visual Place Recognition},
  Author                   = {Pronobis, A. and Luo, J. and Caputo, B.},
  Journal                  = {Image and Vision Computing},
  Year                     = {2010},
  Number                   = {7},
  Pages                    = {1080--1097},
  Volume                   = {28},

  Abstract                 = {The capability to learn from experience is a key property for autonomous cognitive
systems working in realistic settings. To this end, this paper presents an SVM-
-based algorithm, capable of learning model representations incrementally while
keeping under control memory requirements. We combine an incremental extension
of SVMs [45] with a method reducing the number of support vectors needed to build
the decision function without any loss in performance [15] introducing a parameter
which permits a user-set trade-off between performance and memory. The resulting
algorithm is able to achieve the same recognition results as the original incremental
method while reducing the memory growth. Our method is especially suited to
work for autonomous systems in realistic settings. We present experiments on two
common scenarios in this domain: adaptation in presence of dynamic changes and
transfer of knowledge between two different autonomous agents, focusing in both
cases on the problem of visual place recognition applied to mobile robot topological
localization. Experiments in both scenarios clearly show the power of our approach.},
  Publisher                = {Elsevier},
  Timestamp                = {2014.10.24}
}

@InProceedings{Pu2013,
  Title                    = {Whole-home Gesture Recognition Using Wireless Signals},
  Author                   = {Pu, Q. and Gupta, S. and Gollakota, S. and Patel, S.},
  Booktitle                = {Proceedings of the 19th Annual International Conference on Mobile Computing and Networking},
  Year                     = {2013},
  Pages                    = {27--38},

  Abstract                 = {This paper presents WiSee, a novel gesture
recognition system that leverages wireless signals (e.g., Wi-
Fi) to enable whole-home sensing and recognition of human
gestures. Since wireless signals do not require line-of-sight
and can traverse through walls, WiSee can enable wholehome
gesture recognition using few wireless sources. Further,
it achieves this goal without requiring instrumentation of the
human body with sensing devices. We implement a proof-ofconcept
prototype of WiSee using USRP-N210s and evaluate
it in both an office environment and a two-bedroom apartment.
Our results show that WiSee can identify and classify
a set of nine gestures with an average accuracy of 94%.},
  Acmid                    = {2500436},
  Doi                      = {10.1145/2500423.2500436},
  ISBN                     = {978-1-4503-1999-7},
  Keywords                 = {gesture recognition, whole-home interaction, wireless sensing},
  Location                 = {Miami, Florida, USA},
  Numpages                 = {12},
  Timestamp                = {2015.06.30},
  Url                      = {http://doi.acm.org/10.1145/2500423.2500436}
}

@InProceedings{Puydupin-Jamin2012,
  Title                    = {A convex approach to inverse optimal control and its application to modeling human locomotion},
  Author                   = {Puydupin-Jamin, A.-S. and Johnson, M. and Bretl, T.},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2012},
  Pages                    = {531-536},

  Abstract                 = {Inverse optimal control is the problem of computing a cost function that would have resulted in an observed sequence of decisions. The standard formulation of this problem assumes that decisions are optimal and tries to minimize the difference between what was observed and what would have been observed given a candidate cost function. We assume instead that decisions are only approximately optimal and try to minimize the extent to which observed decisions violate first-order necessary conditions for optimality. For a discrete-time optimal control system with a cost function that is a linear combination of known basis functions, this formulation leads to an efficient method of solution as an unconstrained least-squares problem. We apply this approach to both simulated and experimental data to obtain a simple model of human walking trajectories. This model might subsequently be used either for control of a humanoid robot or for predicting human motion when moving a robot through crowded areas.},
  Doi                      = {10.1109/ICRA.2012.6225317},
  ISSN                     = {1050-4729},
  Keywords                 = {biocontrol;biomechanics;discrete time systems;humanoid robots;least squares approximations;optimal control;trajectory control;convex approach;cost function computation problem;difference minimization;discrete-time optimal control system;first-order necessary conditions;human locomotion modeling;human motion prediction;human walking trajectories;humanoid robot;inverse optimal control;unconstrained least-squares problem;Cost function;Data models;Humans;Mathematical model;Optimal control;Trajectory},
  Review                   = {Applies IOC to walking. Assumes that input data is only approximately optimal, and minimizes the non-optimal violations.},
  Timestamp                = {2015.11.06}
}

@Article{Qiu2016,
  Title                    = {A survey of machine learning for big data processing},
  Author                   = {Qiu, J. and Wu, Q. and Ding, G. and Xu, Y. and Feng, S.},
  Journal                  = {EURASIP Journal on Advances in Signal Processing},
  Year                     = {2016},
  Number                   = {1},
  Pages                    = {67},
  Volume                   = {2016},

  Abstract                 = {There is no doubt that big data are now rapidly expanding in all science and engineering domains. While the potential of these massive data is undoubtedly significant, fully making sense of them requires new ways of thinking and novel learning techniques to address the various challenges. In this paper, we present a literature survey of the latest advances in researches on machine learning for big data processing. First, we review the machine learning techniques and highlight some promising learning methods in recent studies, such as representation learning, deep learning, distributed and parallel learning, transfer learning, active learning, and kernel-based learning. Next, we focus on the analysis and discussions about the challenges and possible solutions of machine learning for big data. Following that, we investigate the close connections of machine learning with signal processing techniques for big data processing. Finally, we outline several open issues and research trends.},
  Doi                      = {10.1186/s13634-016-0355-x},
  ISSN                     = {1687-6180},
  Timestamp                = {2016.12.20},
  Url                      = {http://dx.doi.org/10.1186/s13634-016-0355-x}
}

@Conference{Quigley2010,
  Title                    = {Low-cost Accelerometers for Robotic Manipulator Perception},
  Author                   = {Quigley, M. and Brewer, R. and Soundararaj, S. P. and Pradeep, V. and Le, Q. and Ng, A. Y.},
  Booktitle                = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2010},

  Abstract                 = {We present a series of experiments which explore the use of consumer-grade accelerometers as joint position sensors for robotic manipulators. We show that 6- and 7-dof joint angle estimation is possible by using one 3-d accelerometer for each pair of joints. We demonstrate two calibration approaches and experimental results using accelerometer-based control in both position-control and torque-control regimes. We present a manipulator design combining accelerometer-based sensing with low-cost actuation, and conclude by demonstrating the utility of consumer-grade accelerometers even on high-precision manipulators},
  Keywords                 = {Postural detection},
  Review                   = {Using 3DOF Accel + EKF on robots. Noted centripetal/linear accel terms unnecessary (><||), so they modeled it just as rotations of gravity. They do recognize that there are singular points (when the rotation is along the shaft of the link), and need to be avoided

CALIBRATION - reference frames might all be unaligned, like accel internal to the robot itself. This is static and can be calibrated for. They used a checkerboard-based calibration (supposely common in computer vision). Seems like a technique where the robot is placed in known positions a few times. Then used an optimization to minimize the distance between calculated distance (using FK) and measured. They tested this on a robot that they had CAD models to. Position error went from 11mm to 2mm. Noted importance of initial guesses. Although this error is worse than the position encoders, it is better than vision guided systems they have been employing.

This system breaks down at highly dynamic (fast, high freq) systems. Adding addition terms to the equations didn't seem to help much. Perhaps the bandwidth is too low or the calibration is not up to par.

Basically, EKF + accel only position estimation works well.},
  Timestamp                = {2010.11.06}
}

@Article{Quinlan1986,
  Title                    = {Induction of Decision Trees},
  Author                   = {Quinlan, J. R.},
  Journal                  = {Machine Learning},
  Year                     = {1986},
  Number                   = {1},
  Pages                    = {81--106},
  Volume                   = {1},

  Doi                      = {10.1023/A:1022643204877},
  ISSN                     = {0885-6125},
  Keywords                 = {classification; induction; decision trees; information theory; knowledge acquisition; expert systems},
  Language                 = {English},
  Publisher                = {Kluwer Academic Publishers-Plenum Publishers},
  Timestamp                = {2014.03.14}
}

@InProceedings{Quintana2008,
  Title                    = {Qualification of Arm Gestures using Hidden {Markov} Models},
  Author                   = {Quintana, G. E. and Sucar, L. E. and Azcarate, G. and Leder, R.},
  Booktitle                = {Proceedings of the IEEE International Conference on Automatic Face and Gesture Recognition},
  Year                     = {2008},
  Pages                    = {1--6},

  Timestamp                = {2012.04.02}
}

@InProceedings{Ruping2001,
  Title                    = {Incremental learning with support vector machines},
  Author                   = {R{\"u}ping, Stefan},
  Booktitle                = {IEEE International Conference on Data Mining},
  Year                     = {2001},
  Pages                    = {641--641},

  Timestamp                = {2014.11.14}
}

@Article{Rabiner1989,
  author    = {Rabiner, L. R.},
  title     = {A tutorial on Hidden {Markov} Models and Selected Applications in Speech Recognition},
  journal   = {Proceedings of the IEEE},
  year      = {1989},
  volume    = {77},
  pages     = {257--286},
  issn      = {0018-9219},
  abstract  = {This tutorial provides an overview of the basic theory of hidden Markov models (HMMs) as originated by L.E. Baum and T. Petrie (1966) and gives practical details on methods of implementation of the theory along with a description of selected applications of the theory to distinct problems in speech recognition. Results from a number of original sources are combined to provide a single source of acquiring the background required to pursue further this area of research. The author first reviews the theory of discrete Markov chains and shows how the concept of hidden states, where the observation is a probabilistic function of the state, can be used effectively. The theory is illustrated with two simple examples, namely coin-tossing, and the classic balls-in-urns system. Three fundamental problems of HMMs are noted and several practical techniques for solving these problems are given. The various types of HMMs that have been studied, including ergodic as well as left-right models, are described},
  doi       = {10.1109/5.18626},
  groups    = {STAT841, IROS2014},
  keywords  = {balls-in-urns system;coin-tossing;discrete Markov chains;ergodic models;hidden Markov models;hidden states;left-right models;probabilistic function;speech recognition;Markov processes;speech recognition;},
  timestamp = {2011.06.12},
}

@Article{Rabiner1986,
  Title                    = {An Introduction to Hidden Markov Models},
  Author                   = {Rabiner, L. R. and Juang, B.-H.},
  Journal                  = {IEEE ASSP Magazine},
  Year                     = {1986},
  Pages                    = {4--16},
  Volume                   = {1},

  Abstract                 = {The basic theory of Markov chains has been known to mathematicians and engineers for close to 80 years, but it is only in the past decade that it has been applied explicitly to problems in speech processing. One of the major reasons why speech models, based on Markov chains, have not been developed until recently was the lack of a method for optimizing the parameters of the Markov model to match observed signal patterns. 

Such a method was proposed in the late 1960’s and was immediately applied to speech processing in several research institutions. Continued refinements in the theory and implementation of Markov modeling techniques have greatly enhanced the method, leading to a wide range of application of these models. It is the purpose of this tutorial paper to give an introduction to, the theory of Markov models, and to illustrate how they have been applied to problems in speech recognition.},
  Timestamp                = {2010.01.25}
}

@InProceedings{Ramos2013,
  Title                    = {Towards a Time-Feature Independent Phonocardiogram Segmentation},
  Author                   = {Ramos, J. P. and Carvalho, P. and Coimbra, M.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {Delimitation and classification of each heart sound is a rather difficult task. Elevated heart rates, as found in pediatrics and in some adults as well, influence some of the most reliable features used by existing methods. Furthermore, in real life scenarios, cardiologists will not have the time to acquire the signal’s length required by some of the existing algorithms, which make us think that different approaches ought to be pursued. This paper presents the work on heart sound segmentation using structural and energy based features. It is an attempt to not rely on features considered crucial to most existing approaches. Yet, it achieves a high sensitivity and specificity comparable to some literature.},
  Keywords                 = {EMBC2013},
  Review                   = {Want to identify patterns in heart beat. 

Uses Averaged Shannon Energy (a function of the signal) and the Teager Energy (a measure to describe the complexity of the signal), amplitude and width of each heart sound. Hierestic rules are used to determine start and end of signal of interest.

Ramos \etal \cite{Ramos2013} identify patterns in a heart beat sound. They examined averaged Shannon energy (ASE), a signal envelope extraction method, and the Teager energy (TE), a non-linear measurement that represents signal complexity:
%
\begin{align}
 ASE &= \frac{1}{N} \sum{N}{i=1} x^2_i \log_2(x^2_i) \\
 TE &= x^2_n - x_n x_{n-1}
\end{align}
%
\noindent as well as amplitude and width of each heart sound. Primitive candidates are located by wavelet transform decomposition and searching for blocks of normal heart sounds, which occur between 0 and 500 Hz. The ASE is used to determine the signal envelope of these blocks, and zero crossings of the ASE envelope are denoted as segment points. Threshold-based heuristic rules are used to label the primitive candidates, and discard noisy candidates. This algorithm was verified against the PASCAL CHSC2011 digital stethoscope clinical trial dataset. The $Ver_{temporalInv}$ approach was used, where a primitive was marked correct if the manual segment point was found within the algorithmic primitive bounds. An $Acc_{recall}$ of 93\% and $Acc_{specificity}$ of 93\% was noted.},
  Timestamp                = {2013.08.02}
}

@InProceedings{Ratanamahatana2004,
  Title                    = {Making Time-series Classification More Accurate Using Learned Constraints},
  Author                   = {Ratanamahatana, C. A. and Keogh, E.},
  Booktitle                = {Proceedings of the SIAM International Conference on Data Mining},
  Year                     = {2004},
  Pages                    = {11--22},

  __markedentry            = {},
  Review                   = {Ratanamahatana2004
Base algorithm: DTW
Templated? Yes
Details: Proposes a dynamically changing constraint band for DP warping slope. Enlarges and shrinks the band to find a proper band, checking for distance/accuracy. When changing the whole band doesn't help anymore, the band is split into two (ie t = 1:mid and t = mid+1:end), and checked again individually. By setting the proper weighting, they can produce the band profiles of related works
Problems: Assumes that the data are similar in length, since the splitting in half might result in one small section mapping to another
Verification: They seem to have some sort of standard set, but has no references

Ratanamahatana and Keogh \cite{Ratanamahatana2004} proposed an algorithm that calculates an optimal band dynamically. This algorithm starts by performing DTW between two data series with a constraint band width of zero, and increases the band width until the distance between the two data series is minimized, or a threshold is reached. The algorithm then bisects the data, and performs the same iteration individually, on each half of the data series. The algorithm continues to iterate with smaller data lengths, until a minimum length of $\sqrt{m}/2$ is reached, where $m$ is the length of the data series, as anything smaller increases the risk of overfitting. This creates a band that varies in width as a function of time. The algorithm was verified on human arm motion performing gun-draws, synthetic data simulating nuclear power plant instrumentation failure and a handwritting dataset; it was found that the dynamic band method reported better identification rates then the existing fixed-band method. Although this algorithm produces a more customized warping band, it suffers from several drawbacks. This iterative search adds more computation time to an algorithm that is already known to be computationally expensive. A new constraint band needs to be generated for different situations, since a constraint band optimized for the mapping of a given participant performing a specific motion may not be optimal for another participant performing the same motion. Although this method addresses the singularity issue, it does so by increasing the calculation time. It is also uncertain how well this algorithm would do for segmentation purposes, as it was applied primarily to classification cases, which it performs at 99\% accuracy.},
  Timestamp                = {2011.06.07}
}

@InCollection{Ratanamahatana2008,
  Title                    = {Stopping criterion selection for efficient semi-supervised time series classification},
  Author                   = {Ratanamahatana, Chotirat Ann and Wanichsan, Dechawut},
  Booktitle                = {Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing},
  Publisher                = {Springer},
  Year                     = {2008},
  Pages                    = {1--14},

  Abstract                 = {High-quality classifiers generally require significant amount of labeled
data. However, in many real-life applications and domains, labeled positive training
data are difficult to obtain, while unlabeled data are largely available. To resolve the
problem, many researchers have proposed semi-supervised learning methods that can
build good classifiers by using only handful of labeled data. However, the main prob-
lem of the previous approaches for time series domains is the difficulty in selecting an
optimal stopping criterion. This work therefore proposes a novel stopping criterion for
semi-supervised time series classification,
together with an integration of Dynamic Time
Warping distance measure to improve the data selection during a self training. The ex-
perimental results show that this method can build a better classifier that achieves
higher classification accuracy than the previous approach. In addition, the extended
proposed work is shown to have satisfactory result for multi-cluster and multi-class
semi-supervised time series classifier.},
  Review                   = {- want to determine a good "stopping criteria" for semi supervised learning while having a good accuracy for the classifier
- use DTW
 - split training data into a labelled set and unlabelled set
 - map the unlabelled data into the labelled one
-> actually, this just sounds like bagging, where they're dividing up the training set and using other labelled data to verify that it generalizes
- classifies with DTW distance},
  Timestamp                = {2015.05.13}
}

@InProceedings{Ratliff2009,
  Title                    = {CHOMP: Gradient optimization techniques for efficient motion planning},
  Author                   = {N. Ratliff and M. Zucker and J. A. Bagnell and S. Srinivasa},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2009},
  Pages                    = {489--494},

  Abstract                 = {Existing high-dimensional motion planning algorithms are simultaneously overpowered and underpowered. In domains sparsely populated by obstacles, the heuristics used by sampling-based planners to navigate “narrow passages” can be needlessly complex; furthermore, additional post-processing is required to remove the jerky or extraneous motions from the paths that such planners generate. In this paper, we present CHOMP, a novel method for continuous path refinement that uses covariant gradient techniques to improve the quality of sampled trajectories. Our optimization technique both optimizes higher-order dynamics and is able to converge over a wider range of input paths relative to previous path optimization strategies. In particular, we relax the collision-free feasibility prerequisite on input paths required by those strategies. As a result, CHOMP can be used as a standalone motion planner in many real-world planning queries. We demonstrate the effectiveness of our proposed method in manipulation planning for a 6-DOF robotic arm as well as in trajectory generation for a walking quadruped robot.},
  Doi                      = {10.1109/ROBOT.2009.5152817},
  ISSN                     = {1050-4729},
  Keywords                 = {Legged locomotion;Motion planning;Optimal control;Optimization methods;Orbital robotics;Path planning;Robotics and automation;Robots;Space technology;Trajectory},
  Timestamp                = {2017.03.01}
}

@Article{Rautaray2015,
  Title                    = {Vision based hand gesture recognition for human computer interaction: a survey},
  Author                   = {Rautaray, S. S. and Agrawal, A.},
  Journal                  = {Artificial Intelligence Review},
  Year                     = {2015},
  Pages                    = {1--54},
  Volume                   = {43},

  Doi                      = {10.1007/s10462-012-9356-9},
  ISSN                     = {0269-2821},
  Keywords                 = {Hand; Gesture recognition; Human computer interaction; Representations; Recognition; Natural interfaces},
  Language                 = {English},
  Publisher                = {Springer Netherlands},
  Timestamp                = {2015.06.30},
  Url                      = {http://dx.doi.org/10.1007/s10462-012-9356-9}
}

@Article{Razak2008,
  Title                    = {Off-line Handwriting Text Line Segmentation: A Review},
  Author                   = {Razak, Z. and Zulkiflee, K. and Idris, M. Y. I. and Tamil, E. M. and Noor, M. N. M. and Salleh, R. and Yaakob, M. and Yusof, Z. M. and Yaacob, M.},
  Journal                  = {International Journal of Computer Science and Network Security},
  Year                     = {2008},
  Pages                    = {12--20},
  Volume                   = {8},

  Timestamp                = {2014.02.23}
}

@InCollection{Reddy2007,
  Title                    = {Human Action Recognition in Table-Top Scenarios : An HMM-Based Analysis to Optimize the Performance},
  Author                   = {Reddy, Pradeep K. and Grest, Daniel and Krueger, Volker},
  Booktitle                = {Computer Analysis of Images and Patterns},
  Publisher                = {Springer Berlin Heidelberg},
  Year                     = {2007},
  Editor                   = {Kropatsch, WalterG. and Kampel, Martin and Hanbury, Allan},
  Pages                    = {101-108},
  Series                   = {Lecture Notes in Computer Science},
  Volume                   = {4673},

  Abstract                 = {Hidden Markov models have been extensively and successfully used for the recognition of human actions. Though there exist wellestablished algorithms to optimize the transition and output probabilities, the type of features to use and specifically the number of states and
Gaussian have to be chosen manually. Here we present a quantitative
study on selecting the optimal feature set for recognition of simple object manipulation actions pointing, rotating and grasping in a table-top
scenario. This study has resulted in recognition rate higher than 90%.
Also three different parameters, namely the number of states and Gaussian for HMM and the number of training iterations, are considered for
optimization of the recognition rate with 5 different feature sets on our
motion capture data set from 10 persons.},
  Doi                      = {10.1007/978-3-540-74272-2_13},
  ISBN                     = {978-3-540-74271-5},
  Keywords                 = {Hidden Markov model; Action Recognition; Optimization},
  Review                   = {Uses HMM to learn motion model. Dataset with 10 persons, 890 sequences. Want to understand/recognize human actions

Had the people perform pointing, grasping, rotating and displacing tasks, in 3 directions to 2 different heights and 2 different distances, with 5 repetitions each. Mocap Cartesian data was collected. 

Looking at several possible features. Upper body joint angles, direction of torso to wrist, direction of shoulder to wrist, grasp distance. Tried on different state count (5 to 40) and different Gaussian counts (...why do they need 10 per state?). Showed that joint angle isn't the best feature, that shoulder-wrist distance + grasp dist is. 94% accuracy. 

pre-segmented! arg},
  Timestamp                = {2013.10.02},
  Url                      = {http://dx.doi.org/10.1007/978-3-540-74272-2_13}
}

@Conference{Redmond2010,
  Title                    = {Automatic segmentation of triaxial accelerometry signals for falls risk estimation},
  Author                   = {Redmond, S. J. and Scalzi, M. E. and Narayanan, M. R. and Lord, S. R. and Cerutti, S. and Lovell, N. H.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2010},
  Pages                    = {2234--2237},
  Volume                   = {1},

  Abstract                 = {Falls-related injuries in the elderly population represent one of the most significant contributors to rising health care expense in developed countries. In recent years, falls detection technologies have become more common. However, very few have adopted a preferable falls prevention strategy through unsupervised monitoring in the free-living environment. The basis of the monitoring described herein was a self-administered directed-routine (DR) comprising three separate tests measured by way of a waist-mounted triaxial accelerometer. Using features extracted from the manually segmented signals, a reasonable estimate of falls risk can be achieved. We describe here a series of algorithms for automatically segmenting these recordings, enabling the use of the DR assessment in the unsupervised and home environments. The accelerometry signals, from 68 subjects performing the DR, were manually annotated by an observer. Using the proposed signal segmentation routines, an good agreement was observed between the manually annotated markers and the automatically estimated values. However, a decrease in the correlation with falls risk to 0.73 was observed using the automatic segmentation, compared to 0.81 when using markers manually placed by an observer.},
  Keywords                 = {postural detection, motion segmentation},
  Review                   = {- Want to automatically segment accelerometer signals to detect falls.
- this paper reads like a KIN paper...
- uses distance minimization},
  Timestamp                = {2011.01.26}
}

@InBook{Reynolds2009,
  Title                    = {Encyclopedia of Biometrics},
  Author                   = {Reynolds, Douglas},
  Chapter                  = {Gaussian mixture models},
  Pages                    = {659--663},
  Publisher                = {Springer},
  Year                     = {2009},

  Timestamp                = {2014.03.14}
}

@InProceedings{Ricci2013,
  author    = {Ricci, L. and Formica, D. and Tamilia, E. and Taffoni, F. and Sparaci, L. and Capirci, O. and Guglielmelli, E.},
  title     = {An Experimental Protocol for the Definition of Upper Limb Anatomical Frames on Children Using Magneto--inertial Sensors},
  booktitle = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  year      = {2013},
  abstract  = {Motion capture based on magnetoinertial sensors is a technology enabling data collection in unstructured enviroments, allowing “out of the lab” motion analysis. This technology is a good candidate for motion analysis of children thanks to the reduced weight and size as well as the use of wireless communication that improved its wearability and reduced its obtrusivity. A key issue in the application of such technology for motion analysis is its calibration, i.e. a process that allows mapping orientation information from sensor to a physiological reference frame. To date, even if there are several calibration procedures available for adults, no specific calibration procedures have been developed for children. This work addresses this specific issue presenting a calibration procedure for motion capture of thorax and upper limbs on healthy children. Reported results suggest comparable performance with similar studies on adults and emphasize some critical issues, opening the way to further improvements.},
  keywords  = {EMBC2013},
  review    = {Testing calibration technique on 9DOF sensors. Sensors strapped on the thorax, upper arm and forearm. 3 DOF assumed for all joints. Orientation information wrt to earth is provided by the manufacturer's EKF. The patient does 3 reps of 6 upper body/arm exercises. The data was Butterworth filtered, then segmented (based on velocity thresholds)...then apparently resegmented by k-means (...what?)

Not really sure what they're trying to do here...

Ricci \etal \cite{Ricci2013} tests a 9-DOF IMU sensor calibration, with the sensors strapped on the thorax, upper arm and forearm. 3-DOFs were assumed on all joints. Orientation information with respect to the global frame is provided by the manufacturer's extended Kalman filter (EKF) system. 3 repetitions of 6 different upper body exercises were performed. The data was filtered, then segmented by thresholding on the angular velocity. Identification was performed by \emph{k}-means clustering. The system was tested on 4 healthy children and 4 healthy adults. Each participant was asked to perform a initiation task. No segmentation accuracy was reported.

Ricci \etal \cite{Ricci2013} assess the quality of IMU vendor-provided calibration data, and collect the movement data of several healthy children and adults performing 3 repetitions of 6 different exercises. Segmentation was performed when the angular acceleration is close to zero, to separate flexion movements from extension movements.},
  timestamp = {2013.07.30},
}

@InProceedings{Rigoberto2013,
  Title                    = {Analysis of subtle movements related to neurodegenerative diseases using wearable inertial sensors: A study in healthy subjects},
  Author                   = {Rigoberto, Martinez-Mendez and Otniel, Portillo Rodriguez and Juan-Carlos, Avila-Vilchis and Daniel, Lorias-Espinoza and Arturo, Minor-Martinez},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},
  Pages                    = {6119-6122},

  Abstract                 = {Evaluation of movement disorders is a useful tool for the diagnostic and monitoring of diseases related with damage of the motor control systems, such as Parkinson's disease. The evaluation of well characterized movement disorders has been proposed using different techniques each one with their advantages and limitations. This document propose the use a system based on inertial sensors and wireless technology for the measurement and evaluation of three of the most common movement disorders related with Parkinson's disease. Measurement of Anticipatory Postural Adjustments (APAs), Postural Sway and hand's tremor were carried out using inertial sensors modules (IMU). Results obtained from measurements in elderly and young subjects are presented, as well as the set up and parameters suggested for quantitative analysis.},
  Doi                      = {10.1109/EMBC.2013.6610949},
  ISSN                     = {1557-170X},
  Keywords                 = {APAs;Hands tremor;inertial sensors;sway},
  Review                   = {Using IMUs to determine hand tremor, postural sway and postural adjustments. Want to see if there are patterns that can be recognized to separate people suffering from Parkinson's and healthy subjects. 27 healthy subjects (incl 16 elderly) were collected. They compared the data collected by looking at frequency graphs and power spectrums.},
  Timestamp                = {2013.07.30}
}

@Article{Riley1990,
  Title                    = {Modelling of the biomechanics of posture and balance},
  Author                   = {Riley, P. O. and Mann, R. W. and Hodge, W. A.},
  Journal                  = {Biomechanics},
  Year                     = {1990},
  Number                   = {5},
  Pages                    = {503 - 506},
  Volume                   = {23},

  Abstract                 = {A technique for studying the relationship of posture to balance has been developed. To investigate this relationship quantitatively, the human body was treated as consisting of 11 rigid body segments, each with six degrees of freedom. A bilateral Selspot data acquisition system provides position and orientation kinematic data for estimation of the trajectories of the individual body segment centers of gravity. From these, the whole body center of gravity is estimated and compared to concurrent force plate center of force data. Center of gravity and center of force excursions agree where dynamics are not significant. The technique may be employed to study quiet stance, response to postural disturbances, or the initiation and coordination of complex movements such as gait.},
  Doi                      = {DOI: 10.1016/0021-9290(90)90306-N},
  ISSN                     = {0021-9290},
  Keywords                 = {Biomechanics, kinesiology},
  Timestamp                = {2011.06.07},
  Url                      = {http://www.sciencedirect.com/science/article/pii/002192909090306N}
}

@Article{Roaas1982,
  Title                    = {Normal Range of Motion of the Hip, Knee and Ankle Joints in Male Subjects, 30–40 Years of Age},
  Author                   = {Roaas, Asbjørn and Andersson, Gunnar B. J.},
  Journal                  = {Acta Orthopaedica},
  Year                     = {1982},
  Number                   = {2},
  Pages                    = {205--208},
  Volume                   = {53},

  Doi                      = {10.3109/17453678208992202},
  Eprint                   = {http://informahealthcare.com/doi/pdf/10.3109/17453678208992202},
  Timestamp                = {2012.04.27},
  Url                      = {http://informahealthcare.com/doi/abs/10.3109/17453678208992202}
}

@Article{Roach1991,
  Title                    = {Normal Hip and Knee Active Range of Motion: The Relationship to Age},
  Author                   = {Roach, K. E. and Miles, T. P.},
  Journal                  = {Physical Therapy},
  Year                     = {1991},
  Pages                    = {656--665},
  Volume                   = {71},

  Abstract                 = {Abnormal joint mobility is an important factor in movement dysfunction and physical disability. Because the decision to treat impaired joint mobility in an older individual may be influenced by assumptions concerning normal range of motion (ROM) at older ages, it is important to establish population-based normative values for hip and knee ROM by age, race, and sex. This study used data from the first National Health and Nutrition Examination Survey (NHANES 1), which involved a national probability sample of persons drawn from the civilian noninstitutionalized population of the United States. Goniometric measurements of hip and knee active range of motion (AROM) were obtained from a subset of the sample consisting of 1,892 subjects. This analysis was limited to the 1,313 white and 370 black subjects. Univariate statistics, weighted by the probability of selection into the sample, were calculated for 12 sex-race-age-group–specific categories. These normal AROM values for the hip and knee calculated from this population-based sample were found to differ from estimates found in textbooks by as much as 18 degrees. With one exception, normal values for all motions were lower in the oldest age group than in the youngest age group. The differences in mean AROM were generally small, ranging from 3 to 5 degrees. Only in the case of hip extension did the difference in mean AROM between the youngest and the oldest age groups constitute a decline of more than 20% of the arc of motion. With the possible exception of hip extension, this study supports the conclusion that, at least to age 74 years, any substantial loss of joint mobility should be viewed as abnormal and not attributable to aging and therefore should be treated much as it would be in a younger individual.},
  Timestamp                = {2012.04.27}
}

@Article{Robert2013,
  Title                    = {Estimation of external contact loads using an inverse dynamics and optimization approach: General method and application to sit-to-stand maneuvers },
  Author                   = {T. Robert and J. Causse and G. Monnier},
  Journal                  = {Journal of Biomechanics },
  Year                     = {2013},
  Number                   = {13},
  Pages                    = {2220 - 2227},
  Volume                   = {46},

  Abstract                 = {Abstract This paper presents a general method to estimate unmeasured external contact loads (ECLs) acting on a system whose kinematics and inertial properties are known. This method is dedicated to underdetermined problems, e.g. when the system has two or more unmeasured external contact wrenches. It is based on inverse dynamics and a quadratic optimization, and is therefore relatively simple, computationally cost effective and robust. Net joint loads (NJLs) are included as variables of the problem, and thus could be estimated in the same procedure as the \{ECL\} and be used within the cost function. The proposed method is tested on human sit-to-stand maneuvers performed holding a handle with one hand, i.e. asymmetrical movements with multiples external contacts. Three sets of measured and unmeasured contact load components and three cost functions are considered and simulated results are compared to experimental data. For the population and movement studied, better results are obtained for a least-square sharing between actuated degrees-of-freedom of the relative motor torques (motor torques normalized by the maximal torque production capacity). Moreover, the number of unknown \{ECL\} components does not significantly influence the results. In particular, measuring only the vertical force under the seat lead to a relatively correct estimation of the \{ECL\} and NJT: not only the values of R % were small (about 10% for the feet \{ECL\} and 20% for the NJT), but the influence of an experimental parameters (the Seat Height) was also correctly predicted. },
  Doi                      = {10.1016/j.jbiomech.2013.06.037},
  ISSN                     = {0021-9290},
  Keywords                 = {Inverse dynamics},
  Owner                    = {jf2lin},
  Timestamp                = {2016.02.11}
}

@Book{Robertson2014_Biomech,
  Title                    = {Research Methods in Biomechanics},
  Author                   = {Robertson, D. G. E. and Caldwell, G. E. and Hamill, J. and Kamen, G. and Whittlesey, S. N.},
  Publisher                = {Human Kinetics},
  Year                     = {2014},

  Owner                    = {jf2lin},
  Review                   = {page 294ish has a section on movement variability},
  Timestamp                = {2015.07.14}
}

@Article{Roetenberg2007b,
  author    = {Roetenberg, D. and Baten, C. T. M. and Veltink, P. H.},
  title     = {Estimating Body Segment Orientation by Applying Inertial and Magnetic Sensing Near Ferromagnetic Materials},
  journal   = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  year      = {2007},
  volume    = {15},
  pages     = {469--472},
  abstract  = {Inertial and magnetic sensors are very suitable for ambulatory monitoring of human posture and movements. However, ferromagnetic materials near the sensor disturb the local magnetic field and, therefore, the orientation estimation. A Kalman-based fusion algorithm was used to obtain dynamic orientations and to minimize the effect of magnetic disturbances. 

This paper compares the orientation output of the sensor fusion using three-dimensional inertial and magnetic sensors against a laboratory bound opto-kinetic system (VICON) in a simulated work environment.


With the tested methods, the difference between the optical reference system and the output of the algorithm was 2.6 root mean square (RMS) when no metal was near the sensor module. Near a large metal object instant errors up to 50 degrees were measured when no compensation was applied. Using a magnetic Disturbance model, the error reduced significantly to3.6 rms.},
  groups    = {EMBC2013},
  keywords  = {Kalman-based fusion algorithm;Vicon;ambulatory monitoring;body segment orientation estimation;ferromagnetic materials;human movements;human posture;inertial sensor;laboratory bound opto-kinetic system;magnetic disturbances;magnetic sensor;sensor fusion;biomechanics;ferromagnetic materials;magnetic sensors;medical signal processing;motion measurement;sensor fusion;Acceleration;Algorithms;Artifacts;Computer Simulation;Humans;Imaging, Three-Dimensional;Joints;Magnetics;Models, Biological;Reproducibility of Results;Sensitivity and Specificity; postural detection},
  review    = {They compared a MAG (magnet, accel, gyro) + Kalman system to get absolute position, and tested the effects of having a magnet near it. The accuracy is measured against a VICON system. 

Without the magnet, they have accuracy up to 2.6 degrees. With a magnet, 50 degree error was noted, but reduced to 3.6 degrees with a good Kalman model.},
  timestamp = {2010.01.18},
}

@Article{Roetenberg2005,
  Title                    = {Compensation of magnetic disturbances improves inertial and magnetic sensing of human body segment orientation},
  Author                   = {Roetenberg, D. and Luinge, H.J. and Baten, C.T.M. and Veltink, P.H.},
  Journal                  = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  Year                     = {2005},
  Number                   = {3},
  Pages                    = {395--405},
  Volume                   = {13},

  Abstract                 = {This paper describes a complementary Kalman filter design to estimate orientation of human body segments by fusing gyroscope, accelerometer, and magnetometer signals from miniature sensors. Ferromagnetic materials or other magnetic fields near the sensor module disturb the local earth magnetic field and, therefore, the orientation estimation, which impedes many (ambulatory) applications. In the filter, the gyroscope bias error, orientation error, and magnetic disturbance error are estimated. The filter was tested under quasi-static and dynamic conditions with ferromagnetic materials close to the sensor module. The quasi-static experiments implied static positions and rotations around the three axes. In the dynamic experiments, three-dimensional rotations were performed near a metal tool case. The orientation estimated by the filter was compared with the orientation obtained with an optical reference system Vicon. Results show accurate and drift-free orientation estimates. The compensation results in a significant difference (p<0.01) between the orientation estimates with compensation of magnetic disturbances in comparison to no compensation or only gyroscopes. The average static error was 1.4 deg; (standard deviation 0.4) in the magnetically disturbed experiments. The dynamic error was 2.6 deg; root means square.},
  Doi                      = {10.1109/TNSRE.2005.847353},
  ISSN                     = {1534-4320},
  Keywords                 = {accelerometer;complementary Kalman filter design;error estimation;ferromagnetic materials;gyroscope;human body segment orientation;inertial sensing;magnetic disturbances;magnetic sensing;magnetometer;miniature sensors;optical reference system Vicon;Kalman filters;accelerometers;biomagnetism;biomechanics;error analysis;ferromagnetic materials;gyroscopes;magnetic sensors;magnetometers;microsensors;Acceleration;Algorithms;Artifacts;Computer Simulation;Diagnosis, Computer-Assisted;Humans;Joints;Magnetics;Models, Biological;Movement;Posture;Range of Motion, Articular;},
  Timestamp                = {2012.09.10}
}

@TechReport{Roetenberg2009,
  Title                    = {Xsens {MVN}: Full 6DOF Human Motion Tracking Using Miniature Inertial Sensors},
  Author                   = {Roetenberg, D. and Luinge, H. and Slycke, P. J.},
  Institution              = {Xsens Technologies},
  Year                     = {2009},

  Timestamp                = {2012.09.10},
  Url                      = {www.xsens.com/images/stories/PDF/MVN_white_paper.pdf}
}

@Article{Roetenberg2007a,
  Title                    = {Ambulatory Position and Orientation Tracking Fusing Magnetic and Inertial Sensing},
  Author                   = {Roetenberg, D. and Slycke, P. J. and Veltink, P. H.},
  Journal                  = {IEEE Transactions on Biomedical Engineering},
  Year                     = {2007},
  Pages                    = {883--90},
  Volume                   = {54},
  Abstract                 = {This paper presents the design and testing of a portable magnetic system combined with miniature inertial sensors for ambulatory 6 degrees of freedom ( DOF) human motion tracking. The magnetic system consists of three orthogonal coils, the source, fixed to the body and 3-D magnetic sensors, fixed to remote body segments, which measure the fields generated by the source. Based on the measured signals, a processor calculates the relative positions and orientations between source and sensor. Magnetic actuation requires a substantial amount of energy which limits the update rate with a set of batteries. Moreover, the magnetic field can easily be disturbed by ferromagnetic materials or other sources. Inertial sensors can be sampled at high rates, require only little energy and do not suffer from magnetic interferences. However, accelerometers and gyroscopes can only measure changes in position and orientation and suffer from integration drift. By combing measurements from both systems in a complementary Kalman filter structure, an optimal solution for position and orientation estimates is obtained. The magnetic system provides 6 DOF measurements at a relatively low update rate while the inertial sensors track the changes position and orientation in between the magnetic updates. The implemented system is tested against a lab-bound camera tracking system for several functional body movements. The accuracy was about 5 mm for position and 3 degrees for orientation measurements. Errors were higher during movements with high velocities due to relative movement between source and sensor within one cycle of magnetic actuation},
  Doi                      = {10.1109/TBME.2006.889184},
  ISSN                     = {0018-9294},
  Keywords                 = {3-D magnetic sensors;Kalman filter;accelerometers;ambulatory position tracking;gyroscopes;human motion tracking;inertial sensing;lab-bound camera tracking system;magnetic sensing;miniature inertial sensors;orientation tracking;portable magnetic system;Kalman filters;accelerometers;biomagnetism;biomechanics;biomedical equipment;biomedical measurement;electromagnetic actuators;gyroscopes;magnetic sensors;medical signal processing; postural detection},
  Review                   = {Uses MAG. Kalmans them together.



Roetenberg2007
Cited by: 30
Motion type: Arm motions
Recovery methodology: Primarily a magnetic tracking system. A magnetic actuator (emits magnetic fields), sensor and processor unit (calculates distance and orientation to the sensor). Can report this as a rotational matrix from the actuator to sensor. Also uses gyroscope to get angular velocity (and angle, after integration), allowing them to remove gravity. Integrate this to get position. The magnetic data updates slowly (1.6 Hz) compared to the IMU, so typically use dead reckoning to obtain angle and position, and corrected using the magnet information. They did not report how they got 1) inter-joint angle information, 2) initial position
Verification technique: Mocap
Subject demographics: 
Error reported:2.6 degree RMS},
  Timestamp                = {2011.03.01}
}

@Article{Rohrer2002,
  Title                    = {Movement Smoothness Changes during Stroke Recovery},
  Author                   = {Rohrer, Brandon and Fasoli, Susan and Krebs, Hermano Igo and Hughes, Richard and Volpe, Bruce and Frontera, Walter R. and Stein, Joel and Hogan, Neville},
  Journal                  = {The Journal of Neuroscience},
  Year                     = {2002},
  Number                   = {18},
  Pages                    = {8297-8304},
  Volume                   = {22},

  Abstract                 = {Smoothness is characteristic of coordinated human movements, and stroke patients' movements seem to grow more smooth with recovery. We used a robotic therapy device to analyze five different measures of movement smoothness in the hemiparetic arm of 31 patients recovering from stroke. Four of the five metrics showed general increases in smoothness for the entire patient population. However, according to the fifth metric, the movements of patients with recent stroke grew less smooth over the course of therapy. This pattern was reproduced in a computer simulation of recovery based on submovement blending, suggesting that progressive blending of submovements underlies stroke recovery.},
  Eprint                   = {http://www.jneurosci.org/content/22/18/8297.full.pdf+html},
  Timestamp                = {2013.03.02},
  Url                      = {http://www.jneurosci.org/content/22/18/8297.abstract}
}

@InProceedings{Rossi2012,
  Title                    = {Gait segmentation using bipedal foot pressure patterns},
  Author                   = {S. M. M. De Rossi and S. Crea and M. Donati and P. Rebersek and D. Novak and N. Vitiello and T. Lenzi and J. Podobnik and M. Munih and M. C. Carrozza},
  Booktitle                = {Proceedings of IEEE RAS/EMBS International Conference on Biomedical Robotics and Biomechatronics},
  Year                     = {2012},
  Pages                    = {361--366},

  Abstract                 = {We present an automated gait segmentation method based on the analysis of foot plantar pressure patterns elaborated from two wireless pressure-sensitive insoles. The 64 pressure signals recorded by each device are elaborated to extract 10 feature variables which are used to segment the gait cycle into 6 sub-phases following a simplified version of Perry's gait model. The method is based on a Hidden Markov Model with a minimum phase length constraint and a univariate Gaussian emission model, which is decoded using a classic Viterbi algorithm. The method is tested on a pool of 5 healthy young subjects walking at two different speeds, through a leave-one-out cross-subject validation. The results show that the method is highly effective, yielding to an average performance of about 95% of correct phase classification, and 85 to 90% of phase transitions detected inside an acceptance window of 50ms.},
  Doi                      = {10.1109/BioRob.2012.6290278},
  ISSN                     = {2155-1774},
  Keywords                 = {Gaussian processes;gait analysis;hidden Markov models;learning (artificial intelligence);pressure sensors;signal processing;Perrygait model;Viterbi algorithm;automated gait segmentation method;bipedal foot pressure patterns;foot plantar pressure patterns;gait segmentation;hidden Markov model;machine-learning;minimum phase length constraint;pressure signals;univariate Gaussian emission model;wireless pressure-sensitive insoles;Foot;Footwear;Force;Hidden Markov models;Legged locomotion;Sensors;Viterbi algorithm},
  Timestamp                = {2016.03.01}
}

@InProceedings{Rossignol1998,
  Title                    = {Feature extraction and temporal segmentation of acoustic signals},
  Author                   = {Rossignol, S. and Rodet, X. and Soumagne, J. and Collette, J. and Depalle, P.},
  Booktitle                = {Proc. ICMC},
  Year                     = {1998},
  Organization             = {Citeseer},
  Pages                    = {199--202},
  Volume                   = {98},

  Review                   = {- want to characterize sound
- proposes various different features to segment on

Rossignol \etal \cite{Rossignol1998} wants to characterize sounds, and does so by three layers of segmentation. The first layer separates between speech, singing voice and instrumental components. The second layer separates the vibrato from the source signal. The last layer segments into notes or phones. The first layer is done by looking at the mean and variance of STFT, the spectral centroid and the zero-crossing rate (ZCR) between two successive sound frames. Classification is done with pre-trained GMM, \emph{k}-NN and NN classifiers, with the HMM showing the best results if only STFT features are used, and \emph{k}-NN showing the best results if all 6 features are used. The vibrato can be segmented out by a series of frequency-based thresholding. Notes and phone segmenation is conducted by looking at frequency, energy and STFT features.

Rossignol \etal \cite{Rossignol1998} characterize sounds into speech, singing voice and instrumental components. This is done by looking at the mean and variance of STFT, the spectral centroid and the ZCR between two successive sound frames. Classification is done with pre-trained GMM, \emph{k}-NN and NN classifiers, with \emph{k}-NN showing the best result. $Ver_{AllPoints}$ verification was performed on 10 minutes of labelled speech data and 10 minutes of labelled music data. $Ver_{Class}$ for the GMM, \emph{k}-NN and NN classifiers were 23\%, 6\% and 9\%, respectively.},
  Timestamp                = {2013.08.29}
}

@InProceedings{Roussel1998,
  Title                    = {Generation of energy optimal complete gait cycles for biped robots},
  Author                   = {L. Roussel and C. Canudas-De-Wit and A. Goswami},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {1998},
  Pages                    = {2036--2041},
  Volume                   = {3},

  Doi                      = {10.1109/ROBOT.1998.680615},
  ISSN                     = {1050-4729},
  Keywords                 = {legged locomotion;optimal control;robot dynamics;biped robots;energy optimal complete gait cycles;piecewise constant inputs;unconstrained optimal trajectories;Control systems;Equations;Foot;Frequency;Ground support;Humans;Legged locomotion;Mobile robots;Path planning;Robotics and automation},
  Timestamp                = {2017.03.04}
}

@Article{Roweis2000,
  Title                    = {Nonlinear dimensionality reduction by locally linear embedding},
  Author                   = {Roweis, S. T. and Saul, L. K.},
  Journal                  = {Science},
  Year                     = {2000},
  Pages                    = {2323 -- 2326},
  Volume                   = {290},

  Timestamp                = {2011.10.06}
}

@Article{Russell2011,
  Title                    = {Internet-Based Outpatient Telerehabilitation for Patients Following Total Knee Arthroplasty: A Randomized Controlled Trial},
  Author                   = {Russell, T. G. and Buttrum, P. and Wootton, R. and Jull, G. A.},
  Journal                  = {Bone and Joint Surgery},
  Year                     = {2011},
  Pages                    = {113--120},
  Volume                   = {93},

  Abstract                 = {Background: 

Total knee arthroplasty is an effective means for relieving the symptoms associated with degenerative arthritis of the knee. Rehabilitation is a necessary adjunct to surgery and is important in regaining optimum function. Access to high-quality rehabilitation services is not always possible, especially for those who live in rural or remote areas. The aim of this study was to evaluate the equivalence of an Internet-based telerehabilitation program compared with conventional outpatient physical therapy for patients who have had a total knee arthroplasty.
Methods: 

This investigation was a single-blinded, prospective, randomized, controlled noninferiority trial. Sixty-five participants were randomized to receive a six-week program of outpatient physical therapy either in the conventional manner or by means of an Internet-based telerehabilitation program. The primary outcome measure was the Western Ontario and McMaster Universities Osteoarthritis Index (WOMAC) measured at baseline and six weeks by a blinded independent assessor. Secondary outcomes included the Patient-Specific Functional Scale, the timed up-and-go test, pain intensity, knee flexion and extension, quadriceps muscle strength, limb girth measurements, and an assessment of gait. Noninferiority was assessed through the comparison of group differences with a noninferiority margin and with linear mixed model statistics.
Results: 

Baseline characteristics between groups were similar, and all participants had significant improvement on all outcome measures with the intervention (p < 0.01 for all). After the six-week intervention, participants in the telerehabilitation group achieved outcomes comparable to those of the conventional rehabilitation group with regard to flexion and extension range of motion, muscle strength, limb girth, pain, timed up-and-go test, quality of life, and clinical gait and WOMAC scores. Better outcomes for the Patient-Specific Functional Scale and the stiffness subscale of the WOMAC were found in the telerehabilitation group (p < 0.05). The telerehabilitation intervention was well received by participants, who reported a high level of satisfaction with this novel technology.
Conclusions: 

The outcomes achieved via telerehabilitation at six weeks following total knee arthroplasty were comparable with those after conventional rehabilitation.
Level of Evidence: 

Therapeutic Level I. See Instructions to Authors for a complete description of levels of evidence.},
  Timestamp                = {2011.12.29}
}

@InProceedings{Saab1994,
  Title                    = {Automatic alignment and calibration of an inertial navigation system},
  Author                   = {Saab, S.S. and Gunnarsson, K.T.},
  Booktitle                = {Proceedings of the IEEE Position Location and Navigation Symposium},
  Year                     = {1994},
  Month                    = {apr},
  Pages                    = {845 -852},

  Abstract                 = {In this paper we derive a simple six degree of freedom navigator, Earth-surface navigator, for terranean vehicle application, using low grade gyros. The calibration and alignment of the navigator are investigated when the system is at rest. Based on the observability of the error model when the system is at rest, a state transformation is presented. This transformation decouples the observable modes, which are based on physical insight from the unobservable modes. An example is given to illustrate the performance of a Kalman filter for calibration and alignment},
  Doi                      = {10.1109/PLANS.1994.303400},
  Keywords                 = {Earth-surface navigator;Kalman filter;automatic alignment;automatic calibration;calibration;error model observability;gyros;inertial navigation system;observable modes;performance;terranean vehicle application;unobservable modes;Kalman filters;calibration;gyroscopes;inertial navigation;},
  Timestamp                = {2011.07.19}
}

@InProceedings{Saerbeck2010,
  Title                    = {Perception of affect elicited by robot motion},
  Author                   = {Saerbeck, M. and Bartneck, C.},
  Booktitle                = {Proceeding of the ACM/IEEE International Conference on Human-Robot Interaction},
  Year                     = {2010},

  Address                  = {New York, NY, USA},
  Pages                    = {53--60},
  Publisher                = {ACM},
  Series                   = {HRI '10},

  Acmid                    = {1734473},
  Doi                      = {http://doi.acm.org/10.1145/1734454.1734473},
  ISBN                     = {978-1-4244-4893-7},
  Keywords                 = {affective communication, expressive robotic behavior, nonverbal communication, lab reading (Ali)},
  Location                 = {Osaka, Japan},
  Numpages                 = {8},
  Timestamp                = {2011.05.19},
  Url                      = {http://doi.acm.org/10.1145/1734454.1734473}
}

@InProceedings{Sakaguchi1996,
  Title                    = {Human motion capture by integrating gyroscopes and accelerometers },
  Author                   = {Sakaguchi, T. and Kanamori, T. and Katayose, H. and Sato, K. and Inokuchi, S.},
  Booktitle                = {Proceedings of the IEEE/SICE/RSJ International Conference on Multisensor Fusion and Integration for Intelligent Systems},
  Year                     = {1996},
  Month                    = dec,
  Pages                    = {470 -475},

  Abstract                 = {This paper describes a motion capturing system for human arm motion in real time; directly, simply and precisely by integrating two types of sensor; gyroscopes and accelerometers. A new sensor fusion technique is proposed which enlarges the merits of each sensor and compensates for their deficiencies. Its potential precision has been verified by experiment and simulation},
  Doi                      = {10.1109/MFI.1996.572219},
  Keywords                 = {accelerometers;arm motion;gyroscopes;human motion capture;sensor fusion technique;accelerometers;biomechanics;gyroscopes;sensor fusion; postural detection},
  Review                   = {Numerically combined (accel from accel, ang velo from gyro) to get position
Not the greatest...but apparently feels that the full body is "easy" -_-},
  Timestamp                = {2011.03.01}
}

@InProceedings{Sakaki1999,
  Title                    = {TEM: Therapeutic Exercise Machine for Hip and Knee Joints of Spastic Patients},
  Author                   = {Sakaki, T. and Okada, S. and Okajima, Y. and Tanaka, N. and Kimura, A. and Uchida, S. and Taki, M. and Tomita, Y. and Horiuchi, T.},
  Booktitle                = {Proceedings of the International Conference on Rehabilitation Robotics},
  Year                     = {1999},

  Keywords                 = {Rehabilitation robotics},
  Timestamp                = {2011.12.28}
}

@Article{Sakoe1978,
  Title                    = {Dynamic programming algorithm optimization for spoken word recognition},
  Author                   = {Sakoe, H. and Chiba, S.},
  Journal                  = {IEEE Transactions on Speech and Signal Processing},
  Year                     = {1978},
  Pages                    = {43--49},
  Volume                   = {26},

  Abstract                 = {This paper reports on an optimum dynamic progxamming (DP) based time-normalization algorithm for spoken word recognition. First, a general principle of time-normalization is given using time-warping function. Then, two time-normalized distance definitions, called symmetric and asymmetric forms, are derived from the principle. These two forms are compared with each other through theoretical discussions and experimental studies. The symmetric form algorithm superiority is established. A new technique, called slope constraint, is successfully introduced, in which the warping function slope is restricted so as to improve discrimination between words in different categories. The effective slope constraint characteristic is qualitatively analyzed, and the optimum slope constraint condition is determined through experiments. The optimized algorithm is then extensively subjected to experimental comparison with various DP-algorithms, previously applied to spoken word recognition by different research groups. The experiment shows that the present algorithm gives no more than about two-thirds errors, even compared to the best conventional algorithm.},
  ISSN                     = {0096-3518},
  Keywords                 = {Dynamic time warping (dtw)},
  Timestamp                = {2011.03.10}
}

@InProceedings{Sakurai2005,
  Title                    = {FTW: fast similarity search under the time warping distance},
  Author                   = {Sakurai, Y. and Yoshikawa, M. and Faloutsos, C.},
  Booktitle                = {Proceedings of the 24th ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems},
  Year                     = {2005},
  Pages                    = {326--337},

  Abstract                 = {Time-series data naturally arise in countless domains, such as meteorology, astrophysics, geology, multimedia, and economics. Similarity search is very popular, and DTW (Dynamic Time Warping) is one of the two prevailing distance measures. Although DTW incurs a heavy computation cost, it provides scaling along the time axis. In this paper, we propose FTW (Fast search method for dynamic Time Warping), which guarantees no false dismissals in similarity query processing. FTW efficiently prunes a significant number of the search cost. Experiments on real and synthetic sequence data sets reveals that FTW is significantly faster than the best existing method, up to 222 times.},
  Acmid                    = {1065210},
  ISBN                     = {1-59593-062-0},
  Keywords                 = {dynamic time warping, segmentation},
  Location                 = {Baltimore, Maryland},
  Numpages                 = {12},
  Timestamp                = {2011.04.01}
}

@Article{Salarian2010,
  Title                    = {iTUG, a Sensitive and Reliable Measure of Mobility},
  Author                   = {Salarian, A. and Horak, F. B. and Zampieri, C. and Carlson-Kuhta, P. and Nutt, J. G. and Aminian, K.},
  Journal                  = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  Year                     = {2010},
  Pages                    = {303--310},
  Volume                   = {18},

  Abstract                 = {Timed Up and Go (TUG) test is a widely used clinical paradigm to evaluate balance and mobility. Although TUG includes several complex subcomponents, namely: sit-to-stand, gait, 180$^{circ}$ turn, and turn-to-sit; the only outcome is the total time to perform the task. We have proposed an instrumented TUG, called iTUG, using portable inertial sensors to improve TUG in several ways: automatic detection and separation of subcomponents, detailed analysis of each one of them and a higher sensitivity than TUG. Twelve subjects in early stages of Parkinson's disease (PD) and 12 age matched control subjects were enrolled. Stopwatch measurements did not show a significant difference between the two groups. The iTUG, however, showed a significant difference in cadence between early PD and control subjects (111.1 $pm$ 6.2 versus 120.4 $pm$ 7.6 step/min, $p #x0003C;0.006$ ) as well as in angular velocity of arm-swing (123 $pm$ 32.0 versus $174.0pm 50.4^{circ}/{rm s}$, $p #x0003C;0.005$), turning duration (2.18 $pm$ 0.43 versus 1.79 $pm$ 0.27 s, $p #x0003C;0.023$ ), and time to perform turn-to-sits (2.96 $pm$ 0.68 versus 2.40 $pm$ 0.33 s, $p #x0003C;0.023$). By repeating the tests for a second time, the test #x2013;retest reliability of iTUG was also evaluated. Among the subcomponents of iTUG, gait, turning, and turn-to-sit were the most reliable and sit-to-stand was the least reliable.},
  ISSN                     = {1534-4320},
  Review                   = {TUG = Timed Up and Go, is a test for balance and mobility. Get a subject to stand up from a chair, walk 3 meters, turn around, return to the chair, and sit down. This TUG test is widespread used in the clinic (and has been proven to be clinically useful), but it is focused mainly on time-based assessments, and doesn't measure other possible deficiency of movements, so there is a need to break down the analysis to subcomponents of the TUG exercise. The subjective nature of stopwatch start/stop also makes this more difficult to use. This iTUG thingy is designed to address these issues.

Record motion with inertial sensors. Looked at signals directly, there was no need to determine position of limbs. They just wanted a way to measure how long it took to walk, to turn and to return to chair, and used the IMUs to make when event transitions occured. This is more of a segmentation problem then kinematics.},
  Timestamp                = {2010.07.12}
}

@Article{Salter1980,
  Title                    = {The biological effect of continuous passive motion on the healing of full-thickness defects in articular cartilage. An experimental investigation in the rabbit.},
  Author                   = {Salter, R. B. and Simmonds, D. F. and Malcolm, B. W. and Rumble, E. J. and MacMichael, D. and Clements, N. D.},
  Journal                  = {The Journal of Bone and Joint Surgery. American Volume},
  Year                     = {1980},
  Pages                    = {1232--51},
  Volume                   = {62},

  Keywords                 = {Rehabilitation robotics, physiotherapy},
  Timestamp                = {2011.12.28}
}

@InProceedings{Samadani2014,
  Title                    = {Hand gesture recognition based on surface electromyography},
  Author                   = {Samadani, A. and Kuli\'{c}, D.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2014},
  Pages                    = {4196--9},

  Abstract                 = {Human hands are the most dexterous of human limbs and hand gestures play an important role in non-verbal communication. Underlying electromyograms associated with hand gestures provide a wealth of information based on which varying hand gestures can be recognized. This paper develops an inter-individual hand gesture recognition model based on Hidden Markov models that receives surface electromyography (sEMG) signals as inputs and predicts a corresponding hand gesture. The developed recognition model is tested with a dataset of 10 various hand gestures performed by 25 subjects in a leave-one-subject-out cross validation and an inter-individual recognition rate of 79% was achieved. The promising recognition rate demonstrates the efficacy of the proposed approach for discriminating between gesture-specific sEMG signals and could inform the design of sEMG-controlled prostheses and assistive devices.},
  Owner                    = {jf2lin},
  Timestamp                = {2015.05.21}
}

@Article{Sanger2000,
  Title                    = {Human Arm Movements Described by a Low-Dimensional Superposition of Principal Components},
  Author                   = {Sanger, T. D.},
  Journal                  = {Journal of Neuroscience},
  Year                     = {2000},
  Pages                    = {1066--1072},
  Volume                   = {20},

  Abstract                 = {A new method for analyzing kinematic patterns during smooth movements is proposed. Subjects are asked to move the end of a two-joint manipulandum to copy a smooth initial target path. On subsequent trials the target path is the subject's actual movement from the preceding trial. Using Principal Components Analysis, it is shown that the trajectories have very low dimension and that they converge toward a linear superposition of the first few principal components. We show similar results for handwriting on an electronic pen tablet. We hypothesize that the low dimensionality and convergence are attributable to combined properties of the internal controller and the musculoskeletal system. The low dimensionality may allow for efficient descriptions of a large class of arm movements.},
  Timestamp                = {2014.02.23}
}

@InCollection{Sankai2011,
  author      = {Sankai, Y.},
  title       = {HAL: Hybrid Assistive Limb Based on Cybernics},
  booktitle   = {Robotics Research},
  publisher   = {Springer Berlin/Heidelberg},
  year        = {2011},
  volume      = {66},
  series      = {Springer Tracts in Advanced Robotics},
  pages       = {25--34},
  isbn        = {978-3-642-14742-5},
  abstract    = {We aim to develop the Hybrid Assistive Lims (HAL) in order to enhance and upgrade the human capabilities based on the frontier science Cybernics . Cybernics is a new domain of interdisciplinary research centered on cybernetics, mechatronics, and informatics, and integrates neuroscience, robotics, systems engineering, information technology, “kansei” engineering, ergonomics, physiology, social science, law, ethics, management, economics etc. Robot Suit HAL is a cyborg type robot that can expand, augment and support physical capability. The robot suit HAL has two types of control systems such as “Cybernic Voluntary Control System” and “Cybernic Autonomous Control System”. The application fields of HAL are medical welfare, heavy work support and entertainment etc. In this paper, the outline of HAL and some of the important algorithms and recent challenges are described.},
  affiliation = {Global COE Cybernics, System and Information Engineering, University of Tsukuba, 1-1-1, Tennodai, Tsukuba, Ibaraki 305-8573, Japan},
  groups      = {EMBC2013},
  keyword     = {Engineering},
  timestamp   = {2012.11.12},
  url         = {http://dx.doi.org/10.1007/978-3-642-14743-2_3},
}

@Article{Sapankevych2009,
  Title                    = {Time Series Prediction Using Support Vector Machines: A Survey},
  Author                   = {Sapankevych, N. I. and Sankar, R.},
  Journal                  = {IEEE Computational Intelligence Magazine},
  Year                     = {2009},
  Number                   = {2},
  Pages                    = {24--38},
  Volume                   = {4},

  Abstract                 = {Time series prediction techniques have been used in many real-world applications such as financial market prediction, electric utility load forecasting , weather and environmental state prediction, and reliability forecasting. The underlying system models and time series data generating processes are generally complex for these applications and the models for these systems are usually not known a priori. Accurate and unbiased estimation of the time series data produced by these systems cannot always be achieved using well known linear techniques, and thus the estimation process requires more advanced time series prediction algorithms. This paper provides a survey of time series prediction applications using a novel machine learning approach: support vector machines (SVM). The underlying motivation for using SVMs is the ability of this methodology to accurately forecast time series data when the underlying system processes are typically nonlinear, non-stationary and not defined a-priori. SVMs have also been proven to outperform other non-linear techniques including neural-network based non-linear prediction techniques such as multi-layer perceptrons.The ultimate goal is to provide the reader with insight into the applications using SVM for time series prediction, to give a brief tutorial on SVMs for time series prediction, to outline some of the advantages and challenges in using SVMs for time series prediction, and to provide a source for the reader to locate books, technical journals, and other online SVM research resources.},
  Doi                      = {10.1109/MCI.2009.932254},
  ISSN                     = {1556-603X},
  Keywords                 = {multilayer perceptrons;support vector machines;time series;SVM;multilayer perceptrons;neural-network based nonlinear prediction techniques;support vector machines;time series prediction;Books;Control systems;Economic forecasting;Load forecasting;Medical control systems;Nonlinear control systems;Power industry;Support vector machines;USA Councils;Weather forecasting},
  Review                   = {svm survey paper},
  Timestamp                = {2014.10.24}
}

@Article{Sarkar2011,
  Title                    = {GPARS: a general-purpose activity recognition system},
  Author                   = {Sarkar, Jehad and Vinh, LaThe and Lee, Young-Koo and Lee, Sungyoung},
  Journal                  = {Applied Intelligence},
  Year                     = {2011},
  Number                   = {2},
  Pages                    = {242-259},
  Volume                   = {35},

  Doi                      = {10.1007/s10489-010-0217-4},
  ISSN                     = {0924-669X},
  Keywords                 = {Activity recognition; Simple and ubiquitous Sensors; Web mining using Google; Naive Bayes-based classifier; Hierarchical classifier; Smoothing},
  Language                 = {English},
  Publisher                = {Springer US},
  Timestamp                = {2014.12.21},
  Url                      = {http://dx.doi.org/10.1007/s10489-010-0217-4}
}

@InProceedings{Saunders2006,
  Title                    = {Teaching robots by moulding behavior and scaffolding the environment},
  Author                   = {Saunders, Joe and Nehaniv, Chrystopher L and Dautenhahn, Kerstin},
  Booktitle                = {Proceedings of the 1st ACM SIGCHI/SIGART conference on Human-robot interaction},
  Year                     = {2006},
  Organization             = {ACM},
  Pages                    = {118--125},

  Timestamp                = {2013.09.23}
}

@Article{Schaal2010,
  Title                    = {Learning Control in Robotics},
  Author                   = {Schaal, S. and Atkeson, C.},
  Journal                  = {IEEE Robotics Automation Magazine},
  Year                     = {2010},
  Number                   = {2},
  Pages                    = {20--29},
  Volume                   = {17},

  Abstract                 = {Recent trends in robot learning are to use trajectory-based optimal control techniques and reinforcement learning to scale complex robotic systems. On the one hand, increased computational power and multiprocessing, and on the other hand, probabilistic reinforcement learning methods and function approximation, have contributed to a steadily increasing interest in robot learning. Imitation learning has helped significantly to start learning with reasonable initial behavior. However, many applications are still restricted to rather lowdimensional domains and toy applications. Future work will have to demonstrate the continual and autonomous learning abilities, which were alluded to in the introduction.},
  Doi                      = {10.1109/MRA.2010.936957},
  ISSN                     = {1070-9932},
  Keywords                 = {autonomous learning;complex robotic systems;function approximation;imitation learning;reinforcement learning;robot learning;trajectory based optimal control techniques;function approximation;learning (artificial intelligence);optimal control;robots;},
  Review                   = {Robot learning is very important. We want to be able to teach robot things, no?

Given a state input U, the system X and observations Y...
- what if X and Y are not known?
 - function approximation, then fit a controller over the estimated model
 - known as 'model-based learning', 'indirect learning' or 'internal model learning'
 - or, model-free learning exist, for cases where there is an optimization criterion

Type of motor task is also important to look at
- regulator - keeping at some given set point
- tracking - following a trajectory
- one-shot - performing a certain action, then motor terminates
- periodic
- complex/composite

Learning type
- supervised learning
- reinforcement learning
- learning modularization
- feature representations
- a prior knowledge is handy in learning
 - imitation learning is popular approach

Basically, robot learning to find a appropriate control policy to accomplish a given movement task, and can be described in 3 dimensions: direct/indirect, learning method and task class.

Learning-based control is useful when analytical models are too complex, or if the model changes over time. The most common models used is kinematic/dynamic models, such as RNE or Lagrange formation. Sometimes, forward kinematics are used, but inverse kinematis/dynamics may be used too; difficult as inverse relationships could be a one-to-many map.

Several problems that they encounter:
- Non-linear functions -> can be approximated
- High dimensionality, scalingn -> HUGE PROBLEM
- A lot of data available (up to 1000 Hz)
- System needs to be robust
- Good feature extraction

Solutions
- IK
- Weighted regression
- Break down the high dimensionality problem into smaller problems and apply controllers for each of them
- Trajectory optimization - given a model, find some cost function. Minimize.},
  Timestamp                = {2010.07.12}
}

@Article{Schaal2003,
  Title                    = {Computational approaches to motor learning by imitation},
  Author                   = {Schaal, Stefan and Ijspeert, Auke and Billard, Aude},
  Journal                  = {Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences},
  Year                     = {2003},
  Number                   = {1431},
  Pages                    = {537--547},
  Volume                   = {358},

  Abstract                 = {Movement imitation requires a complex set of mechanisms that map an observed movement of a teacher onto one's own movement apparatus. Relevant problems include movement recognition, pose estimation, pose tracking, body correspondence, coordinate transformation from external to egocentric space, matching of observed against previously learned movement, resolution of redundant degrees–of–freedom that are unconstrained by the observation, suitable movement representations for imitation, modularization of motor control, etc. All of these topics by themselves are active research problems in computational and neurobiological sciences, such that their combination into a complete imitation system remains a daunting undertaking—indeed, one could argue that we need to understand the complete perception–action loop. As a strategy to untangle the complexity of imitation, this paper will examine imitation purely from a computational point of view, i.e. we will review statistical and mathematical approaches that have been suggested for tackling parts of the imitation problem, and discuss their merits, disadvantages and underlying principles. Given the focus on action recognition of other contributions in this special issue, this paper will primarily emphasize the motor side of imitation, assuming that a perceptual system has already identified important features of a demonstrated movement and created their corresponding spatial information. Based on the formalization of motor control in terms of control policies and their associated performance criteria, useful taxonomies of imitation learning can be generated that clarify different approaches and future research directions.},
  Doi                      = {10.1098/rstb.2002.1258},
  Eprint                   = {http://rstb.royalsocietypublishing.org/content/358/1431/537.full.pdf+html},
  Timestamp                = {2013.09.19},
  Url                      = {http://rstb.royalsocietypublishing.org/content/358/1431/537.abstract}
}

@InCollection{Schaal2005,
  Title                    = {Learning Movement Primitives},
  Author                   = {Schaal, Stefan and Peters, Jan and Nakanishi, Jun and Ijspeert, Auke},
  Booktitle                = {Robotics Research},
  Publisher                = {Springer Berlin Heidelberg},
  Year                     = {2005},
  Editor                   = {Dario, Paolo and Chatila, Raja},
  Pages                    = {561-572},
  Series                   = {Springer Tracts in Advanced Robotics},
  Volume                   = {15},

  Doi                      = {10.1007/11008941_60},
  ISBN                     = {978-3-540-23214-8},
  Timestamp                = {2013.09.19},
  Url                      = {http://dx.doi.org/10.1007/11008941_60}
}

@Article{Schaal2005_MotorControl,
  Title                    = {Computational motor control in humans and robots},
  Author                   = {Schaal, S and Schweighofer, N.},
  Journal                  = {Current Opinion in Neurobiology },
  Year                     = {2005},
  Pages                    = {675--682},
  Volume                   = {15},

  Abstract                 = {Computational models can provide useful guidance in the design of behavioral and neurophysiological experiments and in the interpretation of complex, high dimensional biological data. Because many problems faced by the primate brain in the control of movement have parallels in robotic motor control, models and algorithms from robotics research provide useful inspiration, baseline performance, and sometimes direct analogs for neuroscience. },
  Doi                      = {http://dx.doi.org/10.1016/j.conb.2005.10.009},
  ISSN                     = {0959-4388},
  Timestamp                = {2015.07.06}
}

@Article{Schabowsky2010,
  Title                    = {Development and pilot testing of HEXORR: Hand EXOskeleton Rehabilitation Robot},
  Author                   = {Schabowsky, C. and Godfrey, S. and Holley, R. and Lum, P.},
  Journal                  = {Journal of NeuroEngineering and Rehabilitation},
  Year                     = {2010},
  Number                   = {1},
  Pages                    = {36},
  Volume                   = {7},

  Abstract                 = {BACKGROUND:Following acute therapeutic interventions, the majority of stroke survivors are left with a poorly functioning hemiparetic hand. Rehabilitation robotics has shown promise in providing patients with intensive therapy leading to functional gains. Because of the hand's crucial role in performing activities of daily living, attention to hand therapy has recently increased.

METHODS:This paper introduces a newly developed Hand Exoskeleton Rehabilitation Robot (HEXORR). This device has been designed to provide full range of motion (ROM) for all of the hand's digits. The thumb actuator allows for variable thumb plane of motion to incorporate different degrees of extension/flexion and abduction/adduction. Compensation algorithms have been developed to improve the exoskeleton's backdrivability by counteracting gravity, stiction and kinetic friction. We have also designed a force assistance mode that provides extension assistance based on each individual's needs. A pilot study was conducted on 9 unimpaired and 5 chronic stroke subjects to investigate the device's ability to allow physiologically accurate hand movements throughout the full ROM. The study also tested the efficacy of the force assistance mode with the goal of increasing stroke subjects' active ROM while still requiring active extension torque on the part of the subject.

RESULTS:For 12 of the hand digits'15 joints in neurologically normal subjects, there were no significant ROM differences (P > 0.05) between active movements performed inside and outside of HEXORR. Interjoint coordination was examined in the 1st and 3rd digits, and no differences were found between inside and outside of the device (P > 0.05). Stroke subjects were capable of performing free hand movements inside of the exoskeleton and the force assistance mode was successful in increasing active ROM by 43 +/- 5% (P < 0.001) and 24 +/- 6% (P = 0.041) for the fingers and thumb, respectively.

CONCLUSIONS:Our pilot study shows that this device is capable of moving the hand's digits through nearly the entire ROM with physiologically accurate trajectories. Stroke subjects received the device intervention well and device impedance was minimized so that subjects could freely extend and flex their digits inside of HEXORR. Our active force-assisted condition was successful in increasing the subjects' ROM while promoting active participation.},
  ISSN                     = {1743-0003},
  Keywords                 = {hand rehabilitation, robotics rehabilitation},
  Pubmedid                 = {20667083},
  Timestamp                = {2011.12.28}
}

@InBook{Schemschat2017,
  Title                    = {Model-Based Optimization for the Design of Exoskeletons that Help Humans to Sustain Large Pushes While Walking},
  Author                   = {Schemschat, R. M.
and Clever, D.
and Millard, M.
and Mombaur, K.},
  Pages                    = {821--825},
  Publisher                = {Springer International Publishing},
  Year                     = {2017},

  Booktitle                = {Converging Clinical and Engineering Research on Neurorehabilitation II: Proceedings of the 3rd International Conference on NeuroRehabilitation},
  Doi                      = {10.1007/978-3-319-46669-9_134},
  ISBN                     = {978-3-319-46669-9},
  Timestamp                = {2017.04.21},
  Url                      = {http://dx.doi.org/10.1007/978-3-319-46669-9_134}
}

@Article{Schultz2010,
  Title                    = {Modeling and Optimal Control of Human-Like Running},
  Author                   = {G. Schultz and K. Mombaur},
  Journal                  = {IEEE/ASME Transactions on Mechatronics},
  Year                     = {2010},
  Number                   = {5},
  Pages                    = {783-792},
  Volume                   = {15},

  Doi                      = {10.1109/TMECH.2009.2035112},
  Keywords                 = {anthropometry;legged locomotion;mechatronics;optimal control;optimisation;robot kinematics;actuators;anthropomorphic mechatronic system;gaits;human like running;kinematics;locomotor system;mathematical optimization;multibody system models;multiphase periodic motion;natural human running motions;optimal control;physics based running motions;spring damper elements;Anthropomorphic whole-body model;legged locomotion;multibody dynamics;optimal control;running robot},
  Timestamp                = {2017.03.04}
}

@Article{Schultz2001,
  Title                    = {Language-independent and language-adaptive acoustic modeling for speech recognition},
  Author                   = {Schultz, T. and Waibel, A.},
  Journal                  = {Speech Communication},
  Year                     = {2001},
  Number                   = {1},
  Pages                    = {31--51},
  Volume                   = {35},

  Abstract                 = {With the distribution of speech technology products all over the world, the portability to new target languages becomes a practical concern. As a consequence our research focuses on the question of how to port large vocabulary continuous speech recognition (LVCSR) systems in a fast and efficient way. More specifically we want to estimate acoustic models for a new target language using speech data from varied source languages, but only limited data from the target language. For this purpose, we introduce different methods for multilingual acoustic model combination and a polyphone decision tree specialization procedure. Recognition results using language-dependent, independent and language-adaptive acoustic models are presented and discussed in the framework of our GlobalPhone project which investigates LVCSR systems in 15 languages.},
  Publisher                = {Elsevier},
  Review                   = {- want to automatically create acoustic models for target lanauge},
  Timestamp                = {2013.08.29}
}

@Article{Schwartz2008,
  Title                    = {The importance of stupidity in scientific research},
  Author                   = {Schwartz, M. A.},
  Journal                  = {Journal of Cell Science},
  Year                     = {2008},
  Number                   = {11},
  Pages                    = {1771--1771},
  Volume                   = {121},

  Doi                      = {10.1242/jcs.033340},
  Eprint                   = {http://jcs.biologists.org/content/121/11/1771.full.pdf},
  ISSN                     = {0021-9533},
  Timestamp                = {2016.11.30},
  Url                      = {http://jcs.biologists.org/content/121/11/1771}
}

@InProceedings{Seiffert2008,
  Title                    = {Resampling or Reweighting: A Comparison of Boosting Implementations},
  Author                   = {Seiffert, C. and Khoshgoftaar, T.M. and Van Hulse, J. and Napolitano, A.},
  Booktitle                = {Proceedings of the IEEE International Conference on Tools with Artificial Intelligence},
  Year                     = {2008},
  Pages                    = {445-451},
  Volume                   = {1},

  Abstract                 = {Boosting has been shown to improve the performance of classifiers in many situations, including when data is imbalanced. There are, however, two possible implementations of boosting, and it is unclear which should be used. Boosting by reweighting is typically used, but can only be applied to base learners which are designed to handle example weights. On the other hand, boosting by resampling can be applied to any base learner. In this work, we empirically evaluate the differences between these two boosting implementations using imbalanced training data. Using 10 boosting algorithms, 4 learners and 15 datasets, we find that boosting by resampling performs as well as, or significantly better than, boosting by reweighting (which is often the default boosting implementation). We therefore conclude that in general, boosting by resampling is preferred over boosting by weighting.},
  Doi                      = {10.1109/ICTAI.2008.59},
  ISSN                     = {1082-3409},
  Keywords                 = {learning (artificial intelligence);pattern classification;sampling methods;AdaBoost;boosting algorithm;imbalanced training data classification;resampling method;reweighting method;Algorithm design and analysis;Artificial intelligence;Boosting;Data mining;Iterative algorithms;Medical diagnosis;Sampling methods;Training data;USA Councils;Voting;adaboost},
  Timestamp                = {2013.10.30}
}

@Article{Sheng2012,
  Title                    = {Realtime Recognition of Complex Human Daily Activities Using Human Motion and Location Data},
  Author                   = {Sheng, W. and Zhu, C.},
  Journal                  = {IEEE Transactions on Biomedical Engineering},
  Year                     = {2012},
  Number                   = {9},
  Pages                    = {2422-2430},
  Volume                   = {59},

  Abstract                 = {Daily activity recognition is very useful in robotassisted living systems. In this paper, we proposed a method to recognize complex human daily activities which consist of simultaneous body activities and hand gestures in an indoor environment. A wireless power-aware motion sensor node is developed which consists of a commercial orientation sensor, a wireless communication module, and a power management unit. To recognize complex daily activities, three motion sensor nodes are attached to the right thigh, the waist, and the right hand of a human subject, while an optical motion capture system is used to obtain his/her location information. A three-level dynamic Bayesian network (DBN) is implemented to model the intra-temporal and inter-temporal constraints among the location, body activity and hand gesture. The body activity and hand gesture are estimated using a Bayesian filter and a short-time Viterbi algorithm, which reduces the computational complexity and memory usage. We conducted experiments in a mock apartment environment and the obtained results showed the effectiveness and accuracy of our method.},
  Doi                      = {10.1109/TBME.2012.2190602},
  ISSN                     = {0018-9294},
  Timestamp                = {2012.07.18}
}

@Article{Shi2011,
  Title                    = {Human Action Segmentation and Recognition Using Discriminative Semi-Markov Models},
  Author                   = {Shi, Qinfeng and Cheng, Li and Wang, Li and Smola, Alex},
  Journal                  = {International Journal of Computer Vision},
  Year                     = {2011},
  Number                   = {1},
  Pages                    = {22-32},
  Volume                   = {93},

  Doi                      = {10.1007/s11263-010-0384-0},
  ISSN                     = {0920-5691},
  Keywords                 = {Action segmentation and recognition; Large-margin method; Semi-Markov model},
  Language                 = {English},
  Publisher                = {Springer US},
  Timestamp                = {2014.12.20},
  Url                      = {http://dx.doi.org/10.1007/s11263-010-0384-0}
}

@InProceedings{Shi2008,
  Title                    = {Discriminative human action segmentation and recognition using semi-Markov model},
  Author                   = {Qinfeng Shi and Li Wang and Li Cheng and Smola, A.},
  Booktitle                = {Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on},
  Year                     = {2008},
  Month                    = {June},
  Pages                    = {1-8},

  Abstract                 = {Given an input video sequence of one person conducting a sequence of continuous actions, we consider the problem of jointly segmenting and recognizing actions. We propose a discriminative approach to this problem under a semi-Markov model framework, where we are able to define a set of features over input-output space that captures the characteristics on boundary frames, action segments and neighboring action segments, respectively. In addition, we show that this method can also be used to recognize the person who performs in this video sequence. A Viterbi-like algorithm is devised to help efficiently solve the induced optimization problem. Experiments on a variety of datasets demonstrate the effectiveness of the proposed method.},
  Doi                      = {10.1109/CVPR.2008.4587557},
  ISSN                     = {1063-6919},
  Keywords                 = {Markov processes;image recognition;image segmentation;image sequences;maximum likelihood estimation;video signal processing;Viterbi-like algorithm;action segments;boundary frames;discriminative human action segmentation-recognition;optimization problem;semiMarkov model;video sequence;Character recognition;Hidden Markov models;Humans;Inference algorithms;Shape;Support vector machines;Surveillance;Tracking;Video sequences},
  Timestamp                = {2014.12.23}
}

@InProceedings{Shi2006,
  Title                    = {Learning Temporal Sequence Model from Partially Labeled Data},
  Author                   = {Shi, Yifan and Bobick, A. and Essa, I.},
  Booktitle                = {Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on},
  Year                     = {2006},
  Pages                    = {1631-1638},
  Volume                   = {2},

  Abstract                 = {Graphical models are often used to represent and recognize activities. Purely unsupervised methods (such as HMMs) can be trained automatically but yield models whose internal structure - the nodes - are difficult to interpret semantically. Manually constructed networks typically have nodes corresponding to sub-events, but the programming and training of these networks is tedious and requires extensive domain expertise. In this paper, we propose a semi-supervised approach in which a manually structured, Propagation Network (a form of a DBN) is initialized from a small amount of fully annotated data, and then refined by an EM-based learning method in an unsupervised fashion. During node refinement (the M step) a boosting-based algorithm is employed to train the evidence detectors of individual nodes. Experiments on a variety of data types - vision and inertial measurements - in several tasks demonstrate the ability to learn from as little as one fully annotated example accompanied by a small number of positive but non-annotated training examples. The system is applied to both recognition and anomaly detection tasks.},
  Doi                      = {10.1109/CVPR.2006.174},
  ISSN                     = {1063-6919},
  Keywords                 = {Application software;Boosting;Computer vision;Detectors;Graphical models;Hidden Markov models;Learning systems;Semisupervised learning;State-space methods;Surveillance},
  Timestamp                = {2014.12.22}
}

@Article{Shilton2005,
  Title                    = {Incremental Training of Support Vector Machines},
  Author                   = {Shilton, A. and Palaniswami, M. and Ralph, D. and Ah Chung Tsoi},
  Journal                  = {IEEE Transactions on Neural Networks},
  Year                     = {2005},
  Number                   = {1},
  Pages                    = {114--131},
  Volume                   = {16},

  Abstract                 = {We propose a new algorithm for the incremental training of support vector machines (SVMs) that is suitable for problems of sequentially arriving data and fast constraint parameter variation. Our method involves using a "warm-start" algorithm for the training of SVMs, which allows us to take advantage of the natural incremental properties of the standard active set approach to linearly constrained optimization problems. Incremental training involves quickly retraining a support vector machine after adding a small number of additional training vectors to the training set of an existing (trained) support vector machine. Similarly, the problem of fast constraint parameter variation involves quickly retraining an existing support vector machine using the same training set but different constraint parameters. In both cases, we demonstrate the computational superiority of incremental training over the usual batch retraining method.},
  Doi                      = {10.1109/TNN.2004.836201},
  ISSN                     = {1045-9227},
  Keywords                 = {learning (artificial intelligence);optimisation;support vector machines;fast constraint parameter variation;linearly constrained optimization problems;sequentially arriving data;support vector machine incremental training;Australia;Constraint optimization;Kernel;Pattern recognition;Quadratic programming;Risk management;Sensor systems;Support vector machine classification;Support vector machines;Training data;Active set method;incremental training;quadratic programming;support vector machines (SVMs);warm start algorithm;Algorithms;Artificial Intelligence;Cluster Analysis;Computing Methodologies;Information Storage and Retrieval;Models, Theoretical;Neural Networks (Computer);Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Signal Processing, Computer-Assisted},
  Timestamp                = {2014.11.14}
}

@TechReport{Shlens2014,
  Title                    = {A Tutorial on Principal Component Analysis},
  Author                   = {Shlens, J.},
  Institution              = {Google Research},
  Year                     = {2014},

  Owner                    = {jf2lin},
  Timestamp                = {2017.01.17}
}

@InProceedings{Shotton2011a,
  Title                    = {Real-Time Human Pose Recognition in Parts from a Single Depth Image},
  Author                   = {Shotton, J. and Fitzgibbon, A. and Cook, M. and Sharp, T. and Finocchio, M. and Moore, R. and Kipman, A. and Blake, A.},
  Booktitle                = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  Year                     = {2011},

  Abstract                 = {We propose a new method to quickly and accurately predict 3D positions of body joints from a single depth image, using no temporal information. We take an object recognition approach, designing an intermediate body parts representation that maps the difficult pose estimation problem into a simpler per-pixel classification problem. Our large and highly varied training dataset allows the classifier to estimate body parts invariant to pose, body shape, clothing, etc. Finally we generate confidence-scored 3D proposals of several body joints by reprojecting the classification result and finding local modes.

The system runs at 200 frames per second on consumer hardware. Our evaluation shows high accuracy on both synthetic and real test sets, and investigates the effect of several training parameters. We achieve state of the art accuracy in our comparison with related work and demonstrate improved generalization over exact whole-skeleton nearest neighbor matching.},
  Keywords                 = {Lab reading (Eric)},
  Timestamp                = {2011.03.25}
}

@Article{Shotton2013,
  Title                    = {Efficient Human Pose Estimation from Single Depth Images},
  Author                   = {Shotton, J. and Girshick, R. and Fitzgibbon, A and Sharp, T. and Cook, M. and Finocchio, M. and Moore, R. and Kohli, P. and Criminisi, A and Kipman, A and Blake, A},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {2013},

  Month                    = {Dec},
  Number                   = {12},
  Pages                    = {2821--2840},
  Volume                   = {35},

  __markedentry            = {},
  Abstract                 = {We describe two new approaches to human pose estimation. Both can quickly and accurately predict the 3D positions of body joints from a single depth image without using any temporal information. The key to both approaches is the use of a large, realistic, and highly varied synthetic set of training images. This allows us to learn models that are largely invariant to factors such as pose, body shape, field-of-view cropping, and clothing. Our first approach employs an intermediate body parts representation, designed so that an accurate per-pixel classification of the parts will localize the joints of the body. The second approach instead directly regresses the positions of body joints. By using simple depth pixel comparison features and parallelizable decision forests, both approaches can run super-real time on consumer hardware. Our evaluation investigates many aspects of our methods, and compares the approaches to each other and to the state of the art. Results on silhouettes suggest broader applicability to other imaging modalities.},
  Doi                      = {10.1109/TPAMI.2012.241},
  ISSN                     = {0162-8828},
  Keywords                 = {pose estimation;shape recognition;body shape;consumer hardware;efficient human pose estimation;field-of-view cropping;imaging modalities;per-pixel classification;single depth images;synthetic set;temporal information;training images;Cameras;Feature extraction;Human factors;Pose estimation;Rendering (computer graphics);Shape analysis;Computer vision;depth cues;games;machine learning;pixel classification;range data},
  Timestamp                = {2014.07.30}
}

@InProceedings{Siegler1997,
  Title                    = {Automatic Segmentation, Classification and Clustering of Broadcast News Audio},
  Author                   = {Siegler, M. A. and Jain, U. and Raj, B. and Stern, R. M.},
  Booktitle                = {Proceedings of the DARPA Broadcast News Workshop},
  Year                     = {1997},
  Pages                    = {11},

  Review                   = {- Break problem into segmentation, classification, clustering
- Does not use a priori knowledge of speakers or acoustic conditions
- Uses KL distance
- Tested against some standard dataset - 64% segments matched hand-labels

Siegler \etal \cite{Siegler1997} built a system to segmentation, classify and cluster speech from radio and television courses, for automatic transcription. To segment, they employed the same two-window approach as Gish and Schmidt \cite{Gish1994}, but used KL distance for the distance metric instead. When the KL distance between two windows reached a local maximum, a segment boundary was generated. To classify, GMMs from existing training were utilized to label the segments. Since the observation data were not known \emph{a priori}, it becomes necessary to cluster samples from the same speaker together. Cepstral features were used to identify a given speaker, and Mahalanobis distances was used to cluster similar segments together.

Siegler \etal \cite{Siegler1997} built a system to segment, classify and cluster speech from radio and television, for automatic transcription. They used the same two-window system, but employed KL distance, calculated from the PDFs from the two sequential windows, as the distance metric instead of the GLR. When the KL distance between the PDFs are at a local maximum, a segment point is declared. Segments are clustered together by speaker identity, which are not known \emph{a priori}. This is identified by examining cepstral features, and the Mahalanobis distance is used to cluster similar segments together. No segmentation accuracy was given.},
  Timestamp                = {2013.08.29}
}

@Book{Silverthorn2006,
  Title                    = {Human Physiology: An Integrated Approach, 4th Edition},
  Author                   = {Silverthorn, D. U.},
  Publisher                = {Benjamin Cummings},
  Year                     = {2006},

  Timestamp                = {2014.08.20}
}

@InProceedings{Simila2006,
  Title                    = {Human Balance Estimation using a Wireless 3D Acceleration Sensor Network},
  Author                   = {Simila, H. and Kaartinen, J. and Lindholm, M. and Saarinen, A. and Mahjneh, I.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2006},
  Pages                    = {1493--1496},

  Abstract                 = {Balance and gait are a consequence of complex coordination between muscles, nerves, and central nervous system structures. The impairment of these functions can pose serious threats to independent living, especially in the elderly. This study was carried out to evaluate the performance of a wireless acceleration sensor network and its capability in balance estimation. The test has been carried out in eight patients and seven healthy controls. The Patients group had larger values in lateral amplitudes of the sensor displacement and smaller values in vertical displacement amplitudes of the sensor. The step time variations for the Patients were larger than those for the controls. A fuzzy logic and clustering classifiers were implemented, which gave promising results suggesting that a person with balance deficits can be recognized with this system. We conclude that a wireless system is easier to use than a wired one and more unobtrusive to the user},
  Doi                      = {10.1109/IEMBS.2006.260126},
  ISSN                     = {1557-170X},
  Keywords                 = {Acceleration;Accelerometers;Bluetooth;Body sensor networks;Humans;Media Access Protocol;Mobile handsets;Sampling methods;Time division multiple access;Wireless sensor networks;acceleration measurement;biomedical measurement;fuzzy logic;gait analysis;mechanoception;muscle;neurophysiology;wireless sensor networks;central nervous system;clustering classifier;complex coordination;fuzzy logic;gait;human balance estimation;muscle;wireless 3D acceleration sensor network;},
  Timestamp                = {2013.01.15}
}

@InProceedings{Singh2001,
  Title                    = {Speech in noisy environments: robust automatic segmentation, feature extraction, and hypothesis combination},
  Author                   = {Singh, R. and Seltzer, M. L. and Raj, B. and Stern, R. M.},
  Booktitle                = {IEEE International Conference on Acoustics, Speech, and Signal Processing},
  Year                     = {2001},
  Organization             = {IEEE},
  Pages                    = {273--276},
  Volume                   = {1},

  Review                   = {- looked at specch in noisy env},
  Timestamp                = {2013.08.29}
}

@InProceedings{Skog2006,
  Title                    = {Calibration of a MEMS inertial measurement unit},
  Author                   = {Skog, I. and Handel},
  Booktitle                = {Imeko World Congress: Metrology for a Sustainable Development},
  Year                     = {2006},

  Abstract                 = {An approach for calibrating a low-cost IMU is studied, requiring no mechanical platform for the accelerometer calibration and only a simple rotating table for the gyro calibration. The proposed calibration methods utilize the fact that ideally the norm of the measured output of the accelerometer and gyro cluster are equal to the magnitude of applied force and rotational velocity, respectively. This fact, together with model of the sensors is used to construct a cost function, which is minimized with respect to the unknown model parameters using Newton’s method. The performance of the calibration algorithm is compared with the Cram´ er-Rao bound for the case when a mechanical platform is used to rotate the IMU into different precisely controlled orientations. Simulation results shows that the mean square error of the estimated sensor model parameters reaches the Cram´ er-Rao bound within 8 dB, and thus the proposed method may be acceptable for a wide range of low-cost applications.},
  Review                   = {- Uses cost function, Newton's method
- Doesn't need sophesticated equipment
- Expects constant angular velocity},
  Timestamp                = {2011.07.19}
}

@Article{Skog2010,
  Title                    = {Zero-Velocity Detection:An Algorithm Evaluation},
  Author                   = {Skog, I. and Handel, P. and Nilsson, J-.O. and Rantakokko, J.},
  Journal                  = {IEEE Transactions on Biomedical Engineering},
  Year                     = {2010},

  Month                    = {nov.},
  Number                   = {11},
  Pages                    = {2657 -2666},
  Volume                   = {57},

  Abstract                 = {In this paper, we investigate the problem of detecting-time epochs when zero-velocity updates can be applied in a foot-mounted inertial navigation (motion-tracking) system. We examine three commonly used detectors: the acceleration-moving variance detector, the acceleration-magnitude detector, and the angular rate energy detector. We demonstrate that all detectors can be derived within the same general likelihood ratio test (LRT) framework, given the different prior knowledge about the sensor signals. Further, by combining all prior knowledge, we derive a new LRT detector. Subsequently, we develop a methodology to evaluate the performance of the detectors. Employing the developed methodology, we evaluate the performance of the detectors using leveled ground, slow (approximately 3 km/h) and normal (approximately 5 #x00A0;km/h) gait data. The test results are presented in terms of detection versus false-alarm probability. Our preliminary results show that the new detector performs marginally better than the angular rate energy detector that outperforms both the acceleration-moving variance detector and the acceleration-magnitude detector.},
  Doi                      = {10.1109/TBME.2010.2060723},
  ISSN                     = {0018-9294},
  Timestamp                = {2010.10.19}
}

@Article{Smith2007,
  Title                    = {The dynamic lift of developmental process},
  Author                   = {Smith, L. B. and Breazeal, C.},
  Journal                  = {Developmental Science},
  Year                     = {2007},
  Number                   = {1},
  Pages                    = {61--68},
  Volume                   = {10},

  Abstract                 = {Abstract What are the essential properties of human intelligence, currently unparalleled in its power relative to other biological forms and relative to artificial forms of intelligence? We suggest that answering this question depends critically on understanding developmental process. This paper considers three principles potentially essential to building human-like intelligence: the heterogeneity of the component processes, the embedding of development in a social world, and developmental processes that change the cognitive system as a function of the history of soft-assemblies of these heterogeneous processes in specific tasks. The paper uses examples from human development and from developmental robotics to show how these processes also may underlie biological intelligence and enable us to generate more advanced forms of artificial intelligence.},
  Doi                      = {10.1111/j.1467-7687.2007.00565.x},
  ISSN                     = {1467-7687},
  Keywords                 = {Human-robot interaction; ECE780},
  Publisher                = {Blackwell Publishing Ltd},
  Review                   = {Want to implement emotions expression and recognition to lean about human learning. 

- Gave a baby "sticky mittens" which allowed them to pick up objects easier. Their hand-eye coord improved
- If a child was given an object to move around, the motion they were told to move it characteristized the motion
- Held object with one hand vs held object with two hands resulted in different catigorization as well

- Facial expression used as a communication method between agents, and communicates internal state non-verbally

- Developing organisms don't learn things in isolation. Learns multiple things together at once
- Piaget's A-not-B task
 - An object was placed at A. Infants played with it at A. The object was moved to B, where it "disappeared"
 - Infants reached for A for the object, even though they saw it disappear at B
 --> implies that infant understanding is tied to where they interacted with the object, which increased "learning" on its location

So dynamic lift is the acceleration of developmental process

See slides 'social interactions' from ECE780},
  Timestamp                = {2011.02.09},
  Url                      = {http://dx.doi.org/10.1111/j.1467-7687.2007.00565.x}
}

@Article{Smola2004,
  Title                    = {A Tutorial on Support Vector Regression},
  Author                   = {Smola, A. J. and Sch{\"o}lkopf, B.},
  Journal                  = {Statistics and Computing},
  Year                     = {2004},
  Number                   = {3},
  Pages                    = {199--222},
  Volume                   = {14},

  Publisher                = {Springer},
  Review                   = {svm regression survey},
  Timestamp                = {2014.10.24}
}

@Article{Sniehotta2005,
  Title                    = {Bridging the intention-behaviour gap: Planning, self-efficacy, and action control in the adoption and maintenance of physical exercise},
  Author                   = {Sniehotta, Falko F. and Scholz, Urte and Schwarzer, Ralf},
  Journal                  = {Psychology and Health},
  Year                     = {2005},
  Number                   = {2},
  Pages                    = {143--160},
  Volume                   = {20},

  Abstract                 = {Although some people may develop an intention to change their health behaviour, they might not take any action. This discrepancy has been labelled the 'intention–behaviour gap.' Detailed action planning, perceived self-efficacy, and self-regulatory strategies (action control) may mediate between intentions and behaviour. This was examined in a longitudinal sample of 307 cardiac rehabilitation patients who were encouraged to adopt or maintain regular exercise. At the first time point, the predictors of intention and intention itself were assessed. Two months and four months later, the mediators and outcomes were measured. Results confirmed that all the three factors (planning, maintenance self-efficacy, and action control) served to mediate between earlier exercise intentions and later physical activity, each of them making a unique contribution. The results have implications for research on the 'intention–behaviour gap,' and indicate that planning, maintenance self-efficacy and action control may be important volitional variables.},
  Doi                      = {10.1080/08870440512331317670},
  Eprint                   = {http://www.tandfonline.com/doi/pdf/10.1080/08870440512331317670},
  Timestamp                = {2014.02.23},
  Url                      = {http://www.tandfonline.com/doi/abs/10.1080/08870440512331317670}
}

@Article{Sokolova2009,
  Title                    = {A systematic analysis of performance measures for classification tasks },
  Author                   = {Marina Sokolova and Guy Lapalme},
  Journal                  = {Information Processing \& Management },
  Year                     = {2009},
  Number                   = {4},
  Pages                    = {427 - 437},
  Volume                   = {45},

  Abstract                 = {This paper presents a systematic analysis of twenty four performance measures used in the complete spectrum of Machine Learning classification tasks, i.e., binary, multi-class, multi-labelled, and hierarchical. For each classification task, the study relates a set of changes in a confusion matrix to specific characteristics of data. Then the analysis concentrates on the type of changes to a confusion matrix that do not change a measure, therefore, preserve a classifier’s evaluation (measure invariance). The result is the measure invariance taxonomy with respect to all relevant label distribution changes in a classification problem. This formal analysis is supported by examples of applications where invariance properties of measures lead to a more reliable evaluation of classifiers. Text classification supplements the discussion with several case studies. },
  Doi                      = {http://dx.doi.org/10.1016/j.ipm.2009.03.002},
  ISSN                     = {0306-4573},
  Keywords                 = {Performance evaluation},
  Timestamp                = {2015.04.21},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0306457309000259}
}

@InProceedings{Somol2011,
  Title                    = {Fast dependence-aware feature selection in very-high-dimensional pattern recognition},
  Author                   = {Petr Somol and Ji\v{r}\'{i} Grim and Pavel Pudil},
  Booktitle                = {Proceedings of the IEEE International Conference on Systems, Man and Cybernetics},
  Year                     = {2011},

  Address                  = {Anchorage, Alaska, USA},
  Volume                   = {1},

  Timestamp                = {2011.11.07}
}

@Book{Spong2006,
  title     = {Robot Modeling and Control},
  publisher = {John Wiley and Sons, Inc.},
  year      = {2006},
  author    = {Spong, M. W. and Hutchinson, S. and Vidyasagar, M},
  editor    = {Shultz, CF},
  groups    = {EMBC2013},
  review    = {Textbook used for ECE 486 (Robotics)},
  timestamp = {2010.01.20},
  url       = {http://ca.wiley.com/WileyCDA/WileyTitle/productCd-EHEP000518.html},
}

@InProceedings{Spriggs2009,
  author    = {Spriggs, E. H. and De la Torre Frade, F. and Hebert, M.},
  title     = {Temporal Segmentation and Activity Classification from First-person Sensing},
  booktitle = {IEEE Workshop on Egocentric Vision},
  year      = {2009},
  month     = jun,
  abstract  = {Temporal segmentation of human motion into actions is central to the understanding and building of computational models of human motion and activity recognition. Several issues contribute to the challenge of temporal segmentation and classification of human motion. These include the large variability in the temporal scale and periodicity of human actions, the complexity of representing articulated motion, and the exponential nature of all possible movement combinations. We provide initial results from investigating two distinct problems - classification of the overall task being performed, and the more difficult problem of classifying individual frames over time into specific actions. We explore first-person sensing through a wearable camera and Inertial Measurement Units (IMUs) for temporally segmenting human motion into actions and performing activity classification in the context of cooking and recipe preparation in a natural environment. We present baseline results for supervised and unsupervised temporal segmentation, and recipe recognition in the CMU-Multimodal activity database (CMU-MMAC).},
  groups    = {STAT841},
  keywords  = {motion segmentation},
  review    = {- want a unsupervised method of segmenting IMU data
- using carnegie mellon's cooking database
- segmented on video, imu, and video + imu
- just reading the imu stuff
 - they use some combination of hmm and pca but wasn't clear on how segmentation actually happened
 - they Gaussian'ed and normalized the data to zero mean and 1 variance

---

- IMU+cameras
- talks about CMU's database
- unsup seg on camera: gist" of an img -> to segment the img components (low level) -> fed into prelearned PCA GMM and genearlized templates -> HMM to classifer later (high level). Also tried Viterbi but GMM did better
- unsup accel: windowed, then PCA then HMM -> doesn't see mto do well
- actually, an activity recognition paper},
  timestamp = {2011.01.27},
}

@Article{Sreenivasa2017,
  Title                    = {Optimal Control Based Stiffness Identification of an Ankle-Foot Orthosis Using a Predictive Walking Model},
  Author                   = {Sreenivasa, M. and Millard, M. and Felis, M. and Mombaur, K. and Wolf, S. I.},
  Journal                  = {Frontiers in Computational Neuroscience},
  Year                     = {2017},
  Pages                    = {23:1--13},
  Volume                   = {11},

  Abstract                 = {Predicting the movements, ground reaction forces and neuromuscular activity during gait can be a valuable asset to the clinical rehabilitation community, both to understand pathology, as well as to plan effective intervention. In this work we use an optimal control method to generate predictive simulations of pathological gait in the sagittal plane. We construct a patient-specific model corresponding to a 7-year old child with gait abnormalities and identify the optimal spring characteristics of an ankle-foot orthosis that minimizes muscle effort. Our simulations include the computation of foot-ground reaction forces, as well as the neuromuscular dynamics using computationally efficient muscle torque generators and excitation-activation equations. The optimal control problem is solved with a direct multiple shooting method. The solution of this problem is physically consistent synthetic neural excitation commands, muscle activations and whole body motion. Our simulations produced similar changes to the gait characteristics as those recorded on the patient. The orthosis-equipped model was able to walk faster with more extended knees. Notably, our approach can be easily tuned to simulate weakened muscles, produces physiologically realistic ground reaction forces and smooth muscle activations and torques, and can be implemented on a standard workstation to produce results within a few hours. These results are an important contribution towards bridging the gap between research methods in computational neuromechanics and day-to-day clinical rehabilitation.},
  Doi                      = {10.3389/fncom.2017.00023},
  ISSN                     = {1662-5188},
  Timestamp                = {2017.04.21},
  Url                      = {http://journal.frontiersin.org/article/10.3389/fncom.2017.00023}
}

@InBook{Sreenivasa2017a,
  Title                    = {Optimizing Wearable Assistive Devices with Neuromuscular Models and Optimal Control},
  Author                   = {Sreenivasa, M.
 and Millard, M. and Manns, P.
 and Mombaur, K.},
  Pages                    = {627--632},
  Publisher                = {Springer International Publishing},
  Year                     = {2017},

  Booktitle                = {Converging Clinical and Engineering Research on Neurorehabilitation II: Proceedings of the 3rd International Conference on NeuroRehabilitation},
  Doi                      = {10.1007/978-3-319-46669-9_103},
  ISBN                     = {978-3-319-46669-9},
  Timestamp                = {2017.04.21},
  Url                      = {http://dx.doi.org/10.1007/978-3-319-46669-9_103}
}

@Article{Stadler2001,
  Title                    = {Jacobian motion and its derivatives},
  Author                   = {Stadler, W. and Eberhard, P.},
  Journal                  = {Mechatronics},
  Year                     = {2001},
  Number                   = {5},
  Pages                    = {563 - 593},
  Volume                   = {11},

  Abstract                 = {An innovative, geometrically appealing, derivation of the differential motion of an end-effector and the corresponding Jacobian matrix is presented. The use of the differential form of the skew-symmetric matrix and the corresponding differential rotation is central to the development, A being the usual rotation matrix. This allows a novel side-by-side presentation of the vector and matrix form of differential rigid motion based on the forward kinematics of the manipulator. The corresponding treatment of the homogeneous motion includes a detailed discussion of the derivative and differential of homogeneous rigid motion and a clarification of some notational ambiguities and errors in previous treatments of this topic. It is also shown that the results are equivalent to what may be termed classical results. The analytical treatment is followed by a detailed presentation of computational and symbolic methods for the derivation and evaluation of the Jacobian matrix, including the use of recently developed methods of automatic differentiation. The AdeptOne Robot is used as an illustrative example with complete agreement of the theoretical and computational results.},
  Doi                      = {DOI: 10.1016/S0957-4158(00)00016-7},
  ISSN                     = {0957-4158},
  Keywords                 = {Trajectory planning},
  Timestamp                = {2010.03.08},
  Url                      = {http://www.sciencedirect.com/science/article/B6V43-43DKXRF-4/2/abdb537a9db95774334f9b74034452e8}
}

@InProceedings{Stapenhurst2011,
  Title                    = {Theoretical and empirical analysis of diversity in non-stationary learning},
  Author                   = {Stapenhurst, R. and Brown, G.},
  Booktitle                = {IEEE Symposium on Computational Intelligence in Dynamic and Uncertain Environments},
  Year                     = {2011},
  Pages                    = {25--32},

  Abstract                 = {In non-stationary learning, we require a predictive model to learn over time, adapting to changes in the concept if necessary. A major concern in any algorithm for non-stationary learning is its rate of adaptation to new concepts. When tackling such problems with ensembles, the concept of diversity appears to be of significance. In this paper, we discuss how we expect diversity to impact the rate of adaptation in non-stationary ensemble learning. We then analyse the relation between voting margins and a popular measure of diversity, KW variance, and use the similarities between them to draw some useful conclusions regarding ensemble adaptivity.},
  Doi                      = {10.1109/CIDUE.2011.5948488},
  Keywords                 = {learning (artificial intelligence);KW variance;ensemble adaptivity;nonstationary ensemble learning;predictive model;Bagging;Diversity reception;Equations;Error analysis;Mathematical model;Measurement uncertainty;Training},
  Review                   = {- need to have some degree of "diversity" in non-stationary learning. they have metrics that can be used to measure diversity. 
- seems to be designed or sudden changes (which would be suitable for our system), but...
 - they have a set of data. to create a "new" situation, they swap around the feature dim and add some noise so that the classifier would need to forget about the old feature set to learn about the new one

- don't really understand their training procedure. they use ANN (perceptrons)},
  Timestamp                = {2015.05.12}
}

@InProceedings{Stelzer2007,
  Title                    = {Efficient dynamic modeling, numerical optimal control and experimental results for various gaits of a quadruped robot},
  Author                   = {Stelzer, M. and Hardt, M. and Von Stryk, O.},
  Booktitle                = {Proceedings of the International Conference on Climbing and Walking Robots},
  Year                     = {2007},

  Timestamp                = {2017.03.04}
}

@Article{Stikic2011,
  Title                    = {Weakly Supervised Recognition of Daily Life Activities with Wearable Sensors},
  Author                   = {Stikic, M. and Larlus, D. and Ebert, S. and Schiele, B.},
  Journal                  = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  Year                     = {2011},

  Month                    = {Dec},
  Number                   = {12},
  Pages                    = {2521-2537},
  Volume                   = {33},

  Abstract                 = {This paper considers scalable and unobtrusive activity recognition using on-body sensing for context awareness in wearable computing. Common methods for activity recognition rely on supervised learning requiring substantial amounts of labeled training data. Obtaining accurate and detailed annotations of activities is challenging, preventing the applicability of these approaches in real-world settings. This paper proposes new annotation strategies that substantially reduce the required amount of annotation. We explore two learning schemes for activity recognition that effectively leverage such sparsely labeled data together with more easily obtainable unlabeled data. Experimental results on two public data sets indicate that both approaches obtain results close to fully supervised techniques. The proposed methods are robust to the presence of erroneous labels occurring in real-world annotation data.},
  Doi                      = {10.1109/TPAMI.2011.36},
  ISSN                     = {0162-8828},
  Keywords                 = {body sensor networks;gait analysis;learning (artificial intelligence);pattern recognition;ubiquitous computing;wearable computers;context awareness;fully supervised techniques;labeled training data;on-body sensing;real-world annotation data;supervised learning;unobtrusive activity recognition;weakly supervised daily life activities recognition;wearable computing;wearable sensors;Supervised learning;Training;Wearable computers;Wearable computing;activity recognition;semi-supervised learning.;wearable sensing},
  Timestamp                = {2014.12.22}
}

@InProceedings{Stikic2009,
  Title                    = {Multi-graph Based Semi-supervised Learning for Activity Recognition},
  Author                   = {Stikic, M. and Larlus, D. and Schiele, B.},
  Booktitle                = {Wearable Computers, 2009. ISWC '09. International Symposium on},
  Year                     = {2009},
  Month                    = {Sept},
  Pages                    = {85-92},

  Abstract                 = {On-body sensing has enabled scalable and unobtrusive activity recognition for context-aware wearable computing. Common methods for activity recognition are based on supervised learning requiring substantial amounts of labeled training data. Obtaining accurate and detailed annotations of activities is a great challenge for these approaches preventing their applicability in real-world settings. This paper introduces a new activity recognition method that combines small amounts of labeled data with easily obtainable unlabeled data in a semi-supervised learning process. The method propagates information through a graph that contains both labeled and unlabeled data. We propose two different ways of combining multiple graphs based on feature similarity and time. We evaluate both the quality of the label propagation process itself and the performance of classifiers trained on the propagated labels. Experimental results on two public datasets indicate that our approach outperforms a recently proposed multi-instance learning approach and in some cases even outperforms fully supervised approaches.},
  Doi                      = {10.1109/ISWC.2009.24},
  ISSN                     = {1550-4816},
  Keywords                 = {graph theory;learning (artificial intelligence);pattern recognition;ubiquitous computing;wearable computers;activity recognition;context-aware wearable computing;label propagation process;multigraph based semisupervised learning;multiinstance learning approach;multiple graphs;Biomedical monitoring;Labeling;Medical diagnosis;Medical diagnostic imaging;Sampling methods;Semisupervised learning;Senior citizens;Supervised learning;Training data;Wearable computers},
  Timestamp                = {2014.12.22}
}

@Article{Stolcke1995_SCFG,
  Title                    = {An Efficient Probabilistic Context-free Parsing Algorithm That Computes Prefix Probabilities},
  Author                   = {Stolcke, Andreas},
  Journal                  = {Comput. Linguist.},
  Year                     = {1995},

  Month                    = jun,
  Number                   = {2},
  Pages                    = {165--201},
  Volume                   = {21},

  Acmid                    = {211197},
  Address                  = {Cambridge, MA, USA},
  ISSN                     = {0891-2017},
  Issue_date               = {June 1995},
  Numpages                 = {37},
  Publisher                = {MIT Press},
  Timestamp                = {2014.03.14},
  Url                      = {http://dl.acm.org/citation.cfm?id=211190.211197}
}

@InProceedings{Stolcke1996,
  author    = {Stolcke, A. and Shriberg, E.},
  title     = {Automatic Linguistic Segmentation of Conversational Speech},
  booktitle = {Proceedings of the International Conference on Spoken Language},
  year      = {1996},
  volume    = {2},
  pages     = {1005--1008},
  abstract  = {As speech recognition moves toward more unconstrained domains such as conversational speech, we encounter a need to be able to segment (or resegment) waveforms and recognizer output into linguistically meaningful units such a sentences. Toward this end, we present a simple automatic segmenter of transcripts based on N-gram language modeling. We also study the relevance of several word-level features for segmentation performance. Using only word-level information, we achieve 85% recall and 70% precision on linguistic boundary detection},
  groups    = {STAT841},
  review    = {- use n-gram language modeling to segment
- 70% precise

Stolcke and Shriberg \cite{Stolcke1996} is interested in producing linguistic segmentations, segmentation by linguistic structures, as oppose to acoustic segmentations, segmentation by pauses and speaker turns. A N-gram language model was trained from parts of the standard Switchboard dataset, which consists of 1.4 million words, annotated into 193 thousand segments. The N-gram model is a n-1 ordered Markov model, and the Viterbi algorithm is used to determine if a segment is coming up. Using a tri-gram model, this algorithm reports 70.2\% recall accuracy. If the model is improved to explicitly model speaker turns, recall improves to 76.9\%. Incorporating parts-of-speech also improves the algorithm to 79.6\%.

Stolcke and Shriberg \cite{Stolcke1996} generate linguistic segmentations, segmentation by linguistic structures, as opposed to acoustic segmentations, segmentation by pauses and speaker turns. A \emph{n}-gram language model was trained from parts of the standard Switchboard dataset, which consists of 1.4 million words, annotated into 193 thousand segments. The \emph{n}-gram model is a \emph{n-1} ordered Markov model, where each word in the model have n syllables. The Viterbi algorithm is used to determine if a segment is coming up. Using a tri-gram model, this algorithm reports $Acc_{recall}$ of 70\% and $Acc_{precision}$ of 61\%. If the model is improved to explicitly model speaker turns, $Acc_{recall}$ improves to 77\% and $Acc_{precision}$ of 67\%. Incorporating parts-of-speech also improves the $Acc_{recall}$ to 80\% and $Acc_{precision}$ of 74\%},
  timestamp = {2013.08.29},
}

@Article{Strickland2012,
  author    = {Strickland, E.},
  title     = {Good-bye, wheelchair},
  journal   = {IEEE Spectrum},
  year      = {2012},
  volume    = {49},
  number    = {1},
  pages     = {30--32},
  groups    = {EMBC2013},
  publisher = {IEEE},
  timestamp = {2012.11.12},
}

@InProceedings{Strisland2013,
  Title                    = {ESUMS: A Mobile System for Continuous Home Monitoring of Rehabilitation Patients},
  Author                   = {Strisland, F. and Svagard, I. and Seeberg, T. M. and Mathisen, B. M. and Vedum, J. and Austad, H. O. and Liverud, A. E. and Kofod-Petersen, A. and Bendixen, O. C.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {The pressure on the healthcare services is building up for several reasons. The ageing population trend, the increase in life-style related disease prevalence, as well as the increased treatment capabilities with associated general expectation all add pressure. The use of ambient healthcare technologies can alleviate the situation by enabling time and cost-efficient monitoring and follow-up of patients discharged from hospital care. We report on an ambulatory system developed for monitoring of physical rehabilitation patients. The system consists of a wearable multisensor monitoring device; a mobile phone with client application aggregating the data collected; a service-oriented-architecture based server solution; and a PC application facilitating patient follow-up by their health professional carers. The system has been tested and verified for accuracy in controlled environment trials on healthy volunteers, and also been usability tested by 5 congestive heart failure patients and their nurses. This investigation indicated that patients were able to use the system, and that nurses got an improved basis for patient follow-up.},
  Keywords                 = {EMBC2013},
  Review                   = {Wearable activity monitor. No details on the algorithms itself, but the activity monitoring system seems to be pretty rudimentry.},
  Timestamp                = {2013.08.05}
}

@Article{Stryk1992,
  Title                    = {Direct and indirect methods for trajectory optimization},
  Author                   = {von Stryk, O. and Bulirsch, R.},
  Journal                  = {Annals of Operations Research},
  Year                     = {1992},
  Number                   = {1},
  Pages                    = {357--373},
  Volume                   = {37},

  Abstract                 = {This paper gives a brief list of commonly used direct and indirect efficient methods for the numerical solution of optimal control problems. To improve the low accuracy of the direct methods and to increase the convergence areas of the indirect methods we suggest a hybrid approach. For this a special direct collocation method is presented. In a hybrid approach this direct method can be used in combination with multiple shooting. Numerical examples illustrate the direct method and the hybrid approach.},
  Doi                      = {10.1007/BF02071065},
  ISSN                     = {1572-9338},
  Timestamp                = {2017.03.04}
}

@Article{Sturman1994,
  Title                    = {A survey of glove-based input},
  Author                   = {Sturman, D. and Zeltzer, D.},
  Journal                  = {IEEE Comput Graph Appl Mag},
  Year                     = {1994},
  Pages                    = {30--9},
  Volume                   = {14},

  Abstract                 = {Clumsy intermediary devices constrain our interaction with computers and their applications. Glove-based input devices let us apply our manual dexterity to the task. We provide a basis for understanding the field by describing key hand-tracking technologies and applications using glove-based input. The bulk of development in glove-based input has taken place very recently, and not all of it is easily accessible in the literature. We present a cross-section of the field to date. Hand-tracking devices may use the following technologies: position tracking, optical tracking, marker systems, silhouette analysis, magnetic tracking or acoustic tracking. Actual glove technologies on the market include: Sayre glove, MIT LED glove, Digital Data Entry Glove, DataGlove, Dexterous HandMaster, Power Glove, CyberGlove and Space Glove. Various applications of glove technologies include projects into the pursuit of natural interfaces, systems for understanding signed languages, teleoperation and robotic control, computer-based puppetry, and musical performance.<>},
  Doi                      = {10.1109/38.250916},
  ISSN                     = {0272-1716},
  Keywords                 = {data gloves;tracking;virtual reality;CyberGlove;DataGlove;Dexterous HandMaster;Digital Data Entry Glove;MIT LED glove;Power Glove;Sayre glove;Space Glove;acoustic tracking;computer-based puppetry;glove-based input devices;hand-tracking devices;magnetic tracking;manual dexterity;marker systems;musical performance;natural interfaces;optical tracking;position tracking;signed language understanding;silhouette analysis;teleoperation;Acoustic devices;Application software;Computer applications;Data gloves;Light emitting diodes;Magnetic analysis;Magnetic devices;Optical devices;Orbital robotics;Space technology},
  Owner                    = {jf2lin},
  Timestamp                = {2015.04.27}
}

@InProceedings{Subramanya2009,
  Title                    = {Entropic graph regularization in non-parametric semi-supervised classification},
  Author                   = {Subramanya, Amarnag and Bilmes, Jeff A},
  Booktitle                = {Advances in Neural Information Processing Systems},
  Year                     = {2009},
  Pages                    = {1803--1811},

  Abstract                 = {We prove certain theoretical properties of a graph-regularized transductive learn-
ing objective that is based on minimizing a Kullback-Leibler divergence based
loss. These include showing that the iterative alternating minimization procedure
used to minimize the objective converges to the correct solution and deriving a test
for convergence. We also propose a graph node ordering algorithm that is cache
cognizant and leads to a linear speedup in parallel computations. This ensures that
the algorithm scales to large data sets. By making use of empirical evaluation on
the TIMIT and Switchboard I corpora, we show this approach is able to outper-
form other state-of-the-art SSL approaches. In one instance, we solve a problem
on a 120 million node graph.},
  Review                   = {graph-based SSL algorithm based on minimizing a Kullback-Leibler divergence (KLD) based loss. 

it seems like the graph Laplacian method is very popular. "Graph-based SSL algorithms are inherently non-parametric, transductive and discriminative "
Uses KNN, makes a connectivity graph. Constructs a cost function designed to minimize new obs' 1) distance to labelled data, 2) remain consistent with the "shape" of the data, and 3) maintain distribution of the labelled data},
  Timestamp                = {2015.05.13}
}

@InProceedings{Sugihara2002,
  Title                    = {Realtime humanoid motion generation through ZMP manipulation based on inverted pendulum control},
  Author                   = {Sugihara, T. and Nakamura, Y. and Hirochika I.},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2002},
  Pages                    = {1404--1409},

  Abstract                 = {Humanoid robot is expected as a rational form of machine to act in the real human environment and support people through interaction with them. Current humanoid robots, however, lack in adaptability, agility, or high-mobility enough to meet the expectations. In order to enhance high-mobility, the humanoid motion should be generated in realtime in accordance with the dynamics, which commonly requires a large amount of computation and has not been implemented so far. We have developed a realtime motion generation method that controls the center of gravity(COG) by indirect manipulation of the zero moment point(ZMP). The realtime responce of the method provides humanoid robots with high-mobility. In this paper, the algorithm is presented. It consists of four parts, namely, the referential ZMP planning, the ZMP manipulation, the COG velocity decomposition to joint angles, and local control of joint angles. An advantage of the algorithm lies in its applicability to humanoids with a lot of degrees of freedom. The effectiveness of proposed method is verified by computer simulations.},
  Keywords                 = {ECE780, ZMP},
  Review                   = {NOVELTY

SUMMARY
Motion generation of humanoids can be classified as either offline (trajectory replaying) or online (realtime generation). Online generation allows robots to better adapt to environment variability. It is typically very computationally heavy, so this paper proposes a better method.

To maintain stability, we want to keep the ZMP within the support polygon. We combine this idea with a set of desired GCOM velocity to generate reference velocities via proportional gain and Jacobian matrices. Excess degree of freedoms are limited by joint-space (joint angle ranges) and non-joint space (end effector motion ranges) constraints.


The definition and the uses of ZMP in this article matches the definition of ZMP given in the previous two articles.},
  Timestamp                = {2011.01.28}
}

@InProceedings{Sugiura2008,
  Title                    = {Motion recognition and generation by combining reference-point-dependent probabilistic models},
  Author                   = {Sugiura, K. and Iwahashi, N.},
  Booktitle                = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2008},
  Month                    = {Sept},
  Pages                    = {852-857},

  Abstract                 = {This paper presents a method to recognize and generate sequential motions for object manipulation such as placing one object on another or rotating it. Motions are learned using reference-point-dependent probabilistic models, which are then transformed to the same coordinate system and combined for motion recognition/generation. We conducted physical experiments in which a user demonstrated the manipulation of puppets and toys, and obtained a recognition accuracy of 63% for the sequential motions. Furthermore, the results of motion generation experiments performed with a robot arm are presented.},
  Doi                      = {10.1109/IROS.2008.4651169},
  Keywords                 = {image motion analysis;image recognition;learning systems;manipulators;mobile robots;probability;robot vision;coordinate system;motion learning;object manipulation;reference-point-dependent probabilistic model;sequential motion generation;sequential motion recognition;Accuracy;Hidden Markov models;Indexes;Robot kinematics;Robots;Stereo vision;Trajectory},
  Review                   = {it seems like each movement segment is trained separately, then woven together over several different HMMs. the learning and recognition is done separately. there does seem to be. uses ML to show classification works.},
  Timestamp                = {2014.12.20}
}

@Conference{SundelaCruz2010,
  Title                    = {Learning Inverse Dynamics for Redundant Manipulator Control},
  Author                   = {Sun de la Cruz, J. AND Kulic, D.},
  Booktitle                = {Proceedings of the International Conference on Autonomous and Intelligent Systems},
  Year                     = {2010},

  Abstract                 = {High performance contorl of robotic systems, including the new generation of humanoid, assistive and entertainment robots, requires adequate knowledge of the dynamics of the system. This can be problematic in the presence of modeling uncertainties as the performance of classical, model-based controllers is highly dependant upon accurate knowledge of the system. In addition, future robotic systems such as humanoids are likely to be redundant, reqirin ga mechanism for redundancy resolution when performing lower degree-of-freedom tasks. In this paper, a learning approach to estimating the inverse dynamic equations is presented. Locally Weighted Projection Regression is used to learn the inverse dynamics of a manipulator in both joint and task space an the resulting controllers are used to drive a 3 and 4 DOF robot in simulation. the performance of the learning controllers is compared to a traditional model based control method and is also shown to be a viable control method for a redundant system.},
  Review                   = {Model-based tracking is very useful, as they prove speed and tracking of the system. But obtaining a highly accurate model is difficult. Machine learning techniques has been created to address this, allowing model data to be built from motions. Current algorithms are computationally expensive and are typically performed offline. These are SVR and GPR. 

The algorithm introduced here, LWPR, is less accurate, but cheaper computationally, so can be used for real time applications. Online changes in the model or structure can be adapted fairly easily. The system also needs to be able to aalocate DOFs properly, and achieve secondary tasks. 

Oh. Joseph used Lagrangian dynamic formation, instead of RNE. Takes joint space and task space and uses Jacobians. Want to cancel non-linear/noise/coupling terms for a simple joint/task equation. But the cancelling terms may be dependent on having accurate physical parameters...},
  Timestamp                = {2010.06.11}
}

@Article{Sung2005,
  Title                    = {Wearable feedback systems for rehabilitation},
  Author                   = {Sung, M. and Marci, C. and Pentland, A.},
  Journal                  = {Journal of NeuroEngineering and Rehabilitation},
  Year                     = {2005},
  Number                   = {1},
  Pages                    = {17},
  Volume                   = {2},

  Abstract                 = {In this paper we describe LiveNet, a flexible wearable platform intended for long-term ambulatory health monitoring with real-time data streaming and context classification. Based on the MIT Wearable Computing Group's distributed mobile system architecture, LiveNet is a stable, accessible system that combines inexpensive, commodity hardware; a flexible sensor/peripheral interconnection bus; and a powerful, light-weight distributed sensing, classification, and inter-process communications software architecture to facilitate the development of distributed real-time multi-modal and context-aware applications. LiveNet is able to continuously monitor a wide range of physiological signals together with the user's activity and context, to develop a personalized, data-rich health profile of a user over time. We demonstrate the power and functionality of this platform by describing a number of health monitoring applications using the LiveNet system in a variety of clinical studies that are underway. Initial evaluations of these pilot experiments demonstrate the potential of using the LiveNet system for real-world applications in rehabilitation medicine.},
  Doi                      = {10.1186/1743-0003-2-17},
  ISSN                     = {1743-0003},
  Pubmedid                 = {15987514},
  Timestamp                = {2010.09.29},
  Url                      = {http://www.jneuroengrehab.com/content/2/1/17}
}

@InCollection{Suutala2007,
  Title                    = {Discriminative Temporal Smoothing for Activity Recognition from Wearable Sensors},
  Author                   = {Suutala, Jaakko and Pirttikangas, Susanna and Röning, Juha},
  Booktitle                = {Ubiquitous Computing Systems},
  Publisher                = {Springer Berlin Heidelberg},
  Year                     = {2007},
  Editor                   = {Ichikawa, Haruhisa and Cho, We-Duke and Satoh, Ichiro and Youn, HeeYong},
  Pages                    = {182-195},
  Series                   = {Lecture Notes in Computer Science},
  Volume                   = {4836},

  Doi                      = {10.1007/978-3-540-76772-5_15},
  ISBN                     = {978-3-540-76771-8},
  Language                 = {English},
  Review                   = {Another SVM -> HMM},
  Timestamp                = {2015.02.06},
  Url                      = {http://dx.doi.org/10.1007/978-3-540-76772-5_15}
}

@Article{Syed2007,
  Title                    = {A new multi-position calibration method for MEMS inertial navigation systems},
  Author                   = {Z F Syed and P Aggarwal and C Goodall and X Niu and N El-Sheimy},
  Journal                  = {Measurement Science and Technology},
  Year                     = {2007},
  Number                   = {7},
  Pages                    = {1897},
  Volume                   = {18},

  Abstract                 = {The Global Positioning System (GPS) is a worldwide navigation system that requires a clear line of sight to the orbiting satellites. For land vehicle navigation, a clear line of sight cannot be maintained all the time as the vehicle can travel through tunnels, under bridges, forest canopies or within urban canyons. In such situations, the augmentation of GPS with other systems is necessary for continuous navigation. Inertial sensors can determine the motion of a body with respect to an inertial frame of reference. Traditionally, inertial systems are bulky, expensive and controlled by government regulations. Micro-electro mechanical systems (MEMS) inertial sensors are compact, small, inexpensive and most importantly, not controlled by governmental agencies due to their large error characteristics. Consequently, these sensors are the perfect candidate for integrated civilian navigation applications with GPS. However, these sensors need to be calibrated to remove the major part of the deterministic sensor errors before they can be used to accurately and reliably bridge GPS signal gaps. A new multi-position calibration method was designed for MEMS of high to medium quality. The method does not require special aligned mounting and has been adapted to compensate for the primary sensor errors, including the important scale factor and non-orthogonality errors of the gyroscopes. A turntable was used to provide a strong rotation rate signal as reference for the estimation of these errors. Two different quality MEMS IMUs were tested in the study. The calibration results were first compared directly to those from traditional calibration methods, e.g. six-position and rate test. Then the calibrated parameters were applied in three datasets of GPS/INS field tests to evaluate their accuracy indirectly by comparing the position drifts during short-term GPS signal outages.},
  Timestamp                = {2011.07.19},
  Url                      = {http://stacks.iop.org/0957-0233/18/i=7/a=016}
}

@InProceedings{Sylla2014_EMBC,
  Title                    = {Assessing neuromuscular mechanisms in human-exoskeleton interaction},
  Author                   = {Sylla, N. and Bonnet, V. and Venture, G. and Armande, N. and Fraisse, P.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2014},
  Pages                    = {1210--1213},

  Abstract                 = {In this study, we propose to evaluate a 7 DOF exoskeleton in terms of motion control. Using criteria from the human motor control literature, inverse optimization was performed to assess an industrial screwing movement. The results of our study show that the hybrid composition of the free arm movement was accurately determined. At contrary, when wearing the exoskeleton, which produces an arbitrary determined torque compensation, the motion is different from the naturally adopted one. This study is part of the evaluation and comprehension of the complex neuromuscular mechanism resulting in wearing an exoskeleton several hours per day for industrial tasks assistance.},
  Doi                      = {10.1109/EMBC.2014.6943814},
  ISSN                     = {1557-170X},
  Keywords                 = {biomechanics;industrial control;motion control;muscle;neurophysiology;optimisation;orthotics;torque;7 DOF exoskeleton evaluation;arbitrary torque compensation determination;complex neuromuscular mechanism comprehension;complex neuromuscular mechanism evaluation;exoskeleton wearing;human motor control literature criteria;human-exoskeleton interaction;hybrid free arm movement composition determination;industrial screwing movement assessment;industrial tasks assistance;inverse optimization;motion control;neuromuscular mechanism assessment;Cost function;Exoskeletons;Joints;Neuromuscular;Torque;Trajectory},
  Review                   = {Human movement trajectory planning have several degrees of redundency, and any cost functions used to model trajectory plannning could be attempting to minimize jerk, torque change, energy, or variance. However, no consensus has been met, as the weight of each criteria appear to change from task to task. Hybrid cost functions have been proposed, with either used overly simple cost functions or simple motions.

This paper fit an exoskel over 8 subjects performing car assembly plant motions, and collected joint angles and torque via the exoskel. The paper saw that geodescic (a function of joint velo) was the most influencial cost variable, from a list of 6 common cost functions, but it varied greatly from trial to trial (exo vs no exo, and varying weights lifted). However, this may be due to the exoskel constraining movement, and the subject adjusting to the existance of the exo.},
  Timestamp                = {2015.06.26}
}

@InProceedings{Sylla2014_ICBRB,
  Title                    = {Human arm optimal motion analysis in industrial screwing task},
  Author                   = {Sylla, N. and Bonnet, V. and Venture, G. and Armande, N. and Fraisse, P.},
  Booktitle                = {Proceedings of IEEE RAS/EMBS International Conference on Biomedical Robotics and Biomechatronics},
  Year                     = {2014},
  Pages                    = {964--969},

  Abstract                 = {In this study, we propose to explore inverse optimization process to better understand human arm motion in industrial screwing task. The process combines several criteria to minimize such as energy expenditure or trajectory smoothness leading to the optimal trajectory of a typical screwing task, often performed by workers. Estimated joint trajectories are similar with the measured ones, with a mean square error of 4 degrees. The resulting cost-function is mainly composed of energy expenditure and geodesic criteria. Results show the relevance of using composite cost function in human motion planning. This study has been conducted to assist workers by using collaborative robots in painful task in PSA Peugeot Citroen factories to improve ergonomics of manual workstations.},
  Doi                      = {10.1109/BIOROB.2014.6913905},
  ISSN                     = {2155-1774},
  Keywords                 = {biomechanics;ergonomics;mean square error methods;energy expenditure;ergonomics;geodesic criteria;human arm optimal motion analysis;industrial screwing task;inverse optimization process;joint trajectory estimation;mean square error;Cost function;Joints;Shoulder;Torque;Trajectory;Wrist},
  Timestamp                = {2015.06.26}
}

@InProceedings{Takano2006_ICHR,
  Title                    = {Humanoid Robot's Autonomous Acquisition of Proto-Symbols through Motion Segmentation},
  Author                   = {Takano, W. and Nakamura, Y.},
  Booktitle                = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  Year                     = {2006},
  Month                    = {Dec},
  Pages                    = {425-431},

  Abstract                 = {Mimesis is the theory that human intelligence originated in the interactive communication of motion recognition and generation through imitation. A mimesis model has been proposed using hidden Markov models (HMMs), which represent proto symbols. In our previous system, the user had to manually divided a sequence of motion into segments in order to embed each segment as an HMM. Automatic segmentation is essential for a system to autonomously learn and develop through imitation. In this paper, we propose an automatic motion segmentation method utilizing correlation among movements for a short time period. In addition, we show that it is possible to acquire proto symbols by providing the automatically segmented motion patterns with the mimesis system},
  Doi                      = {10.1109/ICHR.2006.321307},
  Keywords                 = {biomimetics;hidden Markov models;humanoid robots;image motion analysis;image segmentation;knowledge acquisition;learning (artificial intelligence);robot vision;autonomous protosymbol acquisition;hidden Markov models;humanoid robot;imitation learning;mimesis system;motion patterns;motion recognition;motion segmentation;motion sequence;movement correlation;Computer vision;Data mining;Hidden Markov models;Humanoid robots;Humans;Learning;Mirrors;Motion control;Motion segmentation;Neurons;Hidden Markov Model;Imitation Learning;Mimesis;Segmentation},
  Review                   = {Want to divide human motion into short seq.},
  Timestamp                = {2014.12.23}
}

@InProceedings{Takano2006_ICRA,
  Title                    = {Primitive communication based on motion recognition and generation with hierarchical mimesis model},
  Author                   = {Takano, W. and Yamane, K. and Sugihara, T. and Yamamoto, K. and Nakamura, Y.},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2006},
  Month                    = {May},
  Pages                    = {3602-3609},

  Abstract                 = {Communication skill is essential for social robots in various environments such as homes, offices, and hospitals, where the robots are expected to interact with humans. In this paper, we model the primitive nonverbal communication between two persons by mimetic communication model. The model consists of three groups of hidden Markov models (HMMs) hierarchically combined to recognize motions of the human and to generate the interactive motions of the robot. HMMs in the lower layer abstract the motion patterns and HMMs in the upper layer represent the interaction patterns. We demonstrate the validity of this model through kick boxing match between a motion-captured human and humanoid robot, where the robot can autonomously generate its motion in response to attacks by the human},
  Doi                      = {10.1109/ROBOT.2006.1642252},
  ISSN                     = {1050-4729},
  Keywords                 = {control engineering computing;gesture recognition;hidden Markov models;hierarchical systems;humanoid robots;hidden Markov models;hierarchical mimesis model;humanoid robot;interactive motions;motion recognition;primitive nonverbal communication;social robots;Hidden Markov models;Hospitals;Human robot interaction;Humanoid robots;Learning;Mirrors;Neurons;Pediatrics;Robot sensing systems;Robotics and automation},
  Timestamp                = {2014.12.20}
}

@InProceedings{Takenaka2009,
  Title                    = {Real time motion generation and control for biped robot -1st report: Walking gait pattern generation-},
  Author                   = {Takenaka, T. and Matsumoto, T. and Yoshiike, T.},
  Booktitle                = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2009},
  Pages                    = {1084--1091},

  Abstract                 = {Generating stable dynamic motions for a biped robot in real time is difficult due to the unstable nature of biped systems and their high degrees of freedom. We propose an approximate dynamics model for biped robots with three masses and no kinematic constraints. We also propose a relaxed boundary condition called "the divergent component of motion". These techniques allow us to generate walking gait patterns with large margin from the edges of support polygon in real time},
  Doi                      = {10.1109/IROS.2009.5354662},
  Keywords                 = {ECE780, Gait and Trajectory},
  Timestamp                = {2011.02.04}
}

@InProceedings{Tamura2013,
  Title                    = {Quantitative Analysis of the Fall-Risk Assessment Test with Wearable Inertia Sensors},
  Author                   = {Tamura, T. and Zakaria, N. A. and Kuwae, Y. and Sekine, M. and Minato, K. and Yoshida, M.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {We performed a quantitative analysis of the fall-risk assessment test using a wearable inertia sensor focusing on two tests: the time up and go (TUG) test and the four square step test (FSST). These tests consist of various daily activities, such as sitting, standing, walking, stepping, and turning. The TUG test was performed by subjects at low and high fall risk, while FSST was performed by healthy elderly and hemiplegic patients with high fall risk. In general, the total performance time of activities was evaluated. Clinically, it is important to evaluate each activity for further training and management. The wearable sensor consisted of an accelerometer and angular velocity sensor. The angular velocity and angle of pitch direction were used for TUG evaluation, and those in the pitch and yaw directions at the thigh were used for FSST. Using the threshold of the angular velocity signal, we classified the phase corresponding to each activity. We then observed the characteristics of each activity and recommended suitable training and management. The wearable sensor can be used for more detailed evaluation in fall risk management. The wearable sensor can be used more detailed evaluation for fall-risk management test.},
  Keywords                 = {EMBC2013},
  Review                   = {Want a way to assess fall riskes. The Timed Up and Go (TUG) and Four Square Step (FSST) will be examined. 
TUG - time it takes fo a person to stand up, walk 3m, return to chair. 13.5s is threshold for healthy. 
FSST - stepping over low objects (2.5cm) and movements in 4 directions.


Used 6DOF IMU. 
TUG - broke the exercise up into 8 primitives, and used thresholds to differentiate between them. This was shown to be helpful, can classify subjects as high or low risk, as well as where are dangerous movements for the patients. The phase-by-phase analysis is useful.

FSST - thigh angle was key in classifying phase. Was not as useful.},
  Timestamp                = {2013.07.30}
}

@Article{Tarchanidis2003,
  Title                    = {Data glove with a force sensor},
  Author                   = {Tarchanidis, K. N. AND Lygouras, J. N.},
  Journal                  = {IEEE Transactions on Instrumentation and Measurement},
  Year                     = {2003},
  Pages                    = {984--989},
  Volume                   = {52},

  Abstract                 = {This paper presents a data glove equipped with a force sensor. The construction and the electronic circuit are also described. The glove is selected to be a rubber-coated cotton glove. The sensors are firmly attached to the rubber-coated glove using cyanoacrilic glue. The force sensor is made of a steel plate substrate where the commercial strain gauges are attached. The plate is attached on the thumb. The strain gauge bridge is powered by a digital current source. A digital sine is produced by a microcontroller and a DAC with current output. At the peak, the microcontroller produces a digital output signal. This signal triggers the data acquisition system. The force sensor presents a linear response and a resolution of 0.38 N with a sensitivity of 0.05 V/N. The combination can be used in robotics, telecheric applications, biomechanics and virtual reality applications.},
  Review                   = {Used a rubber-latex-cotton glove with flex sensors in the fingers. Transmits...via RS232 (I guess it's wired) and samples on request from the PC master controller. A strain guage is placed around the thumb,a nd changes voltage on the Wheatstone bridges attached to it. When you apply stress to a material and it deforms, the strain gauge material will experience the same strain as the element to be measured (assume secure attachment). Temperature does factor into things...since when you're moving around, you're generating heat.


Anyway. They calibrated it. Picked up some stuff. Squeezed a ball. Good repeatability.},
  Timestamp                = {2009.12.07},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1213693&tag=1}
}

@InProceedings{Taylor2013,
  Title                    = {Forward Kinematics Using IMU On-Body Sensor Network for Mobile Analysis of Human Kinematics},
  Author                   = {Taylor, T. and Ko, S. and Mastrangelo, C. and Bamberg, S. J. M.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {The feasibility of large network inertial measurement units (IMUs) are evaluated for purposes requiring feedback. A series of wireless IMUs were attached to a human lower-limb laboratory model outfitted with joint angle encoders. The goal was to discover if large networks of wireless IMUs can give realtime joint orientation data while still maintaining an acceptable degree of accuracy.},
  Keywords                 = {EMBC2013},
  Review                   = {Want to calculate joint angles. Uses gyro/accel/mag. 

Direction cosine matrix is generated to get direction (see previous work). Looks like they're just integrating via skew symetric mtx. Accel/mag used to centre the gyro drift. 

(...read their previous work [16] to see what their rationale is.) the results looks good though.},
  Timestamp                = {2013.08.06}
}

@Article{Tegin2009,
  Title                    = {Demonstration-based learning and control for automatic grasping},
  Author                   = {Tegin, Johan and Ekvall, Staffan and Kragic, Danica and Wikander, Jan and Iliev, Boyko},
  Journal                  = {Intelligent Service Robotics},
  Year                     = {2009},
  Number                   = {1},
  Pages                    = {23--30},
  Volume                   = {2},

  Abstract                 = {We present a method for automatic grasp generation based on
ob ject shape primitives in a Programming by Demonstration framework.
The system rst recognizes the grasp performed by a demonstrator as well
as the ob ject it is applied on and then generates a suitable grasping strategy
on the robot. We start by presenting how to model and learn grasps and map
them to robot hands. We continue by performing dynamic simulation of the
grasp execution with a focus on grasping ob jects whose pose is not perfectly
known.},
  Publisher                = {Springer},
  Timestamp                = {2013.10.08}
}

@Article{Tenenbaum2000,
  Title                    = {A global geometric framework for nonlinear dimensionality reduction},
  Author                   = {Tenenbaum, J. B. and de Silva, V. and Langford, J. C.},
  Journal                  = {Science},
  Year                     = {2000},
  Pages                    = {2319-2323},
  Volume                   = {290},

  Keywords                 = {Lab meeting (Cecille)},
  Timestamp                = {2011.06.22}
}

@InProceedings{Tenorth2009,
  Title                    = {The {TUM} Kitchen Data Set of everyday manipulation activities for motion tracking and action recognition},
  Author                   = {Tenorth, M. and Bandouch, J. and Beetz, M.},
  Booktitle                = {IEEE International Conference on Computer Vision Workshops},
  Year                     = {2009},
  Pages                    = {1089--1096},

  Abstract                 = {We introduce the publicly available TUM Kitchen Data Set as a comprehensive collection of activity sequences recorded in a kitchen environment equipped with multiple complementary sensors. The recorded data consists of observations of naturally performed manipulation tasks as encountered in everyday activities of human life. Several instances of a table-setting task were performed by different subjects, involving the manipulation of objects and the environment. We provide the original video sequences, full-body motion capture data recorded by a markerless motion tracker, RFID tag readings and magnetic sensor readings from objects and the environment, as well as corresponding action labels. In this paper, we both describe how the data was computed, in particular the motion tracker and the labeling, and give examples what it can be used for. We present first results of an automatic method for segmenting the observed motions into semantic classes, and describe how the data can be integrated in a knowledge-based framework for reasoning about the observations.},
  Doi                      = {10.1109/ICCVW.2009.5457583},
  Keywords                 = {gesture recognition;image motion analysis;image sensors;image sequences;RFID tag readings;TUM kitchen data set;action recognition;everyday manipulation activities;full- body motion capture data;magnetic sensor readings;markerless motion tracker;motion tracking;multiple complementary sensors;table-setting task;video sequences;Computer vision;Conferences;Humans;Intelligent sensors;Labeling;Magnetic sensors;Motion segmentation;RFID tags;Tracking;Video sequences},
  Timestamp                = {2015.01.21}
}

@InProceedings{Teruyama2013,
  Title                    = {A Basic Study on Variable-Gain Kalman Filter Based on Angle Error Calculated from Acceleration Signals for Lower Limb Angle Measurement with Inertial Sensors},
  Author                   = {Teruyama, Y. and Watanabe, T.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {In this study, development of wearable motion measurement system using inertial sensors has been focused with the aim of rehabilitation support. For measurement of lower limb joint angles with inertial sensors, Kalman-filtering-based angle measurement method was developed. However, it was required to reduce variation of measurement errors that depended on movement speeds or subjects. In this report, variable-gain Kalman filter based on the difference between the estimated angle by the Kalman filter and the angle calculated from acceleration signals was tested. From angle measurement during treadmill walking with healthy subjects, it was shown that measurement accuracy of the foot inclination angle was significantly improved with the proposed method compared to the method of fixed parameter value.},
  Keywords                 = {EMBC2013},
  Review                   = {Looked at IMU signal from treadmill walking. Want to make a variable gain KF. Looks like they're modeling gyro bias and noise as well. They change the noise ratio (not quite sure what that is referring to...ratio between state/obs noise?) according to the calculated error on the accel/gyro signal.},
  Timestamp                = {2013.08.06}
}

@Article{Testart2011,
  Title                    = {A Real-Time Hybrid Architecture for Biped Humanoids with Active Vision Mechanisms},
  Author                   = {Testart, Javier and Ruiz del Solar, Javier and Schulz, Rodrigo and Guerrero, Pablo and Palma-Amestoy, Rodrigo},
  Journal                  = {Journal of Intelligent and Robotic Systems},
  Year                     = {2011},
  Note                     = {10.1007/s10846-010-9515-7},
  Pages                    = {233--255},
  Volume                   = {63},

  Abstract                 = {A real-time hybrid control architecture for biped humanoid robots is proposed. The architecture is modular and hierarchical. The main robotâ€™s functionalities are organized in four parallel modules: perception, actuation, world-modeling, and hybrid control. Hybrid control is divided in three behavior-based hierarchical layers: the planning layer, the deliberative layer, and the reactive layer, which work in parallel and have very different response speeds and planning capabilities. The architecture allows: (1) the coordination of multiple robots and the execution of group behaviors without disturbing the robot's reactivity and responsivity, which is very relevant for biped humanoid robots whose gait control requires real-time processing. (2) The straightforward management of the robot's resources using resource multiplexers. (3) The integration of active vision mechanisms in the reactive layer under control of behavior-dependant value functions from the deliberative layer. This adds flexibility in the implementation of complex functionalities, such as the ones required for playing soccer in robot teams. The architecture is validated using simulated and real Nao humanoid robots. Passive and active behaviors are tested in simulated and real robot soccer setups. In addition, the ability to execute group behaviors in real- time is tested in international robot soccer competitions.},
  Affiliation              = {Department of Electrical Engineering &amp; Advanced Mining Technology Center, Universidad de Chile, Santiago, Chile},
  ISSN                     = {0921-0296},
  Issue                    = {2},
  Keyword                  = {Engineering},
  Publisher                = {Springer Netherlands},
  Timestamp                = {2011.07.20},
  Url                      = {http://dx.doi.org/10.1007/s10846-010-9515-7}
}

@Conference{Tevatia2000,
  Title                    = {Inverse Kinematics for Humanoid Robots},
  Author                   = {Tevatia, G. AND Schaal, S.},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2000},

  Abstract                 = {Real-time control of the endeffector of a humanoid robot in external coordinates requires computationally eficient solutions of the inverse kinematics problem. In this context, this paper investigates methods of resolved motion rate control (RMRC) that employ optimization criteria to resolve kinematic redundancies. In particular we focus on two established techniques, the pseudo inverse with explicit optimization and the extended Jacobian method. We prove that the extended Jacobian method includes pseudo-inverse methods as a special solution. In terms of computational complexity, however, pseudo-inverse and extended Jacobian differ significantly in favor of pseudo-inverse methods. Employing numerical estimation techniques, we introduce a computationally eficient version of the extended Jacobian with performance comparable to the original version. Our results are illustrated in simulation studies with a multiple degree-offreedom robot, and were tested on a 30 degree-of freedom humanoid robot.},
  Keywords                 = {kinematics},
  Review                   = {Transforming coordinates planes can be thought of as an IK procedure. IK transforms can be poor in quality, as matrices are often ill formed. Over-defined matrices results in non-unique solutions, so optimization criterions (some g(theta)) can be applied. If we have a square and non-singular matrix, inverse is fairly straightforward. For non-squares, additional constraints is required to obtain a unique inverse. 

Forward kinematics: x = f(theta)
What we want is reverse kinematics: theta= inv(f(x)). We can use the Jacobian, getting us x_dot = J(theta) * theta_dot

Pseudo-Inverse
PI methods are commonly applied for this end, such as Moore-Penrose (MATLAB: pinv): theta_dot = J^T * (J * J^T) * x_dot -> and minimizes the norm of theta.dot. 
Liegeois came up with a similar system, but it is more expensive to use, especially for highly redundant (so very un-square) systems

Extended Jacobian Method (EJM)
The EJM wants to zero the gradient of g(theta) in the null space of the Jacobian (huh?!)

(will need more lin-alg background to handle the rest of the paper. terms to note is null space, SVD. The paper goes on to discuss how the PI provides a poor answer while the EJM is too computationally expensive. The paper provides a more efficient method of calculating EJM) -> Dana mentioned that this paper has algorithms that's not really all that important. We'll live without it.},
  Timestamp                = {2009.11.10}
}

@Conference{Thakor2009,
  author    = {Thakor, N. V.},
  title     = {Bench to Beside: Motivation for University Industry Partnership},
  booktitle = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  year      = {2009},
  abstract  = {This paper discusses the motivation for entrepreneurship in academia and for forging a relationship between an academic laboratory and a startup. University based personnel, faculty and students, priorities basic bench research. On the other side, industry, particularly startups, prioritize technology development for clinical and commercial translation. The paper presents personal experience as a case study. University based researchers, faculty and students, might participate in and benefit from such an entrepreneurial activity. A University spin off would facilitate translational of bench research ideas and results to technologies for bedside use. Attention to issues such as conflict of interest and concern and ethics of working with human subjects need to be managed by the investigators and the institution. While entrepreneurial activity is not for everyone, it does provide the benefit and satisfaction to see research reach practice.},
  groups    = {EMBS2009},
  review    = {Mission of the University is to the focus on education and research (knowledge creation and dissemination), generating new ideas experimental results, theories and technology, but are typically limited to laboratory settings, and released in the form of publications. 

Mission of Biomedical industries is to produce products for clinical use and commercial benefit. Needs innovative ideas, IP and implementation of technology to serve real needs, and hopefully gain clinical adoption and commercial success. 

The paper then goes on and talks about things to keep in mind, like conflict of interest, resource allocation (using University resources to work on a government...ie NIH, NSERC, etc, funded project). Anyways, it’s hard. 

Conclusion: Bench to bedside is a worthy endeavor for academicians. The process takes one’s work from laboratory to the patient, and helps one see the fruits of discoveries and inventions translate into products with clinical and commercial utility. Attention should be paid to the conflict of interest and other ethical practices and institutional policies. Successful execution of either profession, being an academic researcher or an entrepreneur, requires intense dedication and commitment to excellence and the will and desire to succeed and make an impact.},
  timestamp = {2009.10.06},
}

@Misc{ThalmicMyo,
  Title                    = {Myo},

  Author                   = {{Thalmic Labs Inc.}},
  HowPublished             = {www.thalmic.com},
  Year                     = {2013},

  Owner                    = {jf2lin},
  Timestamp                = {2016.12.06}
}

@Misc{MathworksMatlab,
  Title                    = {MATLAB},

  Author                   = {{The MathWorks Inc.}},
  Year                     = {2012},

  Owner                    = {jf2lin},
  Timestamp                = {2017.01.05}
}

@InProceedings{Thiemjarus2013,
  Title                    = {A Method for Shoulder Range-Of-Motion Estimation Using a Single Wireless Sensor Node},
  Author                   = {Thiemjarus, S. and Marukatat, S. and Poomchoompol, P.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {This study proposes a method for range-of-motion (ROM) estimation based on the acceleration and geomagnetic data acquired using a single miniaturized wireless sensor node. An experiment on eight shoulder rehabilitation protocols in real human subjects has been conducted, with a sensor placed on user’s left and right upper arms and wrists. The experimental results demonstrate the limitations of estimation methods that use sensors placed on skin surface and that, despite being a different body segment, the wrist is a better placement position for sensor-based shoulder joint ROM measurement than the shoulder itself.},
  Keywords                 = {EMBC2013},
  Review                   = {Uses accel/mag signals to figure out ROM. 23 subjects performed shoulder flexion, ext, add, adb, horizontal add, horizontal abd, int rot, ext rot. The joint angle reported are binned (ie only report if the person is at 0d, 30d, 60d, 90d, etc). No mention of algorithm, likely using trig and compass averaged.},
  Timestamp                = {2013.08.06}
}

@Article{Thomaz2008,
  author    = {Thomaz, A. L. and Breazeal, C.},
  title     = {Teachable robots: Understanding human teaching behavior to build more effective robot learners},
  journal   = {Artificial Intelligence},
  year      = {2008},
  volume    = {172},
  number    = {6-7},
  pages     = {716--737},
  issn      = {0004-3702},
  abstract  = {While Reinforcement Learning (RL) is not traditionally designed for interactive supervisory input from a human teacher, several works in both robot and software agents have adapted it for human input by letting a human trainer control the reward signal. In this work, we experimentally examine the assumption underlying these works, namely that the human-given reward is compatible with the traditional RL reward signal. We describe an experimental platform with a simulated RL robot and present an analysis of real-time human teaching behavior found in a study in which untrained subjects taught the robot to perform a new task. We report three main observations on how people administer feedback when teaching a Reinforcement Learning agent: (a) they use the reward channel not only for feedback, but also for future-directed guidance; (b) they have a positive bias to their feedback, possibly using the signal as a motivational channel; and (c) they change their behavior as they develop a mental model of the robotic learner. Given this, we made specific modifications to the simulated RL robot, and analyzed and evaluated its learning behavior in four follow-up experiments with human trainers. We report significant improvements on several learning measures. This work demonstrates the importance of understanding the human-teacher/robot-learner partnership in order to design algorithms that support how people want to teach and simultaneously improve the robot's learning behavior.},
  doi       = {DOI: 10.1016/j.artint.2007.09.009},
  groups    = {IROS2014},
  keywords  = {Human-robot interaction},
  review    = {- how do humans want to teach robots?
 - this paper approaches robot as a social learning exercise
 - don't want to use machine learning approach, where "teachability" issues are ignored
 - want to use scaffolding (teacher-supported/directed teaching) instead
- uses a learning video game called sophie's kitchen
 - want to teach a robot how to bake a cake
 - cannot tell robot directly what to do. can only affirm or disprove its actions, or suggest items to examine
 - only 1/18 participants sucessfully did it
 - training data shows...
 - people prefer social learning (giving them the item to consider) first, consistently
 - then, to affirm the robot everytime it did something right},
  timestamp = {2011.02.09},
  url       = {http://www.sciencedirect.com/science/article/B6TYF-4R3C089-1/2/c7e7393eb2f79fd7b47f5f5102ffeaf0},
}

@Article{Thong2004,
  Title                    = {Numerical double integration of acceleration measurements in noise},
  Author                   = {Thong, Y. K. and Woolfson, M. S. and Crowe, J. A. and Hayes-Gill, B. R. and Jones, D. A.},
  Journal                  = {Measurement},
  Year                     = {2004},
  Pages                    = {73--92},
  Volume                   = {36},

  Abstract                 = {In several applications one or more accelerometers are used to estimate position, which is derived by double integration of the acceleration measurements. An experimental method to calibrate the positional errors due to noise for an accelerometer has already been developed. In this paper, a theoretical formalism for this calibration method is derived, which is based on modelling the acceleration measurements as filtered noise. The effects of numerical integration are included in the model. Two accelerometers, with different noise ratings, are chosen for study. It is found that the theoretical model gives good quantitative agreement between theory and experiment for the variation of positional errors with integration time. The causes of the discrepancies between the theoretical and experimentally found results are discussed and suggestions are made for further research.},
  Doi                      = {DOI: 10.1016/j.measurement.2004.04.005},
  ISSN                     = {0263-2241},
  Keywords                 = {Accelerometers, integration drift},
  Timestamp                = {2010.04.01},
  Url                      = {http://www.sciencedirect.com/science/article/B6V42-4CPDPPS-2/2/6c030e611b0af9ba575075981566e8ac}
}

@Article{Tian2012,
  Title                    = {A multiple kernel framework for inductive semi-supervised SVM learning},
  Author                   = {Tian, Xilan and Gasso, Gilles and Canu, St{\'e}phane},
  Journal                  = {Neurocomputing},
  Year                     = {2012},
  Pages                    = {46--58},
  Volume                   = {90},

  Abstract                 = {We investigate the benefit of combining both cluster assumption and manifold assumption underlying
most of the semi-supervised algorithms using the flexibility and the efficiency of multiple kernel
learning. The multiple kernel version of Transductive SVM (a cluster assumption based approach)
is proposed and it is solved based on DC (Difference of Convex functions) programming. Promising
results on benchmark data sets and the BCI data analysis suggest and support the effectiveness of
proposed work.},
  Publisher                = {Elsevier},
  Timestamp                = {2014.10.24}
}

@Article{Tibshirani1996,
  Title                    = {Regression shrinkage and selection via the lasso},
  Author                   = {Tibshirani, Robert},
  Journal                  = {Journal of the Royal Statistical Society. Series B (Methodological)},
  Year                     = {1996},
  Pages                    = {267--288},

  Publisher                = {JSTOR},
  Review                   = {The Lasso is a constraint optimization where the magnitudes of a least square regression equation is constrained so that the sum of the constraints is less than some value t, which is tuned. We can consider the 't' value as the amount of "shrinkage" applied to the regression betas. The L1 ridge that articles talk about refer to the fact that the t constraint is done in the L1 norm space, such that the L1 nrom of the parameter vector is smaller than the t value. 

Lasso is often contrasted again the ridge regression. Ridge regression is a common modification to ill-posed problems (ie 'x' is not well formed), a matrix coefficent and the x matrix is added to provide preferences for solutions with small norms, in a process known as 'regularization' (ie making a problem less ill-formed). This improves the conditioning of the problem. Lasso is another regularization technique.

p - dim of input vector

Fig 2 - shows the 't' constraint (square, for 2D case) and the least squares constraint (the elipses). When the OLS hits a corner of the constraint, it means that there's only solutions in one dim, and thus some coeff are zero.lin},
  Timestamp                = {2014.04.21}
}

@Conference{Tiesel2006,
  Title                    = {A Mobile Low-Cost Motion Capture System Based on Accelerometers},
  Author                   = {Tiesel, J.-P. and Loviscach, J.},
  Booktitle                = {Proceedings of the Advances in Visual Computing},
  Year                     = {2006},
  Pages                    = {437--446},
  Publisher                = {Springer Berlin / Heidelberg},

  Abstract                 = {Low-cost accelerometers can be employed to create a motion-capture solution for below US$ 100. It may be used in mobile settings employing a portable digital recording device to capture the analog data of 15 degrees of freedom. The solution is integrated with standard 3D animation software. We introduce methods to extract and tweak kinematical as well as timing data from these acceleration sensors, which are attached to an actor’s limbs. These methods take care of the fact that the measured acceleration data alone can neither provide complete nor accurate information to satisfactorily reconstruct the captured motion. Particular emphasis is placed on the ease of use, in particular concerning the calibration of the system.},
  Keywords                 = {Postural detection},
  Review                   = {Cameras are expensive or complicated to use. Mechanical sensors (such as suits) are still rather expensive. They include some related works on using gyro and accels and whatnot. They noted that 

Their end goal is... Want to make motion capture cheap and easy to use. Target audience is animation applications. They'll use only accelerometers. 

This is what they want to do:
1) Obtain orientation of bones, assuming the actor isn't jerky in motion
2) Accel pattern is used...to..."retime" frames. Whatever that means.

Okay. So they have the actor to move slowly first (to grab orientation data), then the action is repeated at real time for scaling purposes.

This is the capture sequence:
1) Accelerometer range calibration (because each sensor is a bit finiky)

2) Calibrate orientation of accelerometers relative to limbs (once per session)
3) Capture limb orientations (slow-motion movement, to reduce dynamic motion error)
4) Smooth out the captured motion via software
5) Repeat motion at actual speed, to rescale the timing of the motion

They noted ~10% error on the accelerometer (which is similar to what I've seen) -> they applied sensor-specific calibrations by rotating the sensors in all directions very slowly and grabing the peak values and setting that as 'g' for those axis. Is this a good idea?

With this technique, they got errors less than 15degrees for elbow joint.},
  Timestamp                = {2010.01.18}
}

@Article{Todorov2004,
  Title                    = {Optimality principles in sensorimotor control},
  Author                   = {Todorov, E.},
  Journal                  = {Nature Neuroscience},
  Year                     = {2004},
  Pages                    = {907--915},
  Volume                   = {7},

  Abstract                 = {The sensorimotor system is a product of evolution, development, learning, adaptation – processes that work on different time scales to improve behavioral performance. Consequenly, many theories of motor function are based on the notion of optimal performance: they quantify the task goals, and apply the sophisticated tools of optimal control theory to obtain detailed behavioral predictions. The resulting models, although not without limitations, has explained a wider range of empirical phenomena than any other class of models. Traditional emphasis has been on optimizing average trajectories while ignoring sensory feedback. Recent work has redefined optimality on the level of feedback control laws, and focused on the mechanisms that generate behavior online. This has made it possible to fit a number of previously unrelated concepts and observations into what may become a unified theoretical framework for interpreting motor function. At the heart of the framework is the relationship between high-level goals, and the realtime sensorimotor control strategies most suitable for accomplishing those goals.},
  Doi                      = {10.1038/nn1309},
  Owner                    = {jf2lin},
  Timestamp                = {2015.07.06}
}

@InCollection{Toereyin2005,
  Title                    = {HMM Based Falling Person Detection Using Both Audio and Video},
  Author                   = {Töreyin, B. and Dedeoglu, Yigithan and Çetin, A.},
  Booktitle                = {Computer Vision in Human-Computer Interaction},
  Publisher                = {Springer Berlin / Heidelberg},
  Year                     = {2005},
  Pages                    = {211--220},
  Series                   = {Lecture Notes in Computer Science},
  Volume                   = {3766},

  Abstract                 = {Automatic detection of a falling person in video is an important problem with applications in security and safety areas including supportive home environments and CCTV surveillance systems. Human motion in video is modeled using Hidden Markov Models (HMM) in this paper. In addition, the audio track of the video is also used to distinguish a person simply sitting on a floor from a person stumbling and falling. Most video recording systems have the capability of recording audio as well and the impact sound of a falling person is also available as an additional clue. Audio channel data based decision is also reached using HMMs and fused with results of HMMs modeling the video data to reach a final decision.},
  Affiliation              = {Department of Electrical and Electronics Engineering, Bilkent University, 06800 Bilkent, Ankara, Turkey},
  Doi                      = {10.1007/11573425_21},
  Timestamp                = {2011.06.15}
}

@Misc{TRI2011,
  Title                    = {Community Balance and Mobility Scale},

  Author                   = {{Toronto Rehabilitation Institute}},
  Year                     = {2011},

  Keywords                 = {Physiotherapy},
  Timestamp                = {2012.12.03}
}

@Misc{TRI_HipKneeExercise,
  author    = {{Toronto Rehabilitation Institute}},
  title     = {Hip and Knee Exercises},
  year      = {2010},
  groups    = {EMBC2013},
  timestamp = {2013.01.13},
}

@Article{Tousignant2006,
  Title                    = {In home telerehabilitation for older adults after discharge from an acute hospital or rehabilitation unit: A proof-of-concept study and costs estimation},
  Author                   = {Tousignant, M. and Boissy, P. and Corriveau, H. and Moffet, H.},
  Journal                  = {Disability and Rehabilitation: Assistive Technology},
  Year                     = {2006},
  Number                   = {4},
  Pages                    = {209--216},
  Volume                   = {1},

  Abstract                 = {Purpose.The purpose of this study is to investigate rehabilitation through teletreatment as an alternative to a physical home-care visit to deliver services to individuals at home following discharge from an acute hospital or rehabilitation unit.

Method.Four community-living elderly people were recruited for telerehabilitation services prior being discharged from an acute-care hospital and a geriatric rehabilitation unit. Once the patient returned home, an appointment was made for the assessing therapist to take the clinical measurements (T1) in a face-to-face session. Four clinical variables were used (functional autonomy, balance, locomotor performance in walking and lower-body strength). Telerehabilitation sessions with the participants were conducted with trained personnel in the individual's home. The system used to support telerehabilitation services for this proof of concept was built around network-attached remotely-controlled pan/tilt/zoom cameras with MJPEG compression, media displays and hands-free phones. Before the patient was discharged from the physiotherapy program, the same assessing therapist visited the subject again to take the T2 measurements in a face-to-face session. The satisfaction of the health-care professional was determined for each session with the homemade questionnaire. Costs related to telerehabilitation were compared to theoretically home visits.

Results.All four subjects improved on the four clinical variables. Mean costs for the telerehabilitation program, comprising 12 sessions over 4 weeks was $487.

Conclusion.Telerehabilitation seems to be a practical alternative for dispensing rehabilitation services after patients are discharged from an acute hospital or rehabilitation unit.},
  Doi                      = {10.1080/17483100600776965},
  Eprint                   = {http://informahealthcare.com/doi/pdf/10.1080/17483100600776965},
  Keywords                 = {Telerehabilitation, physiotherapy},
  Timestamp                = {2011.12.29},
  Url                      = {http://informahealthcare.com/doi/abs/10.1080/17483100600776965}
}

@Article{Tousignant2009,
  Title                    = {In-Home Telerehabilitation for Post-Knee Arthroplasty: A Pilot Study},
  Author                   = {Tousignant, M. and Boissy, P. and Corriveau, H. and Moffet, H. and Cabana, F.},
  Journal                  = {International Journal of Telerehabilitation},
  Year                     = {2009},
  Pages                    = {9--16},
  Volume                   = {1},

  Abstract                 = {The purpose of this study was to investigate the efficacy of in-home telerehabilitation as an alternative to conventional rehabilitation services following knee arthroplasty. Five community-living elders who had knee arthroplasty were recruited prior to discharge from an acute care hospital. A pre/post-test design without a control group was used for this pilot study. Telerehabilitation sessions (16) were conducted by two trained physiotherapists from a service center to the patient’s home using H264 videoconference CODECs (Tandberg 550 MXP) connected at 512 Kb\s. Disability (range of motion, balance and lower body strength) and function (locomotor performance in walking and functional autonomy) were measured in face-to-face evaluations prior to and at the end of the treatments by a neutral evaluator. The satisfaction of the health care professional and patient was measured by questionnaire. Results are as follows. One participant was lost during follow-up. Clinical outcomes improved for all subjects and improvements were sustained two months post-discharge from in-home telerehabilitation. The satisfaction of the participants with in-home telerehabilitation services was very high. The satisfaction of the health care professionals with the technology and the communication experience during the therapy sessions was similar or slightly lower. In conclusion, telerehabilitation for post-knee arthroplasty is a realistic alternative for dispensing rehabilitation services for patients discharged from an acute care hospital.},
  Keywords                 = {Telerehabilitation, Physical Therapy, Total Knee Arthroplasty, Videoconferencing},
  Timestamp                = {2011.12.29}
}

@TechReport{Toussaint2014,
  Title                    = {Technical Reference: Constrained Trajectory Optimization},
  Author                   = {Toussaint, M. and Ratliff, N. and Bohg, J. and Righetti, L. and Englert, P. and Schaal, S.},
  Institution              = {Supplementry Material for 'Dual Execution of Optimized Contact Interaction Trajectories'},
  Year                     = {2014},

  Owner                    = {jf2lin},
  Timestamp                = {2015.12.11}
}

@Article{Trabelsi2013,
  author    = {Trabelsi, D. and Mohammed, S. and Chamroukhi, F. and Oukhellou, L. and Amirat, Y.},
  title     = {An Unsupervised Approach for Automatic Activity Recognition Based on Hidden {Markov} Model Regression},
  journal   = {IEEE Transactions on Automation Science and Engineering},
  year      = {2013},
  volume    = {10},
  number    = {3},
  pages     = {829--835},
  issn      = {1545-5955},
  abstract  = {Using supervised machine learning approaches to recognize human activities from on-body wearable accelerometers generally requires a large amount of labeled data. When ground truth information is not available, too expensive, time consuming or difficult to collect, one has to rely on unsupervised approaches. This paper presents a new unsupervised approach for human activity recognition from raw acceleration data measured using inertial wearable sensors. The proposed method is based upon joint segmentation of multidimensional time series using a Hidden Markov Model (HMM) in a multiple regression context. The model is learned in an unsupervised framework using the Expectation-Maximization (EM) algorithm where no activity labels are needed. The proposed method takes into account the sequential appearance of the data. It is therefore adapted for the temporal acceleration data to accurately detect the activities. It allows both segmentation and classification of the human activities. Experimental results are provided to demonstrate the efficiency of the proposed approach with respect to standard supervised and unsupervised classification approaches.},
  doi       = {10.1109/TASE.2013.2256349},
  groups    = {Lit Review 2013-09},
  keywords  = {acceleration measurement;accelerometers;biomedical equipment;biomedical measurement;body sensor networks;expectation-maximisation algorithm;gait analysis;hidden Markov models;learning (artificial intelligence);medical signal processing;patient monitoring;pattern classification;regression analysis;signal classification;HMM;acceleration data classification;automatic activity recognition;expectation-maximization algorithm;health-monitoring context;hidden Markov model regression;human activity classification;human activity recognition;human activity segmentation;inertial wearable sensors;joint segmentation;left ankle;multidimensional time series;multiple regression context;on-body wearable accelerometers;on-body wearable sensors;physical human activities;raw acceleration data measurement;sequential data appearance;supervised machine learning approach;temporal acceleration data;Activity recognition;hidden Markov model (HMM);multivariate regression;unsupervised learning;wearable computing},
  review    = {Want to recongize human activity with accelerometers. Don't want to assume that supervised data is available, since it's generally pretty expensive. Want to propose unsupervised approaches. 

Each activity is reprsented by a regression model, and switching between activities is governed by a HMM. The likely sequence of activities is estimated by Viterbi.

IMUs strapped on chest, right thigh and left ankle. XSENS sensors. 25 Hz. Activities performed are stairs, standing, sitting, sitting on ground, lying down, standing up, walking. From the 9 DOF accelerations data, this is is a multidimentional time series segmentation. Uses piecewise regression model. Have been used in many places. But instead of using straight lines with constant mean errors, polynomials are used. 

yi = obs, ith measurement
zi = state

They use hidden markov model regression, where the obs data is assumed to be generated by a regression model y = beta t + gamma noise, where y is normally distributed with mean beta t and variance sigma. A modified Baum-Welsh is used to train the HMMR. Segmentation and labeling is made based on which is the best polynomial regression that models the observation, (similar to Viberti?)


89% precision. 96% recall. Beats k-means and HMM. 


[activity recongition, used HMM regression on accel data]},
  timestamp = {2013.10.07},
}

@InProceedings{Trautman2010,
  Title                    = {Unfreezing the robot: Navigation in dense, interacting crowds},
  Author                   = {P. Trautman and A. Krause},
  Booktitle                = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2010},
  Pages                    = {797--803},

  Abstract                 = {In this paper, we study the safe navigation of a mobile robot through crowds of dynamic agents with uncertain trajectories. Existing algorithms suffer from the “freezing robot” problem: once the environment surpasses a certain level of complexity, the planner decides that all forward paths are unsafe, and the robot freezes in place (or performs unnecessary maneuvers) to avoid collisions. Since a feasible path typically exists, this behavior is suboptimal. Existing approaches have focused on reducing the predictive uncertainty for individual agents by employing more informed models or heuristically limiting the predictive covariance to prevent this overcautious behavior. In this work, we demonstrate that both the individual prediction and the predictive uncertainty have little to do with the frozen robot problem. Our key insight is that dynamic agents solve the frozen robot problem by engaging in “joint collision avoidance”: They cooperatively make room to create feasible trajectories. We develop IGP, a nonparametric statistical model based on dependent output Gaussian processes that can estimate crowd interaction from data. Our model naturally captures the non-Markov nature of agent trajectories, as well as their goal-driven navigation. We then show how planning in this model can be efficiently implemented using particle based inference. Lastly, we evaluate our model on a dataset of pedestrians entering and leaving a building, first comparing the model with actual pedestrians, and find that the algorithm either outperforms human pedestrians or performs very similarly to the pedestrians. We also present an experiment where a covariance reduction method results in highly overcautious behavior, while our model performs desirably.},
  Doi                      = {10.1109/IROS.2010.5654369},
  ISSN                     = {2153-0858},
  Keywords                 = {Gaussian processes;collision avoidance;mobile robots;robot vision;uncertain systems;IGP;collision avoidance;crowd interaction estimation;freezing robot problem;goal-driven navigation;human pedestrian;interacting Gaussian process;mobile robot;nonparametric statistical model;predictive covariance;robot navigation;safe navigation;uncertain trajectory},
  Timestamp                = {2016.07.27}
}

@InProceedings{Tritschler1999,
  Title                    = {Improved Speaker Segmentation and Segments Clustering using the Bayesian Information Criterion},
  Author                   = {Tritschler, A. and Gopinath, R. A.},
  Booktitle                = {Eurospeech},
  Year                     = {1999},
  Pages                    = {679--682},
  Volume                   = {99},

  Review                   = {Tritschler and Gopinath \cite{Tritschler1999} use the Bayesian information criterion (BIC) for segmentation. Given a set of models, the BIC is a test used to select the optimal model by selecting the one that results in the best likelihood, while minimizing over-fitting. It is calculated by:
%
\begin{align}
 BIC = -2 \log (L(\mu, \Sigma | x)) + k \log(N)
\end{align}
%
\noindent where $k$ is the number of free parameters used in model $L(\mu, \Sigma | x)$, and $N$ is the number of data points in observation $x$. An increase in $k$ would improve the likelihood value (the first term), but would also increase the chances of over-fitting (the second term). Different $k$ values can be used, and its BIC score evaluated. The lowest BIC score suggests that the corresponding $k$ value results in the most optimal fit. 

Tritschler and Gopinath \cite{Tritschler1999} note that BIC can be used if there are only two models, BIC becomes a test for model selection between the two models, to determine which model fits the data better. Two temporally adjacent windows is tested to see if a single Gaussian can best fit the data, or if each window requires its own Gaussian to be modeled optimally (See Figure \ref{fig:Delacourt2000_segmentModel}). If BIC declares that two Gaussians are needed, then a segment is declared. This algorithm was to applied an audio database of news broadcasts. $Ver_{temporal}$ is used, with a $t_{error}$ = 2s. They define two accuracy metrics, the missed detection rate, $Err_{MAR}$, and the false alarm rate, $Err_{FAR}$:
%
\begin{align}
 Err_{FAR} &= \frac{FP}{FP+TP+FN} \\
 Err_{MDR} &= \frac{FN}{TP+FN}
\end{align}
%
\noindent Tritschler and Gopinath \cite{Tritschler1999} report $Err_{MAR}$ of 24\% and $Err_{FAR}$ of 9\%.},
  Timestamp                = {2013.10.21}
}

@Article{Turaga2008,
  Title                    = {Machine Recognition of Human Activities: A Survey},
  Author                   = {Turaga, P. and Chellappa, R. and Subrahmanian, V. S. and Udrea, O.},
  Journal                  = {IEEE Transactions on Circuits and Systems for Video Technology},
  Year                     = {2008},
  Pages                    = {1473--1488},
  Volume                   = {18},

  Abstract                 = {The past decade has witnessed a rapid proliferation of video cameras in all walks of life and has resulted in a tremendous explosion of video content. Several applications such as content-based video annotation and retrieval, highlight extraction and video summarization require recognition of the activities occurring in the video. The analysis of human activities in videos is an area with increasingly important consequences from security and surveillance to entertainment and personal archiving. Several challenges at various levels of processing-robustness against errors in low-level processing, view and rate-invariant representations at midlevel processing and semantic representation of human activities at higher level processing-make this problem hard to solve. In this review paper, we present a comprehensive survey of efforts in the past couple of decades to address the problems of representation, recognition, and learning of human activities from video and related applications. We discuss the problem at two major levels of complexity: 1) "actions" and 2) "activities." "Actions" are characterized by simple motion patterns typically executed by a single human. "Activities" are more complex and involve coordinated actions among a small number of humans. We will discuss several approaches and classify them according to their ability to handle varying degrees of complexity as interpreted above. We begin with a discussion of approaches to model the simplest of action classes known as atomic or primitive actions that do not require sophisticated dynamical modeling. Then, methods to model actions with more complex dynamics are discussed. The discussion then leads naturally to methods for higher level representation of complex activities.},
  Doi                      = {10.1109/TCSVT.2008.2005594},
  ISSN                     = {1051-8215},
  Keywords                 = {content-based retrieval;human factors;image recognition;image representation;image sequences;content-based video annotation;human activity;low-level processing;machine recognition;midlevel processing;rate-invariant representations;semantic representation;video cameras;video summarization;Human activity analysis;image sequence analysis;machine vision;surveillance},
  Timestamp                = {2014.12.18}
}

@InProceedings{Turetsky2003,
  Title                    = {Ground-Truth Transcriptions of Real Music from Force-Aligned MIDI Syntheses},
  Author                   = {Turetsky, R. and Ellis, D.},
  Booktitle                = {Proceedings of the 4th International Symposium on Music Information Retrieval},
  Year                     = {2003},
  Pages                    = {135-141},

  Abstract                 = {Many modern polyphonic music transcription algorithms are presented in a statistical pattern recognition framework. But without a large corpus of real-world music transcribed at the note level, these algorithms are unable to take advantage of supervised learning methods and also have difficulty reporting a quantitative metric of their performance, such as a Note Error Rate.},
  Keywords                 = {dynamic time warping},
  Timestamp                = {2011.04.01}
}

@Article{Tzanetakis2002,
  Title                    = {Musical genre classification of audio signals},
  Author                   = {Tzanetakis, G. and Cook, P.},
  Journal                  = {IEEE transactions on Speech and Audio Processing},
  Year                     = {2002},
  Number                   = {5},
  Pages                    = {293--302},
  Volume                   = {10},

  Abstract                 = {Musical genres are categorical labels created by humans to characterize pieces of music. A musical genre is characterized by the common characteristics shared by its members. These characteristics typically are related to the instrumentation, rhythmic structure, and harmonic content of the music. Genre hierarchies are commonly used to structure the large collections of music available on the Web. Currently musical genre annotation is performed manually. Automatic musical genre classification can assist or replace the human user in this process and would be a valuable addition to music information retrieval systems. In addition, automatic musical genre classification provides a framework for developing and evaluating features for any type of content-based analysis of musical signals. In this paper, the automatic classification of audio signals into an hierarchy of musical genres is explored. More specifically, three feature sets for representing timbral texture, rhythmic content and pitch content are proposed. The performance and relative importance of the proposed features is investigated by training statistical pattern recognition classifiers using real-world audio collections. Both whole file and real-time frame-based classification schemes are described. Using the proposed feature sets, classification of 61% for ten musical genres is achieved. This result is comparable to results reported for human musical genre classification.},
  Publisher                = {IEEE},
  Review                   = {- music are labeled different genres
- uses an auto-classifier based on features
- no segmentation},
  Timestamp                = {2013.08.29}
}

@Article{Ude2010,
  Title                    = {Task-Specific Generalization of Discrete and Periodic Dynamic Movement Primitives},
  Author                   = {Ude, A. and Gams, A. and Asfour, T. and Morimoto, Jun},
  Journal                  = {Robotics, IEEE Transactions on},
  Year                     = {2010},

  Month                    = {Oct},
  Number                   = {5},
  Pages                    = {800-815},
  Volume                   = {26},

  Abstract                 = {Acquisition of new sensorimotor knowledge by imitation is a promising paradigm for robot learning. To be effective, action learning should not be limited to direct replication of movements obtained during training but must also enable the generation of actions in situations a robot has never encountered before. This paper describes a methodology that enables the generalization of the available sensorimotor knowledge. New actions are synthesized by the application of statistical methods, where the goal and other characteristics of an action are utilized as queries to create a suitable control policy, taking into account the current state of the world. Nonlinear dynamic systems are employed as a motor representation. The proposed approach enables the generation of a wide range of policies without requiring an expert to modify the underlying representations to account for different task-specific features and perceptual feedback. The paper also demonstrates that the proposed methodology can be integrated with an active vision system of a humanoid robot. 3-D vision data are used to provide query points for statistical generalization. While 3-D vision on humanoid robots with complex oculomotor systems is often difficult due to the modeling uncertainties, we show that these uncertainties can be accounted for by the proposed approach.},
  Doi                      = {10.1109/TRO.2010.2065430},
  ISSN                     = {1552-3098},
  Keywords                 = {humanoid robots;knowledge representation;motion estimation;nonlinear dynamical systems;robot vision;statistical analysis;3-D vision data;action learning;discrete dynamic movement primitive;humanoid robot;motor representation;nonlinear dynamic system;oculomotor system;perceptual feedback;periodic dynamic movement primitive;robot learning;sensorimotor knowledge;statistical generalization;statistical method;task specific feature;task specific generalization;vision system;Databases;Equations;Hidden Markov models;Mathematical model;Robots;Training;Trajectory;Active vision on humanoid robots;humanoid robots;imitation learning;learning and adaptive systems},
  Timestamp                = {2014.12.20}
}

@Article{Uicker1964,
  author    = {Uicker, J. J. Jr. and Denavit, J. and Hartenberg, R. S.},
  title     = {An Iterative Method for the Displacement Analysis of Spatial Mechanisms},
  journal   = {Journal of Applied Mechanics},
  year      = {1964},
  volume    = {31},
  number    = {2},
  pages     = {309--314},
  doi       = {10.1115/1.3629602},
  groups    = {EMBC2013},
  publisher = {ASME},
  review    = {Use this citaiton for DH},
  timestamp = {2012.09.01},
  url       = {http://link.aip.org/link/?AMJ/31/309/1},
}

@Article{Voegele2014,
  Title                    = {Efficient unsupervised temporal segmentation of human motion},
  Author                   = {V{\"o}gele, A. and Kr{\"u}ger, B. and Klein, R.},
  Journal                  = {ACM SIGGRAPH Symposium on Computer Animation},
  Year                     = {2014},

  Abstract                 = {This work introduces an efficient method for fully automatic temporal segmentation of human motion sequences
and similar time series. The method relies on a neighborhood graph to partition a given data sequence into distinct
activities and motion primitives according to self-similar structures given in that input sequence. In particular, the
fast detection of repetitions within the discovered activity segments is a crucial problem of any motion processing
pipeline directed at motion analysis and synthesis. The same similarity information in the neighborhood graph
is further exploited to cluster these primitives into larger entities of semantic significance. The elements subject
to this classification are then used as prior for estimating the same target values for entirely unknown streams of
data.
The technique makes no assumptions about the motion sequences at hand and no user interaction is required for
the segmentation or clustering. Tests of our techniques are conducted on the CMU and HDM05 motion capture
databases demonstrating the capability of our system handling motion segmentation, clustering, motion synthesis
and transfer-of-label problems in practice - the latter being an optional step which relies on the preexistence of a
small set of labeled data.},
  Publisher                = {Citeseer},
  Review                   = {Uses a 'lazy neighbourhood graph' (a substitute for DTW)
assessed again CMU and HDM05. reach 82% in some situations. 

want to determine 'distinct activiti'es (ie primitives), then detect such primitives

input: 
- uses mocap data, manually cropped into logical activity segments, then perform automated segmentation within it
 - creates a kd-tree: a tree constructed by taking a given frame and find other frames that have low Euclidean distance from it
 - the region of "associated" movement is used by growing the frame and build a self-similarity matrix, then removing the diagonal (since it'll always be similar to itself), and taking connected sectors as segment points
 - this method is used to replace DTW

-> good paper. should incorporate once we review it one more time},
  Timestamp                = {2015.06.29}
}

@InProceedings{Acht2007,
  Title                    = {Miniature Wireless Inertial Sensor for Measuring Human Motions},
  Author                   = {{v}an Acht, Victor and Bongers, Edwin and Lambert, Niek and Verberne, Rene},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2007},
  Pages                    = {6278--6281},

  Abstract                 = {A sensor system for measuring human motions is presented. The system consists of a number of miniature wireless inertial sensors that are attached to limbs of a person, and a PC with a wireless receiver that interprets and presents the measurement data. Each of the sensors measures 3D- acceleration, 3D-magnetization (earth magnetic field) and 3D- angular speed (gyroscopes). The data is transmitted via a proprietary protocol on an 802.15.4 radio. The angular accuracy of the calibrated system was found to be better than 3 degrees. The system is currently being applied in a pilot trial for motor rehabilitation of stroke patients.},
  Doi                      = {10.1109/IEMBS.2007.4353790},
  ISSN                     = {1557-170X},
  Keywords                 = {3D- acceleration;3D-angular speed;3D-magnetization;gyroscopes;human motions;limbs;miniature wireless inertial sensor;motor rehabilitation;proprietary protocol;stroke patients;wireless receiver;gyroscopes;magnetisation;patient rehabilitation;sensors;},
  Timestamp                = {2011.12.30}
}

@InProceedings{Vahdatpour2009,
  Title                    = {Toward Unsupervised Activity Discovery Using Multi-dimensional Motif Detection in Time Series},
  Author                   = {Vahdatpour, A. and Amini, N. and Sarrafzadeh, M.},
  Booktitle                = {Proceedings of the International Jont Conference on Artifical Intelligence},
  Year                     = {2009},
  Pages                    = {1261--1266},

  Abstract                 = {This paper addresses the problem of activity and event discovery in multi dimensional time series data by proposing a novel method for locating multi dimensional motifs in time series. While recent work has been done in finding single dimensional and multi dimensional motifs in time series, we address motifs in general case, where the elements of multi dimensional motifs have temporal, length, and frequency variations. The proposed method is validated by synthetic data, and empirical evaluation has been done on several wearable systems that are used by real subjects.},
  Acmid                    = {1661647},
  Review                   = {Motif discovery in time series. 
...

Actually, I don't know if this paper is talking about what I think it's talking about. Skipping...},
  Timestamp                = {2015.05.13}
}

@InProceedings{Valizadegan2007,
  Title                    = {A Prototype-driven Framework for Change Detection in Data Stream Classification},
  Author                   = {Valizadegan, H. and Tan, P.-N.},
  Booktitle                = {IEEE Symposium on Computational Intelligence and Data Mining},
  Year                     = {2007},
  Pages                    = {88--95},

  Abstract                 = {This paper presents a prototype-driven framework for classifying evolving data streams. Our framework uses cluster prototypes to summarize the data and to determine whether the current model is outdated. This strategy of rebuilding the model only when significant changes are detected helps to reduce the computational overhead and the amount of labeled examples needed. To improve its accuracy, we also propose a selective sampling strategy to acquire more labeled examples from regions where the model's predictions are unreliable. Our experimental results demonstrate the effectiveness of the proposed framework, both in terms of reducing the amount of model updates and maintaining high accuracy},
  Doi                      = {10.1109/CIDM.2007.368857},
  Keywords                 = {pattern classification;pattern clustering;change detection;cluster prototypes;data stream classification;data summarization;model updates;prototype-driven framework;selective sampling;Classification algorithms;Clustering algorithms;Computational intelligence;Computer science;Data mining;Partitioning algorithms;Predictive models;Prototypes;Sampling methods;Streaming media;SSLs},
  Review                   = {- new datapoints are merged into (kmeans/SOM) clusters, and the cluster distro is updated
- if the distance is too far from any current cluster, a new cluster is made and given the label of the existing cluster
- more samples are drawn from spaces where misclassification occurs (boosting-like concepts)
-},
  Timestamp                = {2015.05.12}
}

@InProceedings{Vallejo2013,
  Title                    = {Artificial Neural Networks As an Alternative to Traditional Fall Detection Methods},
  Author                   = {Vallejo, M. and Isaza, C. V. and Lopez, J. D.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {Falls are common events among older adults and may have serious consequences. Automatic fall detection systems are becoming a popular tool to rapidly detect such events, helping family or health personal to rapidly help the person that falls. This paper presents the results obtained in the process of testing a new fall detection method, based on Artificial Neural Networks (ANN). This method intends to improve fall detection accuracy, by avoiding the traditional threshold – based fall detection methods, and introducing ANN as a suitable option on this application. Also ANN have low computational cost, this characteristic makes them easy to implement on a portable device, comfortable to be wear by the patient},
  Keywords                 = {EMBC2013},
  Review                   = {General approaches are employed for fall detection employs wearable devices, to detect the fall. Commonly, accelerometers are used, employing threshold-based, looking at speed, acceleration, incline, for example. However, these methods may confuse normal everyday movements, such as sitting down quickly, with fall events. 

A hip-mounted accel measures movement. Integrate over the previous 10 timesteps, in all 3 directions. A NN i used to determine if it is a normal activity or a fall. 3 layers of 5 neurons are used (though no justification is given). Low number of false alarms.},
  Timestamp                = {2013.07.30}
}

@InProceedings{Valtazanos2010,
  Title                    = {Comparative study of segmentation of periodic motion data for mobile gait analysis},
  Author                   = {Valtazanos, A. and Arvind, D. K. and Ramamoorthy, S.},
  Booktitle                = {Wireless Health},
  Year                     = {2010},
  Pages                    = {145--154},

  Abstract                 = {Two approaches are presented and compared for segmenting motion data from on-body Orient wireless motion capture system for mobile gait analysis. The first is a basic, model-based algorithm which operates directly on the joint angles computed by the Orient sensor devices. The second is a model-free, Latent Space algorithm, which first aggregates all the sensor data, and then embeds them in a low-dimensional manifold to perform segmentation. The two approaches are compared for segmenting four different styles of walking, and then applied in a hospital-based clinical study for analysing the motion of elderly patients recovering from a fall.},
  Acmid                    = {1921099},
  ISBN                     = {978-1-60558-989-3},
  Keywords                 = {gait analysis, motion segmentation, wireless sensor networks},
  Location                 = {San Diego, California},
  Numpages                 = {10},
  Review                   = {This paper proposes two gait segmentation algorithms, based on the measurements of three 3-axes accelerometer, gyroscope and magnetometer. The joint angles and limb position are calculated from the IMUs and used in the segmentation. The first algorithm takes a greedy approach by identifying local minima and maxima in periodic gait to determine the subject's gait cycle. However, this method is prone to false positives from sensor noise and it is difficult to determine which of the three sensors should be weighted the highest when different joint angles produces different locations for local peaks. Isomap is used to reduce the exemplar a singular dimension system, and local minima and maxima search is applied to the reduced data. The paper estimated the average period length and standard deviation of gait characteristics over the different subjects observed, but provided no segmentation accuracy.

Valtazanos \etal \cite{Valtazanos2010} use Isomap to reduce the input space of gait data to a single DOF, then segmented when this DOF crosses zero.},
  Timestamp                = {2011.06.15}
}

@Conference{VanAntwerp2009,
  author    = {Van Antwerp, W.},
  title     = {Insulin for Implantable Pumps},
  booktitle = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  year      = {2009},
  abstract  = {Implantable devices require biotechnology drugs with a variety of properties. In this paper we discuss some of the more challenging issues with implantable devices.},
  groups    = {EMBS2009},
  review    = {Very biochem.},
  timestamp = {2009.12.01},
}

@Article{VanderMaaten2009,
  Title                    = {Dimensionality Reduction: A Comparative Review},
  Author                   = {Van der Maaten, L. J. P. and Postma, E. O. and Van Den Herik, H. J.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2009},
  Pages                    = {1--41},
  Volume                   = {10},

  Publisher                = {Citeseer},
  Timestamp                = {2014.01.22}
}

@InProceedings{Vanderwater2009,
  Title                    = {A dynamic control approach to studying the effectiveness of rewards in inducing behavior and attitude change},
  Author                   = {Vanderwater, R. and Davison, D.E.},
  Booktitle                = {Proceedings of the IEEE International Conference on Control and Automation},
  Year                     = {2009},
  Month                    = {dec.},
  Pages                    = {1062 -1067},

  Doi                      = {10.1109/ICCA.2009.5410599},
  Keywords                 = {attitude change;dynamic control;dynamic feedback model;induced compliance paradigm of cognitive dissonance theory;overjustification effect;planned behavior theory;rewards;incentive schemes;psychology;},
  Timestamp                = {2011.11.30}
}

@InCollection{Varadarajan2009,
  author    = {Varadarajan, B. and Reiley, C. and Lin, H. and Khudanpur, S. and Hager, G.},
  title     = {Data-Derived Models for Segmentation with Application to Surgical Assessment and Training},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention},
  publisher = {Springer Berlin / Heidelberg},
  year      = {2009},
  editor    = {Yang, Guang-Zhong and Hawkes, David and Rueckert, Daniel and Noble, Alison and Taylor, Chris},
  series    = {Lecture Notes in Computer Science},
  pages     = {426--434},
  address   = {Berlin, Germany},
  abstract  = {This paper addresses automatic skill assessment in robotic minimally invasive surgery. Hidden Markov models (HMMs) are developed for individual surgical gestures (or surgemes) that comprise a typical bench-top surgical training task. It is known that such HMMs can be used to recognize and segment surgemes in previously unseen trials [1]. Here, the topology of each surgeme HMM is designed in a data-driven manner, mixing trials from multiple surgeons with varying skill levels, resulting in HMM states that model specific sub-gestures. The sequence of HMM states visited while performing a surgeme are therefore indicative of the surgeon’s skill level. This expectation is confirmed by the average edit distance between the state-level “transcripts” of the same surgeme performed by two surgeons with di?erent expertise levels. Some surgemes are further shown to be more indicative of skill than others.},
  groups    = {Lit Review 2013-09, IROS2014},
  review    = {Tele-op surgical data was collected from several surgeons. They manually labeled individual components ("surgeme"), and has at least 4 different components. This data is used to train the classifiers.The goal is to use a surgeme recog system that would generate a surgeme transcript and timestamps of when these occured. Cross-validation occured.

LDA dim reduction was applied to reduce the dim from 78 to 3-10. This reduced system is used everywhere. Training is done to a HMM. Each surgeme is modeled by an HMM of n states, and so there are several different sugeme HMMs. Viberbi is used to determine the most likely path (ie offline alg), and the surgeme seq and time stamps are produced by that. 

3 state left-to-right HMM used initially. They used something called successive state splitting, which starts iwth a 1-state HMM, and incriment the state count (BIC based?) until they have a good fit. I think. They use a 6-state system (but tested with 1- and 3-states), and show that LDA dim=20 reports highest accuracy.

Each timestep is labeled as a surgeme. 87% accuracy.

Varadarajan \etal \cite{Varadarajan2009} collected tele-operative surgical data from several surgeons, which consists of several different components, termed 'surgemes'. The goal is to create a surgeme recognition system that would generate a surgeme transcript and accompanying timestamps. The algorithm first applied LDA dimensionality reduction to reduce the system down from 78 DOFs. Each surgeme was modeled by an HMM, and Viterbi was used to determine the most likely path. The surgeme sequence and timestamps were produced by the Viterbi algorithm. Recognition accuracy of 87\% reported.

Varadarajan \etal \cite{Varadarajan2009} collected tele-operative surgical data from several surgeons, consisting of several different sequential motion primitives, termed 'surgemes'. The goal is to create a surgeme recognition system that would generate a surgeme transcript and accompanying timestamps. The algorithm first applied linear discriminant analysis (LDA) dimensionality reduction to reduce the dimensionality down from 78 DOFs to 3-10 DOFs. Each surgeme was modeled by an HMM, with each state representing a sub-gesture, termed 'dexemes', and Viterbi was used to determine the most likely path. The dexemes sequence and timestamps were produced by the Viterbi algorithm. Data was collected via the da Vinci surgical tele-operative surgical system, from 8 surgeons. $Ver_{AllPoints}$ is used, with a reported $Acc_{Class}$ of 87\%.},
  timestamp = {2010.09.24},
}

@Article{Varkey2011,
  Title                    = {Human motion recognition using a wireless sensor-based wearable system},
  Author                   = {Varkey, John and Pompili, Dario and Walls, Theodore},
  Journal                  = {Personal and Ubiquitous Computing},
  Year                     = {2011},
  Pages                    = {1-14},

  Abstract                 = {The future of human computer interaction systems lies in how intelligently these systems can take into account the user’s context. Research on recognizing the daily activities of people has progressed steadily, but little focus has been devoted to recognizing jointly activities as well as movements in a specific activity. For many applications such as rehabilitation, sports medicine, geriatric care, and health/fitness monitoring the importance of combined recognition of activity and movements can drive health care outcomes. A novel algorithm is proposed that can be tuned to recognize on-the-fly range of activities and fine movements within a specific activity. Performance of the algorithm and a case study on obtaining optimal features from sensor and parameter values for the algorithm to detect fine motor movements are presented.},
  Affiliation              = {Department of Electrical and Computer Engineering, Rutgers University, New Brunswick, NJ, USA},
  ISSN                     = {1617-4909},
  Keyword                  = {Computer Science},
  Publisher                = {Springer London},
  Timestamp                = {2012.01.01},
  Url                      = {http://dx.doi.org/10.1007/s00779-011-0455-4}
}

@Article{Vathsangam2011,
  Title                    = {Determining Energy Expenditure from Treadmill Walking using Hip-Worn Inertial Sensors: An Experimental Study},
  Author                   = {Vathsangam, H. and Emken, A. and Spruijt-Metz, D. and Schroeder, E. and Sukhatme, G.},
  Journal                  = {IEEE Transactions on Biomedical Engineering},
  Year                     = {2011},

  Month                    = { },
  Number                   = {99},
  Pages                    = {1},
  Volume                   = {PP},

  Abstract                 = {We describe an experimental study to estimate energy expenditure during treadmill walking using a single hip-mounted inertial sensor ( triaxial accelerometer and triaxial gyroscope). Typical physical activity characterization using commercial monitors use proprietary counts that do not have a physically interpretable meaning. This paper emphasizes the role of probabilistic techniques in conjunction with inertial data modeling to accurately predict energy expenditure for steady-state treadmill walking. We represent the cyclic nature of walking with a Fourier transform and show how to map this representation to energy expenditure ( _V O2, mL/min) using three regression techniques. A comparative analysis of the accuracy of sensor streams in predicting energy expenditure reveals that using triaxial information leads to more accurate energy expenditure prediction compared to only using one axis. Combining accelerometer and gyroscope information leads to improved accuracy compared to using either sensor alone. Nonlinear regression methods showed better prediction accuracy compared to linear methods but required an order of higher magnitude run time.},
  Doi                      = {10.1109/TBME.2011.2159840},
  ISSN                     = {0018-9294},
  Keywords                 = {Accelerometer , Energy expenditure , Gyroscope , Treadmill walking , Wearable sensors},
  Timestamp                = {2011.07.19}
}

@InProceedings{Veeraraghavan2006,
  Title                    = {The Function Space of an Activity},
  Author                   = {Veeraraghavan, A. and Chellappa, R. and Roy-Chowdhury, A.K.},
  Booktitle                = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  Year                     = {2006},
  Pages                    = {959-968},
  Volume                   = {1},

  Abstract                 = {An activity consists of an actor performing a series of actions in a pre-defined temporal order. An action is an individual atomic unit of an activity. Different instances of the same activity may consist of varying relative speeds at which the various actions are executed, in addition to other intra- and inter- person variabilities. Most existing algorithms for activity recognition are not very robust to intra- and inter-personal changes of the same activity, and are extremely sensitive to warping of the temporal axis due to variations in speed profile. In this paper, we provide a systematic approach to learn the nature of such time warps while simultaneously allowing for the variations in descriptors for actions. For each activity we learn an ‘average’ sequence that we denote as the nominal activity trajectory. We also learn a function space of time warpings for each activity separately. The model can be used to learn individualspecific warping patterns so that it may also be used for activity based person identification. The proposed model leads us to algorithms for learning a model for each activity, clustering activity sequences and activity recognition that are robust to temporal, intra- and inter-person variations. We provide experimental results using two datasets.},
  Doi                      = {10.1109/CVPR.2006.304},
  ISSN                     = {1063-6919},
  Keywords                 = {Animation;Anthropometry;Biological system modeling;Clustering algorithms;Data security;Educational institutions;Humans;Legged locomotion;Robustness;Surveillance},
  Timestamp                = {2014.12.22}
}

@InProceedings{Venture2009,
  Title                    = {A numerical method for choosing motions with optimal excitation properties for identification of biped dynamics: an application to human},
  Author                   = {Venture, G. and Ayusawa, K. and Nakamura, Y.},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2009},
  Pages                    = {546--551},

  Abstract                 = {Identification results dramatically depend on the excitation properties of the motion used to sample the identification model. Strategies to define persistent exciting trajectories have been developed for manipulator robots with few DOF. However they can not easily be extended to humanoid systems and humans due to the important number of DOF; and empirical knowledge is often used to generate and select persistent exciting motions. In this paper we propose a method to choose persistent exciting motions from an existing dataset in order to optimize both the identification results and the computation time. This method is based on the use of the identification model of legged systems obtained from the base-link equations. Instead of using well-established consideration on the condition number of the regressor matrix, the method uses a decomposition of the regressor into elementary subregressors and the computation of the condition number for each. A selection rule is then proposed. The overall method is experimentally tested to identify the human body inertial parameters using a data-set of 40 motions. Comparative results obtained from different combinations of motions are given.},
  Acmid                    = {1703524},
  ISBN                     = {978-1-4244-2788-8},
  Keywords                 = {ECE780, System identification},
  Location                 = {Kobe, Japan},
  Numpages                 = {6},
  Review                   = {In Ayusawa2008, equations for parameter identification were determined and tested. However, for parameter identification to work properly, all the dynamic coefficients needs to be properly excited. Typically, this is done with statistics, linear algebra and kinematics. However, this is difficult to do for systems with high DOFs. We would also like to avoid unstable postures in robots. On humans, it is difficult for people to perform arbitrary motion. 

This paper proposes looking at the condition number of a given motion (“the regressor”) and the condition number of its sub-matrices. If these condition numbers are beneath some threshold, the motion is used for trajectory excitation. 

Though, they weren't able to promise that motions would properly excite all parameters.},
  Timestamp                = {2011.01.23}
}

@InProceedings{Venture2009_ISSI,
  Title                    = {Identification of human mass properties from motion},
  Author                   = {Venture, G. and Ayusawa, K. and Nakamura, Y.},
  Booktitle                = {Proceedings of the IFAC Conference on System Identification},
  Year                     = {2009},

  Timestamp                = {2016.03.08}
}

@InProceedings{Venture2008,
  Title                    = {Motion capture based identification of the human body inertial parameters},
  Author                   = {Venture, G. and Ayusawa, K. and Nakamura, Y.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2008},
  Pages                    = {4575--4578},

  Abstract                 = {Identification of body inertia, masses and center of mass is an important data to simulate, monitor and understand dynamics of motion, to personalize rehabilitation programs. This paper proposes an original method to identify the inertial parameters of the human body, making use of motion capture data and contact forces measurements. It allows in-vivo painless estimation and monitoring of the inertial parameters. The method is described and then obtained experimental results are presented and discussed.},
  Doi                      = {10.1109/IEMBS.2008.4650231},
  ISSN                     = {1557-170X},
  Keywords                 = {Algorithms;Artifacts;Biomechanics;Computer Systems;Humans;Image Enhancement;Image Processing, Computer-Assisted;Models, Anatomic;Models, Biological;Models, Statistical;Movement;Reproducibility of Results;Software;Video Recording;},
  Timestamp                = {2011.06.10}
}

@TechReport{Veth2007,
  Title                    = {Alignment and Calibration of Optical and Inertial Sensors Using Stellar Observations},
  Author                   = {Veth, M. and Raquet, J.},
  Institution              = {Air Force Institute of Techology},
  Year                     = {2007},

  Abstract                 = {Aircraft navigation information (position, velocity, and attitude) can be determined using optical measurements from an imaging sensor pointed toward the ground combined with an inertial navigation system. A critical factor governing the level of accuracy achievable in such a system is the alignment and calibration of the sensors. Currently, alignment accuracy is limited by machining and mounting tolerances for low-cost applications. In this paper, a novel alignment and calibration method is proposed which combines inertial and stellar observations using an extended Kalman filter algorithm. The approach is verified using simulation and experimental data, and conclusions regarding alignment accuracy versus sensor quality are drawn.},
  Review                   = {- Don't want to use additional equipment that makes calibration on the field difficult
- Uh. So they actually do use star positions...only the military would have that kind of equipment, I guess...},
  Timestamp                = {2011.07.19}
}

@Article{Vicente2007,
  author    = {Vicente, I. S. and Kyrki, V. and Kragic, D. and Larsson, M.},
  title     = {Action Recognition and Understanding Through Motor Primitives},
  journal   = {Advanced Robotics},
  year      = {2007},
  volume    = {21},
  pages     = {1687--1707},
  groups    = {Lit Review 2013-09, IROS2014},
  publisher = {Taylor \& Francis},
  review    = {Tested system on 10 people, and their grasping methods. Want to perform imitiation learning from demonstration. Uses SVM to model/recog primitives. Primitive seq modeled using HMM. Used left-right HMMs, to represent their models via two different movement archetecture. By having a flexible architecture, they can add inbetween states to bridge between the approach and release phase of a grasping motion. [unsure] it seems like each small action is a state in HMM, and the heirachy is represented by a connected HMM. 

Training data labeled manually. 

The classic flat style of representing motion led to a lot of general confusion if two motions are similar. The entire feature vector is used as input into SVM, and got okay results. The output of the SVM is fed into HMM and Viterbi'ed for segmentation, but didn't perform well.

They then tried their heirarchical approach and found that the labeling accuracy improved, but still had some major labeling errors (on "move-side")

They then removed "move-side" from the training data tried it again. They find that "move-side" input data can be presented as a chain of approach-grasp-pushside-remove, and labeled it at 62.5%, which is not bad given the lack of training data specifically for move-side. Average accuracy of around high 80s%



Excerpt: "The primitives are recognized by an SVM and its
output is then fed to an HMM which describes the time evolution. SVMs were chosen as they have been
demonstrated with great success in many multidimensional classication problems where the training
set is relatively sparse. As the true action primitives are known, SVMs can be directly trained. Regular
and hidden Markov models are then used to describe the temporal sequence of primitives. Regular
Markov models can be used in the training phase since the true class is observ able, while in the test
phase the action is recognized by the Viterbi algorithm as the true states are then hidden and only
the SVM output is av ailable."

Ganapathiraju \etal \cite{Ganapathiraju2004} and Vicente \etal \cite{Vicente2007} both use SVM and HMM hybrids in a similar fashion. The training data is used to train SVMs, and the SVM is used to model and recognize movement primitives. The SVM outputs are used as the feature vectors for the HMM, and the primitive sequences is represented by the HMM state evolution. The Viterbi algorithm is then employed to determine the segments. Vicente \cite{Vicente2007} obtained an average $Acc_{Class}$ of 85\%, in a series of grasping and reaching tasks by 10 people.},
  timestamp = {2013.10.08},
}

@Misc{ViconTracker,
  Title                    = {VICON Cameras},

  Author                   = {{Vicon Motion Systems Ltd.}},
  HowPublished             = {www.vicon.com},
  Year                     = {1984},

  Timestamp                = {2015.01.29}
}

@InProceedings{Vijayakumar2000,
  Title                    = {Locally weighted projection regression: An o(n) algorithm for incremental real time learning in high dimensional space},
  Author                   = {Vijayakumar, S. and Schaal, S.},
  Booktitle                = {Proceedings of the 17th International Conference on Machine Learning},
  Year                     = {2000},
  Pages                    = {1079--1086},
  Volume                   = {2000},

  Abstract                 = {{Locally weighted projection regression is a new algorithm that achieves nonlinear function approximation in high dimensional spaces with redundant and irrelevant input dimensions. At its core, it uses locally linear models, spanned by a small number of univariate regressions in selected directions in input space. This paper evaluates different methods of projection regression and derives a nonlinear function approximator based on them. This nonparametric local learning system i) learns rapidly with second order learning methods based on incremental training, ii) uses statistically sound stochastic cross validation to learn iii) adjusts its weighting kernels based on local information only, iv) has a computational complexity that is linear in the number of inputs, and v) can deal with a large number of- possibly redundant- inputs, as shown in evaluations with up to 50 dimensional data sets. To our knowledge, this is the first truly incremental spatially localized learning method to combine all these properties. 1.}},
  Citeulike-article-id     = {6352572},
  Citeulike-linkout-0      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.63.4252},
  Keywords                 = {learning},
  Posted-at                = {2009-12-11 11:29:23},
  Priority                 = {2},
  Timestamp                = {2011.02.19},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.63.4252}
}

@Article{Vinh2011,
  Title                    = {Semi-Markov conditional random fields for accelerometer-based activity recognition},
  Author                   = {Vinh, LaThe and Lee, Sungyoung and Le, HungXuan and Ngo, HungQuoc and Kim, HyoungIl and Han, Manhyung and Lee, Young-Koo},
  Journal                  = {Applied Intelligence},
  Year                     = {2011},
  Number                   = {2},
  Pages                    = {226-241},
  Volume                   = {35},

  Abstract                 = {Activity recognition is becoming an important research area, and finding its way to many application domains ranging from daily life services to industrial zones. Sensing hardware and learning algorithms are two important components in activity recognition. For sensing devices, we prefer to use accelerometers due to low cost and low power requirement. For learning algorithms, we propose a novel implementation of the semi-Markov Conditional Random Fields (semi-CRF) introduced by Sarawagi and Cohen. Our implementation not only outperforms the original method in terms of computation complexity (at least 10 times faster in our experiments) but also is able to capture the interdependency among labels, which was not possible in the previously proposed model. Our results indicate that the proposed approach works well even for complicated activities like eating and driving a car. The average precision and recall are 88.47% and 86.68%, respectively, which are higher than results obtained by using other methods such as Hidden Markov Model (HMM) or Topic Model (TM).},
  Doi                      = {10.1007/s10489-010-0216-5},
  ISSN                     = {0924-669X},
  Keywords                 = {Activity recognition; Wearable sensors; Accelerometer; Hidden Markov Model (HMM); Conditional Random Fields (CRF)},
  Language                 = {English},
  Publisher                = {Springer US},
  Timestamp                = {2014.12.22},
  Url                      = {http://dx.doi.org/10.1007/s10489-010-0216-5}
}

@Article{Vlasic2007,
  Title                    = {Practical motion capture in everyday surroundings},
  Author                   = {Vlasic, D. and Adelsberger, R. and Vannucci, G. and Barnwell, J. and Gross, M. and Matusik, W. and Popovi\'{c}, J.},
  Journal                  = {ACM Transactions on Graphics},
  Year                     = {2007},
  Number                   = {3},
  Pages                    = {35},
  Volume                   = {26},

  Abstract                 = {Commercial motion-capture systems produce excellent in-studio reconstructions, but offer no comparable solution for acquisition in everyday environments. We present a system for acquiring motions almost anywhere. This wearable system gathers ultrasonic time-of-flight and inertial measurements with a set of inexpensive miniature sensors worn on the garment. After recording, the information is combined using an Extended Kalman Filter to reconstruct joint configurations of a body. Experimental results show that even motions that are traditionally difficult to acquire are recorded with ease within their natural settings. Although our prototype does not reliably recover the global transformation, we show that the resulting motions are visually similar to the original ones, and that the combined acoustic and intertial system reduces the drift commonly observed in purely inertial systems. Our final results suggest that this system could become a versatile input device for a variety of augmented-reality applications.},
  Address                  = {New York, NY, USA},
  Doi                      = {http://doi.acm.org.proxy.lib.uwaterloo.ca/10.1145/1276377.1276421},
  ISSN                     = {0730-0301},
  Keywords                 = {Postural detection},
  Publisher                = {ACM},
  Review                   = {Want to get the technology out of the lab and into real life. They want to design a self-contained wearable solution, with priorty on comfort, low power usage. Relies on acoustic (microphones, to tell distance between sensors) and inertial (accel and gyro) information. Uses an Extended Kalman. Algorithm was designed to reconstruct the entire body. It's a work-in-progress, but they claim that it should be pretty good.},
  Timestamp                = {2010.01.17}
}

@Article{Vukobratovic2004,
  Title                    = {Zero-moment point-thirty five years of its life},
  Author                   = {Vukobratovic, M. and Borovac, B.},
  Journal                  = {International Journal of Humanoid Robotics},
  Year                     = {2004},
  Number                   = {1},
  Pages                    = {157-173},
  Volume                   = {1},

  Abstract                 = {This paper is devoted to the permanence of the concept of Zero-Moment Point, widely-known by the acronym ZMP. Thirty-?ve years have elapsed since its implicit presentation (actually before being named ZMP) to the scienti?c community and thirty-three years since it was explicitly introduced and clearly elaborated, initially in the leading journals published in English. Its ?rst practical demonstration took place in Japan in 1984, at Waseda University, Laboratory of Ichiro Kato, in the first dynamically balanced robot WL-10RD of the robotic family WABOT. 

The paper gives an in-depth discussion of source results concerning ZMP, paying particular attention to some delicate issues that may lead to confusion if this method is applied in a mechanistic manner onto irregular cases of arti?cial gait, i.e. in the case of loss of dynamic balance of a humanoid robot. After a short survey of the history of the origin of ZMP a very detailed elaboration of ZMP notion is given, with a special review concerning “boundary cases” when the ZMP is close to the edge of the support polygon and “?ctious cases” when the ZMP should be outside the support polygon. In addition, the di?erence between ZMP and the center of pressure is pointed out. Finally, some unresolved or insufficient treated phenomena that may yield a signi?cant improvement in robot performance are considered.},
  Abstractnote             = {This paper is devoted to the permanence of the concept of Zero-Moment Point, widelyknown by the acronym ZMP. Thirty-five years have elapsed since its implicit presentation (actually before being named ZMP) to the scientific community and thirty-three years since it was explicitly introduced and clearly elaborated, initially in the leading journals published in English. Its first practical demonstration took place in Japan in 1984, at Waseda University, Laboratory of Ichiro Kato, in the first dynamically balanced robot WL-10RD of the robotic family WABOT. The paper gives an in-depth discussion of source results concerning ZMP, paying particular attention to some delicate issues that may lead to confusion if this method is applied in a mechanistic manner onto irregular cases of artificial gait, i.e. in the case of loss of dynamic balance of a humanoid robot. After a short survey of the history of the origin of ZMP a very detailed elaboration of ZMP notion is given, with a special review concerning boundary cases when the ZMP is close to the edge of the support polygon and fictious cases when the ZMP should be outside the support polygon. In addition, the difference between ZMP and the center of pressure is pointed out. Finally, some unresolved or insufficiently treated phenomena that may yield a significant improvement in robot performance are considered.},
  Keywords                 = {ECE780, ZMP},
  Publisher                = {Citeseer},
  Review                   = {NOVELTY
Overview paper on proper use of ZMP, which, over the years, have deviated from the original definition as intended from its inventor

CRITIQUE SUMMARY 
This paper aims to correct and clarify “inappropriate understanding of [zero-moment point (ZMP) concepts], especially by younger researchers,” by providing an overview of ZMP and its misunderstandings. 

Bipeds gait characteristics are cyclic (repeated), alternating between single (one foot on the ground, open kinematics) and double (two foot on the ground, closed kinematics) support phase. ZMP is the point inside the support polygon where, if the total vertical forces (ground reaction force) on the biped was there, x-axis and y-axis (so non-vertical axes) moments would equal zero. If the support polygon does not contain the ZMP, the ground reaction force would act on the foot edge and have non-zero x-axis or y-axis motion, causing rotation on the biped, which will lead to falling. 
If the calculated ZMP is not within the support polygon, then that location is termed Fictitious ZMP (FZMP), and the biped in that position does not have a real ZMP. The ground reaction force acting point would be on the edge of the support polygon closest to the FZMP and the biped would experience a rotational torque about polygon edge. We're assuming max friction and not thinking about slipping situations.


Lastly, the paper notes that ZMP = COP (Centre of Pressure) if the biped is dynamically balanced, otherwise ZMP does not exist. Ways to prevent falling over when FZMP exists are: move upper body dynamics to shift FZMP back into support polygon, widen stride to increase support polygon size, to grab some surface to prevent falling over, or to go into quadruped formation.},
  Timestamp                = {2011.01.28},
  Url                      = {http://scholar.google.com/scholar?cluster=5120146553564800242}
}

@InProceedings{Wachter2015,
  Title                    = {Hierarchical segmentation of manipulation actions based on object relations and motion characteristics},
  Author                   = {W\"{a}chter, M. and Asfour, T.},
  Booktitle                = {Proceedings of the IEEE International Conference on Advanced Robotics},
  Year                     = {2015},
  Month                    = {July},
  Pages                    = {549-556},

  Abstract                 = {Understanding human actions is an indispensable capability of humanoid robots which acquire task knowledge from human demonstration. Segmentation of such continuous demonstrations into meaningful segments reduces the complexity of understanding an observed task. In this paper, we propose a two-level hierarchical action segmentation approach which considers semantics of an action in addition to human motion characteristics. On the first level, a semantic segmentation is performed based on contact relations between human end-effectors, the scene, and between objects in the scene. On the second level, the semantic segments are further sub-divided based on a novel heuristic that incorporates the motion characteristics into the segmentation procedure. As input for the segmentation, we present an observation method for tracking the human as well as the objects and the environment. 6D pose trajectories of the human's hands and all objects are extracted in a precise and robust manner from data of a marker-based tracking system. We evaluated and compared our approach with a manual reference segmentation and well-known segmentation algorithms based on PCA and zero-velocity-crossings using 13 human demonstrations of daily activities.We show that significantly smaller segmentation errors are achieved with our approach while providing the necessary granularity for representing human demonstrations.},
  Doi                      = {10.1109/ICAR.2015.7251510},
  Keywords                 = {end effectors;humanoid robots;motion control;position control;principal component analysis;trajectory control;6D pose trajectories;PCA;human actions;human demonstration;human end-effectors;human motion characteristics;humanoid robots;manipulation actions;manual reference segmentation;marker-based tracking system;motion characteristics;object relations;task knowledge;two-level hierarchical action segmentation approach;zero-velocity-crossings;Trajectory;Visualization},
  Owner                    = {jf2lin},
  Timestamp                = {2015.12.07}
}

@InProceedings{Wachter2013,
  Title                    = {Action Sequence Reproduction based on Automatic Segmentation and Object-Action Complexes},
  Author                   = {M. W\"{a}chter and S. Schulz and T. Asfour and E. E. Aksoy and F. W\"{o}rg\"{o}tter and R. Dillmann},
  Booktitle                = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  Year                     = {2013},
  Pages                    = {189--195},

  Timestamp                = {2017.01.02}
}

@Article{Worgotter2013,
  Title                    = {A Simple Ontology of Manipulation Actions Based on Hand-Object Relations},
  Author                   = {W\"{o}rg\"{o}tter, F. and Aksoy, E. E. and Kruger, N. and Piater, J. and Ude, A. and Tamosiunaite, M.},
  Journal                  = {IEEE Transactions on Autonomous Mental Development},
  Year                     = {2013},
  Pages                    = {117--134},
  Volume                   = {5},

  Abstract                 = {Humans can perform a multitude of different actions with their hands (manipulations). In spite of this, so far there have been only a few attempts to represent manipulation types trying to understand the underlying principles. Here we first discuss how manipulation actions are structured in space and time. For this we use as temporal anchor points those moments where two objects (or hand and object) touch or un-touch each other during a manipulation. We show that by this one can define a relatively small tree-like manipulation ontology. We find less than 30 fundamental manipulations. The temporal anchors also provide us with information about when to pay attention to additional important information, for example when to consider trajectory shapes and relative poses between objects. As a consequence a highly condensed representation emerges by which different manipulations can be recognized and encoded. Examples of manipulations recognition and execution by a robot based on this representation are given at the end of this study.},
  Doi                      = {10.1109/TAMD.2012.2232291},
  ISSN                     = {1943-0604},
  Keywords                 = {cognition;human-robot interaction;manipulators;ontologies (artificial intelligence);trees (mathematics);hand-object relations;human cognition;manipulation actions;manipulations execution;manipulations recognition;relative poses;temporal anchor points;trajectory shapes;tree-like manipulation ontology;Manipulation action;manipulation ontology;scene graph;semantic event chain},
  Review                   = {"Things" only becomes meaningful objects by it's use},
  Timestamp                = {2014.02.04}
}

@Article{Walters2008,
  Title                    = {Avoiding the uncanny valley: robot appearance, personality and consistency of behavior in an attention-seeking home scenario for a robot companion},
  Author                   = {Walters, M. and Syrdal, D. and Dautenhahn, K. and te Boekhorst, R. and Koay, K.},
  Journal                  = {Autonomous Robots},
  Year                     = {2008},
  Note                     = {10.1007/s10514-007-9058-3},
  Pages                    = {159-178},
  Volume                   = {24},

  Abstract                 = {This article presents the results of video-based Human Robot Interaction (HRI) trials which investigated people’s perceptions of different robot appearances and associated attention-seeking features and behaviors displayed by robots with different appearance and behaviors. The HRI trials studied the participants’ preferences for various features of robot appearance and behavior, as well as their personality attributions towards the robots compared to their own personalities. Overall, participants tended to prefer robots with more human-like appearance and attributes. However, systematic individual differences in the dynamic appearance ratings are not consistent with a universal effect. Introverts and participants with lower emotional stability tended to prefer the mechanical looking appearance to a greater degree than other participants. It is also shown that it is possible to rate individual elements of a particular robot’s behavior and then assess the contribution, or otherwise, of that element to the overall perception of the robot by people. Relating participants’ dynamic appearance ratings of individual robots to independent static appearance ratings provided evidence that could be taken to support a portion of the left hand side of Mori’s theoretically proposed ‘uncanny valley’ diagram. Suggestions for future work are outlined.},
  Affiliation              = {University of Hertfordshire Adaptive Systems Research Group, School of Computer Science College Lane, Hatfield Herts UK},
  ISSN                     = {0929-5593},
  Issue                    = {2},
  Keyword                  = {Computer Science},
  Keywords                 = {Human-robot interaction},
  Publisher                = {Springer Netherlands},
  Review                   = {- Used humaniod robot to interact with people after watching humans interact
 - robot wasn't super realistic...
- Not enough data collected to prove/disprove the uncanny valley
 - People in general like the more humanistic look than the mechanical look though
 - Typically disappointed from interacting with the robot -> doesn't do as much as they appear

20 pages long ><},
  Timestamp                = {2011.02.09},
  Url                      = {http://dx.doi.org/10.1007/s10514-007-9058-3}
}

@InBook{Wan2001_7,
  Title                    = {Kalman Filtering and Neural Networks},
  Author                   = {Wan, E. A. and van der Merwe, R.},
  Chapter                  = {The Unscented Kalman Filter},
  Editor                   = {S. Haykin},
  Publisher                = {John Wiley and Sons, Inc.},
  Year                     = {2001},

  Keywords                 = {filtering},
  Timestamp                = {2010.10.21},
  Url                      = {http://www.cslu.ogi.edu/nsel/ukf/test.html}
}

@InBook{Wan2001_5,
  chapter   = {Dual {EKF} Methods},
  pages     = {123--173},
  title     = {Kalman Filtering and Neural Networks},
  publisher = {John Wiley and Sons, Inc.},
  year      = {2001},
  author    = {Wan, E. A. and Nelson, A. T.},
  editor    = {Haykin, S.},
  groups    = {EMBC2013},
  keywords  = {filtering},
  review    = {EKF approximates maximum-likelihood estimates of the state of a discrete-time nonlinear dynamical system. It combines noisy observations with predictions from a model to do so. However, it is possible to use EKF for parameter estimation as well, hence dual-estimation: state estimation and parameter estimation, given observation. The EKF is an extension of the KF, which handles linear state-space systems with known model and Gaussian noise. It combines the predicted state (x) and the covariance (P) with measured observation (y) in a way that will minimize the mean square error (MMSE). It does so by balancing the "Kalman gain", which essentially tells the filter to trust either the prediction model more, or the measured observation more. However, as oppose to MMSE, we can also think of the KF as minimizing a given cost function.

EKF works by linearizing (first order) the non-linear equation, then pushing this result into the KF. We can also use the EKF to learn parameters from clean state/observations. So we could concurrently run two EKFs that will both estimate the state, which is then fed into the second EKF, which updates the model used. The largest problem with a system like this is there may be multiple combination of weightings that could result in a given dynamics, and that systems like the KF is very sensitive to initial values.},
  timestamp = {2010.10.21},
}

@InProceedings{Wang2003a,
  Title                    = {Speech segmentation without speech recognition},
  Author                   = {Wang, D. and Lu, L. and Zhang, H. J.},
  Booktitle                = {Acoustics, Speech, and Signal Processing, 2003. Proceedings.(ICASSP'03). 2003 IEEE International Conference on},
  Year                     = {2003},
  Organization             = {IEEE},
  Pages                    = {I--468},
  Volume                   = {1},

  Abstract                 = {In this paper, we presented a semantic speech segmentation approach, in particular sentence segmentation, without speech recognition. In order to get phoneme level information without word recognition information, a novel vowel/consonant/pause (V/C/P) classification is proposed. An adaptive pause detection method is also presented to adapt to various backgrounds and environments. Three feature sets, which include pause, rate of speech and prosody, are used to discriminate the sentence boundary. Experiments on broadcasting news indicate that the performance of the proposed algorithm is satisfying.},
  Review                   = {- Sppech seg by looking for vowel/consonant/pauses},
  Timestamp                = {2013.08.29}
}

@Article{Wang2003b,
  Title                    = {Recent developments in human motion analysis},
  Author                   = {Wang, L. and Hu, W. and Tan, T.},
  Journal                  = {Pattern Recognition},
  Year                     = {2003},
  Number                   = {3},
  Pages                    = {585 - 601},
  Volume                   = {36},

  Abstract                 = {Visual analysis of human motion is currently one of the most active research topics in computer vision. This strong interest is driven by a wide spectrum of promising applications in many areas such as virtual reality, smart surveillance, perceptual interface, etc. Human motion analysis concerns the detection, tracking and recognition of people, and more generally, the understanding of human behaviors, from image sequences involving humans. This paper provides a comprehensive survey of research on computer-vision-based human motion analysis. The emphasis is on three major issues involved in a general human motion analysis system, namely human detection, tracking and activity understanding. Various methods for each issue are discussed in order to examine the state of the art. Finally, some research challenges and future directions are discussed.},
  Doi                      = {DOI: 10.1016/S0031-3203(02)00100-0},
  ISSN                     = {0031-3203},
  Keywords                 = {Human motion analysis, detection, tracking, behavior understanding, semantic description, survey},
  Review                   = {A wide survey. Lots of focus on vision. We'll just focus on the stuff I care about. 

Dynamic time warping
- template based dynamic programming
- robust
- handles time scaling well

HMM
- stochastic state machine
- good for time-varying data with spatio-temporal variability
- better than DTW

Neural network

Look up
- VLMM (Variable Length Markov Model)},
  Timestamp                = {2011.01.27},
  Url                      = {http://www.sciencedirect.com/science/article/B6V14-4771RWD-2/2/41d0f27ca154e3140e27fdf68a9df519}
}

@Article{Wannier2001,
  Title                    = {Arm to leg coordination in humans during walking, creeping and swimming activities},
  Author                   = {Wannier, T. and Bastiaanse, C. and Colombo, G. and Dietz, V.},
  Journal                  = {Experimental Brain Research},
  Year                     = {2001},
  Pages                    = {375--379},
  Volume                   = {141},

  Abstract                 = {In walking humans, arm to leg coordination is a well established phenomenon. The origin of this coordination, however, remains a matter for debate. It could derive from the intrinsic organisation of the human CNS, but it could also consist of a movement induced epiphenomenon. In order to establish which of these alternatives applies, we recorded arm and leg movements as well as their muscle activities during walking, creeping on all fours and swimming. The relationship between arm and leg cycle frequency observed under these various conditions was then investigated. We found that during walking, creeping on all fours or swimming, arm and leg movements remain frequency locked with a fixed relationship of 1/1, 2/1, 3/1, 4/1 or 5/1. When movements of the legs are slowed by flippers, the frequency relationship may skip to a different value, but the coordination is preserved. Furthermore, minimising the mechanical interactions between the limbs does not abolish coordination. These findings demonstrate that the arm to leg coordination observed in the walking human is also present during other human locomotor activities. The characteristics of this coordination correspond to those of a system of two coupled oscillators like that underlying quadruped locomotion.},
  Affiliation              = {Department of Physiology, University of Fribourg, Rue du Musée 5, 1700 Fribourg, Switzerland},
  ISSN                     = {0014-4819},
  Issue                    = {3},
  Keyword                  = {Biomedical and Life Sciences},
  Publisher                = {Springer Berlin / Heidelberg},
  Review                   = {- Assessed motion with pots and surface EMG
- Looked at FFT of these signals
- Found coordination between arms and legs},
  Timestamp                = {2011.06.24},
  Url                      = {http://dx.doi.org/10.1007/s002210100875}
}

@Article{Watkins1991,
  Title                    = {Reliability of Goniometric Measurements and Visual Estimates of Knee Range of Motion Obtained in a Clinical Setting},
  Author                   = {Watkins, M. A. and Riddle, D. L. and Lamb, R. L. and Personius, W. J.},
  Journal                  = {Physical Therapy},
  Year                     = {1991},
  Number                   = {2},
  Pages                    = {90-96},
  Volume                   = {71},

  Abstract                 = {The purpose of this study was to examine the intratester and intertester reliability for goniometric measurements of knee flexion and extension passive range of motion (PROM). In addition, parallel-forms reliability for PROM measurements of the knee obtained by use of a goniometer and by visual estimation was examined. The intertester reliability for visual estimates of the PROM of the knee was also examined. Repeated measurements were obtained on 43 patients in a clinical setting. The intraclass correlation coefficients (ICCs) for intratester reliability of measurements obtained with a goniometer were .99 for flexion and .98 for extension. Intertester reliability for measurements obtained with a goniometer was .90 for flexion and .86 for extension. The ICCs for parallel-forms reliability for measurements obtained with a goniometer and by visual estimation ranged from .82 to .94. The intertester reliability for measurements obtained by visual estimation was .83 for flexion and .82 for extension. Results suggest clinicians should use a goniometer to take repeated PROM measurements of a patient's knee to minimize the error associated with these measurements.},
  Eprint                   = {http://ptjournal.apta.org/content/71/2/90.full.pdf+html},
  Timestamp                = {2013.12.10},
  Url                      = {http://ptjournal.apta.org/content/71/2/90.abstract}
}

@InProceedings{wei2006semi,
  Title                    = {Semi-supervised time series classification},
  Author                   = {Wei, Li and Keogh, Eamonn},
  Booktitle                = {Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining},
  Year                     = {2006},
  Organization             = {ACM},
  Pages                    = {748--753},

  Review                   = {5 general classes of SSL in all spaces
- generative models - assumes data is drawn from a mixture of data which can be determined by large amt of unlabelled data
- low density separation - assumes decision boundary is in some low density space
- cotraining - divide data into two pieces, and train two separate classifiers. the prediction of one class is used to train the other
(the bottom two are potentially applicable to time series)
- graph based methods - assumes that high dim data lie on a low dim manifold. need to construct a specific graph for each instance or situation though
- self-training - classifier first trained with small am of labelled data, then classifies unlabelled data, then add this newly classified data to the training. this paper focuses on this method

- want to perform time series classification
- note that generally, the non-positive class are not similar, and thus we can't assume all classes to be obviously separable
- they use 1-NN for the base classifiers
- procedure
 1. all labelled data is considered positive, all unlabelled data is negative
 2. unlabelled data is labelled
 3. newly labelled data, if confident, is added to training set. confidence is determined by distance to labelled data, via euclidean},
  Timestamp                = {2015.04.21}
}

@TechReport{Weinberg2011,
  Title                    = {Gyro Mechanical Performance: The Most Important Parameter},
  Author                   = {Weinberg, Harvey},
  Institution              = {Analog Devices},
  Year                     = {2011},

  Abstract                 = {It makes sense to select a gyroscope basesd on minimization of the largest error sources—in most applications, that will be vibration sensitivity. Other parameters can be easily enhanced via calibration or averaging multiple sensors. Bias stability is one of the smaller components of the error budget.},
  Timestamp                = {2012.06.25}
}

@InProceedings{Weinberger2004,
  Title                    = {Learning a kernel matrix for nonlinear dimensionality reduction},
  Author                   = {Weinberger, K.Q. and Sha, F. and Saul, L.K.},
  Booktitle                = {Proceedings of the 21st international conference on Machine learning},
  Year                     = {2004},
  Organization             = {ACM},
  Pages                    = {106},

  Timestamp                = {2011.10.19}
}

@Article{Weinland2011,
  Title                    = {A Survey of Vision-based Methods for Action Representation, Segmentation and Recognition},
  Author                   = {Weinland, D. and Ronfard, R. and Boyer, E.},
  Journal                  = {Computer Vision and Image Understanding },
  Year                     = {2011},
  Pages                    = {224--241},
  Volume                   = {115},

  Abstract                 = {Action recognition has become a very important topic in computer vision, with many fundamental applications, in robotics, video surveillance, human–computer interaction, and multimedia retrieval among others and a large variety of approaches have been described. The purpose of this survey is to give an overview and categorization of the approaches used. We concentrate on approaches that aim on classification of full-body motions, such as kicking, punching, and waving, and we categorize them according to how they represent the spatial and temporal structure of actions; how they segment actions from an input stream of visual data; and how they learn a view-invariant representation of actions.},
  Doi                      = {http://dx.doi.org/10.1016/j.cviu.2010.10.002},
  ISSN                     = {1077-3142},
  Keywords                 = {Action/activity recognition},
  Timestamp                = {2014.12.18}
}

@TechReport{Welch2006,
  author       = {Welch, G. AND Bishop, G.},
  title        = {An Introduction to Kalman Filters},
  institution  = {University of North Carolina at Chapel Hill},
  year         = {2006},
  groups       = {EMBC2013},
  keywords     = {Kalman Filtering},
  organization = {University of South Carolina (Chapel Hill)},
  timestamp    = {2009.10.12},
}

@Article{Welch2002,
  Title                    = {Motion tracking: no silver bullet, but a respectable arsenal},
  Author                   = {Welch, G. and Foxlin, E.},
  Journal                  = {IEEE Computer Graphics and Applications},
  Year                     = {2002},
  Number                   = {6},
  Pages                    = {24--38},
  Volume                   = {22},

  Abstract                 = {This article introduces the physical principles underlying the variety of approaches to motion tracking. Although no single technology will work for all purposes, certain methods work quite well for specific applications.},
  Doi                      = {10.1109/MCG.2002.1046626},
  ISSN                     = {0272-1716},
  Keywords                 = {computer graphics;motion tracking;computer graphics;image motion analysis;optical tracking;survey},
  Timestamp                = {2011.11.01}
}

@Article{Westby2010,
  Title                    = {Patient and health professional views on rehabilitation practices and outcomes following total hip and knee arthroplasty for osteoarthritis:a focus group study},
  Author                   = {Westby, M. D. and Backman, C. L.},
  Journal                  = {BMC Health Services Research},
  Year                     = {2010},
  Number                   = {1},
  Pages                    = {119},
  Volume                   = {10},

  Abstract                 = {BACKGROUND:There is worldwide variation in rehabilitation practices after total hip arthroplasty (THA) and total knee arthroplasty (TKA) and no agreement on which interventions will lead to optimal short and long term patient outcomes. As a first step in the development of clinical practice guidelines for post-acute rehabilitation after THA and TKA, we explored experiences and attitudes about rehabilitation practices and outcomes in groups of individuals identified as key stakeholders.METHODS:Separate focus groups and interviews were conducted with patients (THA or TKA within past year) and three health professional groups: allied health professionals (AHPs), orthopaedic surgeons, and other physicians, in Canada and the United States. Pairs of moderators led the focus groups using a standardized discussion guide. Discussions were audiotaped and transcribed verbatim. A content analysis within and across groups identified key themes.RESULTS:Eleven focus groups and eight interviews took place in six sites. Patients (n = 32) varied in age, stage of recovery, and surgical and rehabilitation experiences. Health professionals (n = 44) represented a range of disciplines, practice settings and years of experience. Six key themes emerged: 1) Let's talk (issues related to patient-health professional and inter-professional communication); 2) Expecting the unexpected (observations about unanticipated recovery experiences); 3) It's attitude that counts (the importance of the patient's positive attitude and participation in recovery); 4) It takes all kinds of support (along the continuum of care); 5) Barriers to recovery (at patient, provider and system levels), and 6) Back to normal (reflecting diversity of expected outcomes). Patients offered different, but overlapping views compared to health professionals regarding rehabilitation practices and outcomes following THA and TKA.CONCLUSION:Results will inform subsequent phases of guideline development and ensure stakeholders' perspectives shape the priorities, content and scope of the guidelines.},
  Doi                      = {10.1186/1472-6963-10-119},
  ISSN                     = {1472-6963},
  Keywords                 = {physiotherapy},
  Pubmedid                 = {20459834},
  Timestamp                = {2011.12.30},
  Url                      = {http://www.biomedcentral.com/1472-6963/10/119}
}

@Article{Wight2008,
  Title                    = {Introduction of the Foot Placement Estimator: A Dynamic Measure of Balance for Bipedal Robotics},
  Author                   = {Wight, Derek L. and Kubica, Eric G. and Wang, David W. L.},
  Journal                  = {Journal of Computational and Nonlinear Dynamics},
  Year                     = {2008},
  Pages                    = {011009-1--10},
  Volume                   = {3},

  Abstract                 = {The goal of most bipedal robotics research is to develop methods of achieving a dynamically balanced gait. Most current approaches focus on maintaining the balance of the system. This paper introduces a measure called the foot placement estimator (FPE) to restore balance to an unbalanced system. We begin by developing a theoretical proof to define when a biped is stable, as well as defining the region in which stability results are valid. This forms the basis for the derivation of the FPE. The results of the FPE are then extended to a complete gait cycle using the combination of a state machine and simple linear controllers. This control system is applied to a detailed and realistic simulation based on a physical robot currently under construction. Utilizing the FPE as a measure of balance allows us to create dynamically balanced gait cycles in the presence of external disturbances, including gait initiation and termination, without any precalculated trajectories.},
  Doi                      = {10.1115/1.2815334},
  Keywords                 = {legged locomotion; robot dynamics; ECE780},
  Numpages                 = {10},
  Publisher                = {ASME},
  Timestamp                = {2011.03.10}
}

@Article{Williamson2001,
  Title                    = {Detecting absolute human knee angle and angular velocity using accelerometers and rate gyroscopes},
  Author                   = {Williamson, R. AND Andrews, B. J.},
  Journal                  = {Medical and Biological Engineering and Computing},
  Year                     = {2001},
  Pages                    = {294-302},
  Volume                   = {39},
  Abstract                 = {Knee joint angle and angular velocity were calculated in real time during standing up and sitting down. Two small modules comprising rate gyroscopes and accelerometers were attached to the thigh and shank of two able-bodied volunteers and one T5 ASIA(A) paraplegic assisted by functional electrical stimulation (FES). The offset and drift of the rate gyroscopes was compensated for by auto-resetting and auto-nulling algorithms. The tilt of the limb segments was calculated by combining the signals of the accelerometer and the rate gyroscope. The joint angle was calculated as the difference in tilt of the segments. The modules were also tested on a two-dimensional model. The mean differences between the rate gyroscope-accelerometer system and the reference goniometer for the model, able-bodied and paraplegic standing trials were 2.1d, 2.4d and 2.3d respectively for knee angle and 2.3/s, 5.0/s and 11.8/s respectively for knee velocity. The rate gyroscope-accelerometer system was more accurate than using the accelerometer as a tilt meter, possibly due to the greater bandwidth of the rate gyroscope-accelerometer system.},
  Doi                      = {10.1007/BF02345283},
  Keywords                 = {Postural detection},
  Review                   = {Just did frequency filtering and integration...



Williamson2001
Cited by: 80
Motion type: Sit to stand
Recovery methodology: IMU (100 Hz). Uses accel to determine angle while stationary/slow motion, then integrate over gyro reading while moving. The ankle and knee angle-to-ground are obtained, and subtracted to get the actual knee angle
Verification technique: Goniometer
Subject demographics: 2 healthy adults. 
Error reported: RMS deg, 2.4 for knee},
  Timestamp                = {2010.04.01}
}

@Article{Wilson1999,
  Title                    = {Parametric Hidden Markov Models for Gesture Recognition},
  Author                   = {Wilson, A. D. and Bobick, A. F.},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {1999},
  Pages                    = {884--900},
  Volume                   = {21},

  Abstract                 = {A method for the representation, recognition, and interpretation of parameterized gesture is presented. By parameterized gesture we mean gestures that exhibit a systematic spatial variation; one example is a point gesture where the relevant parameter is the two-dimensional direction. Our approach is to extend the standard hidden Markov model method of gesture recognition by including a global parametric variation in the output probabilities of the HMM states. Using a linear model of dependence, we formulate an expectation-maximization (EM) method for training the parametric HMM. During testing, a similar EM algorithm simultaneously maximizes the output likelihood of the PHMM for the given sequence and estimates the quantifying parameters. Using visually derived and directly measured three-dimensional hand position measurements as input, we present results that demonstrate the recognition superiority of the PHMM over standard HMM techniques, as well as greater robustness in parameter estimation with respect to noise in the input features. Finally, we extend the PHMM to handle arbitrary smooth (nonlinear) dependencies. The nonlinear formulation requires the use of a generalized expectation-maximization (GEM) algorithm for both training and the simultaneous recognition of the gesture and estimation of the value of the parameter. We present results on a pointing gesture, where the nonlinear approach permits the natural spherical coordinate parameterization of pointing direction},
  Doi                      = {10.1109/34.790429},
  ISSN                     = {0162-8828},
  Keywords                 = {gesture recognition;hidden Markov models;parameter estimation;position measurement;probability;arbitrary smooth dependencies;expectation-maximization method;gesture recognition;linear dependence model;nonlinear dependencies;output probabilities;parameterized gesture;parametric hidden Markov models;point gesture;systematic spatial variation;three-dimensional hand position measurements;Computer Society;Hidden Markov models;Marine animals;Measurement standards;Noise measurement;Parameter estimation;Position measurement;Prototypes;Speech;Testing},
  Review                   = {PHMM for pointing gestures, parameterized to different directions and oreintations. 1 second sliding window using forward algorithm for recognition. Can be applied to segmentation. Need to consider both likelihood and parameter theta (the "p" in phmm) to reject false positives, use EM to find the best combination.},
  Timestamp                = {2014.12.20}
}

@Article{Winter1995,
  Title                    = {Human balance and posture control during standing and walking },
  Author                   = {D. A. Winter},
  Journal                  = {Gait and Posture},
  Year                     = {1995},
  Number                   = {4},
  Pages                    = {193--214},
  Volume                   = {3},

  Abstract                 = {The common denominator in the assessment of human balance and posture is the inverted pendulum model. If we focus on appropriate versions of the model we can use it to identify the gravitational and acceleration perturbations and pinpoint the motor mechanisms that can defend against any perturbation. We saw that in quiet standing an ankle strategy applies only in the \{AP\} direction and that a separate hip load/unload strategy by the hip abd/adductors is the totally dominant defence in the \{ML\} direction when standing with feet side by side. In other standing positions (tandem, or intermediate) the two mechanisms still work separately, but their roles reverse. In the tandem position \{ML\} balance is an ankle mechanism (invertors/evertors) while in the \{AP\} direction a hip load/unloading mechanism dominates. During initiation and termination of gait these two separate mechanisms control the trajectory of the \{COP\} to ensure the desired acceleration and deceleration of the COM. During initiation the initial acceleration of the \{COM\} forward towards the stance limb is achieved by a posterior and lateral movement of the \{COP\} towards the swing limb. After this release phase there is a sudden loading of the stance limb which shifts the \{COP\} to the stance limb. The \{COM\} is now accelerated forward and laterally towards the future position of the swinging foot. Also \{ML\} shifts of the \{COP\} were controlled by the hip abductors/adductors and all \{AP\} shifts were under the control of the ankle plantar/dorsiflexors. During termination the trajectory of both \{COM\} and \{COP\} reverse. As the final weight-bearing on the stance foot takes place the \{COM\} is passing forward along the medial border of that foot. Hyperactivity of that foot's plantarflexors takes the \{COP\} forward and when the final foot begins to bear weight the \{COP\} moves rapidly across and suddenly stops at a position ahead of the future position of the COM. Then the plantarflexors of both feet release and allow the \{COP\} to move posteriorly and approach the \{COM\} and meet it as quiet stance is achieved. The inverted pendulum model permitted us to understand the separate roles of the two mechanisms during these critical unbalancing and rebalancing periods. During walking the inverted pendulum model explained the dynamics of the balance of \{HAT\} in both the \{AP\} and \{ML\} directions. Here the model includes the couple due to the acceleration of the weight-bearing hip as well as gravitational perturbations. The exclusive control of \{AP\} balance and posture are the hip extensors and flexors, while in the \{ML\} direction the dominant control is with the hip abductors with very minor adductor involvement. At the ankle the inverted pendulum model sees the \{COM\} passing forward along the medial border to the weight-bearing foot. The model predicts that during single support the body is falling forward and being accelerated medially towards the future position of the swing foot. The model predicts an insignificant role of the ankle invertors/evertors in the \{ML\} control. Rather, the future position of the swing foot is the critical variable or more specifically the lateral displacement from the \{COM\} at the start of single support. The position is actually under the control of the hip abd/adductors during the previous early swing phase. The critical importance of the hip abductors/adductors in balance during all phases of standing and walking is now evident. This separate mechanism is important from a neural control perspective and clinically it focuses major attention on therapy and potential problems with some surgical procedures. On the other hand the minuscule role of the ankle invertors/evertors is important to note. Except for the tandem standing position these muscles have negligible involvement in balance control.},
  Doi                      = {http://dx.doi.org/10.1016/0966-6362(96)82849-9},
  ISSN                     = {0966-6362},
  Keywords                 = {Balance},
  Timestamp                = {2016.02.17}
}

@Book{Winter1991,
  Title                    = {Biomechanics and Motor Control of Human Gait: Normal, Elderly and Pathological},
  Author                   = {Winter, D. A.},
  Publisher                = {University of Waterloo Press},
  Year                     = {1991},

  Timestamp                = {2015.02.12}
}

@Book{Winter1990,
  Title                    = {Biomechanics and Motor Control of Human Movement},
  Author                   = {Winter, D. A.},
  Publisher                = {John Wiley and Sons, Inc.},
  Year                     = {1990},

  Timestamp                = {2012.01.10}
}

@TechReport{Winter1980,
  Title                    = {Units, terms and standards in reporting of {EMG} research},
  Author                   = {Winter, D. AND Rau, G. AND Kadefos, R. AND Broman, H. AND De Luca, C.},
  Institution              = {International Society of Electrophysiogical Kinesiology},
  Year                     = {1980},

  Owner                    = {jf2lin},
  Review                   = {Part I - Terminology 

Part II - Recording System
- Depol/Repol is a muscle AP process
- Tissue is a volume conductor
 - difficult to separate sources of AP
- Location/Structure of electrode matters
 - needle, wire, surface
 - Ag-AgCl is good stuff
- Gotta prep the skin
 - Rub, shave, remove dead skin, drop the impedence
- Amplifier
 - amplifer input impedence should be over 1 megaohm
 - they found movement artifacts under 10 Hz
 - preamp is a good idea

Part III - Temporal Processing
Raw EMG
- Should be that at the electrode, not of the amplifier
- Mean or moving average (remember to FWR it), or ensemble average
- I-EMG is abused...some people thinks it's LE
- Linear envelope, 2nd order LPF at 6Hz

Part IV - Frequency Domain Analysis
FFT or Laplace -> gives us something in units of frequency. We can look at its energy content. 
Mean and medium frequency. 

Part V - General Experimental and Kinesiological Information
Contraction
- Isometic (fixed angle/muscle length)
- Isotonic (constant force)
- Isokinetic (constnat linear/angular velocity)
- Concentric (shortening)
- Eccentic (lengthening)},
  Timestamp                = {2009.12.09}
}

@Article{Winters2003,
  Title                    = {Wearable Sensors and Telerehabilitation},
  Author                   = {Winters, J. M. and Wang, Y. and Winters, J. M.},
  Journal                  = {IEEE Engineering in Medicine and Biology Magazine},
  Year                     = {2003},
  Pages                    = {56--65},
  Volume                   = {22},

  Abstract                 = {The article summarizes ongoing research on both mobile interfaces and therapies related to rehabilitation with special focus on emerging possibilities for home therapy programs for two areas of special interest to our group: stroke and cardiac. Both are areas where considerable scientific evidence suggesting the need for new therapeutic strategies has not significantly impacted clinical practice, and where home-based programs may be the answer. The article covers two aspects of the design of the mobile intelligent telerehabilitation assistant (ITA), a long-term project intended to provide an alternative for 21st-century rehabilitative telecare, and describes the interactive, mobile ITA interfaces and telecommunications infrastructure, which was motivated by the need identified by participants at the Home Care Technologies Workshop for user-centered interactive systems. We also discuss an approach for addressing the top recommendation of the Workshop: the critical need for intelligent interpretation and management of healthcare data. With the addition of wearable systems and telehealth tools, embedded intelligence takes added significance. We also address the challenge of extracting expert knowledge.},
  Timestamp                = {2011.12.30}
}

@InProceedings{Wojtusch2015,
  Title                    = {{HuMoD - A Versatile and Open Database for the Investigation, Modeling and Simulation of Human Motion Dynamics on Actuation Level}},
  Author                   = {Wojtusch, J. and von Stryk, O.},
  Booktitle                = {Proceedings of the IEEE/RAS International Conference on Humanoid Robots},
  Year                     = {2015},
  Pages                    = {74--79},

  Doi                      = {10.1109/HUMANOIDS.2015.7363534},
  Timestamp                = {2017.01.16}
}

@Article{Wold1996,
  Title                    = {Content-based classification, search, and retrieval of audio},
  Author                   = {Wold, E. and Blum, T. and Keislar, D. and Wheaten, J.},
  Journal                  = {IEEE MultiMedia},
  Year                     = {1996},
  Number                   = {3},
  Pages                    = {27--36},
  Volume                   = {3},

  Abstract                 = {Many audio and multimedia applications would benefit from the ability to classify and search for audio based on its characteristics. The audio analysis, search, and classification engine described here reduces sounds to perceptual and acoustical features. This lets users search or retrieve sounds by any one feature or a combination of them, by specifying previously learned classes based on these features, or by selecting or entering reference sounds and asking the engine to retrieve similar or dissimilar sounds},
  Publisher                = {IEEE},
  Review                   = {- mainly a classification paper on speech features
- look at feature transistions to segment, but segmentation is not a focus of the paper},
  Timestamp                = {2013.08.29}
}

@Article{Wong2012,
  Title                    = {Impacts of operating conditions and solution chemistry on osmotic membrane structure and performance},
  Author                   = {Mavis C.Y. Wong and Kristina Martinez and Guy Z. Ramon and Eric M.V. Hoek},
  Journal                  = {Desalination},
  Year                     = {2012},
  Note                     = {<ce:title>Special Issue in honour of Professor Takeshi Matsuura on his 75th Birthday</ce:title>},
  Number                   = {0},
  Pages                    = {340 - 349},
  Volume                   = {287},

  Abstract                 = {Herein, we report on changes in the performance of a commercial cellulose triacetate (CTA) membrane, imparted by varied operating conditions and solution chemistries. Changes to feed and draw solution flow rate did not significantly alter the CTA membrane's water permeability, salt permeability, or membrane structural parameter when operated with the membrane skin layer facing the draw solution (PRO-mode). However, water and salt permeability increased with increasing feed or draw solution temperature, while the membrane structural parameter decreased with increasing draw solution, possibly due to changes in polymer intermolecular interactions. High ionic strength draw solutions may de-swell the CTA membrane via charge neutralization, which resulted in lower water permeability, higher salt permeability, and lower structural parameter. This observed trend was further exacerbated by the presence of divalent cations which tends to swell the polymer to a greater extent. Finally, the calculated CTA membrane's structural parameter was lower and less sensitive to external factors when operated in PRO-mode, but highly sensitive to the same factors when the skin layer faced the feed solution (FO-mode), presumably due to swelling/de-swelling of the saturated porous substructure by the draw solution. This is a first attempt aimed at systematically evaluating the changes in performance of the CTA membrane due to operating conditions and solution chemistry, shedding new insight into the possible advantages and disadvantages of this material in certain applications.},
  Doi                      = {10.1016/j.desal.2011.10.013},
  ISSN                     = {0011-9164},
  Keywords                 = {Friends},
  Timestamp                = {2012.07.06},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0011916411008782}
}

@Article{Wong2007,
  Title                    = {Clinical applications of sensors for human posture and movement analysis: A review},
  Author                   = {Wong, W. Y. and Wong, M. S. and Lo, K. H.},
  Journal                  = {Prosthetics and Orthotics International},
  Year                     = {2007},
  Number                   = {1},
  Pages                    = {62-75},
  Volume                   = {31},

  Abstract                 = {Measurement of human posture and movement is an important area of research in the bioengineering and rehabilitation fields. Various attempts have been initiated for different clinical application goals, such as diagnosis of pathological posture and movements, assessment of pre- and post-treatment efficacy and comparison of different treatment protocols. Image-based methods for measurements of human posture and movements have been developed, such as the photogrammetry, optoelectric technique and video analysis. However, it is found that these methods are complicated to set up, time-consuming to operate and could only be applied in laboratory environments. Electronic sensors and systems with advanced technology, namely accelerometer, gyroscope, flexible angular sensor, electromagnetic tracking system and sensing fabrics, have been developed and applied to solve the relevant application problems of the image-based methods. 

Nonetheless, other problems for using these electronic sensors emerged, including the environment influence and signal extraction difficulties. Further development of these electronic sensors and measurement methods could enhance their clinical applications in institutional as well as community levels. This article reviews the possible applications of these electronic sensors and systems, and precautions of their applications in analysis of human posture and movement. Such information would help researchers and clinicians in selecting and developing the most appropriate measurement techniques of using the electronic sensors for clinical applications of human posture and movement analysis.},
  Doi                      = {10.1080/03093640600983949},
  Eprint                   = {http://informahealthcare.com/doi/pdf/10.1080/03093640600983949},
  Keywords                 = {postural detection, survey},
  Review                   = {Surveys sensors and clinical applications of said sensors},
  Timestamp                = {2011.03.01},
  Url                      = {http://informahealthcare.com/doi/abs/10.1080/03093640600983949}
}

@InProceedings{Wu2006,
  Title                    = {Gesture Registration, Relaxation, and Reuse for Multi-Point Direct-Touch Surfaces},
  Author                   = {Wu, M. and Shen, C. and Ryall, K. and Forlines, C. and Balakrishnan, R.},
  Booktitle                = {Proceedings of the 1st IEEE International Workshop on Horizontal Interactive Human-Computer Systems},
  Year                     = {2006},

  Address                  = {Los Alamitos, CA, USA},
  Pages                    = {185-192},
  Publisher                = {IEEE Computer Society},
  Volume                   = {0},

  Abstract                 = {Freehand gestural interaction with direct-touch computation surfaces has been the focus of significant research activity recently. While many interesting gestural interaction techniques have been proposed, their design has been mostly ad-hoc and has not been presented within a constructive design framework. In this paper, we develop and articulate a set of design principles for constructing - in a systematic and extensible manner multi-hand gestures on touch surfaces that can sense multiple points and shapes, and can also accommodate conventional point-based input. To illustrate the generality of these design principles, a set of bimanual continuous gestures that embody these principles are developed and explored within a prototype tabletop publishing application. We carried out a user evaluation to assess the usability of these gestures and use the results and observations to suggest future design guidelines.},
  Doi                      = {http://doi.ieeecomputersociety.org/10.1109/TABLETOP.2006.19},
  ISBN                     = {0-7695-2494-X},
  Journal                  = {International Workshop on Horizontal Interactive Human-Computer Systems},
  Review                   = {No details on motion detection algorithm. Just tried a bunch of motions and people liked it.},
  Timestamp                = {2011.01.25}
}

@Unpublished{fydp2010,
  Title                    = {Atlas: A Wireless Body Motion Analyzer},
  Author                   = {Wu, W. AND Lin, J. F. AND Wong, N. AND Kazerani, A.},
  Note                     = {University of Waterloo, Fourth Year Design Project (2010)},

  Month                    = {03},
  Year                     = {2010},

  Timestamp                = {2010.04.02}
}

@InCollection{Wu1999,
  Title                    = {Vision-Based Gesture Recognition: A Review},
  Author                   = {Wu, Y. and Huang, T.},
  Booktitle                = {Gesture-Based Communication in Human-Computer Interaction},
  Publisher                = {Springer Berlin/Heidelberg},
  Year                     = {1999},
  Pages                    = {103--115},
  Series                   = {Lecture Notes in Computer Science},
  Volume                   = {1739},

  Abstract                 = {The use of gesture as a natural interface serves as a motivating force for research in modeling, analyzing and recognition of gestures. In particular, human computer intelligent interaction needs vision-based gesture recognition, which involves many interdisciplinary studies. A survey on recent vision-based gesture recognition approaches is given in this paper. We shall review methods of static hand posture and temporal gesture recognition. Several application systems of gesture recognition are also described in this paper. We conclude with some thoughts about future research directions.},
  Affiliation              = {Beckman Institute 405 N. Mathews Urbana IL 61801},
  Review                   = {10.1007/3-540-46616-9_10},
  Timestamp                = {2011.06.11}
}

@InProceedings{Xiao2000,
  Title                    = {An approach to incremental SVM learning algorithm},
  Author                   = {Xiao, Rong and Wang, Jicheng and Zhang, Fayan},
  Booktitle                = {Tools with Artificial Intelligence, 2000. ICTAI 2000. Proceedings. 12th IEEE International Conference on},
  Year                     = {2000},
  Pages                    = {268--273},

  Abstract                 = {The Classijication algorithm based on Support Vector 
Machine (SVM) now attracts more attentions due to its 
pelfect theoretical properties and good empirical results. 
In this papel; we first analyze the properties of SV set 
thoroughly, then introduce a new learning method, which 
extends the SVM Classijication algorithm to incremental 
learning area. The theoretical bases of this algorithm are 
the classijication equivalence of the SV set and the 
training set. In this algorithm, the knowledge is 
accumulated in the process of incremental Learning. In 
addition, unimportant samples are discarded optimally by 
LRU scheme. The theoretical analysis and experimental 
results show that this algorithm could not only speedup 
the training process, but also reduce the storage cost, 
while the classijkation precision is also guaranteed.},
  Timestamp                = {2014.10.24}
}

@InProceedings{Xie2013,
  Title                    = {Prediction of Chronic Obstructive Pulmonary Disease (COPD) Exacerbation Using Physiological Time Series Patterns},
  Author                   = {Xie, Y. and Redmond, S. J. and Mohktar, M. S. and Shany, T. and Basilakis, J. and Hession, M. and Lovell, N. H.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {COPD is a complex disease that has been acknowledged as one of the top five leading causes of deaths. Recent clinical research has indicated a strong association between physiological homeostasis and the onset of COPD exacerbation. Thus the manipulation of these variables may eventually yield an effective means of predicting the risk of occurrence of an exacerbation event in the near future. However, the accuracy of existing prediction methods based on statistical analysis of periodic snapshots of certain physiological variables is still far from satisfactory, due to lack of the study in long-term and interactive effects of the physiological variables. Therefore, developing a relatively accurate method for predicting COPD exacerbation is an outstanding challenge. In this paper, a regression-based machine learning technique was developed, using trend pattern variables extracted from COPD patients' longitudinal physiological records, to classify subjects into ‘’low-ris’’ and ‘’high-risk’’ categories, indicating their risk of suffering a COPD exacerbation event. Experiment results from cross validation of the classifier model show an average accuracy of 79.27% using this method.},
  Keywords                 = {EMBC2013},
  Review                   = {Research shows an association between HR, SpO2, BP and body temperature physioloigcal parameters on onset of COPD exacerbation, which increases COPD morbidity. Patterns have been derived from statistical analysis based on weekly or monthly snapshots. A trend detection technique was developed to see if we can use long term longtiudinal data to predict COPD events. 

7 COPD patients were examined. Tracked daily weight, diastolic blood pressure, systolic blood pressure, HR, SpO2 and temperature for a year. Standard health questionnaires were applied to assess illness progress and mood of patient. Piecewise regression was employed to fit the time series data. Breakpoints in the fit are found by removing breakpoints that gives the least increase in MSE, under some MSE threshold. Data is added "online" and several metrics, such as the slope and sandard deviation, was calculated. 

Sections in the data were labelled "low-risk" or "high-risk" based on patient status, and a logistic regression classifier was used to predict if some data sequence would fall into the low-risk or high-risk section. They then determined which metric combination works best at predicting COPD events.},
  Timestamp                = {2013.07.30}
}

@Article{Xing2010,
  Title                    = {A brief survey on sequence classification},
  Author                   = {Xing, Zhengzheng and Pei, Jian and Keogh, Eamonn},
  Journal                  = {ACM SIGKDD Explorations Newsletter},
  Year                     = {2010},
  Number                   = {1},
  Pages                    = {40--48},
  Volume                   = {12},

  Publisher                = {ACM},
  Review                   = {A general survey on various sequential datasets. Has a section on SSL. 

- Nigam et al
 - naive Bayes classifier, use EM to adjust the params of the classifier until the classification result of the unlabelled data is stable
- Zhong et al
 - use label data to train HMM, then adjust the labels using unlabelled data via EM
- Wei et al
 - 1-NN (this is that other really confusion paper on stopping criteria)
 - assume all of data is TN, and supply TP cases to the 1NN training until the the minimum distance (within class?) of the TP class decrease, until it plateaus, then start decrease (overfit?) again. Stop at the overfit point
- Weston et al
 - SVM with cluster kernel
 -},
  Timestamp                = {2015.05.13}
}

@Article{Xu2012,
  Title                    = {Enabling Large Scale Ground-truth Acquisition and System Evaluation in Wireless Health},
  Author                   = {Xu, J. and Pottie, G. and Kaiser, W.},
  Journal                  = {IEEE Transactions on Biomedical Engineering},
  Year                     = {2012},

  Month                    = { },
  Number                   = {99},
  Pages                    = {1},
  Volume                   = {PP},

  Abstract                 = {large scale activity monitoring is a core component of systems aiming to improve our ability to manage fitness, deliver care and diagnose conditions. While much research has been devoted to the accurate classification of motion, the challenges arising from scaling to large communities has received little attention. This paper introduces the problem of scaling, and addresses two of the most important issues: enabling robust large scale ground-truth acquisition and building a common database for systems comparison. The paper presents a voice powered mobile acquisition system with efficient annotation tools and an extendable online searchable activity database with 331 datasets totaling 700+ hours with 8 sensing modalities and 15 activities.},
  Doi                      = {10.1109/TBME.2012.2208111},
  ISSN                     = {0018-9294},
  Timestamp                = {2012.07.18}
}

@InProceedings{Yabuki2013,
  Title                    = {Motion recognition from contact force measurement},
  Author                   = {T. Yabuki and G. Venture},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},
  Pages                    = {7245--7248},

  Abstract                 = {Optical motion capture systems, which are used in broad fields of research, are costly; they need large installation space and calibrations. We find difficulty in applying it in typical homes and care centers. Therefore we propose to use low cost contact force measurement systems to develop rehabilitation and healthcare monitoring tools. Here, we propose a novel algorithm for motion recognition using the feature vector from force data solely obtained during a daily exercise program. We recognized 7 types of movement (Radio Exercises) of two candidates (mean age 22, male). The results show that the recognition rate of each motion has high score (mean: 86.9%). The results also confirm that there is a clustering of each movement in personal exercises data, and a similarity of the clustering even for different candidates thus that motion recognition is possible using contact force data.},
  Doi                      = {10.1109/EMBC.2013.6611230},
  ISSN                     = {1557-170X},
  Keywords                 = {biomedical measurement;force measurement;health care;patient monitoring;patient rehabilitation;calibrations;contact force measurement systems;feature vector;healthcare monitoring;installation space;motion recognition;optical motion capture systems;patient rehabilitation;personal exercises data;Clustering algorithms;Force;Force measurement;Principal component analysis;Training;Training data;Vectors},
  Timestamp                = {2016.03.10}
}

@InProceedings{Yamamoto2006,
  author    = {Yamamoto, M. and Mitomi, H. and Fujiwara, F. and Sato, T.},
  title     = {Bayesian Classification of Task-oriented Actions Based on Stochastic Context-free Grammar},
  booktitle = {International Conference on Automatic Face and Gesture Recognition},
  year      = {2006},
  pages     = {317--322},
  abstract  = {This paper proposes a new approach for recognition of task-oriented actions based on stochastic context-free grammar (SCFG). Our attention puts on actions in the Japanese tea ceremony, where the action can be described by context-free grammar. Our aim is to recognize the action in the tea services. Existing SCFG approach consists of generating symbolic string, parsing it and recognition. The symbolic string often includes uncertainty. Therefore, the parsing process needs to recover the errors at the entry process. This paper proposes a segmentation method errorless as much as possible to segment an action into a string of finer actions. This method, based on an acceleration of the body motion, can produce the fine action corresponding to a terminal symbol with little error. After translating the sequence of fine actions into a set of symbolic strings, SCFG-based parsing of this set leaves small number of ones to be derived. Among the remaining strings, Bayesian classifier answers the action name with a maximum posterior probability. Giving one SCFG rule the multiple probabilities, one SCFG can recognize multiple actions},
  groups    = {Lit Review 2013-09, EMBC2014},
  review    = {Want to classify the Japanese tea ceremony. Want to use stochastic context free grammar (SCFG) to do so. It is relevant to temae (a set of rules for the tea ceremony, and consists of sub-actions). They segment by looking at local minimums on the sum of the magnitude of the angular acceleration.


Yamamoto \etal \cite{Yamamoto2006} want to segment and classify the different components of the Japanese tea ceremony. The state progress is presented by the stochastic context free grammar and auto-regression models, but the segmentation is performed by examining local minimums on the sum of the magnitude of the angular acceleration. No segmentation accuracy was given.

Yamamoto \etal \cite{Yamamoto2006} segment and classify the different components of the Japanese tea ceremony via image-based segmentation. The segmentation is performed by examining local minimums on the sum of the magnitude of the angular acceleration in the actor poses. Labels are assigned via a SCFG.},
  timestamp = {2013.10.08},
}

@Article{Yamane2009,
  Title                    = {Comparative Study on Serial and Parallel Forward Dynamics Algorithms for Kinematic Chains},
  Author                   = {Yamane, K. and Nakamura, Y.},
  Journal                  = {The International Journal of Robotics Research},
  Year                     = {2009},
  Number                   = {5},
  Pages                    = {622-629},
  Volume                   = {28},

  Abstract                 = {The main focus of this paper is to investigate the essential differences among four forward dynamics algorithms: the Articulated-Body Algorithm (ABA) and Divide-and-Conquer Algorithm (DCA) by Featherstone; the Constraint Force Algorithm (CFA) by Fijany et al.; and the Assembly—Disassembly Algorithm (ADA) by the present authors. All of the algorithms have O(N) asymptotic complexity for serial computation where N is the number of rigid bodies, and three of them can also be processed in parallel which results in O (log N ) complexity on O (N) processors. We start by summarizing two essential backgrounds of the forward dynamics algorithms, i.e. articulated-body inertias and joint constraint representation. We then present a new formulation of ADA as well as the outlines of the other three algorithms using the same notation. Finally, we perform qualitative as well as quantitative comparisons of the algorithms using our implementations of ABA, CFA, and ADA.},
  Doi                      = {10.1177/0278364909102350},
  Eprint                   = {http://ijr.sagepub.com/content/28/5/622.full.pdf+html},
  Keywords                 = {ECE780},
  Timestamp                = {2011.01.12},
  Url                      = {http://ijr.sagepub.com/content/28/5/622.abstract}
}

@Article{Yamane2003a,
  Title                    = {Dynamics Filter - concept and implementation of online motion Generator for human figures},
  Author                   = {Yamane, Katsu and Nakamura, Yoshihiko},
  Journal                  = {IEEE Transactions on Robotics and Automation},
  Year                     = {2003},
  Number                   = {3},
  Pages                    = { 421 - 432},
  Volume                   = {19},

  Abstract                 = {In this paper, we describe the concept and implementation of a dynamics filter, an online, full-body motion generator that converts a physically infeasible reference motion into a feasible one for the given human figure. Our implementation of the dynamics filter only uses time-local information, that is, does not require the whole motion sequence in advance. Therefore, the reference motion may be changed online in response to the interaction with a human or the environment. The dynamics filter is implemented based on an efficient rigid-body collision/contact model. This model itself provides an efficient algorithm for dynamics simulation of collisions and contacts. We demonstrate the power of the dynamics filter by several example motions that use motion capture data as a reference.},
  Doi                      = {10.1109/TRA.2003.810579},
  ISSN                     = {1042-296X},
  Keywords                 = {dynamics filter; dynamics simulation; full-body motion generator; motion sequence; physically infeasible reference motion; computer animation; mobile robots; path planning; ECE780, gait and trajectory},
  Timestamp                = {2011.02.04}
}

@Article{Yamane2003b,
  Title                    = {Natural Motion Animation through Constraining and Deconstraining at Will},
  Author                   = {Yamane, K. and Nakamura, Y.},
  Journal                  = {IEEE Transactions on Visualization and Computer Graphics},
  Year                     = {2003},
  Pages                    = {352--360},
  Volume                   = {9},

  Abstract                 = {The paper presents a computational technique for creating whole-body motions of human and animal characters without reference motion. Our work enables animators to generate a natural motion by dragging a link to an arbitrary position with any number of links pinned in the global frame, as well as other constraints such as desired joint angles and joitn motion ranges. The method leads to an intuitive pin-and-drag interface where the user can generate whole-body motions by simply switching on or off or strengthening or weakening constraints. The work is based on a new interactive invrse kinematics technique that allows more flexible attachment of pins and various types of constraints. Editing or retargetign captured motion requires only a small modification to the original method, althrough it can also create natural motions from scratch. We demonstrate the usefulness and advantage of our method with a number of example motion clips.},
  Keywords                 = {Animation, online inverse kinematics computation, multiple constraints, motion editing, joint motion range; ECE780},
  Review                   = {NOVELTY


READING SUMMARY
Inverting the Jacobian, even if non-square

Resolved Motion Rate Control (RMRC): Robotic control. Control variables are velocity vectors of the end points of a manipulator, and the angular velocities of the joitns are determined to obtain the desired results.

Synergetics (Hermann Haken): Addresses the formation and self-organization of patterns and structures in open systems far from thermodyamic equilibrium. Systems are macroscopic in anture, and has many non-linearly interacting subsystems. We want to understand how internal coupling of joints and joint motion ranges are constrained and whatnot. The human body has a lot of DOFs...so instead of setting all the DOFs, what if we just set a small handful and let these relationships derive a natural combination of DOFs?

Closed-form expression: Iff an expression can be expressed analytically and bounded. Typically are elementary functions. Infinite series, limits don't count. 


Introduction and related works
Realistic human animation relies on motion capture or animator skills. It is difficult to reuse in another scene or for another character. This is too bad, since digital animation is used everywhere, ie films, Internet and games. These people might not necessarily be specialists, so to develop whole-body motions without special knowledge is pretty essential.This group developed a CG animation software package, using "articulated figure positioning" (ie pin and drag), allowing the user to drag a link to pin onto the global frame. They've demonstrated the ability to create natural and human-like motions, without any reference motions, when used by untrained people. They achieve this by applying constraints on link positions, joint angle motion ranges.

Motion capture should not be underestimated, however. Motion libraries, editing and retargetting tools have been developed and commercially available. Much of the research goes towards motion editing from existing clips instead of creating new motion from scratch. Motion capture is ultimately not the solution, however: 1) Users must capture/purchase new motion data when they need motions not in their library, and 2) motions generated generated from a single library tends to be relatively uniform/similar. 

Inverse kinematics (IK) is critical in this field. Two basic categories: analytical and numerical. Analytical IK tends to work well only for certain structure types, such as a single limb of human. It lacks generalitiy. Numerical methods are much easier to work with, but might be harder to adapt for online applications. Relatively few work is on generating new motion, since people view this as too difficult. The algorithm presented in this paper is more flexible than previous similar techniques due to SR-robust. 

Many other related works uses spherical joints parameterized into Euler, which has major singularity issues. 


Pin dragging
We want specified links to stay where they're suppose to, joints to stay within motion range, as as close to given angle as possible. This is hard:
- It is very difficult to derive analytical general cases, since the link relations are expressed by a set of complicated non-linear equations. We can use differential kinematics, which gives linear relationships between constrains and joitn velocity. 
- Constraints may also conflict with each other, such as when we try dragging a link beyond reachable space. We'll have to set different priority levels and satisfy what we can. We can also introduce optimization techniques (such as least squares) to help with this. To help counter against singular situations, singularity-robust inverses are used. SR has also been shown to be a bit more computationally cheap. 

Since our Jacobian is not square, we'll need to use a pseudo-inverse. They have a formula for the pseudoinverse (eqn6), which gets near singular points. The SR-robust form (eqn7) is used instead.

So from all this, the procedure is...
1. calculate velocity of dragged link
2. calculate desired nearby joints positions. They define a weighted Jacobian to determine which to twist more. 
3. calculate Jacobian. This gets the angular velocity
4. calculate linear velocity. Do so by taking the delta of positions and multiplying by a pos-def mtx. 

Spherical Joints
Some specific modifications needs to be made for spherical joints, which are represented by a 3x3 rotational matrix. They have this way of calculating displacement (since it's not just x_prev - x_curr anymore). Can get angular velocity by multiplying the error by a pos-def mtx. They also have their own way of representing joint motion (3.5.2), (which I totally don't understand)

Examples
- Multiframe animation. Several key postures were set and the inbetween motion are generated
- Existing collected motion modified},
  Timestamp                = {2009.11.10}
}

@Article{Yang2011,
  Title                    = {Activity Recognition Based on RFID Object Usage for Smart Mobile Devices},
  Author                   = {Yang, Jaeyoung and Lee, Joonwhan and Choi, Joongmin},
  Journal                  = {Journal of Computer Science and Technology},
  Year                     = {2011},
  Number                   = {2},
  Pages                    = {239-246},
  Volume                   = {26},

  Doi                      = {10.1007/s11390-011-9430-9},
  ISSN                     = {1000-9000},
  Keywords                 = {activity recognition; activity theory; context-awareness; RFID},
  Language                 = {English},
  Publisher                = {Springer US},
  Timestamp                = {2014.12.21},
  Url                      = {http://dx.doi.org/10.1007/s11390-011-9430-9}
}

@Article{Yang1997,
  Title                    = {Human action learning via hidden Markov model},
  Author                   = {Jie Yang and Yangsheng Xu and Chen, Chiou S.},
  Journal                  = {Systems, Man and Cybernetics, Part A: Systems and Humans, IEEE Transactions on},
  Year                     = {1997},

  Month                    = {Jan},
  Number                   = {1},
  Pages                    = {34-44},
  Volume                   = {27},

  Abstract                 = {To successfully interact with and learn from humans in cooperative modes, robots need a mechanism for recognizing, characterizing, and emulating human skills. In particular, it is our interest to develop the mechanism for recognizing and emulating simple human actions, i.e., a simple activity in a manual operation where no sensory feedback is available. To this end, we have developed a method to model such actions using a hidden Markov model (HMM) representation. We proposed an approach to address two critical problems in action modeling: classifying human action-intent, and learning human skill, for which we elaborated on the method, procedure, and implementation issues in this paper. This work provides a framework for modeling and learning human actions from observations. The approach can be applied to intelligent recognition of manual actions and high-level programming of control input within a supervisory control paradigm, as well as automatic transfer of human skills to robotic systems},
  Doi                      = {10.1109/3468.553220},
  ISSN                     = {1083-4427},
  Keywords                 = {hidden Markov models;knowledge acquisition;learning systems;pattern recognition;robots;action modeling;cooperative modes;hidden Markov model;human action learning;human skill learning;robots;supervisory control paradigm;Automatic control;Automatic programming;Character recognition;Feedback;Hidden Markov models;Human robot interaction;Intelligent robots;Manuals;Robot programming;Robot sensing systems},
  Review                   = {Handwriting gestures -> FFT -> feed into pre-trained HMM to do recognition using Forward algorithm. No segmentation.},
  Timestamp                = {2014.12.20}
}

@Article{Yang2006,
  author    = {Yang, Q. and Wu, X.},
  title     = {10 Challenging Problems in Data Mining Research},
  journal   = {International Journal of Information Technology \& Decision Making},
  year      = {2006},
  volume    = {5},
  number    = {04},
  pages     = {597--604},
  abstract  = {In October 2005, we took an initiative to identify 10 challenging problems in data mining research, by consulting some of the most active researchers in data mining and machine learning for their opinions on what are considered important and worthy topics for future research in data mining. We hope their insights will inspire new research efforts, and give young researchers (including PhD students) a high-level guideline as to where the hot problems are located in data mining.

Due to the limited amount of time, we were only able to send out our survey requests to the organizers of the IEEE ICDM and ACM KDD conferences, and we received an overwhelming response. We are very grateful for the contributions provided by these researchers despite their busy schedules. This short article serves to summarize the 10 most challenging problems of the 14 responses we have received from this survey. The order of the listing does not reflect their level of importance.},
  doi       = {10.1142/S0219622006002258},
  eprint    = {http://www.worldscientific.com/doi/pdf/10.1142/S0219622006002258},
  groups    = {STAT841},
  timestamp = {2013.12.03},
  url       = {http://www.worldscientific.com/doi/abs/10.1142/S0219622006002258},
}

@Article{Yao2007,
  Title                    = {Integration of Vision and Inertial Sensors for 3D Arm Motion Tracking in Home-based Rehabilitation},
  Author                   = {Yao, Y. AND Hu, H. AND Zhou, H.},
  Journal                  = {International Journal of Robotics Research},
  Year                     = {2007},
  Pages                    = {607--624},
  Volume                   = {26},

  Abstract                 = {The integration of visual and inertial sensors for human motion tracking has attracted significant attention recently, due to its robust performance and wide potential application. This paper introduces a real-time hybrid solution to articulated 3D arm motion tracking for home-based rehabilitation by combining visual and inertial sensors. Data fusion is a key issue in this hybrid system and two different data fusion methods are proposed. The first is a deterministic method based on arm structure and geometry information, which is suitable for simple rehabilitation motions. The second is a probabilistic method based on an Extended Kalman Filter (EKF) in which data from two sensors is fused in a predict-correct manner in order to deal with sensor noise and model inaccuracy. Experimental results are presented and compared with commercial marker-based systems, CODA and Qualysis. They show good performance for the proposed solution.},
  Keywords                 = {Postural detection},
  Timestamp                = {2010.01.17}
}

@Article{Yardley2005,
  Title                    = {Development and initial validation of the Falls Efficacy Scale-International},
  Author                   = {Yardley, L. and Beyer, N. and Hauer, K. and Kempen, G. and Piot-Ziegler, C. and Todd, C.},
  Journal                  = {Age and Ageing},
  Year                     = {2005},
  Number                   = {6},
  Pages                    = {614--19},
  Volume                   = {34},

  Abstract                 = {Background: there is a need for a measure of fear of falling that assesses both easy and difficult physical activities and social activities and is suitable for use in a range of languages and cultural contexts, permitting direct comparison between studies and populations in different countries and settings.Objective: to develop a modified version of the Falls Efficacy Scale to satisfy this need, and to establish its psychometric properties, reliability, and concurrent validity (i.e. that it demonstrates the expected relationship with age, falls history and falls risk factors).Design: cross-sectional survey.Setting: community sample.Method: 704 people aged between 60 and 95 years completed The Falls Efficacy Scale-International (FES-I) either in postal self-completion format or by structured interview.Results: the FES-I had excellent internal and test–retest reliability (Cronbach’s=0.96, ICC=0.96). Factor analysis suggested a unitary underlying factor, with two dimensions assessing concern about less demanding physical activities mainly in the home, and concern about more demanding physical activities mainly outside the home. The FES-I had slightly better power than the original FES items to discriminate differences in concern about falling between groups differentiated by sex, age, occupation, falls in the past year, and falls risk factors (chronic illness, taking multiple or psychoactive medications, dizziness).Conclusions: the FES-I has close continuity with the best existing measure of fear of falling, excellent psychometric properties, and assesses concerns relating to basic and more demanding activities, both physical and social. Further research is required to confirm cross-cultural and predictive validity.},
  Doi                      = {10.1093/ageing/afi196},
  Eprint                   = {http://ageing.oxfordjournals.org/content/34/6/614.full.pdf+html},
  Timestamp                = {2012.06.21}
}

@Article{Yazdi1998,
  Title                    = {Micromachined inertial sensors},
  Author                   = {Yazdi, N. and Ayazi, F. and Najafi, K.},
  Journal                  = {Proceedings of the IEEE},
  Year                     = {1998},

  Month                    = {aug},
  Number                   = {8},
  Pages                    = {1640 -1659},
  Volume                   = {86},

  Abstract                 = {This paper presents a review of silicon micromachined accelerometers and gyroscopes. Following a brief introduction to their operating principles and specifications, various device structures, fabrication, technologies, device designs, packaging, and interface electronics issues, along with the present status in the commercialization of micromachined inertial sensors, are discussed. Inertial sensors have seen a steady improvement in their performance, and today, microaccelerometers can resolve accelerations in the micro-g range, while the performance of gyroscopes has improved by a factor of 10 times; every two years during the past eight years. This impressive drive to higher performance, lower cost, greater functionality, higher levels of integration, and higher volume will continue as new fabrication, circuit, and packaging techniques are developed to meet the ever increasing demand for inertial sensors},
  Doi                      = {10.1109/5.704269},
  ISSN                     = {0018-9219},
  Keywords                 = {Si;accelerometer;device design;fabrication;gyroscope;interface electronics;packaging;silicon micromachined inertial sensor;accelerometers;elemental semiconductors;gyroscopes;inertial systems;micromachining;microsensors;silicon;},
  Review                   = {Talks about the physics behind IMU devices},
  Timestamp                = {2011.07.19}
}

@Article{Yi2011,
  Title                    = {Incremental SVM based on reserved set for network intrusion detection},
  Author                   = {Yi, Yang and Wu, Jiansheng and Xu, Wei},
  Journal                  = {Expert Systems with Applications},
  Year                     = {2011},
  Number                   = {6},
  Pages                    = {7698--7707},
  Volume                   = {38},

  Abstract                 = {We develop an improved incremental SVM algorithm, named RS-ISVM, to deal with network intrusion
detection. To reduce the noise generated by feature differences, we propose a modified kernel function
U-RBF, with the mean and mean square difference values of feature attributes embedded in kernel function RBF. Then, given the oscillation problem that usually occurs in traditional incremental SVM’s followup learning process, we present a reserved set strategy which can keep those samples that are more likely
to be the support vectors in the following computation process. Moreover, in order to shorten the training
time, a concentric circle method is suggested to be used in selecting samples to form the reserved set.
Academic researches and data experiments show that RS-ISVM can ease the oscillation phenomenon
in the learning process and achieve pretty good performance, meanwhile, its reliability is relative high.},
  Review                   = {The math is a bit confusing, but they mentioned a good point. Just using current SVs and discarding the original training data might mean that the addition of new data (and thus new SVs) might lead to a big shift in decision boundary that otherwise would not have happened if the original training data contributed new SVs that were overshadowed by the original SVM's SVs. 

won't look too much into this for now, but this oscillating error has been noted},
  Timestamp                = {2014.10.24}
}

@Article{Yin2008,
  Title                    = {Sensor-Based Abnormal Human-Activity Detection},
  Author                   = {Jie Yin and Qiang Yang and Pan, J. J.},
  Journal                  = {Knowledge and Data Engineering, IEEE Transactions on},
  Year                     = {2008},

  Month                    = {Aug},
  Number                   = {8},
  Pages                    = {1082--1090},
  Volume                   = {20},

  Abstract                 = {With the availability of affordable sensors and sensor networks, sensor-based human activity recognition has attracted much attention in artificial intelligence and ubiquitous computing. In this paper, we present a novel two-phase approach for detecting abnormal activities based on wireless sensors attached to a human body. Detecting abnormal activities is a particular important task in security monitoring and healthcare applications of sensor networks, among many others. Traditional approaches to this problem suffer from a high false positive rate, particularly when the collected sensor data are biased towards normal data while the abnormal events are rare. Therefore, there is a lack of training data for many traditional data mining methods to be applied. To solve this problem, our approach first employs a one-class support vector machine (SVM) that is trained on commonly available normal activities, which filters out the activities that have a very high probability of being normal. We then derive abnormal activity models from a general normal model via a kernel nonlinear regression (KNLR) to reduce false positive rate in an unsupervised manner. We show that our approach provides a good tradeoff between abnormality detection rate and false alarm rate, and allows abnormal activity models to be automatically derived without the need to explicitly label the abnormal training data, which are scarce. We demonstrate the effectiveness of our approach using real data collected from a sensor network that is deployed in a realistic setting.},
  Doi                      = {10.1109/TKDE.2007.1042},
  ISSN                     = {1041-4347},
  Keywords                 = {data mining;gesture recognition;monitoring;regression analysis;support vector machines;wireless sensor networks;abnormal activity model;artificial intelligence;data mining;general normal model;healthcare application;kernel nonlinear regression;one-class support vector machine;security monitoring;sensor-based abnormal human-activity detection;sensor-based human activity recognition;ubiquitous computing;wireless sensors;Activity Recognition;Data Mining;Outlier Detection;Sensor Networks},
  Timestamp                = {2014.12.21}
}

@InProceedings{Yoshikawa2007,
  Title                    = {A myoelectric interface for robotic hand control using support vector machine},
  Author                   = {Yoshikawa, M. and Mikawa, M. and Tanaka, K.},
  Booktitle                = {IROS},
  Year                     = {2007},
  Pages                    = {2723--8},

  Abstract                 = {This paper reports a new myoelectric interface for robotic hand control consisting of two main parts. The first part concerns the motion classification using electromyogram (EMG) signals of a support vector machine (SVM). Because there has been little research on the application of the SVM to motion classification using EMG signals, its effectiveness has not yet been established. The SVM has some advantages with respect to generalization and computational complexity, and therefore, we used the SVM to examine its classification ability. The second part concerns the estimation of an operator's joint angle corresponding to the motion determined by the first part. Estimation of the operator's joint angles is based on EMG-Joint angle models, which express the linear relationships between the EMG signals and joint angles. To verify the effectiveness of our interface, we performed off-line hand motion classification and real-time robotic hand control experiments with eight subjects. The experimental results showed that seven hand motions achieved a classification rate of more than 90% for all subjects. In addition, a three-dimensional computer graphics robotic hand was controlled in real-time (62.5 Hz) without delay.},
  Owner                    = {jf2lin},
  Review                   = {want to classify motion EMG using via SVM
uses a EMG->Joint angle model...builds linear equations from EMG to get joint angles. the proc is:
- measure emg
- calculate features
- classify using svm
- using the label, select a EMG->joint angle model to estimate joint angles. linear regression

4 channel EMG. 64 ms windows, shift of 16 ms, and fullwave rectified to "IEMG"
- uses these features: average IMEG, CC, diff(CC)
- rbf kernel for svm

7 primitives, one-vs-one SVM in voting scheme. to reduce misclassification, the current label is decided by the previous 5 labels

8 subjects, forearm. SVM tuned by grid searching},
  Timestamp                = {2015.05.21}
}

@InCollection{Young2010,
  Title                    = {Estimation of Lower Limb Joint Angles during Walking Using Extended Kalman Filtering},
  Author                   = {Young, D. and D’Orey, S. and Opperman, R. and Hainley, C. and Newman, D. J.},
  Booktitle                = {6th World Congress of Biomechanics},
  Publisher                = {Springer Berlin Heidelberg},
  Year                     = {2010},
  Editor                   = {Lim, C.T. and Goh, J.C.H.},
  Pages                    = {1319-1322},
  Series                   = {IFMBE Proceedings},
  Volume                   = {31},

  Abstract                 = {In order to evaluate the performance of an extended Kalman filter (EKF) for the estimation of lower limb joint angles generated during human walking, a pilot study is conducted using commercial inertial measurement units (IMUs) to capture 3D acceleration and angular velocity data produced by the leg during level ground, stair ascent, and stair descent walking. The inertial data from three IMUs, one mounted on each lower limb segment, are input to an EKF to estimate sagittal and coronal angles of the individual limb segments and the corresponding knee and ankle joint angles. This method is evaluated against the standard method performed using optical motion capture and inverse kinematics software. Results from three subjects are reviewed, and the promising potential of this technique for realtime applications is discussed.},
  Doi                      = {10.1007/978-3-642-14515-5_336},
  ISBN                     = {978-3-642-14514-8},
  Keywords                 = {Kalman filter; inertial measurement; joint angle; walking},
  Timestamp                = {2013.05.15},
  Url                      = {http://dx.doi.org/10.1007/978-3-642-14515-5_336}
}

@InProceedings{Yuwono2013,
  Title                    = {Unsupervised Segmentation of Heel-Strike IMU Data Using Rapid Cluster Estimation of Wavelet Features},
  Author                   = {Yuwono, M. and Su, S. W. and Moulton, B. D. and Nguyen, H. T.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {When undertaking gait-analysis, one of the most important factors to consider is heel-strike (HS). Signals from a waist worn Inertial Measurement Unit (IMU) provides sufficient accelerometric and gyroscopic information for estimating gait parameter and identifying HS events. In this paper we propose a novel adaptive, unsupervised, and parameter-free identification method for detection of HS events during gait episodes. Our proposed method allows the device to learn and adapt to the profile of the user without the need of supervision. The algorithm is completely parameter-free and requires no prior fine tuning. Autocorrelation features (ACF) of both antero-posterior acceleration a_AP and medio-lateral acceleration a_ML are used to determine cadence episodes. The Discrete Wavelet Transform (DWT) features of signal peaks during cadence are extracted and clustered using Swarm Rapid Centroid Estimation (Swarm RCE). Left HS (LHS), Right HS (RHS), and movement artifacts are clustered based on intra-cluster correlation. Initial pilot testing of the system on 8 subjects show promising results up to 84.3%+-9.2% and 86.7%+-6.9% average accuracy with 86.8%+-9.2% and 88.9%+-7.1% average precision for the segmentation of LHS and RHS respectively.},
  Keywords                 = {EMBC2013},
  Review                   = {One hip-mounted IMU used to segment heel-strike events. Similar prior methods tend to perform poorly in real life, due to sensor noise, gait pattern variability and sensor drift. Need an algorithm that can distinguish movement artifacts from HS patterns. This paper proposes a pattern cluster technique that allows the system to adapt to the user's gait over time.

They used a 9DOF Shimmer. Attached the Shimmer to the belt, right side of the person. x-axis is down towards gravity. y-axis is forward. z-axis is sideways. 50 Hz. Processed in MATLAB. Looked at vertical and forward acceleration. Peak detection applied to pull out HS, TO and artifacts. Around each peak, gyro/accel wavelet features are calculated. The extracted HS features are clustered into being either L-HS, R-HS or outliers (includes TO and other movement artifats). Consecutive HS with similar duration are detected as a stride. 

Can extract gait parameters by looking at the autocorrelation function (ACF) of the acceleration. Cadence from frequency analysis of the vertical ACF. Stride length from freqnecy analysis of the horizontal ACF. Candence specifically calculated by binning the signal with length delta t, Butterworth filter it between 0.5 and 3Hz, and performing spectral analysis to pull out the largest frequency ("spectral centroids"). .Discrete wavelet transform (DWT) detect frequency patterns at a specific time. Has adv over FFT because FFT loses temporal information. Large values in the DWT coefficients implies high similiarty between mother wavelet and the target signal at a given time.

Since HS patterns change over time, a data clustering approach is suggested to increase robustness. The clustering is applied to separate R-HS, L-HS and TO. Strides are determine by similarity in timing in the acceleration peaks. 

Tested on 8 people. Walk for 5 minutes at normal pace. Numbers of steps taken was counted, but it doesn't look like they did a temporal analysis on accuracy...they determined accuracy by dividing HS positive rate by total number of steps.




Yuwono \etal \cite{Yuwono2013} used a hip mounted 9-DOF IMU to segment heel-strike events in walking. Similar prior methods tend to perform poorly in real life, due to sensor noise, gait pattern variability and sensor drift, thus an algorithm that can distinguish movement artifacts from heel-strike patterns is needed. This paper proposes a pattern cluster technique that allows the system to adapt to the user's gait over time. Focusing on the vertical and forward acceleration, peak detection is applied to isolate heel-strike, toe-off and artifacts. At each peak, the IMU wavelet features are calculated, and clustered into either left-heel-strike, right-heel-strike, or outliers. Consecutive heel-strikes with similar durations are detected as a stride. Further gait parameters can be extracted by examining the auto-correlation function (ACF) of the acceleration: gait cadence from frequency analysis of the vertical ACF and stride length from the horizontal ACF. Segmentation accuracy was determined by dividing heel-strike events by total number of steps, but no temporal analysis was done.

Yuwono \etal \cite{Yuwono2013} use a hip mounted 9-DOF IMU to segment on heel-strikes during walking. Focusing on the vertical and forward acceleration, peak detection is applied to isolate heel-strike, toe-off and artifacts. At each peak, the IMU wavelet features are calculated, and clustered into either left-heel-strike, right-heel-strike, or outliers. Consecutive heel-strikes with similar durations are detected as a stride. This algorithm was tested on the gait data of 8 subjects. Ground truth obtained by counting, as par Section \ref{lbl:verification_counting}. $Acc_{TAP}$ and $Acc_{precision}$ was reported to be 86\% and 88\%, respectively.},
  Timestamp                = {2013.07.30}
}

@InProceedings{Zaidi2010,
  Title                    = {Local Adaptive SVM for Object Recognition},
  Author                   = {Zaidi, N. A. and Squire, D. M.},
  Booktitle                = {International Conference on Digital Image Computing: Techniques and Applications},
  Year                     = {2010},
  Pages                    = {196--201},

  Abstract                 = {The Support Vector Machine (SVM) is an effective classification tool. Though extremely effective, SVMs are
not a panacea. SVM training and testing is computationally
expensive. Also, tuning the kernel parameters is a complicated
procedure. On the other hand, the Nearest Neighbor (KNN)
classifier is computationally efficient. In order to achieve the
classification efficiency of an SVM and the computational
efficiency of a KNN classifier, it has been shown previously
that, rather than training a single global SVM, a separate
SVM can be trained for the neighbourhood of each query
point. In this work, we have extended this Local SVM (LSVM)
formulation. Our Local Adaptive SVM (LASVM) formulation
trains a local SVM in a modified neighborhood space of a
query point. The main contributions of the paper are twofold:
First, we present a novel LASVM algorithm to train a local
SVM. Second, we discuss in detail the motivations behind
the LSVM and LASVM formulations and its possible impacts
on tuning the kernel parameters of an SVM. We found that
training an SVM in a local adaptive neighborhood can result in
significant classification performance gain. Experiments have
been conducted on a selection of the UCIML, face, object, and
digit database},
  Review                   = {doesn't seem online. seems like they need to retrain the svm everytime new testing data comes in},
  Timestamp                = {2014.10.24}
}

@InProceedings{Zecca2013,
  Title                    = {Use of an Ultra-Miniaturized IMU-Based Motion Capture System for Objective Evaluation and Assessment of Walking Skills},
  Author                   = {Zecca, M. and Saito, K. and Sessa, S. and Bartolomeo, L. and Lin, Z. and Cosentino, S. and Ishii, H. and Ikai, T. and Takanishi, A.},
  Booktitle                = {Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology Society},
  Year                     = {2013},

  Abstract                 = {The increasing age of the world population is posing new challenges to our society, such as how to keep this aging population healthy and active despite of the age. In recent years, there has been a lot of interest for gait analysis for rehabilitation purposes as well as for performance assessment of this aging population. While current systems work well, they still have several limitations. Cost, need for specialized personnel, need to be used in a research center, and sporadic measurement prevent these systems from being widely used. The authors propose the use of extremely miniaturized, portable measurement systems, which can be worn by the users during their everyday life, and can monitor their gait over a long timespan. This paper presents the preliminary experiments with such a system.},
  Keywords                 = {EMBC2013},
  Review                   = {Monitorying walking speed and daily activities to see if they're suffering from a cognitive decline.

Using a MARG (200 Hz!), 5x of them, to determine joitn angle while walking. However, no algorithm details were given.},
  Timestamp                = {2013.08.05}
}

@InProceedings{Zelnikmanor2001,
  Title                    = {Event-based analysis of video},
  Author                   = {Zelnik-Manor, Lihi and Irani, Michal},
  Booktitle                = {Computer Vision and Pattern Recognition, 2001. CVPR 2001. Proceedings of the 2001 IEEE Computer Society Conference on},
  Year                     = {2001},
  Organization             = {IEEE},
  Pages                    = {II--123},
  Volume                   = {2},
  Abstract                 = {Dynamic events can be regarded as long-term temporal objects, which are characterized by spatiotemporal featur es at multiple temporal scales. Based on this, we design a simple statistical distance
measure between video sequences (possibly of differ ent lengths) based on their behavioral content. This
measure is non-parametric and can thus handle a wide range of dynamic events. Having an event-based
distance measure between sequences, we use it for a variety of tasks, including: (i) event-based search
and indexing into long video sequences (for “intelligent fast forwar d”), (ii) temporal se gmentation of
long video sequences based on behavioral content, and (iii) clustering events within long video sequence
into event-consistent sub-sequences (i.e., into event-consistent “clusters”). These tasks are performed
without prior knowledge of the types of events, their models, or their temporal extents.
Our simple event representation and associated distance measure supports event-based search and
indexing even when only one short example-clip is available. However , when multiple example-clips of
the same event are available (either as a result of the clustering process, or supplied manually), these
can be used to refine the event representation, the associated distance measure, and accordingly the
quality of the detection and clustering process.},
  Timestamp                = {2013.10.08}
}

@InProceedings{Zhang2005,
  Title                    = {Navigation with IMU/GPS/digital compass with unscented Kalman filter},
  Author                   = {P. Zhang and J. Gu and E.E. Milios and P. Huynh},
  Booktitle                = {Proceedings of the IEEE International Conference on Mechatronics and Automation},
  Year                     = {2005},
  Month                    = { },
  Pages                    = {1497 -1502 Vol. 3},
  Volume                   = {3},

  Abstract                 = {Autonomous vehicle navigation with standard IMU and differential GPS has been widely used for aviation and military applications. Our research interesting is focused on using some low-cost off-the-shelf sensors, such as strap-down IMU, inexpensive single GPS receiver. In this paper, we present an autonomous vehicle navigation method by integrating the measurements of IMU, GPS, and digital compass. Two steps are adopted to overcome the low precision of the sensors. The first is to establish sophisticated dynamics models which consider Earth self rotation, measurement bias, and system noise. The second is to use a sigma Kalman filter for the system state estimation, which has higher accuracy compared with the extended Kalman filter. The method was evaluated by experimenting on a land vehicle equipped with IMU, GPS, and digital compass.},
  Doi                      = {10.1109/ICMA.2005.1626777},
  Keywords                 = {Earth self rotation;autonomous vehicle navigation;differential GPS;digital compass;inertial measurement unit;measurement bias;sigma Kalman filter;state estimation;system noise;unscented Kalman filter;Global Positioning System;Kalman filters;mobile robots;remotely operated vehicles;sensor fusion;state estimation;IMU calibration;UKF},
  Review                   = {- I can't use the GPS, but kind of interested in the UKF
- Uses off-the-shelf things
- Strapdown IMU, GPS, digital compass, combined under UKF to determine location of a vehicle},
  Timestamp                = {2011.07.19}
}

@Article{Zhang2008,
  Title                    = {An interactive Internet-based system for tracking upper limb motion in home-based rehabilitation},
  Author                   = {Zhang, S. and Hu, H. and Zhou, H.},
  Journal                  = {Medical and Biological Engineering and Computing},
  Year                     = {2008},

  Month                    = {March},
  Number                   = {3},
  Pages                    = {241--249},
  Volume                   = {46},

  Abstract                 = {In this paper, we introduce an interactive telecommunication system that supports video/audio signal acquisition, data processing, transmission, and 3D animation for post stroke rehabilitation. It is designed for stroke patients to use in their homes. It records motion exercise data, and immediately transfers this data to hospitals via the internet. A real-time videoconferencing interface is adopted for patients to observe therapy instructions from therapists. The system uses a peer-to-peer network architecture, without the need for a server. This is a potentially effective approach to reducing costs, allowing easy setup and permitting group-rehabilitation sessions. We evaluate this system using the following steps: (1) motion detection in different movement patterns, such as reach, drink, and reach-flexion; (2) online bidirectional visual telecommunication; and (3) 3D rendering using a proposed offline animation package. This evaluation has subjectively been proved to be optimal.},
  Doi                      = {10.1007/s11517-007-0295-6},
  ISSN                     = {0140-0118 (Print) 1741-0444 (Online)},
  Keywords                 = {Telemedicine - Telerehabilitation - 3D animation - Peer-to-peer - Multicast, Postural detection},
  Publisher                = {Springer Berlin / Heidelberg},
  Review                   = {Tele-rehab. Tracking upper limb motion. Uses P2P. Microphone, speaker, webcam, transmit over internet. Also has inertial senors. Graphs the data with a stick person (Java3D). 

Uses accel + gyro + mag sensors. Kalman filtering. Good reproduction. No details on gravity subtraction. Or much other stuff, really...more focus on internet transmission techniques, and illustration methods. Had initial calibration methods.},
  Subject_collection       = {Engineering},
  Timestamp                = {2010.07.08},
  Url                      = {http://www.springerlink.com/content/cr220736r363864t/}
}

@InProceedings{Zhang2013,
  author    = {Zhang, T. and Karg, M. E. and Lin, J. F.-S. and Kuli\'{c}, D. and Venture, G.},
  title     = {IMU based Single Stride Identification of Humans},
  booktitle = {Proceedings of the IEEE International Symposium on Robot and Human Interactive Communication},
  year      = {2013},
  pages     = {220-225},
  groups    = {EMBC2014, My Work},
  timestamp = {2013.08.07},
}

@Article{Zhang2001,
  Title                    = {Audio content analysis for online audiovisual data segmentation and classification},
  Author                   = {Zhang, T. and Kuo, C. C. J.},
  Journal                  = {IEEE Transactions on Speech and Audio Processing},
  Year                     = {2001},
  Pages                    = {441--457},
  Volume                   = {9},

  Publisher                = {IEEE},
  Review                   = {While current approaches for audiovisual data segmentation and classification are mostly focused on visual cues, audio signals may actually play a more important role in content parsing for many applications. An approach to automatic segmentation and classification of audiovisual data based on audio content analysis is proposed. The audio signal from movies or TV programs is segmented and classified into basic types such as speech, music, song, environmental sound, speech with music background, environmental sound with music background, silence, etc. Simple audio features including the energy function, the average zero-crossing rate, the fundamental frequency, and the spectral peak tracks are extracted to ensure the feasibility of real-time processing. A heuristic rule-based procedure is proposed to segment and classify audio signals and built upon morphological and statistical analysis of the time-varying functions of these audio features. Experimental results show that the proposed scheme achieves an accuracy rate of more than 90% in audio classification.


Zhang and Kuo \cite{Zhang2001} notes that auditory cues and data can serve as a more important role in content parsing than its video counterpart. They perform segmentation by focusing on several key features: energy, average zero-crossing rate, fundamental frequency and spectral peaks. These features were used to segment over 1000 sound clips of various background sounds, music, singing, and language. Compared against labeled data, this algorithm reports a 90\% accuracy.

Zhang and Kuo \cite{Zhang2001} segment and label audio data streams. They examine several audio-based features like energy, average zero-crossing rate, and fundamental frequency, and perform segmentation when the variance of any of these signals abruptly changes. Labels were applied using heuristic rules based on the segmented features. Segmentation was applied to 20 audio clips, and verification was performed by $Ver_{temporal}$. At $t_{error}$ = 1s, $Acc_{recall}$ of 95\% was reported. 90\% of the primitives were labelled correctly.},
  Timestamp                = {2013.08.29}
}

@InBook{Zhang2012b,
  Title                    = {Biometrics from Gait Using Feature Value Method},
  Author                   = {Zhang, T.
and Venture, G.},
  Editor                   = {Ramsay, A.
and Agre, G.},
  Pages                    = {325--333},
  Publisher                = {Springer Berlin Heidelberg},
  Year                     = {2012},

  __markedentry            = {},
  Booktitle                = {Artificial Intelligence: Methodology, Systems, and Applications},
  Doi                      = {10.1007/978-3-642-33185-5_36},
  ISBN                     = {978-3-642-33185-5},
  Owner                    = {jf2lin},
  Timestamp                = {2017.04.24},
  Url                      = {http://dx.doi.org/10.1007/978-3-642-33185-5_36}
}

@Article{Zhang2011_emg,
  Title                    = {A framework for hand gesture recognition based on accelerometer and {EMG} sensors},
  Author                   = {Zhang, X. and Chen, X. and Li, Y. and Lantz, V. and Wang, K. and Yang, J.},
  Journal                  = {IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans},
  Year                     = {2011},
  Pages                    = {1064--76},
  Volume                   = {41},

  Abstract                 = {This paper presents a framework for hand gesture
recognition based on the information fusion of a three-axis ac-
celerometer (ACC) and multichannel electromyography (EMG)
sensors. In our framework, the start and end points of meaningful
gesture segments are detected automatically by the intensity of
the EMG signals. A decision tree and multistream hidden Markov
models are utilized as decision-level fusion to get the final results.
For sign language recognition (SLR), experimental results on the
classification of 72 Chinese Sign Language (CSL) words demon-
strate the complementary functionality of the ACC and EMG
sensors and the effectiveness of our framework. Additionally,
the recognition of 40 CSL sentences is implemented to evaluate
our framework for continuous SLR. For gesture-based control,
a real-time interactive system is built as a virtual Rubik’s cube
game using 18 kinds of hand gestures as control commands.
While ten subjects play the game, the performance is also ex-
amined in user-specific and user-independent classification. Our
proposed framework facilitates intelligent and natural control in
gesture-based interaction.},
  Owner                    = {jf2lin},
  Publisher                = {IEEE},
  Review                   = {Applies accel and emg to chinese sign language recog. uses decision trees and HMM to combine the two. segments incoming data based on threshold of instantaneous energy of average signal of emg channels automatically, to determine "active segments", which are the primitives of interest. calculated from moving average of window size 60. 

extracts 3d accel data. all accel data is scaled to be the same length. mean and sd calculated, and will be fed into a DT
extracts emg data, using zeroc-rossing rate, rms, ar model, short time fourier, wavelet coeff. actually, they only used mean abs value and 4th order ar coeff. used windows of 250 ms, with 125 ms overlap. 

DT is design to figure out:
- static vs dynamic gesture based on accel sd
- short vs long gestures based on duration data from emg
- hand orientation based on accel values. determined on k-means and LDA. if the k-means and LDA is indecisive, an HMM is used to determine the actual label. 
-> the actual word for the active segment is determined by traversing the tree

2 subjects, 5 sessions, 72 gestures, 12 rep per motion. 
- emg only has confusion mtx of 56-99%
- acc only has confusion matrix of 54-100%
- combined to get 95%

no segmentation results reported},
  Timestamp                = {2015.04.03}
}

@Article{Zhang2012,
  Title                    = {Microsoft Kinect Sensor and Its Effect},
  Author                   = {Zhang, Z.},
  Journal                  = {IEEE Multimedia},
  Year                     = {2012},
  Pages                    = {4--10},
  Volume                   = {19},

  Abstract                 = {Recent advances in 3D depth cameras such as Microsoft Kinect sensors (www.xbox.com/en-US/kinect) have created many opportunities for multimedia computing. The Kinect sensor lets the computer directly sense the third dimension (depth) of the players and the environment. It also understands when users talk, knows who they are when they walk up to it, and can interpret their movements and translate them into a format that developers can use to build new experiences. While the Kinect sensor incorporates several advanced sensing hardware, this article focuses on the vision aspect of the Kinect sensor and its impact beyond the gaming industry.},
  Doi                      = {10.1109/MMUL.2012.24},
  ISSN                     = {1070-986X},
  Keywords                 = {CMOS image sensors;computer vision;human computer interaction;infrared detectors;multimedia computing;optical projectors;3D depth cameras;CMOS image sensor;IR projector;Kinect sensor vision aspect;Microsoft Kinect sensor;advanced sensing hardware;computer vision;gaming industry;infrared projector;multimedia computing;Cameras;Games;Sensors;Three dimensional displays;Video recording;Microsoft Kinect;computer vision;human-computer interaction;motion capture;multimedia},
  Timestamp                = {2015.01.29}
}

@InProceedings{Zhao2009,
  author    = {Zhao, L. and Sukthankar, G.},
  title     = {An active learning approach for segmenting human activity datasets},
  booktitle = {Proceedings of the 17th ACM international conference on Multimedia},
  year      = {2009},
  pages     = {765--768},
  abstract  = {Human activity datasets collected under natural conditions are an important source of data. Since these contain multiple activities in unscripted sequence, temporal segmentation of multimodal datasets is an important precursor to recognition and analysis. Manual segmentation is prohibitively time consuming and unsupervised approaches for segmentation are unreliable since they fail to exploit the semantic context of the data. Gathering labels for supervised learning places a large workload on the human user since it is relatively easy to gather a mass of unlabeled data but expensive to annotate. This paper proposes an active learning approach for segmenting large motion capture datasets with both small training sets and working sets. Support Vector Machines (SVMs) are learned using an active learning paradigm; after the classifiers are initialized with a small set of labeled data, the users are iteratively queried for labels as needed. We propose a novel method for initializing the classifiers, based on unsupervised segmentation and clustering of the dataset. By identifying and training the SVM with points from pure clusters, we can improve upon a random sampling strategy for creating the query set. Our active learning approach improves upon the initial unsupervised segmentation used to initialize the classifier, while requiring substantially less data than a fully supervised method; the resulting segmentation is comparable to the latter while requiring significantly less effort from the user.},
  acmid     = {1631408},
  groups    = {STAT841},
  isbn      = {978-1-60558-608-3},
  keywords  = {active learning, motion segmentation, semi-supervised learning, support vector machines (SVM)},
  location  = {Beijing, China},
  numpages  = {4},
  review    = {- a lot of related work on manual segmentation
- but of course, we like automatic segmentaiton

- they use SVM (support vector machine)

SEGMENT
- PCA is applied to training data, and is used to project each timestep in obs. PCA is taken of timestep (dim = 56)
- "Transitions are detected using the discrete derivative of reconstruction error; if this error is more than 3 standard deviations from the average of all previous data points, a motion cut is introduced." -> well. Just say it builds off of Barbic2004 as coarse seg. 
- once these coarse segments are done, the user is asked to label the motions. like motions are merged together, and is used to initalize SVMs. They note that only a few labels are needed. 
- Tested on a CMU database. Each datapoint is labeled using SVM

[not enough details given in this paper. refer to the journal version instead]},
  timestamp = {2011.01.27},
}

@Article{Zhao2010,
  author    = {Zhao, L. and Wang, X. and Sukthankar, G.},
  title     = {Recognizing Household Activities from Human Motion Data using Active Learning and Feature Selection},
  journal   = {Technology and Disability},
  year      = {2010},
  volume    = {22},
  number    = {1},
  pages     = {17--26},
  groups    = {Lit Review 2013-09},
  publisher = {IOS Press},
  review    = {- a lot of related work on manual segmentation
- but of course, we like automatic segmentaiton

- they use SVM (support vector machine)

SEGMENT
- PCA is applied to training data, and is used to project each timestep in obs. PCA is taken of timestep (dim = 56)
- "Transitions are detected using the discrete derivative of reconstruction error; if this error is more than 3 standard deviations from the average of all previous data points, a motion cut is introduced." -> well. Just say it builds off of Barbic2004 as coarse seg. 
- once these coarse segments are done, the user is asked to label the end-of-segment frames of. like motions are merged together, and is used to initalize SVMs. One vs all classifiers are used. Once the SVMs are trained, the SVM is ran against the remaining unlabeled data, and the unlabeled data with the smallest distance from the hpyerplane is polled for label, and the SVM is retrained. They note that only a few labels are needed. 
-> The SVM seems to be classifing between "known motion" (ie labeled data) vs "unknown motion" (...which seems to be their segment bound)...though they're using one-vs-all, which implies a bunch of different SVMs all running at once. however, they still employ CRF 
- Tested on a CMU database, performing 15 different motions. The SVM classification reports 95% accuracy. 

- then trains a CRF classifier to perform motif discovery (ie labeling)},
  timestamp = {2013.10.16},
}

@InProceedings{Zhao2013,
  Title                    = {Online Human Gesture Recognition from Motion Data Streams},
  Author                   = {Zhao, X. and Li, X. and Pang, C. and Zhu, X. and Sheng, Quan Z.},
  Booktitle                = {Proceedings of the ACM International Conference on Multimedia},
  Year                     = {2013},

  Address                  = {New York, NY, USA},
  Pages                    = {23--32},
  Publisher                = {ACM},
  Series                   = {MM '13},

  Abstract                 = {Online human gesture recognition has a wide range of applications
in computer vision, especially in human-computer
interaction applications. Recent introduction of cost-effective
depth cameras brings on a new trend of research on bodymovement
gesture recognition. However, there are two major
challenges: i) how to continuously recognize gestures
from unsegmented streams, and ii) how to differentiate different
styles of a same gesture from other types of gestures.
In this paper, we solve these two problems with a new effective
and efficient feature extraction method that uses a
dynamic matching approach to construct a feature vector
for each frame and improves sensitivity to the features of
different gestures and decreases sensitivity to the features
of gestures within the same class. Our comprehensive experiments
on MSRC-12 Kinect Gesture and MSR-Action3D
datasets have demonstrated a superior performance than the
stat-of-the-art approaches.},
  Acmid                    = {2502103},
  Doi                      = {10.1145/2502081.2502103},
  ISBN                     = {978-1-4503-2404-5},
  Keywords                 = {depth camera, feature extraction, gesture recognition},
  Location                 = {Barcelona, Spain},
  Numpages                 = {10},
  Review                   = {Online. Uses joint positions from depth camera. 

MAnually segment training stream, then cluster similar motions together to create a template dictionary. each DOF is clustered individually, so they'd have smaller clusters per DOF, over a bunch of DOFs, instead of a system that has unified DOFs but a lot of clusters. the motion is then transformed to another space ("SSS feature extraction") that represent DTW distance between frames. a relative distance metric, of sorts. a classifier is used to learn this distance. 

they use DTW to reduce execution speed differences

...

not a segmentation paper though. this is only activity recognition, but it can probably be extended for segmentation...

Zhao \emph{et al.} \cite{Zhao2013} cluster manually segmented data of single dimensional data together to create a template dictionary, leading to a large number of simple templates and to less computational costs. A time-warping distance feature is calculated between the observed data and the template dictionary, to reduce the temporal impact. Segmentation and identification are performed simultaneously by using a linear classifier.},
  Timestamp                = {2015.06.30},
  Url                      = {http://doi.acm.org/10.1145/2502081.2502103}
}

@Article{Zheng2005,
  Title                    = {Position-sensing technologies for movement analysis in stroke rehabilitation},
  Author                   = {Zheng, H. and Black, N. and Harris, N.},
  Journal                  = {Medical and Biological Engineering and Computing},
  Year                     = {2005},
  Note                     = {10.1007/BF02344720},
  Pages                    = {413-420},
  Volume                   = {43},

  Abstract                 = {Research has focused on improvement of the quality of life of stroke patients. Gait detection, kinematics and kinetics analysis, home-based rehabilitation and telerehabilitation are the areas where there has been increasing research interest. The paper reviews position-sensing technologies and their application for human movement tracking and stroke rehabilitation. The review suggests that it is feasible to build a home-based telerehabilitation system for sensing and tracking the motion of stroke patients.},
  Affiliation              = {University of Ulster School of Computing &amp; Mathematics Newtownabbey Northern Ireland Newtownabbey Northern Ireland},
  ISSN                     = {0140-0118},
  Issue                    = {4},
  Keyword                  = {Medicine},
  Publisher                = {Springer Berlin / Heidelberg},
  Review                   = {Review paper - looks at different human movement technologies

Pedometers
- uses spring-suspended horizontal arm, which moves up and down to open/close a switch, which registers a step
- accurate to count steps, and not much else

Goniometer
- a pot, used to tell joint angles

Pressure sensors},
  Timestamp                = {2010.10.11},
  Url                      = {http://dx.doi.org/10.1007/BF02344720}
}

@InProceedings{Zhou2008b,
  author    = {Zhou, F. and De la Torre Frade, F. and Hodgins, J. K.},
  title     = {Aligned Cluster Analysis for Temporal Segmentation of Human Motion},
  booktitle = {Proceedings of the IEEE Conference on Automatic Face and Gestures Recognition},
  year      = {2008},
  abstract  = {Temporal segmentation of human motion into actions is a crucial step for understanding and building computational models of human motion. Several issues contribute to the challenge of this task. These include the large variability in the temporal scale and periodicity of human actions, as well as the exponential nature of all possible movement combinations. We formulate the temporal segmentation problem as an extension of standard clustering algorithms. In particular, this paper proposes Aligned Cluster Analysis (ACA), a robust method to temporally segment streams of motion capture data into actions. ACA extends standard kernel k-means clustering in two ways: (1) the cluster means contain a variable number of features, and (2) a dynamic time warping (DTW) kernel is used to achieve temporal invariance. Experimental results, reported on synthetic data and the Carnegie Mellon Motion Capture database, demonstrate its effectiveness.},
  groups    = {Lit Review 2013-09, IROS2014},
  keywords  = {Motion Segmentation},
  review    = {"The inherent difficulty of human motion segmentation stems from the large intra-person physical variability, wide range of temporal scales, irregularity in the periodicity of human actions, and the exponential nature of possible movement combinations. To partially address these problems, we formulate the temporal segmentation of human behavior as a temporal clustering problem."

- Using Aligned Cluster Analysis
 - a form of k-means clustering
- And Dynamic Time Alignment Kernal
- Segmentation posed as an energy minimization problem

okay. rereading this paper. 

uses kernal k-means. they reformualte temporal segmenation problem as a clustering problem. Well. extended on the k-means by assuming that each segment Yi has a different number of frames (instead of k-means, which have a fix number of features). The kernal used for ACA is DTW. Calculate a distance metric.

and rereading...

Want to temporal segment. View this as a clustering problem (ACA is casted as an extension of k-means). A},
  timestamp = {2015.06.29},
}

@Article{Zhou2013,
  Title                    = {Hierarchical Aligned Cluster Analysis for Temporal Clustering of Human Motion},
  Author                   = {Zhou, F. and de la Torre, F. and Hodgins, J. K.},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {2013},
  Pages                    = {582--596},
  Volume                   = {35},

  Abstract                 = {Temporal segmentation of human motion into plausible motion primitives is central to understanding and building computational models of human motion. Several issues contribute to the challenge of discovering motion primitives: the exponential nature of all possible movement combinations, the variability in the temporal scale of human actions, and the complexity of representing articulated motion. We pose the problem of learning motion primitives as one of temporal clustering, and derive an unsupervised hierarchical bottom-up framework called hierarchical aligned cluster analysis (HACA). HACA finds a partition of a given multidimensional time series into m disjoint segments such that each segment belongs to one of k clusters. HACA combines kernel k-means with the generalized dynamic time alignment kernel to cluster time series data. Moreover, it provides a natural framework to find a low-dimensional embedding for time series. HACA is efficiently optimized with a coordinate descent strategy and dynamic programming. Experimental results on motion capture and video data demonstrate the effectiveness of HACA for segmenting complex motions and as a visualization tool. We also compare the performance of HACA to state-of-the-art algorithms for temporal clustering on data of a honey bee dance. The HACA code is available online.},
  Doi                      = {10.1109/TPAMI.2012.137},
  ISSN                     = {0162-8828},
  Keywords                 = {dynamic programming;image motion analysis;image representation;image segmentation;pattern clustering;time series;HACA;articulated motion representation;dynamic programming;exponential nature;hierarchical aligned cluster analysis;human motion;k clusters;m disjoint segments;motion primitives discovery;multidimensional time series;plausible motion;temporal clustering;temporal scale;temporal segmentation;Clustering algorithms;Heuristic algorithms;Humans;Kernel;Legged locomotion;Motion segmentation;Time series analysis;Temporal segmentation;dynamic programming;human motion analysis;kernel k-means;spectral clustering;time series clustering;time series visualization},
  Review                   = {Clustering approach. A form of k-means and clustering.
- uses kernal kmeans to overcome key kmeans problem, which is that it's optimal only for spherical clusters
- declare clusters by minimizing some energy function. some sort of time series clustering technique
 - minimizes such that the energy kernel distance of each segment 

tests against real data. not bad

Zhou \emph{et al.} uses an extension of DTW to produce similarity measures between two temporally aligned segments. These measures are used in kernel \emph{k}-means clustering in order to cluster with consideration to temporal ordering of data. The optimal segment boundaries are determined by employing coordinate descent to minimize the sum of distances between each segment and the cluster means.


k means minimizes a cost function between all the individual data points and its assigned cluster},
  Timestamp                = {2015.06.29}
}

@Article{Zhou2010,
  Title                    = {Reducing Drifts in the Inertial Measurements of Wrist and Elbow Positions},
  Author                   = {Zhou, H. and Hu, H.},
  Journal                  = {IEEE Transactions on Instrumentation and Measurement},
  Year                     = {2010},
  Number                   = {3},
  Pages                    = {575--585},
  Volume                   = {59},

  Abstract                 = {In this paper, we present an inertial-sensor-based monitoring system for measuring the movement of human upper limbs. Two wearable inertial sensors are placed near the wrist and elbow joints, respectively. The measurement drift in segment orientation is dramatically reduced after a Kalman filter is applied to estimate inclinations using accelerations and turning rates from gyroscopes. Using premeasured lengths of the upper and lower arms, we compute the position of the wrist and elbow joints via a proposed kinematic model. Experimental results demonstrate that this new motion capture system, in comparison to an optical motion tracker, possesses an RMS position error of less than 0.009 m, with a drift of less than 0.005 ms-1 in five daily activities. In addition, the RMS angle error is less than 3d. This indicates that the proposed approach has performed well in terms of accuracy and reliability.},
  Doi                      = {10.1109/TIM.2009.2025065},
  ISSN                     = {0018-9456},
  Keywords                 = {Kalman filter;RMS angle error;elbow position;gyroscopes;human upper limbs;inertial measurements;inertial-sensor-based monitoring system;segment orientation;wearable inertial sensors;wrist position;Kalman filters;biomechanics;biomedical measurement;gyroscopes;magnetic sensors;patient monitoring;, filtering, Postural detection},
  Review                   = {- System on arm, uses Kalman to minimise drift + kinematic model
- Uses accel, gyroscope and magnetic sensor
- Interface uses Bluetooth, transmitting to a base PC
- Assumed shoulder is fixed
- ...he refered to a textbook for his rotation matrix update algorithm! -_-
- they gave up on their strapdown integration (still don't know what that is) since it's sensitive to drift (didn't they claim it wasn't on their last paper?) and is going for Kalman instead
- They have some Kalman equations
 - used a different noise model...?
 - They have their own way of calculating the "C" matrix...might be useful
- Add restrictions to rotation matrix (assume that the jump will not be more than 10 degree between time steps) -> didn't say what they did if it did exceed 10 degrees though

Simulation
- One dim motion with Gaussian noise inserted, in MATLAB

Actual
- Drew a circle and a square in the air
- Measured joint length
- Slow motion...less than 80deg/s, done over 20 seconds 
- Also did some random motions
- They noted that shoulder movement (they assumed rigid shouldeR) and movement speed messed things up
- Interestingly, they said sensor relocation didn't impact measurement much},
  Timestamp                = {2010.09.29}
}

@Article{Zhou2008c,
  Title                    = {Human motion tracking for rehabilitation - A survey},
  Author                   = {Zhou, H. and Hu, H.},
  Journal                  = {Biomedical Signal Processing and Control},
  Year                     = {2008},
  Number                   = {1},
  Pages                    = {1--18},
  Volume                   = {3},

  Abstract                 = {Human motion tracking for rehabilitation has been an active research topic since the 1980s. It has been motivated by the increased number of patients who have suffered a stroke, or some other motor function disability. Rehabilitation is a dynamic process which allows patients to restore their functional capability to normal. To reach this target, a patients' activities need to be continuously monitored, and subsequently corrected. This paper reviews recent progress in human movement detection/tracking systems in general, and existing or potential application for stroke rehabilitation in particular. Major achievements in these systems are summarised, and their merits and limitations individually presented. In addition, bottleneck problems in these tracking systems that remain open are highlighted, along with possible solutions.},
  Doi                      = {DOI: 10.1016/j.bspc.2007.09.001},
  ISSN                     = {1746-8094},
  Keywords                 = {Stroke rehabilitation, Postural detection, survey},
  Review                   = {The rise of these type of interest is due to a desire to decrease the need for face-to-face therapy to increase efficiency/expense issues. "Rehabilitation is adynamic process which uses available facilities to correct any undesired motion behaviour in order to reach an expectation. Therefore, in a rehabilitation course the movement of patients needs to be continously monitored and rectified so as to hold a correct motion. Detecting/tracking human movement becomes vital and necessary in a home-based rehabilitation scheme"

The things they covered are:
Visual marker camera
- Low errors
- Marker occlusion is a problem (requires line-of-sight to be maintained)
- Also cannot tell if a joint is rotating
- Examples:
 - Passive (ie VICON) relies on IR reflection
 - Active (ie CODA) uses a time-multiplex sequence

Marker-free visual tracking
- Arose as a counter against visual marker
 - using stnadard bony landmarks can be unreliable
 - tissues over landmarks can shift
 - markers can drift
- however, conventional camera are not fast enough
 - want sampling rate of at least 60 Hz...
- Examples:
 - 2D with explicit shapes
 - 2D without explicit shapes (human motion are non-rigid, so boundary are variable)
 - 3D approaches (model, stick-figure, volumetric, feature-extraction)

Inertial sensors (accel and gyro)
- Position and angle cannot be inherently obtained
 - Must consider offsets of each device, measurement noise, integration error
 -> Though, using Kalman and kinematics, they claimed to have reduced noise

Magnetic sensors
- Good size and sampling rate
- Suffers from jitter (magnetic interference)

Acoustic (ultrasonic)
- Efficiency of an acoustic transducer is proportional to active surface area
 - ie range matters
 - can improve this by dropping frequency, but that affects response time
- needs line-of-sight

Microwave and radio
- used for large devices (so not suitable for humans detection)

Electromyogram
- Detects muscle electrical activity

Gloves
- Photosensors, strain gauges, pots

Robot-aided tracking
- Uses "sense-measure-feedback" techniques},
  Timestamp                = {2010.01.18}
}

@Article{Zhou2006a,
  Title                    = {Applications of wearable inertial sensors in estimation of upper limb movements},
  Author                   = {Zhou, H. and Hu, H. and Harris, N. D. and Hammerton, J.},
  Journal                  = {Biomedical Signal Processing and Control},
  Year                     = {2006},
  Pages                    = {22--32},
  Volume                   = {1},

  Abstract                 = {A new data fusion-based tracking algorithm is proposed, based on two wearable inertial sensors that are placed around the wrist and elbow joints, respectively. Assuming that the lengths of two segments of an upper limb are known, measurements of gyro turning rates can be used to locate the wrist and elbow joints via an established kinematic model. To determine the position of a translated and rotated shoulder joint, an equality-constrained optimisation technique is then proposed to seek an optimal solution, incorporating measurements from the tri-axial accelerometers. Experimental results demonstrate that the algorithm is capable of providing consistent motion tracking of human arms without drifts in 45 s, where each standard deviation is less than half of the corresponding mean value of the Euclidean distance between the estimated joint position and the origin of the world coordinate system.},
  ISSN                     = {1746-8094},
  Keywords                 = {Biomedical signal processing and control},
  Timestamp                = {2010.07.08}
}

@Article{Zhou2006b,
  Title                    = {Inertial measurements of upper limb motion},
  Author                   = {Zhou, H. and Hu, H. and Tao, Y.},
  Journal                  = {Medical and Biological Engineering and Computing},
  Year                     = {2006},
  Number                   = {6},
  Pages                    = {479--487},
  Volume                   = {44},

  Abstract                 = {We present an inertial sensor based monitoring system for measuring upper limb movements in real time. The purpose of this study is to develop a motion tracking device that can be integrated within a home-based rehabilitation system for stroke patients. Human upper limbs are represented by a kinematic chain in which there are four joint variables to be considered: three for the shoulder joint and one for the elbow joint. Kinematic models are built to estimate upper limb motion in 3-D, based on the inertial measurements of the wrist motion. An efficient simulated annealing optimisation method is proposed to reduce errors in estimates. Experimental results demonstrate the proposed system has less than 5% errors in most motion manners, compared to a standard motion tracker.},
  Doi                      = {10.1007/s11517-006-0063-z},
  ISSN                     = {0140-0118 (Print) 1741-0444 (Online)},
  Keywords                 = {Inertial measurement - Stroke rehabilitation - Motion tracking - Upper limb - Simulated annealing},
  Publisher                = {Springer Berlin / Heidelberg},
  Review                   = {Position sensing of limbs. Double integration. Fitted to two-link kinematic model of shoulder and elbow. Used "monte Carlo Sampling" optimisation to avoid drifting issues. MCS is a technique known as simulated annealing, which is: "a generic probabilistic metaheuristic for the global optimization problem of applied mathematics, namely locating a good approximation to the global optimum of a given function in a large search space. It is often used when the search space is discrete (e.g., all tours that visit a given set of cities)." - Wiki

Assume segment lengths are known. Uses R = Rinit + dR * dt, which they seem to get from double integration. They refered to another paper (Foxlin, 2004) for removal of gravity. How do they deal with integration error? They claim that the error is non-Gaussian, so can't use Kalman filtering. Instead, they use MCS, which sees to minimize the coordinate of elbow (x1, y1, z1) and the length of the upper arm (that is...x1^2 + y1^2 + z1^2 - L1^2 --> 0), and do the same for the lower arm, and optimize for it. 

Of course, when they tested it, there is a 3mm error max when stationary and 1.8cm error max when moving.},
  Subject_collection       = {Engineering},
  Timestamp                = {2010.07.08}
}

@Article{Zhou2008a,
  author    = {Zhou, H. AND Stone, T. AND Hu, H. AND Harris, N.},
  title     = {Use of multiple wearable inertial sensors in upper limb motion tracking},
  journal   = {Medical Engineering and Physics},
  year      = {2008},
  volume    = {30},
  pages     = {123--133},
  issn      = {1350-4533},
  abstract  = {This paper presents a new human motion tracking system using two wearable inertial sensors that are placed near the wrist and elbow joints of the upper limb. Each inertial sensor consists of a tri-axial accelerometer, a tri-axial gyroscope and a tri-axial magnetometer. The turning rates of the gyroscope were utilised for localising the wrist and elbow joints on the assumption that the two upper limb segment lengths are known a priori. To determine the translation and rotation of the shoulder joint, an equality-constrained optimisation technique is adopted to find an optimal solution, incorporating measurements from the tri-axial accelerometer and gyroscope. Experimental results demonstrate that this new system, compared to an optical motion tracker, has RMS position errors that are normally less than 0.01[thin space]m, and RMS angle errors that are 2.5-4.8°.},
  doi       = {DOI: 10.1016/j.medengphy.2006.11.010},
  groups    = {EMBC2013},
  keywords  = {Motion tracking, Postural Detection},
  review    = {Zhou2008a
Cited by: 32
Motion type: Arm motions
Recovery methodology: Gyro strapdown integration obtains angle, which is used to rotate the gravity vector. Once gravity is eliminated, double integration is applied with Lagrangian optimisation (using length constraint and the angle/rotation information as constraints) to obtain EF location of elbow and hand. It would appear that length is obtained via mocap 
Verification technique: CODA motion capture
Subject demographics: 4 healthy adults
Error reported: 2.5 deg RMS



Stroke is a large cause of disability, and stroke rehabilitation is important to assist stroke patients to regain the highest degree of motor function possible. In order to reduce wait-lines and to extend rehabilitation to the home environment, lightweight and easy-to-use methods must be developed. This way, rehabilitation will not be always tied to the physiotherapist and the hospital.

Inertial measurement units (IMUs), like accelerometers and gyroscopes, are inexpensive, sourceless and light. This group compares a accelerometer-gyroscope IMU system against a CODA system (motion capture system). They took data at 25 Hz.

They applied filters: 10 Hz LPF for accelerometer and 0.05 Hz HPF for the gyroscope. Then, they rotated the data into the world frame in order to subtract gravity from the acceleration data. They fit this into a basic 2-link kinematic. To reduce drift effects, they applied Lagrangian optimisation and kinematics to combine acceleration and gyroscope data.

Two sets experiments were conducted: moving in a circle and square patterns (seems to be horizontal movement), and series of small movements (reaching task, shoulder shrugging and forearm rotation).

They report good accuracy. Most errors were due to sharking arms while performing the motion. Also, when they moved the sensors to another location on the arm (they didn't mention if they corrected the kinematic equations), the errors were small. Looks pretty good for the test cases.

Noted shortcomings:

 * Why did they model the elbow as a 3DOF system? Usually, it is modeled as a 1DOF system.
 * What is 'strapdown integration'? It seems like a fairly critical component of the algorithm, but they don't go into details
 * How did they deal with angular (gyroscope) drift? The Lagrange method (which claims to reduce drift for the acceleration) is applied after the gyroscope data is used in the rotation matrix.
 * Angular error and position error do not correlate in a trig-accurate manner (too small)
 * They did not talk about general applications
 * 5% error for when the sensor slide seems awfully small, especially for an integrative system},
  timestamp = {2010.01.18},
}

@InProceedings{Zhu2009,
  Title                    = {Human daily activity recognition in robot-assisted living using multi-sensor fusion},
  Author                   = {Zhu, C. and Weihua Sheng},
  Booktitle                = {Proceedings of the IEEE International Conference on Robotics and Automation},
  Year                     = {2009},
  Month                    = {May},
  Pages                    = {2154-2159},

  Abstract                 = {In this paper, we propose a human daily activity recognition method by fusing the data from two wearable inertial sensors attached on one foot and the waist of the subject, respectively. We developed a multi-sensor fusion scheme for activity recognition. First, data from these two sensors are fused for coarse-grained classification in order to determine the type of the activity: zero displacement activity, transitional activity, and strong displacement activity. Second, a fine-grained classification module based on heuristic discrimination or hidden Markov models (HMMs) is applied to further distinguish the activities. We conducted experiments using a prototype wearable sensor system and the obtained results prove the effectiveness and accuracy of our algorithm.},
  Doi                      = {10.1109/ROBOT.2009.5152756},
  ISSN                     = {1050-4729},
  Keywords                 = {hidden Markov models;medical robotics;sensor fusion;coarse-grained classification;hidden Markov models;human daily activity recognition;multi-sensor fusion;robot-assisted living;strong displacement activity;transitional activity;wearable inertial sensors;zero displacement activity;Acceleration;Accelerometers;Hidden Markov models;Humans;Robot sensing systems;Robotics and automation;Senior citizens;Sensor fusion;Testing;Wearable sensors},
  Timestamp                = {2014.12.22}
}

@Article{Zhu2004,
  Title                    = {Realtime articulated human motion tracking using tri-axis inertial/magnetic sensors package},
  Author                   = {Zhu, R. AND Zhou, Z.},
  Journal                  = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  Year                     = {2004},
  Pages                    = {295--302},
  Volume                   = {12},
  Abstract                 = {Basic requirement in virtual environments is the tracking of objects, especially humans. A real time motion-tracking system was presented and evaluated in this paper. System sensor were built using tri-axis microelectromechanical accelerometer, rate gyros, and magnetometers. A Kalman-based funsion algorithm was applied to obtain dynamic orientations and further positions of segments of the subject's body. The system with the proposed algorithm was evaluated via dynamically measuring Euler orientation and comparing with other two conventional methods. An arm motion experiment was demonstrated using the developed system and algorithm. The results validated the effectiveness of the proposed method.},
  Keywords                 = {Fusion algorithm, human motion tracking, inertial sensors, Postural detection},
  Review                   = {Zhu2004
Cited by: 125
Motion type: Arm motions
Recovery methodology: Obtains joint angles. Want to remove inertial acceleration, and combine the gravity vector from accelerometer with magnetometer to get orientation. No way to avoid magnetic distortion. Advice is to stay away from them. The gyro is used to obtain the angular velocity, and substracts out the inertial accel. Uses KF. State variable are the gravity vector xyz and magnetic field xyz. Gyro used in the state update equations. Accelerometer and magnetometer readings used as the observation model. Solving for inter-frame rotation to get joint angle. 
Verification technique:
Subject demographics: 
Error reported: 1.5 degree error



Lots of technology exists. Mechanical, electromagnetic, acoustic, optical, IMU (using accel, gyro and magnetic sensors). IMU is good since there's no sources (not as environment dependent). Earlier, they used a 3-axis accelerometer as an inclinometer (which had gravity contamination with dynamic motions). They also tried integrating gyro data (which had drift errors). Since those were bad, they went for an integrated IMU system with Kalman filter + quaternion model. So their final system consists of...
- 3-axis accel
- 3-axis gryo
- 3-axis magnetometer > hmm. they used this to determine earth direction and attempted to subtract gravity with it... but local ferromagnetic stuff would influence this reading
- ADC, uC, axis/angle coordinates
They represent the human model as a stickman (15 segments). For Kalman, the input is gravity (in x, y, z) and componets of magnetic field, output is the sensors (so accel and magnetometer)

They compared the Kalman alg to an integration alg...it should be fairly evident which is better. The same action is a elbow flexion. They claim accuracy to 1cm for position.},
  Timestamp                = {2010.01.16}
}

@TechReport{Zhu2005_survey,
  Title                    = {Semi-Supervised Learning Literature Survey},
  Author                   = {Zhu, X.},
  Institution              = {University of Wisconsin-Madison},
  Year                     = {2005},
  Number                   = {1530},

  Timestamp                = {2015.05.13}
}

@InProceedings{Ziebart2012,
  Title                    = {Probabilistic Pointing Target Prediction via Inverse Optimal Control},
  Author                   = {Ziebart, Brian and Dey, Anind and Bagnell, J. Andrew},
  Booktitle                = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
  Year                     = {2012},

  Address                  = {New York, NY, USA},
  Pages                    = {1--10},
  Publisher                = {ACM},
  Series                   = {IUI '12},

  Abstract                 = {Numerous interaction techniques have been developed that make "virtual" pointing at targets in graphical user interfaces easier than analogous physical pointing tasks by invoking target-based interface modifications. These pointing facilitation techniques crucially depend on methods for estimating the relevance of potential targets. Unfortunately, many of the simple methods employed to date are inaccurate in common settings with many selectable targets in close proximity. In this paper, we bring recent advances in statistical machine learning to bear on this underlying target relevance estimation problem. By framing past target-driven pointing trajectories as approximate solutions to well-studied control problems, we learn the probabilistic dynamics of pointing trajectories that enable more accurate predictions of intended targets.},
  Acmid                    = {2166968},
  Doi                      = {10.1145/2166966.2166968},
  ISBN                     = {978-1-4503-1048-2},
  Keywords                 = {continuous control, cursor prediction, probabilistic inference},
  Location                 = {Lisbon, Portugal},
  Numpages                 = {10},
  Review                   = {Probablistic inverse LQR applied to pointing tasks. The state is Cartesian pos/velo/accel},
  Timestamp                = {2015.11.06},
  Url                      = {http://doi.acm.org.proxy.lib.uwaterloo.ca/10.1145/2166966.2166968}
}

@InProceedings{Zollner2004,
  Title                    = {Programming by demonstration: dual-arm manipulation tasks for humanoid robots},
  Author                   = {Zollner, R. and Asfour, T. and Dillmann, R.},
  Booktitle                = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2004},
  Pages                    = {479-484 vol.1},
  Volume                   = {1},

  Abstract                 = {This paper deals with easy programming methods of dual-arm manipulation tasks for humanoid robots. Hereby a programming by demonstration system is used in order to observe, learn and generalize tasks performed by humans. A classification for dual-arm manipulations is introduced, enabling a segmentation of tasks into adequate subtasks. Further it is shown how the generated programs are mapped on and executed by a humanoid robot.},
  Doi                      = {10.1109/IROS.2004.1389398},
  Keywords                 = {automatic programming;humanoid robots;manipulators;dual-arm manipulation tasks;humanoid robots;programming by demonstration system;programming methods;Data mining;Fault tolerance;Hospitals;Humanoid robots;Humans;Layout;Robot kinematics;Robot programming;Senior citizens;Service robots},
  Timestamp                = {2013.10.02}
}

@InProceedings{Marteau2016b,
  author    = {Marteau, Pierre-Fran{\c c}ois},
  title     = {{Assessing pattern recognition or labeling in streams of temporal data}},
  booktitle = {{2nd ECML/PKDD Workshop on Advanced Analytics and Learning on Temporal Data}},
  year      = {2016},
  address   = {Riva del Garda, Italy},
  month     = Sep,
  file      = {streamLabellingAssessment-hal.pdf:https\://hal.archives-ouvertes.fr/hal-01403948/file/streamLabellingAssessment-hal.pdf:PDF},
  keywords  = { sequential data ; automatic labelling assessment ; assessment measure ; dynamic programming ; temporal data },
  review    = {This algorithm determines if two time-series data streams are similar by using adopting a word edit approach via dynamic programming. Assuming the data has already been segmented and labelled, the distance between the two data streams are calculated by assigning a penalty value if primitives match (ie segment i from stream 1 and segment j from stream 2 overlap), have been inserted, or deleted. A distance matrix can be constructed between the first i^th segment of stream 1, and the first j^th segment of stream 2, via dynamic programming and the shortest path is taken.},
  timestamp = {2017-06-03},
  url       = {https://hal.archives-ouvertes.fr/hal-01403948},
}

@Article{Marteau2016a,
  author    = {Pierre{-}Fran{\c{c}}ois Marteau},
  title     = {Times series averaging and denoising from a probabilistic perspective on time-elastic kernels},
  journal   = {CoRR},
  year      = {2016},
  volume    = {abs/1611.09194},
  abstract  = {In the light of regularized dynamic time warping kernels, this paper re-considers the concept of time elastic centroid for a setof time series. We derive a new algorithm based on a probabilistic interpretation of kernel alignment matrices. This algorithm expressesthe averaging process in terms of a stochastic alignment automata. It uses an iterative agglomerative heuristic method for averagingthe aligned samples, while also averaging the times of occurrence of the aligned samples. By comparing classification accuracies for45 heterogeneous time series datasets obtained by first nearest centroid/medoid classifiers we show that: i) centroid-basedapproaches significantly outperform medoid-based approaches, ii) for the considered datasets, our algorithm that combines averagingin the sample space and along the time axes, emerges as the most significantly robust model for time-elastic averaging with apromising noise reduction capability. We also demonstrate its benefit in an isolated gesture recognition experiment and its ability tosignificantly reduce the size of training instance sets. Finally we highlight its denoising capability using demonstrative synthetic data:we show that it is possible to retrieve, from few noisy instances, a signal whose components are scattered in a wide spectral band.},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/Marteau16},
  review    = {This paper is interested in creating a base template given multiple examples of a trajectory by using a modified version of the DTW. They comment on a few DTW-based methods to create a trajectory template and noted that they are highly heuristical and too dependent on initial condition and tuning, and thus modifies DTW by borrowing concepts from left-right HMMs. Instead of creating a HMM where the state sequence traverses through the time series motion, the states describe the alignment between two trajectories instead. The state transition is similar to DTW (diagonal, right, or down). I haven't wrapped my mind around all the math yet, but it seems like their training and identification methods modifies HMM's Expectation-Maximization and Forward-Backward in order to fit their formulations. They compared their method against other DTW methods by training a central trajectory template using different DTW-based technique, aligning the observed trajectory to the template, then classify using either kNN or SVM. They also show that their method can be used to combine noisy training data together to create a denoised template.},
  timestamp = {Thu, 01 Dec 2016 19:32:08 +0100},
  url       = {http://arxiv.org/abs/1611.09194},
}

@Article{Mockford2008,
  author    = {Brian James Mockford and Neville W. Thompson and Patricia Humphreys and David E. Beverland},
  title     = {Does a Standard Outpatient Physiotherapy Regime Improve the Range of Knee Motion After Primary Total Knee Arthroplasty?},
  journal   = {The Journal of Arthroplasty},
  year      = {2008},
  volume    = {23},
  number    = {8},
  pages     = {1110 - 1114},
  issn      = {0883-5403},
  doi       = {http://dx.doi.org/10.1016/j.arth.2007.08.023},
  keywords  = {total knee arthroplasty, physiotherapy},
  timestamp = {2017-09-11},
  url       = {http://www.sciencedirect.com/science/article/pii/S0883540307005918},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:Courses\;0\;;
2 ExplicitGroup:CS 489\;0\;;
2 ExplicitGroup:KIN 612\;0\;;
2 KeywordGroup:ECE780\;0\;keywords\;ECE780\;0\;0\;;
2 KeywordGroup:Lab reading\;0\;keywords\;Lab reading\;0\;0\;;
1 ExplicitGroup:Research\;0\;;
2 KeywordGroup:Wireless Sensor Networks\;0\;keywords\;wireless sensor networks\;0\;0\;;
2 KeywordGroup:Filtering and Drift\;0\;keywords\;filtering\;0\;0\;;
2 KeywordGroup:Postural Detection\;0\;keywords\;Postural Detection\;0\;0\;;
2 ExplicitGroup:Robotics\;0\;;
3 KeywordGroup:Motion Segmentation\;0\;keywords\;.*segmentation\;0\;1\;;
3 KeywordGroup:Motion Primitive\;0\;keywords\;.*.primitive\;0\;1\;;
3 KeywordGroup:Kinematics\;0\;keywords\;kinematics\;0\;0\;;
3 KeywordGroup:Human-robot interaction\;0\;keywords\;Human-robot interaction\;0\;0\;;
2 ExplicitGroup:Kinesiology\;0\;;
3 KeywordGroup:Rehabilitation\;0\;keywords\;Rehabilitation\;0\;0\;;
3 KeywordGroup:Biomechanics\;0\;keywords\;Biomechanics\;0\;0\;;
3 KeywordGroup:Physiotherapy\;0\;keywords\;Physiotherapy\;0\;0\;;
2 ExplicitGroup:Pose\;0\;;
2 ExplicitGroup:EMBS2009\;0\;;
2 ExplicitGroup:EMBC2013\;0\;;
1 ExplicitGroup:Lit Review 2013-09\;0\;;
1 ExplicitGroup:References\;0\;;
2 ExplicitGroup:STAT841\;0\;;
2 ExplicitGroup:IROS2014\;0\;;
2 ExplicitGroup:EMBC2014\;0\;;
1 ExplicitGroup:My Work\;0\;;
}
